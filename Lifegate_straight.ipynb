{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPSw/5e+oNcEsHqYaWNvGE2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajagota7/Reward-Shaping/blob/main/Lifegate_straight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zZ2S2CI8K_jT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jsHzrhmfpiTr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "# np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "from scipy.optimize import minimize\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import torch\n",
        "import sys\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deadend dependencies"
      ],
      "metadata": {
        "id": "UMj8NNrGfwu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/med-deadend.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KStXBTWK3f64",
        "outputId": "124c3862-1d84-46f0-e766-a2d2c9bfd757"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'med-deadend'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 130 (delta 52), reused 77 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (130/130), 395.48 KiB | 10.14 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# shaping dependencies"
      ],
      "metadata": {
        "id": "AsZMw4C0f2K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ajagota7/Shaping.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu7X59dK3hqk",
        "outputId": "a7089a83-1201-4659-c2fe-46b1cbf0b476"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Shaping'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 101 (delta 49), reused 74 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (101/101), 11.74 MiB | 23.21 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping"
      ],
      "metadata": {
        "id": "5SkpvWFqz631"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull origin main"
      ],
      "metadata": {
        "id": "8QRHhC-G0AiH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/"
      ],
      "metadata": {
        "id": "hZ8dnFnidxL_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/Shaping/lifegate_1.zip', 'r') as zip_ref:\n",
        "    # zip_ref.extractall('/content/med-deadend/lifegate/results/lifegate_1')\n",
        "    zip_ref.extractall('/content/Shaping/')"
      ],
      "metadata": {
        "id": "2noY6FOTdsmY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/med-deadend/lifegate')\n",
        "sys.path.append('/content/Shaping/')\n",
        "\n"
      ],
      "metadata": {
        "id": "id2reVHQ3heg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import q_networks"
      ],
      "metadata": {
        "id": "DgppFp3cDm4L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/med-deadend/lifegate\n",
        "\n",
        "\n",
        "# results_dir = 'results/lifegate_1/'\n",
        "results_dir = '/content/Shaping/'\n",
        "# Load the Q tables from the primary learning agent, Q_D and Q_R value functions\n",
        "with open(results_dir+'tabular_qnet.pkl', 'rb') as fq:\n",
        "    ai = pickle.load(fq)\n",
        "\n",
        "with open(results_dir+'tabular_qd.pkl', 'rb') as fd:\n",
        "    ai_d = pickle.load(fd)\n",
        "\n",
        "with open(results_dir+'tabular_qr.pkl', 'rb') as fr:\n",
        "    ai_r = pickle.load(fr)"
      ],
      "metadata": {
        "id": "7lv4ZIBkeLW3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.zeros((10, 10, 5))\n",
        "q_d = np.zeros_like(q_table)\n",
        "q_r = np.zeros_like(q_table)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        for a in range(5):\n",
        "            key = tuple([j, i, a])\n",
        "            try:\n",
        "                q_table[i,j,a] = ai.q[key]\n",
        "                q_d[i,j,a] = ai_d.q[key]\n",
        "                q_r[i,j,a] = ai_r.q[key]\n",
        "            except:\n",
        "                pass"
      ],
      "metadata": {
        "id": "Rk0Z42sNebl4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import random\n",
        "from lifegate import LifeGate\n",
        "params = yaml.safe_load(open(results_dir+'config.yaml', 'r'))\n",
        "np.random.seed(seed=params['random_seed'])\n",
        "random.seed(params['random_seed'])\n",
        "random_state = np.random.RandomState(params['random_seed'])"
      ],
      "metadata": {
        "id": "4uTTjsWNfK21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5882dd-ad4e-48bb-de4c-d415e195ccbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = LifeGate(max_steps=params['episode_max_len'], state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.0)"
      ],
      "metadata": {
        "id": "XUoJuLN0fabn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_30 = LifeGate(max_steps=30, state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.1)"
      ],
      "metadata": {
        "id": "7wG_zU6SM3xY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZp-8-f7far2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Shaping\n",
        "from Shaping import *\n",
        "# %cd /content/Shaping\n",
        "\n",
        "from choose_actions import action_probs_top_n_epsilon\n",
        "from shaping_features import *\n",
        "from gen_policies import *\n",
        "from IS import *\n",
        "from subset_policies import *\n",
        "from v_pi_e import *\n",
        "from optimization import *\n",
        "from neural_net import *\n",
        "from prep_variance import *\n",
        "from SCOPE_variance import SCOPE_variance"
      ],
      "metadata": {
        "id": "hS65UmL5Yu_K"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCOPE straight"
      ],
      "metadata": {
        "id": "aIFnUpUIlyr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SCOPE_straight(object):\n",
        "\n",
        "  def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, percent_to_estimate_phi, dtype):\n",
        "        self.model = model\n",
        "        self.gamma = gamma\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.pi_b = pi_b\n",
        "        self.P_pi_b = P_pi_b\n",
        "        self.P_pi_e = P_pi_e\n",
        "        self.dtype = dtype\n",
        "\n",
        "        self.percent_to_estimate_phi = percent_to_estimate_phi\n",
        "        # self.num_epochs = num_epochs\n",
        "\n",
        "  def subset_policies(self):\n",
        "    # seed_value = 0\n",
        "    # np.random.seed(seed_value)\n",
        "    num_policies = len(self.pi_b)\n",
        "    num_policies_to_estimate_phi = int(num_policies * self.percent_to_estimate_phi)\n",
        "\n",
        "    policies_for_scope = self.pi_b[num_policies_to_estimate_phi:]\n",
        "    policies_for_phi = self.pi_b[:num_policies_to_estimate_phi]\n",
        "\n",
        "    return policies_for_phi, policies_for_scope\n",
        "\n",
        "  def prep_policies(self, chosen_policies):\n",
        "      # Initialize lists to store axis data for each policy\n",
        "      timesteps = []\n",
        "      # states = []\n",
        "      # state_first = []\n",
        "      # state_last = []\n",
        "      actions = []\n",
        "      rewards = []\n",
        "      # gamma_last = []\n",
        "      # weight_last = []\n",
        "      # weight_first = []\n",
        "      # all_weights_temp, weights = calculate_importance_weights(P_pi_e, P_pi_b, pi_b)\n",
        "      weights = calculate_importance_weights(self.P_pi_e, self.P_pi_b, chosen_policies)\n",
        "      psi = []\n",
        "\n",
        "      states_current = []\n",
        "      states_next = []\n",
        "\n",
        "      for index, policy in enumerate(chosen_policies):\n",
        "          policy_array = np.array(policy)\n",
        "\n",
        "          timesteps.append(policy_array['timestep'].astype(int))\n",
        "          actions.append(policy_array['action'])\n",
        "          rewards.append(policy_array['reward'].astype(float))\n",
        "\n",
        "          states_next.append(policy_array['state_next'])\n",
        "          states_current.append(policy_array['state'])\n",
        "\n",
        "      return timesteps, rewards, states_next, states_current, weights, actions\n",
        "\n",
        "  def padding_IS_terms(self, timesteps, actions, rewards, weights):\n",
        "\n",
        "    # Find the maximum length among all lists\n",
        "    max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "    # Define the padding values\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each list to match the maximum length\n",
        "    padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "    padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "    padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "    padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "    return padded_timesteps, padded_rewards, padded_actions, padded_weights\n",
        "\n",
        "\n",
        "  def tensorize_IS_terms(self, padded_timesteps, padded_rewards, padded_weights):\n",
        "\n",
        "    padded_timestep_tensors = torch.tensor(padded_timesteps, dtype = self.dtype)\n",
        "    padded_reward_tensors = torch.tensor(padded_rewards, dtype = self.dtype)\n",
        "    padded_weight_tensors = torch.tensor(padded_weights, dtype = self.dtype)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors\n",
        "\n",
        "  def padding_states(self, states_next, states_current):\n",
        "    # Find the maximum length of trajectories\n",
        "    max_length = max(len(trajectory) for trajectory in states_current)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states_next = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states_next\n",
        "    ]\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states_current = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states_current\n",
        "    ]\n",
        "\n",
        "    return padded_states_next, padded_states_current\n",
        "\n",
        "\n",
        "  def tensorize_padded_terms(self, padded_states_next, padded_states_current):\n",
        "    padded_states_next_tensors = torch.tensor(padded_states_next, dtype = self.dtype)\n",
        "    padded_states_current_tensors = torch.tensor(padded_states_current, dtype = self.dtype)\n",
        "\n",
        "    return padded_states_next_tensors, padded_states_current_tensors\n",
        "\n",
        "\n",
        "  def prepare_IS(self):\n",
        "    timesteps, rewards, states_next, states_current, weights, actions = self.prep_policies(self.pi_b)\n",
        "    padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors = self.tensorize_IS_terms(padded_timesteps, padded_rewards, padded_weights)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors\n",
        "\n",
        "  def prepare_SCOPE(self, policies):\n",
        "    timesteps, rewards, states_next, states_current, weights, actions = self.prep_policies(policies)\n",
        "    padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors = self.tensorize_IS_terms(padded_timesteps, padded_rewards, padded_weights)\n",
        "    padded_states_next, padded_states_current = self.padding_states(states_next, states_current)\n",
        "    padded_states_next_tensors, padded_states_current_tensors = self.tensorize_padded_terms(padded_states_next, padded_states_current)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors\n",
        "\n",
        "  def prepare_SCOPE_phi(self):\n",
        "    phi_set,_ = self.subset_policies()\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = self.prepare_SCOPE(phi_set)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors\n",
        "\n",
        "  def prepare_SCOPE_test(self):\n",
        "    _, scope_set = self.subset_policies()\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = self.prepare_SCOPE(scope_set)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors\n",
        "\n",
        "  def pass_states(self, model, padded_states_next_tensors, padded_states_current_tensors):\n",
        "    states_next_output = self.model(padded_states_next_tensors)\n",
        "    states_current_output = self.model(padded_states_current_tensors)\n",
        "\n",
        "    return states_next_output.squeeze(), states_current_output.squeeze()\n",
        "\n",
        "  def bootstrap_straight(self, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output):\n",
        "    seed = 42\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    num_samples = self.num_bootstraps\n",
        "    num_bootstraps_lin = num_samples*padded_timestep_tensors.shape[0]\n",
        "\n",
        "    # Sample indices with replacement\n",
        "    sampled_indices = torch.randint(0, len(padded_timestep_tensors), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "    reshaped_size = (num_samples, padded_timestep_tensors.shape[0], padded_timestep_tensors.shape[1])\n",
        "\n",
        "    timestep_bootstraps = padded_timestep_tensors[sampled_indices].view(reshaped_size)\n",
        "    rewards_bootstraps = padded_reward_tensors[sampled_indices].view(reshaped_size)\n",
        "    weights_bootstraps = padded_weight_tensors[sampled_indices].view(reshaped_size)\n",
        "\n",
        "    phi_states_next_bootstraps = states_next_output[sampled_indices].view(reshaped_size)\n",
        "    phi_states_current_bootstraps = states_current_output[sampled_indices].view(reshaped_size)\n",
        "\n",
        "    return timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps\n",
        "\n",
        "  def bootstrap_IS(self, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors):\n",
        "    seed = 42\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    num_samples = self.num_bootstraps\n",
        "    num_bootstraps_lin = num_samples*padded_timestep_tensors.shape[0]\n",
        "\n",
        "    # Sample indices with replacement\n",
        "    sampled_indices = torch.randint(0, len(padded_timestep_tensors), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "    reshaped_size = (num_samples, padded_timestep_tensors.shape[0], padded_timestep_tensors.shape[1])\n",
        "\n",
        "    timestep_bootstraps = padded_timestep_tensors[sampled_indices].view(reshaped_size)\n",
        "    rewards_bootstraps = padded_reward_tensors[sampled_indices].view(reshaped_size)\n",
        "    weights_bootstraps = padded_weight_tensors[sampled_indices].view(reshaped_size)\n",
        "    return timestep_bootstraps, rewards_bootstraps, weights_bootstraps\n",
        "\n",
        "\n",
        "  def pass_then_boostraps(self, padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors):\n",
        "    states_next_output, states_current_output = self.pass_states(self.model, padded_states_next_tensors, padded_states_current_tensors)\n",
        "    timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output)\n",
        "\n",
        "    return timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps\n",
        "\n",
        "  def calc_variance_IS(self, timestep_bootstraps, weights_bootstraps, rewards_bootstraps):\n",
        "    IS_bootstraps = self.gamma**(timestep_bootstraps)* weights_bootstraps *(rewards_bootstraps)\n",
        "\n",
        "    # Step 1: Sum along the third dimension\n",
        "    sum_IS_trajectories = torch.sum(IS_bootstraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "    # Step 2: Take the mean along the second dimension\n",
        "    mean_IS_sum = torch.mean(sum_IS_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "    # Step 3: Calculate the variance across the first dimension\n",
        "    IS_variance = torch.var(mean_IS_sum)  # A single scalar value\n",
        "\n",
        "    IS_mean = torch.mean(mean_IS_sum) # A single scalar value\n",
        "\n",
        "    return IS_mean, IS_variance\n",
        "\n",
        "  def IS_pipeline(self):\n",
        "    padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS = self.prepare_IS()\n",
        "    timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS = self.bootstrap_IS(padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS)\n",
        "    IS_mean, IS_variance = self.calc_variance_IS(timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS)\n",
        "\n",
        "    return IS_mean, IS_variance\n",
        "\n",
        "\n",
        "  def calc_variance_straight(self, timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps):\n",
        "\n",
        "    # IS_boostraps = self.gamma**(timestep_bootstraps)* weights_bootstraps *(rewards_bootstraps)\n",
        "    scope_bootstraps = self.gamma**(timestep_bootstraps)* weights_bootstraps *(rewards_bootstraps  +self.gamma*phi_states_next_bootstraps - phi_states_current_bootstraps)\n",
        "\n",
        "    # # Step 1: Sum along the third dimension\n",
        "    # sum_IS_trajectories = torch.sum(IS_boostraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "    # # Step 2: Take the mean along the second dimension\n",
        "    # mean_IS_sum = torch.mean(sum_IS_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "    # # Step 3: Calculate the variance across the first dimension\n",
        "    # IS_variance = torch.var(mean_IS_sum)  # A single scalar value\n",
        "\n",
        "\n",
        "    # Step 1: Sum along the third dimension\n",
        "    sum_scope_trajectories = torch.sum(scope_bootstraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "    # Step 2: Take the mean along the second dimension\n",
        "    mean_scope_sum = torch.mean(sum_scope_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "    # Step 3: Calculate the variance across the first dimension\n",
        "    scope_variance = torch.var(mean_scope_sum)  # A single scalar value\n",
        "\n",
        "    scope_mean = torch.mean(mean_scope_sum) # A single scalar value\n",
        "\n",
        "    return scope_mean, scope_variance\n",
        "\n",
        "  def train_var_scope(self, num_epochs, learning_rate):\n",
        "\n",
        "\n",
        "      padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS = self.prepare_IS()\n",
        "      timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS = self.bootstrap_IS(padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS)\n",
        "      IS_mean, IS_variance = self.calc_variance_IS(timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS)\n",
        "\n",
        "      padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = self.prepare_SCOPE_phi()\n",
        "\n",
        "\n",
        "      self.model.train()\n",
        "\n",
        "      # Enable anomaly detection\n",
        "      torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "      optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "          total_loss = 0\n",
        "\n",
        "          timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.pass_then_boostraps(padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "          SCOPE_mean, SCOPE_variance = self.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)\n",
        "          print(f\"Epoch {epoch+1}\")\n",
        "          print(\"IS variance: \", IS_variance)\n",
        "          print(\"SCOPE Var loss: \", SCOPE_variance)\n",
        "          # print(\"MSE loss: \", mse_loss.item())\n",
        "\n",
        "\n",
        "          tot = SCOPE_variance\n",
        "          # tot = variance_loss + mse_loss\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Retain the graph to avoid clearing it before backward pass\n",
        "          tot.backward(retain_graph=True)\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          total_loss += tot.item()\n",
        "\n",
        "          print(f\"Total Loss: {total_loss}\")\n",
        "          print(\"-\" * 40)\n",
        "\n",
        "      # Disable anomaly detection after running the code\n",
        "      torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "      for name, param in self.model.named_parameters():\n",
        "          if param.requires_grad:\n",
        "              print(f\"Parameter name: {name}\")\n",
        "              print(f\"Weights: {param.data}\")\n",
        "\n",
        "      return self.model\n",
        "\n",
        "  def evaluate_scope(self):\n",
        "    self.model.eval()\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = self.prepare_SCOPE_test()\n",
        "    timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.pass_then_boostraps(padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "    SCOPE_mean, SCOPE_variance = self.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)\n",
        "\n",
        "    return SCOPE_mean, SCOPE_variance\n",
        "\n",
        "\n",
        "  # -----------------------\n",
        "  # Heatmaps for lifegate\n",
        "  # -----------------------\n",
        "  def get_model_output_dict(self):\n",
        "\n",
        "    self.model.eval()\n",
        "\n",
        "    # Initialize an empty dictionary to store data\n",
        "    data = {}\n",
        "\n",
        "    # Loop through all combinations from [0,0] to [9,9]\n",
        "    for i in range(10):\n",
        "      for j in range(10):\n",
        "          # Prepare input data\n",
        "          input_data = torch.tensor([i, j], dtype=torch.float64)\n",
        "\n",
        "          # Pass input through the self.model\n",
        "          output = self.model(input_data)\n",
        "\n",
        "          # Store data in the dictionary\n",
        "          data[(i, j)] = output.item()\n",
        "\n",
        "    return data\n",
        "\n",
        "  def plot_heatmap(self, data):\n",
        "    values = np.zeros((10, 10))\n",
        "    for (x, y), value in data.items():\n",
        "        values[y, x] = value\n",
        "\n",
        "    # Create the heatmap\n",
        "    fig = go.Figure(data=go.Heatmap(z=values, colorscale='viridis'))\n",
        "\n",
        "    # Add colorbar\n",
        "    fig.update_layout(coloraxis_colorbar=dict(title='Values',\n",
        "                                              ticks='outside',\n",
        "                                              tickvals=[np.min(values), np.max(values)],\n",
        "                                              ticktext=[np.min(values), np.max(values)]))\n",
        "\n",
        "    # Add labels and title\n",
        "    fig.update_layout(xaxis=dict(tickvals=np.arange(10), ticktext=list(range(10)), title='X'),\n",
        "                      yaxis=dict(tickvals=np.arange(9, -1, -1), ticktext=list(range(9, -1, -1)), title='Y', autorange=\"reversed\"),\n",
        "                      title='Heatmap')\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "  def get_heatmap(self):\n",
        "    data = self.get_model_output_dict()\n",
        "    self.plot_heatmap(data)\n"
      ],
      "metadata": {
        "id": "P8buR941l0JC"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BEq_Xz8xeeOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test class"
      ],
      "metadata": {
        "id": "P6c1J5GDaf86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env_30, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e = experiment_actions(200, env, P_pi_e)\n",
        "model_200_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64)\n",
        "test_200_0p99 = SCOPE_straight(model_200_0p99, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "0ueKh2Cfahjf"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_0p99.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqq1JfG4oFEw",
        "outputId": "0c621b2f-81ce-4b16-9986-7b54bad7a6dc"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0176, dtype=torch.float64), tensor(0.0001, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_e = experiment_actions(1000, env_30, P_pi_e)\n"
      ],
      "metadata": {
        "id": "mqgINIVonyQX"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Qjc3OHnlwK",
        "outputId": "badd2dac-0024-4f34-b32f-fe0e543edac3"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02696880170276661"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_0p99.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvFwsJRZoT4N",
        "outputId": "ee108ea8-e89c-4908-ab13-44b04bf0d0f5"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0358, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_0p99.train_var_scope(50, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlkljTT0j4JH",
        "outputId": "92e1b557-56f8-40c0-f91f-6873409495a3"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028689004977398017\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1809e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.180862088559544e-06\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3946e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.394565779552828e-06\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1937e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.193661968978786e-06\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1998e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.199817916659181e-06\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1484e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.148377929665042e-06\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8701e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.87005984089298e-06\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5251e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.525110109740566e-06\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3200e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.3199517441476595e-06\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2823e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.2822611907907465e-06\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3134e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.313391754015855e-06\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3318e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.331794944663465e-06\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3065e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.3064542380290165e-06\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2089e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.208867361983076e-06\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0417e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.0416554589404275e-06\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8708e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.870846690948106e-06\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7394e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.739439807200906e-06\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6476e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.647604308527263e-06\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5558e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.555820420720405e-06\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4388e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.438836444992444e-06\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3170e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.3169938235450555e-06\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2150e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.214994285956095e-06\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1284e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.128370336163812e-06\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0305e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.030494083706953e-06\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9136e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.913577229424126e-06\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7979e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.797907032372404e-06\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6926e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.692613973837551e-06\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5894e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.5894451100452025e-06\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4896e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.489550261698454e-06\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4062e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.406175260367115e-06\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3392e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.339190187418678e-06\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2718e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.271837263861564e-06\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1952e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.195238093199352e-06\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1192e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.1192189142514975e-06\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0539e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.05389264992596e-06\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9942e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9941635040467996e-06\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9286e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.928598832156393e-06\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8581e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.858092297987689e-06\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7919e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.79186424039178e-06\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7347e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.734695460295099e-06\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6831e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.683096037073163e-06\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6336e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.633607329149376e-06\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5843e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.5842643294765195e-06\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5279e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.5278945037131166e-06\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4698e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.469821229172056e-06\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4139e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.413871730204246e-06\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3611e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.361086209713763e-06\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3073e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.307261793303732e-06\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2520e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.2520459690554225e-06\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(0.0001, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1998e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.19982841460179e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.5992, -0.0770],\n",
            "        [ 0.4766, -0.2601],\n",
            "        [ 0.3080,  0.0954],\n",
            "        [ 0.1183, -0.2603],\n",
            "        [ 0.6073,  0.1530],\n",
            "        [-0.2607, -0.6321],\n",
            "        [-0.7033, -0.3404],\n",
            "        [-0.5834, -0.1342],\n",
            "        [ 0.1798, -0.5612],\n",
            "        [-0.4154,  0.3823],\n",
            "        [-0.4621, -0.6912],\n",
            "        [ 0.6251, -0.4189],\n",
            "        [ 0.2339, -0.6705],\n",
            "        [ 0.5158,  0.2490],\n",
            "        [ 0.6128, -0.0349],\n",
            "        [-0.1569, -0.2980]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.7229,  0.5292,  0.6443,  0.2463,  0.3690,  0.1721,  0.3640,  0.2282,\n",
            "         0.5627,  0.0159,  0.2460, -0.7294,  0.6949, -0.5945, -0.2650,  0.5816],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 1.2386e-01, -1.6138e-01, -1.0303e-01,  2.1614e-01,  2.2587e-01,\n",
            "          6.3637e-02,  3.5722e-02, -1.2352e-01, -1.1883e-01, -1.8244e-01,\n",
            "          1.7001e-01,  2.7159e-01,  4.8004e-02,  4.8128e-02, -1.8120e-01,\n",
            "         -3.3542e-02],\n",
            "        [ 4.3382e-02, -1.5989e-01,  1.8082e-01,  3.3650e-02, -2.0951e-01,\n",
            "         -2.2469e-01,  3.2124e-02, -1.1786e-01, -2.0484e-01,  1.8992e-03,\n",
            "         -1.8120e-01, -1.8439e-01,  2.3055e-01,  2.2436e-01,  3.7177e-02,\n",
            "          1.2501e-01],\n",
            "        [-1.2028e-01, -2.0009e-01, -9.5267e-02,  2.0951e-02,  2.4871e-01,\n",
            "         -8.9647e-02,  1.0802e-01,  8.8250e-02, -2.0060e-01, -6.9397e-02,\n",
            "         -2.4271e-02, -1.6058e-01, -2.4759e-01, -9.6262e-02,  1.3224e-01,\n",
            "          6.4986e-02],\n",
            "        [ 1.2966e-01,  1.0934e-01,  7.6855e-02,  1.3751e-01,  4.6037e-02,\n",
            "          1.6742e-02,  6.0140e-02,  1.6866e-01, -1.4993e-01, -1.5371e-01,\n",
            "         -2.2014e-01, -1.9920e-01, -1.2828e-02, -2.0265e-01,  7.4856e-02,\n",
            "          2.2450e-02],\n",
            "        [-4.8071e-03,  2.0730e-01,  2.2515e-01, -1.2108e-01, -1.4238e-01,\n",
            "         -2.4803e-01,  1.3377e-02, -4.9486e-02,  9.1577e-03, -2.0054e-01,\n",
            "          2.0011e-01,  2.6779e-01,  2.7549e-01, -2.4159e-01, -2.2004e-02,\n",
            "         -2.8929e-02],\n",
            "        [-2.1328e-02, -8.7217e-02, -1.5841e-01,  8.9052e-03, -7.8839e-02,\n",
            "          1.5483e-01,  1.3361e-01,  1.3709e-01, -2.2399e-01,  9.1005e-02,\n",
            "          1.0681e-01,  7.2816e-02,  1.7716e-01, -1.8763e-02, -2.5665e-01,\n",
            "          9.4986e-02],\n",
            "        [-2.9262e-01,  2.2768e-03, -4.0198e-02, -7.0517e-02, -3.0941e-01,\n",
            "          6.1380e-02, -2.0414e-01, -8.1497e-02,  1.5635e-01,  1.0739e-02,\n",
            "          2.4309e-01,  7.8574e-02,  1.8323e-01,  4.9287e-04,  1.3410e-01,\n",
            "         -2.4482e-01],\n",
            "        [ 3.0532e-02,  1.3525e-01, -7.5952e-02,  2.6134e-01,  6.0204e-02,\n",
            "         -1.6126e-01,  1.8163e-01, -1.7269e-01,  2.3130e-01, -9.1636e-02,\n",
            "         -5.8181e-02, -4.2377e-02, -2.7070e-02,  7.6789e-03, -4.0482e-02,\n",
            "          1.3159e-01],\n",
            "        [-1.4447e-01, -5.3329e-02, -1.4704e-01, -7.9732e-03,  1.7037e-01,\n",
            "         -1.2013e-01,  1.3873e-01,  1.5010e-01,  2.2626e-01, -2.2080e-01,\n",
            "         -1.8497e-01, -1.7610e-01, -7.0990e-02, -1.8570e-01,  1.6955e-01,\n",
            "          1.8138e-01],\n",
            "        [ 1.0954e-01, -2.6514e-01, -7.0737e-02,  2.6183e-01,  1.2297e-01,\n",
            "          1.6996e-01,  1.5586e-01, -1.0916e-01,  1.6720e-01, -6.2372e-02,\n",
            "         -2.4478e-01, -8.2872e-02, -2.8939e-01,  4.8685e-02, -2.0434e-01,\n",
            "         -3.2069e-02],\n",
            "        [-3.0995e-01, -1.3790e-01,  4.2978e-02,  1.0022e-01,  2.4911e-01,\n",
            "         -2.0614e-01,  2.1780e-01, -1.8906e-01,  2.3220e-01, -1.8139e-01,\n",
            "          2.2091e-01,  7.0211e-02, -1.0620e-01,  2.0770e-01,  1.1259e-01,\n",
            "         -9.5604e-02],\n",
            "        [ 2.7255e-01, -1.2800e-01,  1.8359e-01, -6.3042e-02,  3.6512e-02,\n",
            "          1.5864e-01,  1.8815e-01,  7.4287e-03,  9.4387e-02, -1.1462e-01,\n",
            "         -1.3912e-04,  2.1721e-01,  1.2074e-02,  3.4494e-02,  1.6494e-01,\n",
            "         -2.1003e-01],\n",
            "        [ 2.7485e-01, -8.4315e-02, -3.0226e-03, -2.7195e-01,  1.8325e-01,\n",
            "         -2.0078e-01, -9.1050e-02,  3.8632e-02, -2.3278e-01, -2.1332e-01,\n",
            "         -1.4911e-02, -8.5598e-02, -1.7196e-01,  6.5072e-02,  1.0335e-01,\n",
            "          3.2384e-02],\n",
            "        [ 2.7229e-01, -6.8381e-02, -2.8002e-01,  6.4651e-02,  8.1021e-03,\n",
            "         -9.3782e-02,  1.5367e-01, -8.0826e-02,  1.5440e-01,  1.1101e-01,\n",
            "         -1.3212e-01,  1.3099e-02, -8.9914e-02, -6.9052e-02,  7.6471e-02,\n",
            "          5.3369e-02],\n",
            "        [-1.8075e-01,  1.9160e-01,  1.8652e-01, -5.1262e-02, -1.1931e-01,\n",
            "          4.9254e-02, -2.2479e-02,  1.1894e-01, -2.6462e-02,  1.1777e-01,\n",
            "          7.3961e-02, -3.6355e-02, -5.4749e-02, -2.3740e-01, -6.1457e-02,\n",
            "          1.6345e-01],\n",
            "        [-2.3351e-01,  1.3187e-01,  1.2546e-01,  9.7839e-02,  1.6333e-02,\n",
            "          7.1479e-02, -1.6773e-01,  2.0375e-01, -2.2814e-02, -2.1999e-02,\n",
            "         -1.7433e-01,  2.4220e-01,  1.7573e-01,  1.0503e-01, -3.3029e-02,\n",
            "         -1.0926e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1508, -0.0149, -0.1468,  0.0422,  0.2333,  0.1423,  0.0762,  0.0268,\n",
            "        -0.0439,  0.1079, -0.1880, -0.0080, -0.1076, -0.0923,  0.0402,  0.1848],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.0328, -0.0072,  0.0348,  0.1068, -0.1386,  0.0361,  0.1174, -0.1021,\n",
            "         -0.1474,  0.0513, -0.0126, -0.0025,  0.0308, -0.0978,  0.0059, -0.0159]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1632], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test random policy"
      ],
      "metadata": {
        "id": "1enrp4izvB3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env_30, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 5, 0.05)\n",
        "# pi_e = experiment_actions(200, env_30, P_pi_e)\n",
        "model_200_random = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64)\n",
        "test_200_random = SCOPE_straight(model_200_random, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "o1Yatyj_vBQw"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random.train_var_scope(200, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haUOaqCUwE1Z",
        "outputId": "61573e7c-84a8-4e29-a3d1-43b4ddf79a36"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005218583187486271\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8199e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.819862798753365e-06\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0250e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.024958128773479e-05\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3286e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.328558541237725e-06\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3393e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.339343710615368e-06\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6211e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.6211430442459475e-06\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2653e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.265335151122525e-06\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0510e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.051047600597096e-06\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8702e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.870209703818152e-06\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7126e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.712563882034527e-06\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5836e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.583572711832976e-06\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4577e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.4576827574062896e-06\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3125e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.3124976815032185e-06\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0066e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.006596834226985e-06\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6917e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.69172072462017e-06\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4814e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.481446272610602e-06\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4082e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.408237363289505e-06\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3609e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.360898500363375e-06\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2893e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.289300722576919e-06\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1854e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.185418847790483e-06\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0697e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.069714783891458e-06\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9426e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.942574680761142e-06\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7829e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.7829417752681105e-06\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5794e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.57935947901364e-06\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3608e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.360810140060177e-06\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1808e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.1807924057078715e-06\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0601e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.060120898765123e-06\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9717e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.9717408236799345e-06\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8730e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.872999221427799e-06\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7516e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.7516474596638177e-06\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6306e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.6305590452069293e-06\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5235e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.523523543249152e-06\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4194e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.4194498364047354e-06\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3129e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.3128939880993014e-06\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2141e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.214062016990148e-06\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1367e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1367109298641893e-06\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0838e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.083815783841163e-06\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0376e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0375979569506807e-06\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9805e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9805008954865997e-06\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9141e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.914083240956638e-06\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8499e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8498630487635488e-06\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7934e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.79340060248865e-06\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7418e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7417869716767264e-06\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6932e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.693229088537973e-06\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6521e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.652083330895247e-06\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6183e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6182684387381757e-06\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5885e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.588513485400126e-06\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5554e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5554372379718102e-06\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5175e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5175046438766148e-06\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4801e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.480053377309589e-06\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4473e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.447324435934277e-06\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4183e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.418310600076487e-06\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3903e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.390265070521835e-06\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3637e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3637086263004655e-06\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3383e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3383400083150835e-06\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3125e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.31250659928688e-06\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2847e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2846957422101712e-06\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2560e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2559596512447755e-06\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2286e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.228577050500867e-06\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2033e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2033493843786976e-06\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1797e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1797144203416527e-06\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1562e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.156154608006684e-06\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1327e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.132736368288874e-06\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1098e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1098159459796553e-06\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0874e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.087387176553559e-06\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0654e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0653765430733716e-06\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0440e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0440016768329383e-06\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0238e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.023774640913568e-06\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0046e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.004644345872273e-06\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9855e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9855444021115104e-06\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9664e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9664473496712084e-06\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9480e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9479648155239455e-06\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9302e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.930246841945334e-06\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9135e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.913469938622366e-06\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8966e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8966349425248998e-06\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8803e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8802689506063122e-06\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8646e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8646384465865746e-06\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8494e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8494220482641309e-06\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8342e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.834248940106725e-06\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8194e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8193945827479823e-06\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8050e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8050239952374909e-06\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7911e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7910790319948859e-06\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7775e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.777472533367116e-06\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7643e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7642696400697195e-06\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7514e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7513736303655654e-06\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7386e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7386393443419527e-06\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7261e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.72605917588156e-06\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7137e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7137111172087957e-06\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7017e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.70168246177967e-06\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6898e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6898050135129278e-06\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6781e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.678111787146935e-06\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6667e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.666665924812708e-06\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6554e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6554311453160312e-06\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6443e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6443288200276103e-06\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6333e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6332934110030025e-06\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6224e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6224489114033852e-06\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6118e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6118267902468544e-06\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6014e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6013985499298854e-06\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5912e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.591187594489545e-06\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5811e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5811012101060652e-06\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5711e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.57113862838106e-06\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5613e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.56128487380117e-06\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5516e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5515787813700968e-06\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5420e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5420405119450996e-06\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5326e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5325912797062999e-06\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5233e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5232583624091237e-06\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5140e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5140374537668416e-06\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5049e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5049193258219863e-06\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4959e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.495938102032153e-06\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4872e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4871653763708906e-06\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4785e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4785098772109553e-06\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4700e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4699533544220917e-06\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4615e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4614845358204992e-06\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4531e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4530988801505674e-06\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4448e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.444794670666121e-06\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4366e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4366200492836897e-06\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4286e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4285575526343965e-06\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4206e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4206169498874845e-06\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4128e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.412758364642678e-06\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4049e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4049271362319458e-06\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3972e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3971676686681605e-06\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3895e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3895229745871703e-06\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3820e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3819691075902093e-06\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3745e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3744673334075072e-06\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3670e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3670360353007032e-06\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3597e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3596744211206814e-06\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3523e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.352348448508024e-06\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3450e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3450428355096257e-06\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3378e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3377695234585822e-06\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3305e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.33053801186768e-06\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3234e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3233702453599088e-06\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3163e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3163022681213861e-06\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3094e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3093599621481132e-06\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3023e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3023491527108688e-06\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2955e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2954738530788846e-06\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2886e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2886319027444451e-06\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2818e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2818478290293494e-06\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2752e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2752080422592504e-06\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2688e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2687634407935566e-06\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2623e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.262301999489526e-06\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2560e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.255998893826394e-06\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2495e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2494783983748676e-06\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2430e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.242969612112399e-06\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2367e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2366863057883822e-06\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2305e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.230498586588437e-06\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2243e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2243098508692354e-06\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2181108655731147e-06\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2119e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2119121829076057e-06\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2057e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2057381808493915e-06\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1998e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1997800473889394e-06\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1937e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1937131089699019e-06\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1876e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1876458393676022e-06\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1818e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.181773606693398e-06\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1759e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1758905989545526e-06\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1700e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1699926729808505e-06\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1640e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.163994028472344e-06\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1581e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1581407484250805e-06\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1522e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1522375862878014e-06\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1464e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1464352317216299e-06\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1407e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1406573996968808e-06\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1349e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1348688616956476e-06\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1291e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1291225899890357e-06\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1234e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1234246321396223e-06\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1177e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1176959485926347e-06\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1120e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1119844601246873e-06\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1065e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.106545404528081e-06\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1010e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1009598616667592e-06\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0953e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0952879991166997e-06\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0898e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.089796881799858e-06\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0843e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0843320026362492e-06\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0789e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0788984591451425e-06\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0735e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.073479139144111e-06\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0681e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0681016344893633e-06\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0628e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.062755341972131e-06\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0574e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0574296328530208e-06\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0522e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0522455339942676e-06\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0470e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0469772202589901e-06\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0418e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0417855918657226e-06\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0367e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0366911934089256e-06\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0316e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0316145825176385e-06\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0265e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0265281392125857e-06\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0214e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.021445206457885e-06\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0164e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.016406392588562e-06\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0115e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0114971322467864e-06\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0066e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.006569971077742e-06\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0018e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0018493962329524e-06\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9700e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.970021111012322e-07\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9221e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.92208605463252e-07\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8756e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.87559806023695e-07\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8290e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.828956505026449e-07\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7822e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.782213794239675e-07\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7367e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.736746673102684e-07\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6909e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.690934024226122e-07\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6459e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.645924509598353e-07\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6012e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.60123381744426e-07\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5564e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.55641787749128e-07\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5122e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.512165528154774e-07\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4685e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.46854749711329e-07\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4257e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.425665982668925e-07\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3830e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.382997772972921e-07\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.4160, -0.5639],\n",
            "        [-0.0252,  0.5018],\n",
            "        [-0.2653, -0.4130],\n",
            "        [-0.4997,  0.5405],\n",
            "        [-0.1369,  0.1777],\n",
            "        [-0.5486,  0.5722],\n",
            "        [-0.5864,  0.2929],\n",
            "        [ 0.0592, -0.6384],\n",
            "        [ 0.1675, -0.5224],\n",
            "        [ 0.5592, -0.0803],\n",
            "        [-0.3333,  0.2056],\n",
            "        [-0.1957,  0.1838],\n",
            "        [ 0.1333,  0.1802],\n",
            "        [-0.2681, -0.1993],\n",
            "        [-0.1323, -0.1753],\n",
            "        [ 0.4818,  0.4107]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.5324,  0.6085,  0.4263, -0.1060,  0.0831, -0.1741, -0.2859, -0.2251,\n",
            "        -0.2082, -0.1651,  0.4732,  0.3228,  0.3390,  0.5883, -0.2635, -0.4474],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.1070, -0.2702, -0.0483, -0.2136,  0.1762,  0.1867, -0.1716,  0.1543,\n",
            "         -0.0730, -0.2434,  0.0650,  0.1376, -0.1726, -0.0664, -0.0461, -0.0685],\n",
            "        [ 0.2396, -0.1336, -0.0745, -0.0321, -0.0140,  0.1095,  0.1047, -0.1067,\n",
            "         -0.0900,  0.3086, -0.1483, -0.1186, -0.2119,  0.0208,  0.2383, -0.0535],\n",
            "        [-0.2005, -0.1586,  0.0359, -0.2290, -0.2166, -0.0359, -0.2091,  0.0215,\n",
            "         -0.0640,  0.0093, -0.1375,  0.0683,  0.0392,  0.0846, -0.0960, -0.1645],\n",
            "        [ 0.0424, -0.0669,  0.0631, -0.1053, -0.1674, -0.0228,  0.0862, -0.0299,\n",
            "          0.0131, -0.2525, -0.1101,  0.2235, -0.1300,  0.0178, -0.0321,  0.0657],\n",
            "        [-0.0862, -0.1556, -0.0223,  0.1965,  0.2476,  0.0061,  0.2042, -0.0860,\n",
            "          0.0050, -0.0380,  0.1883,  0.1462, -0.0586,  0.1278, -0.2156, -0.0348],\n",
            "        [-0.0610, -0.0633, -0.0139, -0.1922,  0.0268,  0.2602, -0.1128, -0.1555,\n",
            "         -0.0180, -0.2591,  0.1349, -0.1974, -0.2445,  0.0949,  0.1655,  0.0896],\n",
            "        [-0.1709, -0.0613,  0.1730,  0.1006,  0.0804,  0.1342, -0.1666, -0.0862,\n",
            "         -0.1633,  0.0841, -0.2249, -0.2067,  0.0528,  0.1978, -0.0231, -0.1150],\n",
            "        [ 0.0101, -0.1598,  0.0618, -0.1438,  0.1242,  0.1703, -0.1244,  0.1451,\n",
            "         -0.0706, -0.0748, -0.1685, -0.0056, -0.3079,  0.1874, -0.1245, -0.1703],\n",
            "        [ 0.2167, -0.0338,  0.2416, -0.1259,  0.1644,  0.0219,  0.2940, -0.0612,\n",
            "          0.1897,  0.2130, -0.1672, -0.1017, -0.0618,  0.0045, -0.1073, -0.0891],\n",
            "        [ 0.0406,  0.0587,  0.1533,  0.0328, -0.2861, -0.1048,  0.2664, -0.1565,\n",
            "         -0.0930, -0.3120,  0.0886, -0.0790, -0.1761,  0.0170, -0.1685, -0.1635],\n",
            "        [-0.0381,  0.1997, -0.1271, -0.1610, -0.1112,  0.0758,  0.2706, -0.1461,\n",
            "          0.0094,  0.0642, -0.2784, -0.2383,  0.1415, -0.0176,  0.2465,  0.0517],\n",
            "        [-0.0303,  0.1057, -0.1684, -0.1017,  0.1226, -0.0618, -0.1092, -0.0255,\n",
            "         -0.0422, -0.2011, -0.0173, -0.2302,  0.1458, -0.0878, -0.2043,  0.0288],\n",
            "        [ 0.2119,  0.0598, -0.1821, -0.0253, -0.1287, -0.0026, -0.1990,  0.2326,\n",
            "          0.0518, -0.2119,  0.1062, -0.0222,  0.0961,  0.2374,  0.1947,  0.0329],\n",
            "        [-0.1676,  0.0646, -0.1637, -0.1722,  0.1660, -0.0766,  0.1817,  0.2113,\n",
            "         -0.0733, -0.2040,  0.0988, -0.2459, -0.1081, -0.1914,  0.0588, -0.1499],\n",
            "        [ 0.1433,  0.1387,  0.1297,  0.1363, -0.1367, -0.1227, -0.1628, -0.2121,\n",
            "         -0.0241,  0.2838,  0.0140,  0.0870, -0.1988, -0.1736,  0.0209, -0.0470],\n",
            "        [ 0.1765,  0.1835, -0.0616,  0.0656,  0.2218,  0.1011,  0.0832, -0.0714,\n",
            "         -0.2270,  0.1006, -0.0272, -0.0073, -0.2399,  0.0144,  0.1693,  0.1717]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.2081, -0.1037, -0.0968, -0.1189, -0.0342, -0.1509, -0.1145,  0.1007,\n",
            "         0.0441,  0.0807, -0.2352,  0.0309, -0.2310, -0.0054,  0.0056, -0.0388],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.2270,  0.1609, -0.0928, -0.2061, -0.0097, -0.0516,  0.0728,  0.1352,\n",
            "         -0.0922, -0.0372, -0.0109,  0.0101, -0.0600,  0.1787, -0.0322,  0.0047]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.2554], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "FWrKK2gq1saa",
        "outputId": "b4ffd8e0-55b8-4603-f6aa-af1509382657"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"2b109429-c4fd-4b6c-9c66-42c9b997c534\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2b109429-c4fd-4b6c-9c66-42c9b997c534\")) {                    Plotly.newPlot(                        \"2b109429-c4fd-4b6c-9c66-42c9b997c534\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.23332330352492367,0.24258862148102012,0.23326124374902843,0.22878496516599747,0.23283042956419,0.23671336700501938,0.2405963044458487,0.24447924188667805,0.2483621793275074,0.2522451167683367],[0.25413643178137496,0.2543538585060284,0.24413886937359366,0.23220636506747233,0.23015959799339447,0.23620391182244574,0.2402891258198424,0.2443743398172391,0.24845955381463578,0.2525447678120325],[0.25369140656555744,0.2549150708830124,0.2503195817929705,0.24058524914151114,0.22915152788461285,0.22200536514036334,0.23151309079690852,0.24102081645345372,0.24770807247629067,0.25179328647368737],[0.2535487848738608,0.2553627495507404,0.25164981117617097,0.24607433853601487,0.23715388889797126,0.22609669070175334,0.21520767261430818,0.2233588579438774,0.23286658360042256,0.24237430925696773],[0.2535897042622119,0.2563298737031791,0.2532750516346418,0.2473929340825205,0.24183266378065255,0.2337225286544314,0.22304185351889383,0.2121123596374682,0.21520462509084626,0.22471235074739143],[0.2531524882894386,0.2566668811877895,0.25424189966710403,0.24901817454099137,0.24313605698887003,0.23779751312068914,0.23029116841089153,0.21989192794329337,0.20905752245460868,0.2070503922378151],[0.2527152723166653,0.255055520532074,0.25459055723578977,0.25064341499946224,0.2447612974473409,0.2388791798952196,0.23376236246072576,0.22685980816735168,0.21654106325645045,0.20600268527174923],[0.2517107972563284,0.2539434013785719,0.25493921480447557,0.25050390949868095,0.24638653790581178,0.24050442035369043,0.23482181940783137,0.2297272118007624,0.2234284479238118,0.21319019856960758],[0.2505986781028264,0.2528312822250699,0.25528787237316136,0.2508983942747231,0.24801177836428265,0.2421296608121613,0.23624754326004,0.23085721048438684,0.22573812491142803,0.21999708768027199],[0.2494865589493243,0.25171916307156783,0.25398403144691317,0.25129287905076525,0.24669240342662943,0.24375490127063218,0.23787278371851084,0.2320116871339011,0.2268926015609423,0.2217735159879835]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.20600268527174923,0.2566668811877895],\"ticktext\":[0.20600268527174923,0.2566668811877895]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2b109429-c4fd-4b6c-9c66-42c9b997c534');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafec005-5da2-4910-f383-be828faa4eb1",
        "id": "bMNdZyX0wP74"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0130, dtype=torch.float64), tensor(8.9415e-05, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_e = experiment_actions(1000, env_30, P_pi_e)\n"
      ],
      "metadata": {
        "id": "dNqOUUhNwP8L"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f86508de-5c8a-4490-9ee5-80cf50f2ec8f",
        "id": "_BFL3TclwP8L"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.12203056843017494"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c09e80-d734-4659-d9e9-79376a8ed433",
        "id": "XXIslB1ZwP8M"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0521, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test random pi_b"
      ],
      "metadata": {
        "id": "AT8DEpH257IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 5, 0.4)\n",
        "pi_b = experiment_actions(200, env_30, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "# pi_e = experiment_actions(200, env_30, P_pi_e)\n",
        "model_200_random_pi_b = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64)\n",
        "test_200_random_pi_b = SCOPE_straight(model_200_random_pi_b, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "WMPIrLYl5-8M"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.train_var_scope(200, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbp_-3l56PPN",
        "outputId": "f61e6193-07fc-44f9-cd29-924b90259c5f"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.02867102506653055\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005117103406371684\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005069477039305052\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005035621463707624\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005020553982758296\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005002554239954662\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004956411988171686\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004889395075318338\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00048239234664848276\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00047633823555979284\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004709003639810457\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004655046530777875\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004583342944453858\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00044998835639543564\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004422019688695813\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004346940369808588\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00042779946771819255\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004205660809117596\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00041307016647918897\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004058573054167046\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003986520329881627\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00039208205421561293\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00038585584829850495\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003795890704158265\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003734232749719739\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00036766646627215375\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003621989355342928\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00035689580423057523\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003516093624139432\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003462037726460508\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000340717763034715\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033530626019057514\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033004802152265133\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00032487623299844127\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00032030755162553587\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00031573566205450246\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003111170460305279\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003065532237479143\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00030201900241217934\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002976897283303273\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002933084574326034\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028897786800867573\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028480400406899844\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028067841084060836\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00027654373852111045\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002723965595907615\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00026853765510921965\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002648597891119259\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002612321876545493\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00025782527396034464\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002546578989689914\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00025142579541863607\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002482630849029395\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002451666029252397\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00024205899099930214\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023895574981984907\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002358848000843591\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023285206935530408\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022984415686816623\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022685745848976301\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002240237893889413\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022141438316978905\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021887044740033086\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021623922693177785\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021365518856123345\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021109327869687364\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020854044673565572\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020599360414548932\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002035147831612647\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002011761960185903\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00019887366245777724\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000196624196877015\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00019439900884868477\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001921717467205605\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00019004180797009223\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001879443325835925\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018585399146812072\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018378111390529892\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018172406129649343\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017969078092546664\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001776803714239805\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017568298157606414\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017371023707972078\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000171770884240207\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016991610492444046\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001680427301296578\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016617045045619732\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016432600104447867\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016248231606410618\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016064196441401484\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015890881762483205\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015714068176825476\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015539792558111155\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001536083286324206\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015177634406297291\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014995434737477694\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014812453676708138\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014630160083439555\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014455211110112276\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014279668194350115\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014109636939194312\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013940441476625854\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013769953840263467\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001360001934820845\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000134358036985624\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013270115602862417\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013104388111896142\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012941303766470273\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001278053930460651\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012624730593286705\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001246682811783405\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012301278149238836\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012151377434389917\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012014370424713201\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011878582874743082\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011744241680016099\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011610883587151402\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011479331603280764\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001134957079000253\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011220676501021504\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011093593347881034\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010968544575016674\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001084465369104258\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010721176116837154\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010600724903148836\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010481082483338075\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010365969752629704\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010250114835740828\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010132747409043561\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9880e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.987998603685989e-05\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8462e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.846226471162701e-05\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7024e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.702417475760597e-05\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5582e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.558230686333786e-05\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4138e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.413786997610885e-05\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2695e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.269495690156659e-05\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1286e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.128582122538676e-05\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9884e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.988443182799984e-05\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8494e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.849360211492677e-05\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7113e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.711309363931655e-05\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5744e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.574428289446046e-05\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4391e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.439088546813288e-05\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3055e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.305548379179956e-05\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1763e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.176294668258124e-05\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0486e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.048565795461372e-05\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9222e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.922232737394275e-05\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7974e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.797372141964995e-05\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6740e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.6740254337146e-05\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5543e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.554279941496131e-05\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4373e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.437329688848443e-05\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3223e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.322290561527515e-05\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2092e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.209224089394356e-05\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0984e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.098417183317778e-05\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9894e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.989367404030381e-05\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8825e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.882486897989087e-05\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7778e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.777751102225054e-05\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6751e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.675080861369686e-05\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5744e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.574444244013147e-05\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4775e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.477530473696625e-05\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3817e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.381680287293212e-05\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2869e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.286884333438564e-05\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1932e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.193199804254627e-05\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1028e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.1028418004855406e-05\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0142e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.014215472419843e-05\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9270e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.9270109692041745e-05\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8415e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.841479165263062e-05\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7576e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7575885905520035e-05\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6753e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.675313411085096e-05\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5946e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.594625335018142e-05\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5156e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.515639138796778e-05\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4378e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.437829774672287e-05\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3616e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.3615828672745455e-05\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2868e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.286840620627447e-05\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2135e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.2135134018253914e-05\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1418e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.141812003543495e-05\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0710e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.0710224761507644e-05\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0018e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.0017644596022994e-05\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9338e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.933771208387757e-05\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8670e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8670199283789835e-05\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8015e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.80148144136044e-05\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7371e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.7371260523181666e-05\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6739e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.673933936414381e-05\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6119e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.611873947170038e-05\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5517e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.5516827512754246e-05\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4965e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.49651458322518e-05\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4419e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.44188121462834e-05\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3879e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.3879278676088016e-05\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3282e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.328229588208086e-05\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2677e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.2676640883628254e-05\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2067e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.20673310617337e-05\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1456e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.1456211128844236e-05\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0846e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.084588189298785e-05\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0238e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.023812040929546e-05\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9634e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.963364570987235e-05\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9034e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.9033706611127605e-05\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8457e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8457078078401154e-05\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7910e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.7909649559590766e-05\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7366e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.73662557701e-05\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6828e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.682818439280119e-05\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6296e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.629592440335648e-05\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(1.0768e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5770e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.5769934169559344e-05\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.5256, -0.1848],\n",
            "        [ 0.6294, -0.1176],\n",
            "        [ 0.3192,  0.1718],\n",
            "        [ 0.0903, -0.3086],\n",
            "        [ 0.5691,  0.1906],\n",
            "        [-0.2607, -0.6321],\n",
            "        [-0.7033, -0.3404],\n",
            "        [-0.5834, -0.1342],\n",
            "        [ 0.0973, -0.5953],\n",
            "        [-0.4303,  0.4418],\n",
            "        [-0.4621, -0.6912],\n",
            "        [ 0.7367, -0.2587],\n",
            "        [ 0.2174, -0.6775],\n",
            "        [ 0.4519,  0.3001],\n",
            "        [ 0.6602, -0.0443],\n",
            "        [-0.1381, -0.2667]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.5900,  0.6348,  0.6967,  0.1991,  0.3988,  0.1721,  0.3640,  0.2282,\n",
            "         0.4886,  0.0506,  0.2460, -0.6296,  0.6823, -0.5593, -0.2640,  0.6094],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 2.0148e-01, -1.4236e-01, -1.1707e-02,  1.6529e-01,  2.0735e-01,\n",
            "          6.3637e-02,  3.5722e-02, -1.2352e-01, -1.8455e-01, -2.3483e-01,\n",
            "          1.7001e-01,  2.1809e-01, -1.0857e-02, -1.9933e-02, -1.4845e-01,\n",
            "         -5.8214e-02],\n",
            "        [-1.2462e-01,  1.8235e-01,  2.8114e-01,  1.1584e-01, -1.4167e-01,\n",
            "         -2.2469e-01,  3.2124e-02, -1.1786e-01, -1.7891e-01,  2.7997e-02,\n",
            "         -1.8120e-01, -2.1680e-01,  2.4667e-01,  2.7249e-01, -4.1566e-02,\n",
            "          1.1889e-01],\n",
            "        [ 3.2235e-02, -3.9127e-01, -1.8113e-01,  2.7325e-03,  2.2641e-01,\n",
            "         -8.9647e-02,  1.0802e-01,  8.8250e-02, -1.3935e-01,  6.6746e-02,\n",
            "         -2.4271e-02, -2.6390e-01, -1.5708e-01,  2.7789e-02, -2.9701e-02,\n",
            "          6.4986e-02],\n",
            "        [-1.3489e-01,  3.2101e-01,  1.0008e-01,  1.7155e-01,  4.3869e-02,\n",
            "          1.6742e-02,  6.0140e-02,  1.6866e-01, -4.4046e-02, -3.1381e-01,\n",
            "         -2.2014e-01, -1.8149e-01,  5.7494e-02, -2.7895e-01, -1.9999e-02,\n",
            "          1.1568e-02],\n",
            "        [ 2.0862e-01,  1.3480e-01,  2.2521e-01, -2.2695e-01, -3.1193e-01,\n",
            "         -2.4803e-01,  1.3377e-02, -4.9486e-02, -9.9579e-02, -1.7097e-01,\n",
            "          2.0011e-01,  1.6170e-01,  1.5863e-01, -2.7838e-01,  8.4230e-03,\n",
            "         -7.5493e-02],\n",
            "        [ 1.8708e-01, -2.1194e-01, -1.9674e-01,  4.1319e-02, -2.3347e-02,\n",
            "          1.5483e-01,  1.3361e-01,  1.3709e-01, -2.0251e-01,  1.7355e-01,\n",
            "          1.0681e-01,  1.0673e-01,  2.1468e-01,  5.4904e-02, -3.6922e-01,\n",
            "          8.9360e-02],\n",
            "        [-9.2576e-02, -2.4792e-01, -6.7769e-03,  2.1107e-02, -2.4903e-01,\n",
            "          6.1380e-02, -2.0414e-01, -8.1497e-02,  2.1766e-01,  1.0137e-01,\n",
            "          2.4309e-01,  1.5084e-01,  2.4080e-01,  4.4809e-02,  1.2152e-01,\n",
            "         -2.4873e-01],\n",
            "        [ 3.0900e-02, -1.4569e-01, -7.8610e-02,  2.4284e-01,  1.0982e-01,\n",
            "         -1.6126e-01,  1.8163e-01, -1.7269e-01,  1.3467e-01, -1.0973e-01,\n",
            "         -5.8181e-02, -4.8294e-02, -1.2336e-01, -8.7663e-02, -9.0803e-02,\n",
            "          1.2644e-01],\n",
            "        [ 1.1816e-01, -2.3539e-01, -2.5603e-01,  4.0176e-02,  2.5738e-01,\n",
            "         -1.2013e-01,  1.3873e-01,  1.5010e-01,  1.6154e-01, -2.8727e-01,\n",
            "         -1.8497e-01, -1.5224e-01, -1.4463e-01, -3.0585e-01,  6.7351e-02,\n",
            "          1.9456e-01],\n",
            "        [ 9.8262e-02, -2.9094e-01, -1.4025e-01,  1.4969e-01,  1.6891e-01,\n",
            "          1.6996e-01,  1.5586e-01, -1.0916e-01,  2.0549e-01, -8.6835e-02,\n",
            "         -2.4478e-01, -1.8197e-01, -1.8341e-01,  5.0097e-02, -2.8432e-01,\n",
            "          6.1310e-03],\n",
            "        [-6.1088e-02, -2.8623e-01,  1.6116e-01,  5.9608e-04,  2.2478e-01,\n",
            "         -2.0614e-01,  2.1780e-01, -1.8906e-01,  1.3525e-01, -1.8243e-01,\n",
            "          2.2091e-01,  7.8225e-02, -1.9600e-01,  1.3405e-01,  4.5522e-02,\n",
            "         -1.1828e-01],\n",
            "        [ 1.8280e-01, -1.5981e-01,  1.9346e-01, -9.8611e-02,  6.8918e-02,\n",
            "          1.5864e-01,  1.8815e-01,  7.4287e-03,  6.8590e-02,  1.4864e-02,\n",
            "         -1.3912e-04,  1.9674e-01, -6.0974e-03,  1.2276e-01,  1.7881e-01,\n",
            "         -1.9647e-01],\n",
            "        [ 7.0488e-02,  1.8844e-01,  9.7298e-02, -2.4820e-01,  1.3541e-01,\n",
            "         -2.0078e-01, -9.1050e-02,  3.8632e-02, -1.4598e-01, -3.7405e-01,\n",
            "         -1.4911e-02, -1.4846e-01, -8.1250e-02,  1.3649e-01,  6.3506e-02,\n",
            "          1.6330e-02],\n",
            "        [ 1.0848e-01, -2.3279e-01, -1.6502e-01,  5.7319e-02,  3.7028e-02,\n",
            "         -9.3782e-02,  1.5367e-01, -8.0826e-02,  1.4979e-01,  2.2095e-01,\n",
            "         -1.3212e-01,  9.2721e-03, -1.7887e-01, -9.8793e-02,  1.2222e-02,\n",
            "          5.9483e-02],\n",
            "        [-1.6451e-01,  3.2993e-01,  2.5604e-01, -2.4412e-02, -8.7958e-02,\n",
            "          4.9254e-02, -2.2479e-02,  1.1894e-01,  2.9502e-02,  1.1337e-01,\n",
            "          7.3961e-02, -3.6546e-03,  1.0278e-02, -2.6169e-01, -6.3770e-02,\n",
            "          1.6718e-01],\n",
            "        [-9.5427e-02,  1.6457e-01,  2.3359e-01,  6.0072e-02, -7.9079e-02,\n",
            "          7.1479e-02, -1.6773e-01,  2.0375e-01, -3.6926e-02,  5.2058e-02,\n",
            "         -1.7433e-01,  2.4639e-01,  1.4080e-01,  3.8722e-02, -4.4300e-02,\n",
            "         -1.2372e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1616,  0.0111, -0.0060,  0.0558,  0.2558,  0.1964,  0.2088,  0.1120,\n",
            "         0.0628,  0.1641, -0.2807,  0.0897,  0.0025,  0.0419,  0.0784,  0.2509],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0655,  0.0835,  0.0774,  0.1414, -0.0742,  0.1362,  0.0873, -0.2367,\n",
            "         -0.2790,  0.1580, -0.0483,  0.0118,  0.1076, -0.1514,  0.1086, -0.0086]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0354], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "It3Bo2HN6YX6",
        "outputId": "6c469f5b-ca75-4f75-f9b6-20fd08ec8700"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"c8b8f2b6-8e24-4682-ab17-5cf37b61a534\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c8b8f2b6-8e24-4682-ab17-5cf37b61a534\")) {                    Plotly.newPlot(                        \"c8b8f2b6-8e24-4682-ab17-5cf37b61a534\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.0772242430901483,0.17903289422445948,0.2249602462379773,0.26425739561580003,0.3038732130732885,0.33984937428195405,0.37736707258890745,0.4153823705424622,0.45339766849601665,0.49141296644957133],[0.0660454496946137,0.19061755838393782,0.24294394129518124,0.28142990905829407,0.31944520701184875,0.3574605049654034,0.39547580291895795,0.43349110087251247,0.47150639882606726,0.5095216967796218],[0.04026957201195048,0.15403325630231882,0.24584447715998606,0.28643049928098396,0.3256049379407999,0.36614665607220714,0.4084240806230395,0.45070150517387164,0.4896151291561177,0.5276304271096723],[0.056369629082098756,0.11546992238536694,0.21600556177304844,0.28331556404647273,0.32409405671533886,0.3583371001411757,0.3925801435670126,0.4317215816225153,0.4721763741250782,0.5138103496440186],[0.07099725375210814,0.09622554376938541,0.17343062497338413,0.2501766327229359,0.3174866349963602,0.3591477178028166,0.3933907612286535,0.4276338046544904,0.46187684808032725,0.4961198915061641],[0.08772350832027209,0.08607112133882996,0.15256319845843877,0.21703770139939907,0.28434770367282336,0.3516577059462476,0.3942013788902944,0.4284444223161313,0.4626874657419682,0.496930509167805],[0.10166585914482926,0.09309723281029997,0.14288415150730538,0.20828596800986507,0.25540074700888354,0.3185187746227108,0.38582877689613504,0.42925503997777215,0.4634980834036092,0.49774112682944605],[0.113802113698629,0.10616325480488267,0.13320510455617202,0.1996971816757808,0.24867346551755412,0.2988612092377566,0.35268984557259836,0.4199998478460225,0.46430870106524996,0.49855174449108675],[0.1275098058666374,0.1174637420485675,0.12823671534407027,0.19001813472464749,0.24706720451686406,0.2921339277464272,0.34232167146662956,0.39250941518683186,0.45417091879591004,0.4993623621527279],[0.14121749803464598,0.1310717403418337,0.12608255092722195,0.1803390877735141,0.24683116489312293,0.28568043672026205,0.3355943899753001,0.38578213369550257,0.4359698774157049,0.48834198974579746]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.04026957201195048,0.5276304271096723],\"ticktext\":[0.04026957201195048,0.5276304271096723]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c8b8f2b6-8e24-4682-ab17-5cf37b61a534');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ca5369-0532-432a-b3bd-b21304482140",
        "id": "sRHfeo2M61vf"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-3.4482e-06, dtype=torch.float64),\n",
              " tensor(1.0768e-11, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_e = experiment_actions(1000, env_30, P_pi_e)\n"
      ],
      "metadata": {
        "id": "ApQD9_AH61vp"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f7aeaa-e064-40ac-c11a-eceeb4607c54",
        "id": "wfsewrsW61vp"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15990763270320862"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab45c36b-2ced-4d96-aae6-2a8bb8199e9c",
        "id": "A9HyHxak61vq"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0015, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(1.3966e-05, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2WrUWX46wy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the state_dict of the model\n",
        "model_state_dict = test_200_0p99.model.state_dict()\n",
        "\n",
        "# Print the keys to see the structure of the state_dict\n",
        "print(model_state_dict.keys())\n",
        "\n",
        "# Extract and print the weights of each layer\n",
        "for name, param in model_state_dict.items():\n",
        "    if 'weight' in name:\n",
        "        print(f\"Layer: {name}\")\n",
        "        print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rR01pJ4hQ-z",
        "outputId": "ea85e642-64fe-4767-c74a-4187ab9ae0d5"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output_layer.weight', 'output_layer.bias'])\n",
            "Layer: hidden_layers.0.weight\n",
            "tensor([[-0.5992, -0.0774],\n",
            "        [ 0.4740, -0.2568],\n",
            "        [ 0.3057,  0.1028],\n",
            "        [ 0.1205, -0.2533],\n",
            "        [ 0.6123,  0.1611],\n",
            "        [-0.2607, -0.6321],\n",
            "        [-0.7033, -0.3404],\n",
            "        [-0.5834, -0.1342],\n",
            "        [ 0.1821, -0.5556],\n",
            "        [-0.4225,  0.3797],\n",
            "        [-0.4621, -0.6912],\n",
            "        [ 0.6232, -0.4203],\n",
            "        [ 0.2262, -0.6769],\n",
            "        [ 0.5225,  0.2460],\n",
            "        [ 0.6153, -0.0401],\n",
            "        [-0.1569, -0.2980]], dtype=torch.float64)\n",
            "Layer: hidden_layers.1.weight\n",
            "tensor([[ 1.0516e-01, -1.5570e-01, -8.9501e-02,  2.2105e-01,  2.2795e-01,\n",
            "          6.3637e-02,  3.5722e-02, -1.2352e-01, -1.2532e-01, -1.9321e-01,\n",
            "          1.7001e-01,  2.7690e-01,  5.0010e-02,  4.4123e-02, -1.7390e-01,\n",
            "         -3.3544e-02],\n",
            "        [ 2.9563e-02, -1.6539e-01,  1.8811e-01,  2.4416e-02, -2.0411e-01,\n",
            "         -2.2469e-01,  3.2124e-02, -1.1786e-01, -2.0997e-01, -2.9288e-03,\n",
            "         -1.8120e-01, -1.8996e-01,  2.2284e-01,  2.0928e-01,  3.6049e-02,\n",
            "          1.2501e-01],\n",
            "        [-1.2149e-01, -2.1002e-01, -9.7943e-02,  1.5191e-02,  2.5198e-01,\n",
            "         -8.9647e-02,  1.0802e-01,  8.8250e-02, -2.0667e-01, -6.7170e-02,\n",
            "         -2.4271e-02, -1.6559e-01, -2.0982e-01, -1.0798e-01,  1.0970e-01,\n",
            "          6.4986e-02],\n",
            "        [ 1.4588e-01,  1.0558e-01,  8.0609e-02,  1.3330e-01,  4.9129e-02,\n",
            "          1.6742e-02,  6.0140e-02,  1.6866e-01, -1.4508e-01, -1.5118e-01,\n",
            "         -2.2014e-01, -2.0411e-01, -1.6783e-02, -1.8986e-01,  6.8790e-02,\n",
            "          2.2454e-02],\n",
            "        [-1.0514e-02,  2.0386e-01,  2.2841e-01, -1.2321e-01, -1.4372e-01,\n",
            "         -2.4803e-01,  1.3377e-02, -4.9486e-02,  1.2915e-03, -1.9275e-01,\n",
            "          2.0011e-01,  2.5863e-01,  2.6719e-01, -2.4577e-01, -2.6740e-02,\n",
            "         -2.8935e-02],\n",
            "        [-2.3204e-02, -8.9060e-02, -1.4838e-01,  8.9374e-03, -7.6390e-02,\n",
            "          1.5483e-01,  1.3361e-01,  1.3709e-01, -2.2401e-01,  1.0198e-01,\n",
            "          1.0681e-01,  7.2959e-02,  1.7711e-01, -4.4961e-03, -2.2231e-01,\n",
            "          9.4986e-02],\n",
            "        [-2.7593e-01,  7.9180e-03, -4.1311e-02, -7.7472e-02, -3.1525e-01,\n",
            "          6.1380e-02, -2.0414e-01, -8.1497e-02,  1.6221e-01,  2.6618e-02,\n",
            "          2.4309e-01,  8.4607e-02,  1.8900e-01,  4.1116e-03,  1.3827e-01,\n",
            "         -2.4482e-01],\n",
            "        [ 2.6721e-02,  1.3537e-01, -8.0593e-02,  2.6549e-01,  6.6624e-02,\n",
            "         -1.6126e-01,  1.8163e-01, -1.7269e-01,  2.2547e-01, -7.9082e-02,\n",
            "         -5.8181e-02, -5.0510e-02, -3.5746e-02,  7.3083e-03, -4.3919e-02,\n",
            "          1.3159e-01],\n",
            "        [-1.3592e-01, -4.7488e-02, -1.4664e-01, -3.0966e-03,  1.7579e-01,\n",
            "         -1.2013e-01,  1.3873e-01,  1.5010e-01,  2.3158e-01, -2.1094e-01,\n",
            "         -1.8497e-01, -1.7136e-01, -6.6302e-02, -1.8402e-01,  1.7502e-01,\n",
            "          1.8137e-01],\n",
            "        [ 1.2734e-01, -2.7244e-01, -6.1841e-02,  2.5599e-01,  1.3099e-01,\n",
            "          1.6996e-01,  1.5586e-01, -1.0916e-01,  1.6139e-01, -6.0406e-02,\n",
            "         -2.4478e-01, -8.9742e-02, -2.4928e-01,  5.3839e-02, -1.9965e-01,\n",
            "         -3.2069e-02],\n",
            "        [-3.1707e-01, -1.4542e-01,  6.7969e-02,  1.0453e-01,  2.5124e-01,\n",
            "         -2.0614e-01,  2.1780e-01, -1.8906e-01,  2.2606e-01, -1.6723e-01,\n",
            "          2.2091e-01,  5.7679e-02, -1.1455e-01,  2.0786e-01,  1.1073e-01,\n",
            "         -9.5604e-02],\n",
            "        [ 2.6024e-01, -1.2099e-01,  2.0291e-01, -7.6303e-02,  3.9195e-02,\n",
            "          1.5864e-01,  1.8815e-01,  7.4287e-03,  9.7794e-02, -1.0302e-01,\n",
            "         -1.3912e-04,  2.1948e-01,  1.1797e-02,  4.6641e-02,  1.7714e-01,\n",
            "         -2.1003e-01],\n",
            "        [ 2.8777e-01, -9.0522e-02, -6.7675e-03, -2.7429e-01,  1.7504e-01,\n",
            "         -2.0078e-01, -9.1050e-02,  3.8632e-02, -2.2507e-01, -2.2281e-01,\n",
            "         -1.4911e-02, -8.6514e-02, -1.7430e-01,  6.1942e-02,  9.1970e-02,\n",
            "          3.2384e-02],\n",
            "        [ 2.6618e-01, -6.2434e-02, -2.8002e-01,  5.8639e-02,  1.6358e-02,\n",
            "         -9.3782e-02,  1.5367e-01, -8.0826e-02,  1.4841e-01,  1.1282e-01,\n",
            "         -1.3212e-01,  1.4293e-02, -9.5888e-02, -7.1260e-02,  7.8707e-02,\n",
            "          5.3369e-02],\n",
            "        [-1.8876e-01,  1.7914e-01,  1.7690e-01, -6.0962e-02, -1.1442e-01,\n",
            "          4.9254e-02, -2.2479e-02,  1.1894e-01, -3.4903e-02,  1.3051e-01,\n",
            "          7.3961e-02, -3.1765e-02, -5.4896e-02, -2.4755e-01, -7.3570e-02,\n",
            "          1.6345e-01],\n",
            "        [-2.4118e-01,  1.2800e-01,  1.3045e-01,  1.0121e-01,  1.7293e-02,\n",
            "          7.1479e-02, -1.6773e-01,  2.0375e-01, -2.9049e-02, -1.8083e-02,\n",
            "         -1.7433e-01,  2.3663e-01,  1.6658e-01,  1.0704e-01, -3.2912e-02,\n",
            "         -1.0926e-01]], dtype=torch.float64)\n",
            "Layer: output_layer.weight\n",
            "tensor([[-0.0364, -0.0046,  0.0472,  0.1042, -0.1400,  0.0453,  0.1236, -0.1070,\n",
            "         -0.1542,  0.0594, -0.0120,  0.0009,  0.0361, -0.1014,  0.0087, -0.0164]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scope_testing = SCOPE_straight(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "pmjnzbuDy9sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = scope_testing.prepare()\n",
        "timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = scope_testing.pass_then_boostraps(model, padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "IS_variance, scope_variance = scope_testing.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)"
      ],
      "metadata": {
        "id": "hoOaF9W7zLoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train var scope"
      ],
      "metadata": {
        "id": "UWo2rOO_SLUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_var_scope(model, num_epochs, learning_rate, test1):\n",
        "\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = test1.prepare()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Enable anomaly detection\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Forward pass\n",
        "        # states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "        # sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "        # gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "        # # sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "        # samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor, padded_psi_tensors)\n",
        "\n",
        "\n",
        "        # Calculate MSE loss between states_output and padded_state_tensors\n",
        "        # mse_loss = F.mse_loss(states_output, padded_state_tensors)\n",
        "\n",
        "        # E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss, E_IS, E_SCOPE = calculate_shaped_variance_play(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)\n",
        "\n",
        "        timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = test1.pass_then_boostraps(model, padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "        IS_variance, variance_loss = test1.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"IS variance: \", IS_variance)\n",
        "        print(\"SCOPE Var loss: \", variance_loss)\n",
        "        # print(\"MSE loss: \", mse_loss.item())\n",
        "\n",
        "\n",
        "        tot = variance_loss\n",
        "        # tot = variance_loss + mse_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Retain the graph to avoid clearing it before backward pass\n",
        "        tot.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Disable anomaly detection after running the code\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "c0xC288M7vT0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UOqxfdgBmS81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fNLH1JIcmTJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "40GxgnTBmj9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(200, env, P_pi_e)"
      ],
      "metadata": {
        "id": "FmgfU0K6mk6G"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_200 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "911brDimm4wh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200 = SCOPE_straight(model_200, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "U79ry5NxmnCx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_200 = train_var_scope(model_200, 1000, 0.0005, test_200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pIcVizym9n_",
        "outputId": "e69cdfd5-0595-4226-80fb-a82cd7b0d07c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008492256656322879\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000832036997470311\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008178091443168292\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008067588044517235\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007938512145564716\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007788995781305973\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007657443959582411\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007538666733296384\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007421691758702111\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007303255456230735\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007187112391046453\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000707883908565864\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006971014030871082\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006862588634799347\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006757597277906554\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006657211420834642\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00065551527512402\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006457058049450084\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006359561093684281\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006268297890434793\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006176695790374126\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006088172295279874\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006001613262505393\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005917351211344535\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005834743861129547\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005753437649026478\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005674102836727932\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005595685919933554\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000551992504895417\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005444868933553543\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005371548163724429\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005299083217440924\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005228363198028344\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005158219587202258\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005088778763243133\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005020616816041798\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004952986833330397\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004886668705097123\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00048214910421574147\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004757488869078596\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00046944728948148724\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004632417046995436\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00045707461168116657\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00045102825216827223\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00044507496219341197\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004391699970035594\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004333230599644562\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00042761250144480274\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004219644492074685\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004164604380851949\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004110514097699362\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004057153133658589\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004004735708122344\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00039543175676454563\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003904754894518335\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003855896335018986\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00038081944363259194\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003761076287718471\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00037148031388432314\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00036694533068793947\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003624837490230216\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003581522064171912\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00035390981479894247\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003497487072180543\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003456423814906023\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003415342148518471\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033748409519833525\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033357758121261124\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00032966937145839447\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003257789056837663\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00032201754209288264\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003183200983898995\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003146851804160395\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00031110142682717515\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003075700186692655\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003040839840760883\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003006453888635111\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002972676159097015\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00029397181536515573\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000290714618616006\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028754093491767526\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028436621835897314\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002812702834925871\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002782205293417825\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00027517542848118186\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002721673910811486\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002691772934722593\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002662458741311763\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00026334525372414023\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00026048058207414274\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000257679029752464\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00025491702413513233\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00025218869607327197\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002495659451975771\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002470028098219896\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00024446738640779373\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00024197302723749767\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023949914758569896\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023706675344837175\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023467001993446638\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023230188876613452\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022996372596278763\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002276657162691316\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022540613135710726\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022318047154214616\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022097652743278528\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021880198498063093\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002166567722388153\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002145398967420797\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021244651154387546\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002103786889959395\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020834284407611194\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020633337019717728\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002043474151014792\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020238983145584003\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020046381092816209\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001985589834736423\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001966728843224388\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001948101544284598\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00019297127622431426\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000191153527420611\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018935645490605007\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018758075254708326\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001858269587543017\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018409581733747497\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001823877852810283\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001806990919695813\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017902986656422035\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017738397061152375\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017575113374770711\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017412878630337895\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017252730053461684\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001709447546339227\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016937549791380736\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016780965197323638\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016626873679654024\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016476819395158548\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001632822592991993\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016181057413798233\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016035359810366101\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001589068409013391\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015746872186145762\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001560398248287147\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015461560722389406\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015319526770349903\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015178367998271887\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015038312943554743\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014899510745470528\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001476054614344439\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014621893399159946\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014485502160647672\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014350339452472911\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014216087793788164\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000140830490821699\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013950732187264974\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013820179762622683\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001368967432458594\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013559422535950943\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001343162810900871\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013303815065772028\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013177523769975145\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013052931057876144\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012930307436596485\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012809870006286737\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012692767144281705\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001257186136946716\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012440407716868436\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012311919427811604\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012197322557004407\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012087626076809482\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011971664442531696\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001185639369531777\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011752053728073698\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001164592934238245\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011533870288203292\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011426861724768149\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011326264215393649\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011222679364241443\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011119125356414037\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011020430921033742\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010922351280646204\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010822126360227963\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010723283976101278\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010627933906459941\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010532171637350396\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010435902241609148\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010341922065436709\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010248465969284747\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001015440703268652\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010061149169569957\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9697e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.969677409070994e-05\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8783e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.878335989654519e-05\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7873e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.787279168785962e-05\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6976e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.69758197476198e-05\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6105e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.610492493381914e-05\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5233e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.523263355361816e-05\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4360e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.435985163446957e-05\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3505e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.35053755766774e-05\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2670e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.266979831918592e-05\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1839e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.183938236310378e-05\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0988e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.098814326320734e-05\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0143e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.014278646659148e-05\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9306e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.930625427545809e-05\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8480e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.847991591928882e-05\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7656e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.765628041198527e-05\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6843e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.68429811717542e-05\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6045e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.604519059921131e-05\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5246e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.524567753589901e-05\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4455e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.445540310284939e-05\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3675e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.367503866475242e-05\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2888e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.28877858052401e-05\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2091e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.209147611315046e-05\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1303e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.130269964015309e-05\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0524e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.052404453516736e-05\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9769e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.976872594309536e-05\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9008e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.900798278279476e-05\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8226e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.82262197504637e-05\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7463e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.746266993315425e-05\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6717e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.67171917254087e-05\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5976e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.597618400565901e-05\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5234e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.523359023477829e-05\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4502e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.45021281678714e-05\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3773e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.377297094007641e-05\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3053e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.305314289660489e-05\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2360e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.236024390150411e-05\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1663e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.16630498391982e-05\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0977e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.097702283039156e-05\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0308e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.030772379447493e-05\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9643e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.964279675343819e-05\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8975e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.897455842562479e-05\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8315e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.8315215636455e-05\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7702e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.770222175028961e-05\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7116e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.711640575376605e-05\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6542e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.654200496153875e-05\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5981e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.598050820401602e-05\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5400e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.539972867814303e-05\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4821e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.482105817145616e-05\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4261e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.426106372951936e-05\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3702e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.370162752683761e-05\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3136e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.313604238992362e-05\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2593e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.259344745237913e-05\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2057e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.205717658728037e-05\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1516e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.151618398033388e-05\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0991e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.099073526508293e-05\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0472e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.0471672927703575e-05\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9963e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.996324473357272e-05\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9476e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.947636380901482e-05\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8994e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.899372743628718e-05\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8505e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.8504877289483376e-05\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8037e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.803672900925304e-05\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7575e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.757533646635286e-05\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7113e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7113019288540736e-05\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6658e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.665847843405303e-05\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6213e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.6212753710204996e-05\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5769e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.576871097714104e-05\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5335e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.53349274830648e-05\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4908e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.490777826260673e-05\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4483e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.448341001642345e-05\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4064e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.4064165372956725e-05\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3653e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.365268471371259e-05\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3246e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.3245848267945756e-05\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2842e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.284200317169358e-05\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2449e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.244853348082652e-05\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2058e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.205816813909749e-05\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1672e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.167185029830273e-05\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1288e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.1287687115397415e-05\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0911e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.091104628457276e-05\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0538e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.053780690285663e-05\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0169e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.016907290713931e-05\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9800e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.980032913959201e-05\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9447e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.944722636349524e-05\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9087e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.908725615747006e-05\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8734e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.873403874893399e-05\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8391e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.839098239765689e-05\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8042e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.804195425956049e-05\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7699e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.7699016412675674e-05\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7364e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.736420606014769e-05\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7034e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.703361545076622e-05\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6701e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.670104210312564e-05\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6374e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.637362142046941e-05\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6054e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.6054495865686785e-05\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5737e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.5736593336108175e-05\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5420e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.54204996567932e-05\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5108e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.510752497015295e-05\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4799e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4799312244357624e-05\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4493e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.449283518855385e-05\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4189e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.418855865310275e-05\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3887e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.3886564498877126e-05\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3589e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.358852927114633e-05\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3292e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.329234679500792e-05\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3001e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.300096193925238e-05\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2713e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.27131341388663e-05\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2426e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.24258690960057e-05\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2142e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.214246737842867e-05\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1860e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.186002219363668e-05\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1580e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.1580304956656985e-05\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.1300166107670276e-05\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1021e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.1021377296911025e-05\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0741e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.074067824852833e-05\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0460e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.046027264010877e-05\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0181e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.018076411126676e-05\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9903e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.990324351557248e-05\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9627e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.9627310512778886e-05\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9357e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.9356599173565026e-05\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9084e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.908405524791476e-05\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8813e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8812922690681225e-05\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8543e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8543174461272455e-05\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8273e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8273267673638243e-05\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8011e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.801086596798809e-05\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7747e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.774661066157103e-05\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7481e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.74807408492115e-05\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7220e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.722009498015186e-05\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6964e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.696391533399378e-05\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6705e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.670514778304468e-05\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6456e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.645607882622268e-05\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6209e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.620887551657613e-05\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5962e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.5962129599482044e-05\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5717e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.571652022907381e-05\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5473e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.54727578233288e-05\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5232e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.5232076211667935e-05\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4996e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.499647598281811e-05\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4765e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.476507410630298e-05\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4527e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.4527102922746365e-05\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4295e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.429497861910557e-05\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4066e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.4065595822805726e-05\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3839e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.3838730341864375e-05\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3617e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.361732272030674e-05\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3398e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.339790885123833e-05\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3183e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.3183031258184304e-05\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2965e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.296462021882803e-05\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2754e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.2753967063140575e-05\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2547e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.254742624683552e-05\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2341e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.234098979016392e-05\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2136e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.213612970216434e-05\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1933e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1933096691888275e-05\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1731e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1731352755415303e-05\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1529e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1528698844340294e-05\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1324e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.132389925184917e-05\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1124e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1123505979830835e-05\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0924e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.092428357645794e-05\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0726e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0726477289141325e-05\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0533e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0533185541762077e-05\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0342e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0341954897718023e-05\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0153e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.015280160167472e-05\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9968e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.99678468118364e-05\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9786e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9786352860800152e-05\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9602e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9601761435657524e-05\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9421e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9420716377132473e-05\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9239e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.923944645598509e-05\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9061e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.906081881145796e-05\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8885e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8884577157553185e-05\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8708e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.870755882730994e-05\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8532e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8531896822173865e-05\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8359e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8358575559953866e-05\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8187e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.818710442596032e-05\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8017e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.801693561541207e-05\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7848e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7848416772059425e-05\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7681e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7680500128531057e-05\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7514e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.751419461686585e-05\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7348e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.734784383544903e-05\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7186e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7185931422522828e-05\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7023e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7023125039210853e-05\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6863e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6863493479831305e-05\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6703e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.670337194452883e-05\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6544e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.654419782910289e-05\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6389e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6388700967940504e-05\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6237e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6236880869231954e-05\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6086e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6085819491730384e-05\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5939e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.593896646818686e-05\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5789e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5789407186383366e-05\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5644e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5643708177398852e-05\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5500e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5499624871587048e-05\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5355e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.535532471342399e-05\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5213e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5212757055899176e-05\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5072e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5071699817538887e-05\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4933e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.493262536643489e-05\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4794e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4794294381524616e-05\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4656e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4656222111300847e-05\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4520e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.452047769151297e-05\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4386e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.438598920121162e-05\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4252e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4252336504901778e-05\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4121e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4120600911082388e-05\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3989e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3989189377619764e-05\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3861e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3861140146277532e-05\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3732e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3732133377032427e-05\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3607e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3606626665311617e-05\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3482e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.348188999480035e-05\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3355e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3355472861304606e-05\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3230e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3229766814136952e-05\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3104e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.310436656111011e-05\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2980e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.297972945239816e-05\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2856e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2856254769874023e-05\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2731e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2730639048937134e-05\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2608e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.260753688836752e-05\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2485e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2484807601067045e-05\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2367e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.236660147184186e-05\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2249e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.224896625176123e-05\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2130e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2130331333236658e-05\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2013e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.201331193753736e-05\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1899e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.189871441964559e-05\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1786e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.178604235923495e-05\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1672e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1672329830814667e-05\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1561e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.156052820502702e-05\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1448e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1447777429019927e-05\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1340e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1340203138769182e-05\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1228e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.122849526024304e-05\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1121e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1121202014858878e-05\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1015e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.101464024934643e-05\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0908e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.090780466993527e-05\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0803e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0802669561112895e-05\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0699e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0699277092889588e-05\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0596e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0596134505556497e-05\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0495e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0494959421655e-05\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0394e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0393504773549608e-05\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0293e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0292973013855927e-05\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0192e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0192416726704118e-05\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0092e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.009183223398696e-05\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9992e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.999158992109217e-05\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9891e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9891422384120074e-05\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9792e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.979216785937777e-05\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9692e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9692416269238992e-05\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9593e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9592931401757175e-05\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9495e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9494554860774023e-05\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9398e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9397953354304037e-05\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9302e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.930209545470215e-05\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9207e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9206778996021408e-05\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9113e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9113254234977327e-05\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9020e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9019701785588482e-05\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8927e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8926752179458734e-05\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8836e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8835796686918132e-05\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8745e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.87450241339437e-05\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8655e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8654538954842562e-05\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8565e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8565150988417155e-05\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8477e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.847709347057959e-05\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8390e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8389731639103224e-05\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8303e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8302783463865627e-05\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8215e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8214857097142336e-05\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8129e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8128720934006212e-05\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8043e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.804266788917738e-05\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7957e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7957274338526418e-05\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7873e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7873255212023606e-05\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7791e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.779063946834054e-05\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7708e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.770802216897308e-05\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7627e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.762659969324139e-05\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7546e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7546331469657008e-05\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7469e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.746864035205386e-05\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7392e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.739151021747901e-05\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7314e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.73139029512958e-05\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7237e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7236710599925994e-05\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7159e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.715911809498747e-05\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7082e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.708191352659031e-05\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7005e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7005262697572185e-05\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6927973083020383e-05\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6853e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6852547893865636e-05\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6778e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6778307054558186e-05\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6705e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.670502756884706e-05\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6633e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.663301490671409e-05\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6562e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6561971869183986e-05\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6492e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6491785031238073e-05\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6423e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.642274963991396e-05\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6354e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6353731192078812e-05\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6285e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6285349431132467e-05\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6217e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6217367325363588e-05\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6150e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6150050515679848e-05\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6083e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6082915428412144e-05\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6016e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6015979152122895e-05\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5950e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.594963551359844e-05\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5884e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5883806895374583e-05\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5818e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5818153318074477e-05\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5753e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.575308359263744e-05\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5689e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5688642018873506e-05\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5624e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.562365422278097e-05\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5560e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.555953189594072e-05\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5496e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.54958877636794e-05\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5432e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5432485288769504e-05\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5369e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5369176800630954e-05\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5306e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.530629581785336e-05\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5244e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5244048797021676e-05\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5182e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5182087726207302e-05\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5120e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5120433276237812e-05\n",
            "----------------------------------------\n",
            "Epoch 501\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5059e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5058893194364405e-05\n",
            "----------------------------------------\n",
            "Epoch 502\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4998e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4997875960890615e-05\n",
            "----------------------------------------\n",
            "Epoch 503\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4938e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4937688852518146e-05\n",
            "----------------------------------------\n",
            "Epoch 504\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4878e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4878287872223396e-05\n",
            "----------------------------------------\n",
            "Epoch 505\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4819e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.481914846659287e-05\n",
            "----------------------------------------\n",
            "Epoch 506\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4760e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4760053905106438e-05\n",
            "----------------------------------------\n",
            "Epoch 507\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4701e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.470114402608226e-05\n",
            "----------------------------------------\n",
            "Epoch 508\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4643e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4642555226838194e-05\n",
            "----------------------------------------\n",
            "Epoch 509\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4585e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4585212200931878e-05\n",
            "----------------------------------------\n",
            "Epoch 510\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4527e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4527255570958493e-05\n",
            "----------------------------------------\n",
            "Epoch 511\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4470e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4469658713834085e-05\n",
            "----------------------------------------\n",
            "Epoch 512\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4413e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4413036097390941e-05\n",
            "----------------------------------------\n",
            "Epoch 513\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4357e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4356986633671797e-05\n",
            "----------------------------------------\n",
            "Epoch 514\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4301e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4300961843194654e-05\n",
            "----------------------------------------\n",
            "Epoch 515\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4246e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4245965779599444e-05\n",
            "----------------------------------------\n",
            "Epoch 516\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4191e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4191465180584123e-05\n",
            "----------------------------------------\n",
            "Epoch 517\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4137e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4137418715206713e-05\n",
            "----------------------------------------\n",
            "Epoch 518\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4084e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4083840394217231e-05\n",
            "----------------------------------------\n",
            "Epoch 519\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4031e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4031369381442996e-05\n",
            "----------------------------------------\n",
            "Epoch 520\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3980e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3979767288086743e-05\n",
            "----------------------------------------\n",
            "Epoch 521\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3929e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3929029429790715e-05\n",
            "----------------------------------------\n",
            "Epoch 522\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3880e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3879787641502867e-05\n",
            "----------------------------------------\n",
            "Epoch 523\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3833e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3833282945940465e-05\n",
            "----------------------------------------\n",
            "Epoch 524\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3789e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3789311085996936e-05\n",
            "----------------------------------------\n",
            "Epoch 525\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3749e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3748512057519106e-05\n",
            "----------------------------------------\n",
            "Epoch 526\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3712e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3711506120304935e-05\n",
            "----------------------------------------\n",
            "Epoch 527\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3677e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3677399224067588e-05\n",
            "----------------------------------------\n",
            "Epoch 528\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3640e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3640232934691128e-05\n",
            "----------------------------------------\n",
            "Epoch 529\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3595e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3595288371342423e-05\n",
            "----------------------------------------\n",
            "Epoch 530\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3536e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3535786642943022e-05\n",
            "----------------------------------------\n",
            "Epoch 531\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3462e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3461942184752149e-05\n",
            "----------------------------------------\n",
            "Epoch 532\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3383e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3382525330336567e-05\n",
            "----------------------------------------\n",
            "Epoch 533\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3313e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.331273786771144e-05\n",
            "----------------------------------------\n",
            "Epoch 534\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3259e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3259455289393232e-05\n",
            "----------------------------------------\n",
            "Epoch 535\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3219e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.321907805264832e-05\n",
            "----------------------------------------\n",
            "Epoch 536\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3182e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3182016322868137e-05\n",
            "----------------------------------------\n",
            "Epoch 537\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3138e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3137942094978146e-05\n",
            "----------------------------------------\n",
            "Epoch 538\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3083e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.30827082220143e-05\n",
            "----------------------------------------\n",
            "Epoch 539\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3020e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3019555271513447e-05\n",
            "----------------------------------------\n",
            "Epoch 540\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2958e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2957513681047242e-05\n",
            "----------------------------------------\n",
            "Epoch 541\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2904e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2903573660642584e-05\n",
            "----------------------------------------\n",
            "Epoch 542\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2858e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2857931159112953e-05\n",
            "----------------------------------------\n",
            "Epoch 543\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2815e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2814590467297593e-05\n",
            "----------------------------------------\n",
            "Epoch 544\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2767e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2767143180473518e-05\n",
            "----------------------------------------\n",
            "Epoch 545\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2714e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2713672943365728e-05\n",
            "----------------------------------------\n",
            "Epoch 546\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2657e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.265748857122879e-05\n",
            "----------------------------------------\n",
            "Epoch 547\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2603e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2603020204993312e-05\n",
            "----------------------------------------\n",
            "Epoch 548\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2554e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.25537145001066e-05\n",
            "----------------------------------------\n",
            "Epoch 549\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2509e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2508510697431409e-05\n",
            "----------------------------------------\n",
            "Epoch 550\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2464e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2463536351825626e-05\n",
            "----------------------------------------\n",
            "Epoch 551\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2417e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2416606631806624e-05\n",
            "----------------------------------------\n",
            "Epoch 552\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2366e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2366392164307541e-05\n",
            "----------------------------------------\n",
            "Epoch 553\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2315e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2315357659531196e-05\n",
            "----------------------------------------\n",
            "Epoch 554\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2266e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2266280248494186e-05\n",
            "----------------------------------------\n",
            "Epoch 555\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2220e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2220086530058517e-05\n",
            "----------------------------------------\n",
            "Epoch 556\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2176e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2175940709417794e-05\n",
            "----------------------------------------\n",
            "Epoch 557\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2132e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2131848979581588e-05\n",
            "----------------------------------------\n",
            "Epoch 558\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2086e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.20855292439563e-05\n",
            "----------------------------------------\n",
            "Epoch 559\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2037e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2037222013742187e-05\n",
            "----------------------------------------\n",
            "Epoch 560\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1989e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1988777494849121e-05\n",
            "----------------------------------------\n",
            "Epoch 561\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1942e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1941542208167131e-05\n",
            "----------------------------------------\n",
            "Epoch 562\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1896e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.189563170775708e-05\n",
            "----------------------------------------\n",
            "Epoch 563\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1850e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1850412578222707e-05\n",
            "----------------------------------------\n",
            "Epoch 564\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1806e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.180627193819347e-05\n",
            "----------------------------------------\n",
            "Epoch 565\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1763e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1763210772942293e-05\n",
            "----------------------------------------\n",
            "Epoch 566\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1720e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1719552989049111e-05\n",
            "----------------------------------------\n",
            "Epoch 567\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1676e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1676227263652522e-05\n",
            "----------------------------------------\n",
            "Epoch 568\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1634e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1633581025971187e-05\n",
            "----------------------------------------\n",
            "Epoch 569\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1592e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.159172264729097e-05\n",
            "----------------------------------------\n",
            "Epoch 570\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1550e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1550036513231593e-05\n",
            "----------------------------------------\n",
            "Epoch 571\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1508e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1508163951290118e-05\n",
            "----------------------------------------\n",
            "Epoch 572\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1466e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1466228662072152e-05\n",
            "----------------------------------------\n",
            "Epoch 573\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1424e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1424334363443679e-05\n",
            "----------------------------------------\n",
            "Epoch 574\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1383e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.138264559405212e-05\n",
            "----------------------------------------\n",
            "Epoch 575\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1341e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1341226534236857e-05\n",
            "----------------------------------------\n",
            "Epoch 576\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.130041380680045e-05\n",
            "----------------------------------------\n",
            "Epoch 577\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1260e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.126008620819722e-05\n",
            "----------------------------------------\n",
            "Epoch 578\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1220e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1220092209194774e-05\n",
            "----------------------------------------\n",
            "Epoch 579\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1180e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1180171453493145e-05\n",
            "----------------------------------------\n",
            "Epoch 580\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1140e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1140379866225069e-05\n",
            "----------------------------------------\n",
            "Epoch 581\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1101e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1100899660488096e-05\n",
            "----------------------------------------\n",
            "Epoch 582\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1062e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1061638923151898e-05\n",
            "----------------------------------------\n",
            "Epoch 583\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1023e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1023103736370482e-05\n",
            "----------------------------------------\n",
            "Epoch 584\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0985e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0984890401719405e-05\n",
            "----------------------------------------\n",
            "Epoch 585\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0947e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0946870864490308e-05\n",
            "----------------------------------------\n",
            "Epoch 586\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0909e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0909314778314988e-05\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0872e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0871802540498322e-05\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0834e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0834353312926589e-05\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0797e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0797101491303865e-05\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0760e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0760289699887326e-05\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0724e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0724417154202008e-05\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0689e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0688570969159785e-05\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0653e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0652522610515287e-05\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0616e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0615996888453128e-05\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0580e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0579707040886388e-05\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0544e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0544111172965866e-05\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0509e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0508621555403671e-05\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0473e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0473302119117834e-05\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0438e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0438119444852171e-05\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0403e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0403257132164128e-05\n",
            "----------------------------------------\n",
            "Epoch 601\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0369e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0368533288679419e-05\n",
            "----------------------------------------\n",
            "Epoch 602\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0334e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0334106903667875e-05\n",
            "----------------------------------------\n",
            "Epoch 603\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.029996942972543e-05\n",
            "----------------------------------------\n",
            "Epoch 604\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0266e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0265960908875135e-05\n",
            "----------------------------------------\n",
            "Epoch 605\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0232e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0232084873461173e-05\n",
            "----------------------------------------\n",
            "Epoch 606\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0198e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0198205279745892e-05\n",
            "----------------------------------------\n",
            "Epoch 607\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0165e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0164531088021264e-05\n",
            "----------------------------------------\n",
            "Epoch 608\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0131e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.013142253059981e-05\n",
            "----------------------------------------\n",
            "Epoch 609\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0098e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0098139454524867e-05\n",
            "----------------------------------------\n",
            "Epoch 610\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0065e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.00647081914433e-05\n",
            "----------------------------------------\n",
            "Epoch 611\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0031e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.003143903870121e-05\n",
            "----------------------------------------\n",
            "Epoch 612\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9998e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.999838436869885e-06\n",
            "----------------------------------------\n",
            "Epoch 613\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9687e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.968666052112891e-06\n",
            "----------------------------------------\n",
            "Epoch 614\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9378e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.937831374207047e-06\n",
            "----------------------------------------\n",
            "Epoch 615\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9071e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.907147060115282e-06\n",
            "----------------------------------------\n",
            "Epoch 616\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8767e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.87674094776269e-06\n",
            "----------------------------------------\n",
            "Epoch 617\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8466e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.846583033751407e-06\n",
            "----------------------------------------\n",
            "Epoch 618\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8165e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.816473742809703e-06\n",
            "----------------------------------------\n",
            "Epoch 619\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7866e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.786617656248949e-06\n",
            "----------------------------------------\n",
            "Epoch 620\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7569e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.756938815910973e-06\n",
            "----------------------------------------\n",
            "Epoch 621\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7274e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.727424303635867e-06\n",
            "----------------------------------------\n",
            "Epoch 622\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6982e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.698172373983967e-06\n",
            "----------------------------------------\n",
            "Epoch 623\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6691e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.66908274436466e-06\n",
            "----------------------------------------\n",
            "Epoch 624\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6400e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.639998531985638e-06\n",
            "----------------------------------------\n",
            "Epoch 625\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6112e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.611246451765864e-06\n",
            "----------------------------------------\n",
            "Epoch 626\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5825e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.582513522807958e-06\n",
            "----------------------------------------\n",
            "Epoch 627\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5539e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.55389304348151e-06\n",
            "----------------------------------------\n",
            "Epoch 628\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5255e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.525491614583638e-06\n",
            "----------------------------------------\n",
            "Epoch 629\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4971e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.497144979917675e-06\n",
            "----------------------------------------\n",
            "Epoch 630\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4690e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.468958087616972e-06\n",
            "----------------------------------------\n",
            "Epoch 631\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4409e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.440863781604734e-06\n",
            "----------------------------------------\n",
            "Epoch 632\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4127e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.412672557181043e-06\n",
            "----------------------------------------\n",
            "Epoch 633\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3845e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.384519028883956e-06\n",
            "----------------------------------------\n",
            "Epoch 634\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3565e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.356526185389734e-06\n",
            "----------------------------------------\n",
            "Epoch 635\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3288e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.32876652182987e-06\n",
            "----------------------------------------\n",
            "Epoch 636\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3013e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.301317104443821e-06\n",
            "----------------------------------------\n",
            "Epoch 637\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2742e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.274194194131709e-06\n",
            "----------------------------------------\n",
            "Epoch 638\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2470e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.24695524175791e-06\n",
            "----------------------------------------\n",
            "Epoch 639\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2201e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.220055651422837e-06\n",
            "----------------------------------------\n",
            "Epoch 640\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1933e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.193288169708878e-06\n",
            "----------------------------------------\n",
            "Epoch 641\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1666e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.166582800732414e-06\n",
            "----------------------------------------\n",
            "Epoch 642\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1400e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.140031188250686e-06\n",
            "----------------------------------------\n",
            "Epoch 643\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1137e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.113718415575919e-06\n",
            "----------------------------------------\n",
            "Epoch 644\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0876e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.087572255137824e-06\n",
            "----------------------------------------\n",
            "Epoch 645\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0617e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.061680786827047e-06\n",
            "----------------------------------------\n",
            "Epoch 646\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0359e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.035936826516608e-06\n",
            "----------------------------------------\n",
            "Epoch 647\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.01031868737301e-06\n",
            "----------------------------------------\n",
            "Epoch 648\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9845e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.984519395677459e-06\n",
            "----------------------------------------\n",
            "Epoch 649\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9588e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.958789341063496e-06\n",
            "----------------------------------------\n",
            "Epoch 650\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9331e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.93305912837144e-06\n",
            "----------------------------------------\n",
            "Epoch 651\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9075e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.907523770881543e-06\n",
            "----------------------------------------\n",
            "Epoch 652\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8821e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.88208840945759e-06\n",
            "----------------------------------------\n",
            "Epoch 653\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8569e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.856907933899592e-06\n",
            "----------------------------------------\n",
            "Epoch 654\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8316e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.831641721042123e-06\n",
            "----------------------------------------\n",
            "Epoch 655\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8065e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.80651531990067e-06\n",
            "----------------------------------------\n",
            "Epoch 656\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7816e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.781562201349515e-06\n",
            "----------------------------------------\n",
            "Epoch 657\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7571e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.757052820987406e-06\n",
            "----------------------------------------\n",
            "Epoch 658\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7326e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.732621727888613e-06\n",
            "----------------------------------------\n",
            "Epoch 659\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7082e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.708218839392676e-06\n",
            "----------------------------------------\n",
            "Epoch 660\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6836e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.683634746674374e-06\n",
            "----------------------------------------\n",
            "Epoch 661\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6591e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.659147994333974e-06\n",
            "----------------------------------------\n",
            "Epoch 662\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6347e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.634701623340153e-06\n",
            "----------------------------------------\n",
            "Epoch 663\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.610322283631594e-06\n",
            "----------------------------------------\n",
            "Epoch 664\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5860e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.586021961310189e-06\n",
            "----------------------------------------\n",
            "Epoch 665\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5618e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.561826339949466e-06\n",
            "----------------------------------------\n",
            "Epoch 666\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5377e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.537703614020985e-06\n",
            "----------------------------------------\n",
            "Epoch 667\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5138e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.513778561470222e-06\n",
            "----------------------------------------\n",
            "Epoch 668\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4902e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.490245877767958e-06\n",
            "----------------------------------------\n",
            "Epoch 669\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4662e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.466220177384649e-06\n",
            "----------------------------------------\n",
            "Epoch 670\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4429e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.442868717934825e-06\n",
            "----------------------------------------\n",
            "Epoch 671\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4192e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.419158074182264e-06\n",
            "----------------------------------------\n",
            "Epoch 672\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3952e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.395199273154264e-06\n",
            "----------------------------------------\n",
            "Epoch 673\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3718e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.371771104755943e-06\n",
            "----------------------------------------\n",
            "Epoch 674\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3482e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.34815357058824e-06\n",
            "----------------------------------------\n",
            "Epoch 675\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3246e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.3246232449536e-06\n",
            "----------------------------------------\n",
            "Epoch 676\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3013e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.301295469311155e-06\n",
            "----------------------------------------\n",
            "Epoch 677\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2779e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.277887737956466e-06\n",
            "----------------------------------------\n",
            "Epoch 678\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2550e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.255021414070895e-06\n",
            "----------------------------------------\n",
            "Epoch 679\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2327e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.23265362469655e-06\n",
            "----------------------------------------\n",
            "Epoch 680\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.210254343107245e-06\n",
            "----------------------------------------\n",
            "Epoch 681\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1880e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.188036870540324e-06\n",
            "----------------------------------------\n",
            "Epoch 682\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1660e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.16604475997928e-06\n",
            "----------------------------------------\n",
            "Epoch 683\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1441e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.144077488635671e-06\n",
            "----------------------------------------\n",
            "Epoch 684\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1223e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.122265090159514e-06\n",
            "----------------------------------------\n",
            "Epoch 685\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1006e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.10058347179006e-06\n",
            "----------------------------------------\n",
            "Epoch 686\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0790e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.079020880662618e-06\n",
            "----------------------------------------\n",
            "Epoch 687\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0578e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.057766052877307e-06\n",
            "----------------------------------------\n",
            "Epoch 688\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0363e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.036280377318548e-06\n",
            "----------------------------------------\n",
            "Epoch 689\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0151e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.015065637825286e-06\n",
            "----------------------------------------\n",
            "Epoch 690\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9940e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.994002564768659e-06\n",
            "----------------------------------------\n",
            "Epoch 691\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9730e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.973035385261864e-06\n",
            "----------------------------------------\n",
            "Epoch 692\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9522e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.952192644660669e-06\n",
            "----------------------------------------\n",
            "Epoch 693\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9314e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.93140048381596e-06\n",
            "----------------------------------------\n",
            "Epoch 694\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9107e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.910724071018069e-06\n",
            "----------------------------------------\n",
            "Epoch 695\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8902e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.89016715285379e-06\n",
            "----------------------------------------\n",
            "Epoch 696\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8697e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.869659562954376e-06\n",
            "----------------------------------------\n",
            "Epoch 697\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8492e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.849235328898694e-06\n",
            "----------------------------------------\n",
            "Epoch 698\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8289e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.828937689531348e-06\n",
            "----------------------------------------\n",
            "Epoch 699\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8087e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.808684675910992e-06\n",
            "----------------------------------------\n",
            "Epoch 700\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7885e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.788530282395569e-06\n",
            "----------------------------------------\n",
            "Epoch 701\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7685e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.768465746182588e-06\n",
            "----------------------------------------\n",
            "Epoch 702\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7485e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.7484588213387e-06\n",
            "----------------------------------------\n",
            "Epoch 703\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7286e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.728554176904503e-06\n",
            "----------------------------------------\n",
            "Epoch 704\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7088e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.708776137790376e-06\n",
            "----------------------------------------\n",
            "Epoch 705\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6891e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.689133910635681e-06\n",
            "----------------------------------------\n",
            "Epoch 706\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6696e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.669557248638832e-06\n",
            "----------------------------------------\n",
            "Epoch 707\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6500e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.650008925786037e-06\n",
            "----------------------------------------\n",
            "Epoch 708\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6305e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.630532593999313e-06\n",
            "----------------------------------------\n",
            "Epoch 709\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6112e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.611218365355172e-06\n",
            "----------------------------------------\n",
            "Epoch 710\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5918e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.5918418710316424e-06\n",
            "----------------------------------------\n",
            "Epoch 711\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5726e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.572628322041073e-06\n",
            "----------------------------------------\n",
            "Epoch 712\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5535e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.553477746666121e-06\n",
            "----------------------------------------\n",
            "Epoch 713\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5344e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.534419900088396e-06\n",
            "----------------------------------------\n",
            "Epoch 714\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5154e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.515434514529349e-06\n",
            "----------------------------------------\n",
            "Epoch 715\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4966e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.496596332069689e-06\n",
            "----------------------------------------\n",
            "Epoch 716\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4779e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.477856884793299e-06\n",
            "----------------------------------------\n",
            "Epoch 717\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4592e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.459168653946338e-06\n",
            "----------------------------------------\n",
            "Epoch 718\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4405e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.440486642149688e-06\n",
            "----------------------------------------\n",
            "Epoch 719\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4220e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.4219528544730574e-06\n",
            "----------------------------------------\n",
            "Epoch 720\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4034e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.403362910834853e-06\n",
            "----------------------------------------\n",
            "Epoch 721\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3849e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.384889696145958e-06\n",
            "----------------------------------------\n",
            "Epoch 722\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3665e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.36648746031029e-06\n",
            "----------------------------------------\n",
            "Epoch 723\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3481e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.348145234779892e-06\n",
            "----------------------------------------\n",
            "Epoch 724\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3299e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.329863347652183e-06\n",
            "----------------------------------------\n",
            "Epoch 725\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3117e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.311652236359258e-06\n",
            "----------------------------------------\n",
            "Epoch 726\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2935e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.2935198664173674e-06\n",
            "----------------------------------------\n",
            "Epoch 727\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2755e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.275487632998186e-06\n",
            "----------------------------------------\n",
            "Epoch 728\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2575e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.257526515993993e-06\n",
            "----------------------------------------\n",
            "Epoch 729\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2396e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.239634009678592e-06\n",
            "----------------------------------------\n",
            "Epoch 730\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2218e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.221835917382804e-06\n",
            "----------------------------------------\n",
            "Epoch 731\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2041e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.20408456614118e-06\n",
            "----------------------------------------\n",
            "Epoch 732\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1864e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.18640496646378e-06\n",
            "----------------------------------------\n",
            "Epoch 733\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1688e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.1687991913397746e-06\n",
            "----------------------------------------\n",
            "Epoch 734\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1513e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.151250847977357e-06\n",
            "----------------------------------------\n",
            "Epoch 735\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1338e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.133762459958404e-06\n",
            "----------------------------------------\n",
            "Epoch 736\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1164e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.1163926856956925e-06\n",
            "----------------------------------------\n",
            "Epoch 737\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0990e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.0990107375325055e-06\n",
            "----------------------------------------\n",
            "Epoch 738\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0818e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.081753703571002e-06\n",
            "----------------------------------------\n",
            "Epoch 739\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0645e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.064534968864768e-06\n",
            "----------------------------------------\n",
            "Epoch 740\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0474e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.047395876215032e-06\n",
            "----------------------------------------\n",
            "Epoch 741\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0303e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.030344032509025e-06\n",
            "----------------------------------------\n",
            "Epoch 742\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0133e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.013344800074168e-06\n",
            "----------------------------------------\n",
            "Epoch 743\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9964e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.996435181977323e-06\n",
            "----------------------------------------\n",
            "Epoch 744\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9796e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.979591902911158e-06\n",
            "----------------------------------------\n",
            "Epoch 745\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9628e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.962772387680999e-06\n",
            "----------------------------------------\n",
            "Epoch 746\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9460e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.945954116777822e-06\n",
            "----------------------------------------\n",
            "Epoch 747\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9292e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.929200718724065e-06\n",
            "----------------------------------------\n",
            "Epoch 748\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9124e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.912411147351215e-06\n",
            "----------------------------------------\n",
            "Epoch 749\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8956e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.895597880154173e-06\n",
            "----------------------------------------\n",
            "Epoch 750\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8788e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.878817339184308e-06\n",
            "----------------------------------------\n",
            "Epoch 751\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8620e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.862031104265756e-06\n",
            "----------------------------------------\n",
            "Epoch 752\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8453e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.845251969490648e-06\n",
            "----------------------------------------\n",
            "Epoch 753\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8285e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.828538497285855e-06\n",
            "----------------------------------------\n",
            "Epoch 754\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8118e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.811849649776431e-06\n",
            "----------------------------------------\n",
            "Epoch 755\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7955e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.795455037503317e-06\n",
            "----------------------------------------\n",
            "Epoch 756\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7791e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.779103456600541e-06\n",
            "----------------------------------------\n",
            "Epoch 757\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7628e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.7628466955375215e-06\n",
            "----------------------------------------\n",
            "Epoch 758\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7467e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.746739735400868e-06\n",
            "----------------------------------------\n",
            "Epoch 759\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7307e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.730741851678048e-06\n",
            "----------------------------------------\n",
            "Epoch 760\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7149e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.714892501900936e-06\n",
            "----------------------------------------\n",
            "Epoch 761\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6992e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.699195131003278e-06\n",
            "----------------------------------------\n",
            "Epoch 762\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6837e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.68368906645652e-06\n",
            "----------------------------------------\n",
            "Epoch 763\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6685e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.668450419808167e-06\n",
            "----------------------------------------\n",
            "Epoch 764\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6536e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.653582638385843e-06\n",
            "----------------------------------------\n",
            "Epoch 765\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6392e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.6392174317431225e-06\n",
            "----------------------------------------\n",
            "Epoch 766\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6255e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.625474652504363e-06\n",
            "----------------------------------------\n",
            "Epoch 767\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6126e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.61255237816874e-06\n",
            "----------------------------------------\n",
            "Epoch 768\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6006e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.600555761343627e-06\n",
            "----------------------------------------\n",
            "Epoch 769\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5896e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.589622677653054e-06\n",
            "----------------------------------------\n",
            "Epoch 770\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5796e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.579551759164323e-06\n",
            "----------------------------------------\n",
            "Epoch 771\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5701e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.5701050876781375e-06\n",
            "----------------------------------------\n",
            "Epoch 772\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5604e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.560404292768259e-06\n",
            "----------------------------------------\n",
            "Epoch 773\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5491e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.549056206772362e-06\n",
            "----------------------------------------\n",
            "Epoch 774\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5347e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.53467573158713e-06\n",
            "----------------------------------------\n",
            "Epoch 775\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5160e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.5159924642491045e-06\n",
            "----------------------------------------\n",
            "Epoch 776\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4928e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.492759010520037e-06\n",
            "----------------------------------------\n",
            "Epoch 777\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4645e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.464486044523303e-06\n",
            "----------------------------------------\n",
            "Epoch 778\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6160e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.6159711745993e-06\n",
            "----------------------------------------\n",
            "Epoch 779\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3493e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.349339091096235e-06\n",
            "----------------------------------------\n",
            "Epoch 780\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5970e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.597001741826103e-06\n",
            "----------------------------------------\n",
            "Epoch 781\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5323e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.5322558845222235e-06\n",
            "----------------------------------------\n",
            "Epoch 782\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7347e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.734664198914599e-06\n",
            "----------------------------------------\n",
            "Epoch 783\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1505e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.1505067244313395e-06\n",
            "----------------------------------------\n",
            "Epoch 784\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3819e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.381854300748931e-06\n",
            "----------------------------------------\n",
            "Epoch 785\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7326e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.732638662315612e-06\n",
            "----------------------------------------\n",
            "Epoch 786\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7506e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.750590011138753e-06\n",
            "----------------------------------------\n",
            "Epoch 787\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3037e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.303683752874833e-06\n",
            "----------------------------------------\n",
            "Epoch 788\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7223e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.722321137708598e-06\n",
            "----------------------------------------\n",
            "Epoch 789\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3917e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.391651437897074e-06\n",
            "----------------------------------------\n",
            "Epoch 790\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3856e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.385599653483475e-06\n",
            "----------------------------------------\n",
            "Epoch 791\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5396e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.539573153944552e-06\n",
            "----------------------------------------\n",
            "Epoch 792\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2217e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.221744449630972e-06\n",
            "----------------------------------------\n",
            "Epoch 793\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4467e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.446671425943872e-06\n",
            "----------------------------------------\n",
            "Epoch 794\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2824e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.28237274480974e-06\n",
            "----------------------------------------\n",
            "Epoch 795\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2483e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.248331746412401e-06\n",
            "----------------------------------------\n",
            "Epoch 796\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3423e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.342271104255554e-06\n",
            "----------------------------------------\n",
            "Epoch 797\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1497e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.14965648874693e-06\n",
            "----------------------------------------\n",
            "Epoch 798\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2785e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.278458539976854e-06\n",
            "----------------------------------------\n",
            "Epoch 799\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1667e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.166698402074632e-06\n",
            "----------------------------------------\n",
            "Epoch 800\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1542e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.154249412641356e-06\n",
            "----------------------------------------\n",
            "Epoch 801\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1907e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.190700510876305e-06\n",
            "----------------------------------------\n",
            "Epoch 802\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0763e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.076339519591238e-06\n",
            "----------------------------------------\n",
            "Epoch 803\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1493e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.149259105283037e-06\n",
            "----------------------------------------\n",
            "Epoch 804\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0688e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.068758248930306e-06\n",
            "----------------------------------------\n",
            "Epoch 805\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0671e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.0671356897930855e-06\n",
            "----------------------------------------\n",
            "Epoch 806\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0739e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.07392324556847e-06\n",
            "----------------------------------------\n",
            "Epoch 807\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0055e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.005498723006554e-06\n",
            "----------------------------------------\n",
            "Epoch 808\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0435e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.043512302261288e-06\n",
            "----------------------------------------\n",
            "Epoch 809\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9858e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.985775077132882e-06\n",
            "----------------------------------------\n",
            "Epoch 810\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9848e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.98478150017932e-06\n",
            "----------------------------------------\n",
            "Epoch 811\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9782e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.9781873529238695e-06\n",
            "----------------------------------------\n",
            "Epoch 812\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9349e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.934863310040185e-06\n",
            "----------------------------------------\n",
            "Epoch 813\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9515e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.951504487124688e-06\n",
            "----------------------------------------\n",
            "Epoch 814\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9098e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.909803378560522e-06\n",
            "----------------------------------------\n",
            "Epoch 815\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9068e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.906827554194401e-06\n",
            "----------------------------------------\n",
            "Epoch 816\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8945e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.894468212921086e-06\n",
            "----------------------------------------\n",
            "Epoch 817\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8652e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.865191462813886e-06\n",
            "----------------------------------------\n",
            "Epoch 818\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8692e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.869179198792307e-06\n",
            "----------------------------------------\n",
            "Epoch 819\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8381e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.838147352209301e-06\n",
            "----------------------------------------\n",
            "Epoch 820\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8325e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.832452398396235e-06\n",
            "----------------------------------------\n",
            "Epoch 821\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8181e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.818100011606705e-06\n",
            "----------------------------------------\n",
            "Epoch 822\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7964e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.796381683228385e-06\n",
            "----------------------------------------\n",
            "Epoch 823\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7928e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.792779359558954e-06\n",
            "----------------------------------------\n",
            "Epoch 824\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7687e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.768697480019575e-06\n",
            "----------------------------------------\n",
            "Epoch 825\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7603e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.760280849667393e-06\n",
            "----------------------------------------\n",
            "Epoch 826\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7458e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7458282528529195e-06\n",
            "----------------------------------------\n",
            "Epoch 827\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7280e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.728027895908281e-06\n",
            "----------------------------------------\n",
            "Epoch 828\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7206e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7205883564861304e-06\n",
            "----------------------------------------\n",
            "Epoch 829\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7008e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.700783911632315e-06\n",
            "----------------------------------------\n",
            "Epoch 830\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6911e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.691086035410192e-06\n",
            "----------------------------------------\n",
            "Epoch 831\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6769e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.676898239823332e-06\n",
            "----------------------------------------\n",
            "Epoch 832\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6614e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.66135172285795e-06\n",
            "----------------------------------------\n",
            "Epoch 833\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6516e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.651636642250814e-06\n",
            "----------------------------------------\n",
            "Epoch 834\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6348e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.634772019611635e-06\n",
            "----------------------------------------\n",
            "Epoch 835\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6239e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.62385819704428e-06\n",
            "----------------------------------------\n",
            "Epoch 836\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.610310135528389e-06\n",
            "----------------------------------------\n",
            "Epoch 837\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5961e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.596129889991644e-06\n",
            "----------------------------------------\n",
            "Epoch 838\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5853e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.585349290528626e-06\n",
            "----------------------------------------\n",
            "Epoch 839\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5703e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.570305097053238e-06\n",
            "----------------------------------------\n",
            "Epoch 840\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5590e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.559012039114551e-06\n",
            "----------------------------------------\n",
            "Epoch 841\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5462e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.546236889684056e-06\n",
            "----------------------------------------\n",
            "Epoch 842\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5330e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.53303355013229e-06\n",
            "----------------------------------------\n",
            "Epoch 843\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5221e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.522146231936849e-06\n",
            "----------------------------------------\n",
            "Epoch 844\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5087e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.508701476645154e-06\n",
            "----------------------------------------\n",
            "Epoch 845\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4973e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.497330719966634e-06\n",
            "----------------------------------------\n",
            "Epoch 846\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4851e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.485099001966675e-06\n",
            "----------------------------------------\n",
            "Epoch 847\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4725e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.472533504436025e-06\n",
            "----------------------------------------\n",
            "Epoch 848\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4614e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.461375486021435e-06\n",
            "----------------------------------------\n",
            "Epoch 849\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4487e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.448714082019441e-06\n",
            "----------------------------------------\n",
            "Epoch 850\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4372e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.437238528576331e-06\n",
            "----------------------------------------\n",
            "Epoch 851\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4254e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.425352672076715e-06\n",
            "----------------------------------------\n",
            "Epoch 852\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4133e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.4132852699277435e-06\n",
            "----------------------------------------\n",
            "Epoch 853\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4021e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.402053641687304e-06\n",
            "----------------------------------------\n",
            "Epoch 854\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3899e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.389855603477778e-06\n",
            "----------------------------------------\n",
            "Epoch 855\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3784e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.3784393455637436e-06\n",
            "----------------------------------------\n",
            "Epoch 856\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3669e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.366877628887148e-06\n",
            "----------------------------------------\n",
            "Epoch 857\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3551e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.355131054173876e-06\n",
            "----------------------------------------\n",
            "Epoch 858\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3440e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.343965143251497e-06\n",
            "----------------------------------------\n",
            "Epoch 859\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3321e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.332149092016089e-06\n",
            "----------------------------------------\n",
            "Epoch 860\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3209e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.320890575137618e-06\n",
            "----------------------------------------\n",
            "Epoch 861\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3095e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.3095205231500804e-06\n",
            "----------------------------------------\n",
            "Epoch 862\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2979e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.297908946892838e-06\n",
            "----------------------------------------\n",
            "Epoch 863\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2867e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.286653656274361e-06\n",
            "----------------------------------------\n",
            "Epoch 864\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2751e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.275106637347438e-06\n",
            "----------------------------------------\n",
            "Epoch 865\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2637e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.263737809006187e-06\n",
            "----------------------------------------\n",
            "Epoch 866\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2525e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.252515736782866e-06\n",
            "----------------------------------------\n",
            "Epoch 867\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2412e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.241180270279359e-06\n",
            "----------------------------------------\n",
            "Epoch 868\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2299e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.22994663835292e-06\n",
            "----------------------------------------\n",
            "Epoch 869\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2187e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.218703514673314e-06\n",
            "----------------------------------------\n",
            "Epoch 870\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2076e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.207587632752226e-06\n",
            "----------------------------------------\n",
            "Epoch 871\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1965e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.196516661550964e-06\n",
            "----------------------------------------\n",
            "Epoch 872\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1853e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.1852984025598685e-06\n",
            "----------------------------------------\n",
            "Epoch 873\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1743e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.174250659546256e-06\n",
            "----------------------------------------\n",
            "Epoch 874\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1632e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.163163180810256e-06\n",
            "----------------------------------------\n",
            "Epoch 875\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1521e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.152121827766469e-06\n",
            "----------------------------------------\n",
            "Epoch 876\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1412e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.141164166020394e-06\n",
            "----------------------------------------\n",
            "Epoch 877\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1302e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.130220575599021e-06\n",
            "----------------------------------------\n",
            "Epoch 878\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1194e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.119373186024773e-06\n",
            "----------------------------------------\n",
            "Epoch 879\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1086e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.108597314541698e-06\n",
            "----------------------------------------\n",
            "Epoch 880\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0979e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.09790063602426e-06\n",
            "----------------------------------------\n",
            "Epoch 881\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0873e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.087251541828544e-06\n",
            "----------------------------------------\n",
            "Epoch 882\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0766e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.076555318539462e-06\n",
            "----------------------------------------\n",
            "Epoch 883\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0660e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.066002312950064e-06\n",
            "----------------------------------------\n",
            "Epoch 884\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0555e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.055524649919032e-06\n",
            "----------------------------------------\n",
            "Epoch 885\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0449e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.044882275100243e-06\n",
            "----------------------------------------\n",
            "Epoch 886\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0343e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.034258117403481e-06\n",
            "----------------------------------------\n",
            "Epoch 887\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0238e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.023816203431153e-06\n",
            "----------------------------------------\n",
            "Epoch 888\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0134e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.013399852650723e-06\n",
            "----------------------------------------\n",
            "Epoch 889\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0029e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.002923051920174e-06\n",
            "----------------------------------------\n",
            "Epoch 890\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9925e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.992482435251689e-06\n",
            "----------------------------------------\n",
            "Epoch 891\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9821e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9821346300589355e-06\n",
            "----------------------------------------\n",
            "Epoch 892\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9718e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.97180439716603e-06\n",
            "----------------------------------------\n",
            "Epoch 893\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9615e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.96151021619495e-06\n",
            "----------------------------------------\n",
            "Epoch 894\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9512e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.951152700059951e-06\n",
            "----------------------------------------\n",
            "Epoch 895\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9409e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.940938900394557e-06\n",
            "----------------------------------------\n",
            "Epoch 896\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9307e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9307071378884275e-06\n",
            "----------------------------------------\n",
            "Epoch 897\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9205e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.920486168857144e-06\n",
            "----------------------------------------\n",
            "Epoch 898\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9102940291907676e-06\n",
            "----------------------------------------\n",
            "Epoch 899\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9001e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9001117349174336e-06\n",
            "----------------------------------------\n",
            "Epoch 900\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8899e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8899168716507156e-06\n",
            "----------------------------------------\n",
            "Epoch 901\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8797e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.879722911972981e-06\n",
            "----------------------------------------\n",
            "Epoch 902\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8695e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.869546529152836e-06\n",
            "----------------------------------------\n",
            "Epoch 903\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8594e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8593994169870915e-06\n",
            "----------------------------------------\n",
            "Epoch 904\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8493e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.849283125814158e-06\n",
            "----------------------------------------\n",
            "Epoch 905\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8392e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.839166701820462e-06\n",
            "----------------------------------------\n",
            "Epoch 906\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8291e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.829071932964402e-06\n",
            "----------------------------------------\n",
            "Epoch 907\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8190e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8190269004042555e-06\n",
            "----------------------------------------\n",
            "Epoch 908\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8092e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.809175938133802e-06\n",
            "----------------------------------------\n",
            "Epoch 909\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7993e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.7993275674220465e-06\n",
            "----------------------------------------\n",
            "Epoch 910\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7895e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.789473477068608e-06\n",
            "----------------------------------------\n",
            "Epoch 911\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7796e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.779610564338512e-06\n",
            "----------------------------------------\n",
            "Epoch 912\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7698e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.7697641865245785e-06\n",
            "----------------------------------------\n",
            "Epoch 913\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7599e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.759901287749582e-06\n",
            "----------------------------------------\n",
            "Epoch 914\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7500e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.749977931509845e-06\n",
            "----------------------------------------\n",
            "Epoch 915\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7401e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.74005711536166e-06\n",
            "----------------------------------------\n",
            "Epoch 916\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7302e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.730181272237483e-06\n",
            "----------------------------------------\n",
            "Epoch 917\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7203e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.720314048829986e-06\n",
            "----------------------------------------\n",
            "Epoch 918\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7104e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.710434841245707e-06\n",
            "----------------------------------------\n",
            "Epoch 919\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7006e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.700605443710088e-06\n",
            "----------------------------------------\n",
            "Epoch 920\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6908e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.690822098434268e-06\n",
            "----------------------------------------\n",
            "Epoch 921\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6811e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.681076685665487e-06\n",
            "----------------------------------------\n",
            "Epoch 922\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6714e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.671354238553826e-06\n",
            "----------------------------------------\n",
            "Epoch 923\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6616e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.661644617101923e-06\n",
            "----------------------------------------\n",
            "Epoch 924\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6520e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.651969175425576e-06\n",
            "----------------------------------------\n",
            "Epoch 925\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6423e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.642336961972815e-06\n",
            "----------------------------------------\n",
            "Epoch 926\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6327e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.632713792896418e-06\n",
            "----------------------------------------\n",
            "Epoch 927\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6231e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.623122168402589e-06\n",
            "----------------------------------------\n",
            "Epoch 928\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6136e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.613588195885479e-06\n",
            "----------------------------------------\n",
            "Epoch 929\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6041e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.604082886974572e-06\n",
            "----------------------------------------\n",
            "Epoch 930\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5946e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.594605343767997e-06\n",
            "----------------------------------------\n",
            "Epoch 931\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5852e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.585214720786681e-06\n",
            "----------------------------------------\n",
            "Epoch 932\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5759e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.575876582608836e-06\n",
            "----------------------------------------\n",
            "Epoch 933\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5666e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.566565402371411e-06\n",
            "----------------------------------------\n",
            "Epoch 934\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5573e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.5572927468761126e-06\n",
            "----------------------------------------\n",
            "Epoch 935\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5480e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.548037740526441e-06\n",
            "----------------------------------------\n",
            "Epoch 936\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5388e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.538814458172767e-06\n",
            "----------------------------------------\n",
            "Epoch 937\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5296e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.529617422222607e-06\n",
            "----------------------------------------\n",
            "Epoch 938\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5205e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.520465589268317e-06\n",
            "----------------------------------------\n",
            "Epoch 939\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5113e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.511329747184247e-06\n",
            "----------------------------------------\n",
            "Epoch 940\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5022e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.502203075066162e-06\n",
            "----------------------------------------\n",
            "Epoch 941\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4931e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.493116872740971e-06\n",
            "----------------------------------------\n",
            "Epoch 942\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4840e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.484040054513565e-06\n",
            "----------------------------------------\n",
            "Epoch 943\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4750e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4749985676383265e-06\n",
            "----------------------------------------\n",
            "Epoch 944\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4660e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.465997593583453e-06\n",
            "----------------------------------------\n",
            "Epoch 945\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4570e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.457006201090774e-06\n",
            "----------------------------------------\n",
            "Epoch 946\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4480e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.448045306877989e-06\n",
            "----------------------------------------\n",
            "Epoch 947\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4391e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.439108439532241e-06\n",
            "----------------------------------------\n",
            "Epoch 948\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4302e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.430171713457378e-06\n",
            "----------------------------------------\n",
            "Epoch 949\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4213e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4212711533638305e-06\n",
            "----------------------------------------\n",
            "Epoch 950\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4124e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4124345145791485e-06\n",
            "----------------------------------------\n",
            "Epoch 951\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4036e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.403607418654391e-06\n",
            "----------------------------------------\n",
            "Epoch 952\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3948e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.394815631471154e-06\n",
            "----------------------------------------\n",
            "Epoch 953\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3860e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.386026739928362e-06\n",
            "----------------------------------------\n",
            "Epoch 954\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3772e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.377233455496574e-06\n",
            "----------------------------------------\n",
            "Epoch 955\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3684e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.368446346895171e-06\n",
            "----------------------------------------\n",
            "Epoch 956\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3597e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.359722221080673e-06\n",
            "----------------------------------------\n",
            "Epoch 957\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3510e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.351017474159306e-06\n",
            "----------------------------------------\n",
            "Epoch 958\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3423e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.342336084592606e-06\n",
            "----------------------------------------\n",
            "Epoch 959\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3337e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.333688648587514e-06\n",
            "----------------------------------------\n",
            "Epoch 960\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3251e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.325057787878992e-06\n",
            "----------------------------------------\n",
            "Epoch 961\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3164e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.3164381596847845e-06\n",
            "----------------------------------------\n",
            "Epoch 962\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3078e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.307827435558673e-06\n",
            "----------------------------------------\n",
            "Epoch 963\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2992e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.2992476350854304e-06\n",
            "----------------------------------------\n",
            "Epoch 964\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2907e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.29071877412872e-06\n",
            "----------------------------------------\n",
            "Epoch 965\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2822e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.2821963090279245e-06\n",
            "----------------------------------------\n",
            "Epoch 966\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2737e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.273668232812994e-06\n",
            "----------------------------------------\n",
            "Epoch 967\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2652e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.265167145533412e-06\n",
            "----------------------------------------\n",
            "Epoch 968\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2567e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.256689727540196e-06\n",
            "----------------------------------------\n",
            "Epoch 969\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2483e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.248296632267837e-06\n",
            "----------------------------------------\n",
            "Epoch 970\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2398e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.239814806018294e-06\n",
            "----------------------------------------\n",
            "Epoch 971\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2314e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.231404450146819e-06\n",
            "----------------------------------------\n",
            "Epoch 972\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2230e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.223002413154543e-06\n",
            "----------------------------------------\n",
            "Epoch 973\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2146e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.214621937106034e-06\n",
            "----------------------------------------\n",
            "Epoch 974\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2063e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.206264709457703e-06\n",
            "----------------------------------------\n",
            "Epoch 975\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1980e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.197956119099178e-06\n",
            "----------------------------------------\n",
            "Epoch 976\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1896e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.189641136705306e-06\n",
            "----------------------------------------\n",
            "Epoch 977\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1814e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.181395767840048e-06\n",
            "----------------------------------------\n",
            "Epoch 978\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1732e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.173233441268033e-06\n",
            "----------------------------------------\n",
            "Epoch 979\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1650e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.165035590883192e-06\n",
            "----------------------------------------\n",
            "Epoch 980\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1569e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.156930354061651e-06\n",
            "----------------------------------------\n",
            "Epoch 981\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1489e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.148853966873219e-06\n",
            "----------------------------------------\n",
            "Epoch 982\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1408e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.140782895061452e-06\n",
            "----------------------------------------\n",
            "Epoch 983\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1326e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.132614890319409e-06\n",
            "----------------------------------------\n",
            "Epoch 984\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1245e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.124466018701765e-06\n",
            "----------------------------------------\n",
            "Epoch 985\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1164e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.11641935301327e-06\n",
            "----------------------------------------\n",
            "Epoch 986\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1084e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.108387582364282e-06\n",
            "----------------------------------------\n",
            "Epoch 987\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1005e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.100472480701735e-06\n",
            "----------------------------------------\n",
            "Epoch 988\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0924e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.092407132352681e-06\n",
            "----------------------------------------\n",
            "Epoch 989\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0845e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.0844629952304134e-06\n",
            "----------------------------------------\n",
            "Epoch 990\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0766e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.076563157941235e-06\n",
            "----------------------------------------\n",
            "Epoch 991\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0687e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.068657002009449e-06\n",
            "----------------------------------------\n",
            "Epoch 992\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0608e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.060771900774584e-06\n",
            "----------------------------------------\n",
            "Epoch 993\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0529e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.052896907629822e-06\n",
            "----------------------------------------\n",
            "Epoch 994\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0450e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.045022629156914e-06\n",
            "----------------------------------------\n",
            "Epoch 995\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0372e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.037157314750649e-06\n",
            "----------------------------------------\n",
            "Epoch 996\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0293e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.029300901823153e-06\n",
            "----------------------------------------\n",
            "Epoch 997\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0214e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.021449635842377e-06\n",
            "----------------------------------------\n",
            "Epoch 998\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0136e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.013638560524795e-06\n",
            "----------------------------------------\n",
            "Epoch 999\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0058e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.005830628139071e-06\n",
            "----------------------------------------\n",
            "Epoch 1000\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9982e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.9981560197614436e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-5.5204e-04, -1.1648e-01],\n",
            "        [-4.5293e-01, -3.8106e-01],\n",
            "        [-2.5930e-01, -8.7127e-02],\n",
            "        [ 4.4813e-01, -1.6232e-01],\n",
            "        [-8.1455e-03,  7.8029e-02],\n",
            "        [ 1.1004e-01,  3.4091e-03],\n",
            "        [ 2.9693e-01,  4.3980e-01],\n",
            "        [ 6.2576e-01, -5.5355e-01],\n",
            "        [-1.0444e-01,  5.5520e-01],\n",
            "        [-3.0028e-01, -1.3046e-01],\n",
            "        [-5.3901e-01, -2.4041e-01],\n",
            "        [ 1.0723e-01,  1.4509e-01],\n",
            "        [-4.1380e-01,  2.4634e-01],\n",
            "        [ 1.7922e-01,  3.3803e-01],\n",
            "        [-3.7337e-01, -1.3246e-01],\n",
            "        [-6.9054e-01, -6.8765e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.5092,  0.4352,  0.7202,  0.4023,  0.4572, -0.6651, -0.0837,  0.3502,\n",
            "        -0.6959,  0.6241, -0.0528, -0.1184, -0.6749,  0.5630, -0.3820,  0.4062],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1059,  0.0348, -0.1211, -0.1186, -0.2161,  0.2042, -0.0126,  0.1244,\n",
            "          0.2356,  0.0704,  0.2263, -0.0731,  0.1759, -0.1584, -0.1582, -0.0644],\n",
            "        [ 0.0482,  0.1365,  0.2008, -0.1384,  0.1320,  0.0593, -0.0738,  0.0601,\n",
            "         -0.0785, -0.0454,  0.1469, -0.2405, -0.0496,  0.0664,  0.0934,  0.0403],\n",
            "        [ 0.0710,  0.0682, -0.0611,  0.0600,  0.1012, -0.2105, -0.2516,  0.1933,\n",
            "         -0.1968, -0.0189,  0.1533, -0.1566, -0.1075,  0.1345, -0.1637,  0.0113],\n",
            "        [-0.1001,  0.0853, -0.1011,  0.1986,  0.1516, -0.1680, -0.0438, -0.0598,\n",
            "          0.1153, -0.1011, -0.1849,  0.0017, -0.0356,  0.0592,  0.1066, -0.2067],\n",
            "        [ 0.0485,  0.2396, -0.0166,  0.2245,  0.0383,  0.1002,  0.1858,  0.0793,\n",
            "          0.0560, -0.1151,  0.1724, -0.0213,  0.0387,  0.1261,  0.0363, -0.0657],\n",
            "        [ 0.1195,  0.1694, -0.1735, -0.2022, -0.1880, -0.1023, -0.0673,  0.1393,\n",
            "         -0.0087, -0.0683, -0.0222,  0.1336, -0.1221,  0.2136, -0.2079,  0.1589],\n",
            "        [-0.0781, -0.1996,  0.1168,  0.1149,  0.0527,  0.1633, -0.1541,  0.2709,\n",
            "          0.0268,  0.0679,  0.1485,  0.0339,  0.0422,  0.0662, -0.0014,  0.0425],\n",
            "        [-0.0461, -0.1450, -0.1952,  0.1243,  0.1511,  0.0309,  0.1699,  0.1166,\n",
            "         -0.2554, -0.2381,  0.0199,  0.1038, -0.1051, -0.0508, -0.2054, -0.1726],\n",
            "        [-0.1728,  0.1716,  0.3580, -0.1372, -0.0661,  0.1081,  0.1373,  0.1145,\n",
            "          0.0249,  0.1201, -0.0654,  0.0284,  0.0638, -0.1162,  0.0172,  0.1396],\n",
            "        [ 0.1042,  0.1746,  0.3908,  0.0058,  0.1786, -0.1368, -0.0759, -0.0043,\n",
            "          0.0850,  0.0507, -0.0090, -0.1311,  0.1271,  0.0124,  0.1397,  0.2339],\n",
            "        [ 0.2133,  0.0509,  0.2322, -0.1479, -0.2051, -0.0269, -0.1886, -0.1002,\n",
            "         -0.1174, -0.0421,  0.2283, -0.1851,  0.1653,  0.1272, -0.2184, -0.2322],\n",
            "        [ 0.2097,  0.2253,  0.3185,  0.1029,  0.0387,  0.0292,  0.0161,  0.0778,\n",
            "         -0.0773, -0.1021,  0.1186, -0.0954, -0.0134, -0.0401, -0.1185,  0.2487],\n",
            "        [ 0.0689, -0.0969, -0.0106,  0.0204,  0.0230,  0.2184, -0.2816, -0.0923,\n",
            "          0.2334,  0.1604,  0.0403, -0.1636,  0.1268, -0.0127,  0.1386,  0.1866],\n",
            "        [ 0.2480,  0.1819,  0.0612, -0.1424,  0.0304, -0.0997, -0.2740,  0.3344,\n",
            "          0.0511, -0.1114,  0.0226, -0.0524,  0.0449,  0.1124, -0.2474,  0.1864],\n",
            "        [ 0.1872,  0.2367, -0.2487,  0.0882,  0.0338,  0.1907,  0.1273, -0.1082,\n",
            "         -0.0604,  0.0663,  0.0350, -0.1319,  0.1821, -0.0847, -0.2468, -0.2229],\n",
            "        [ 0.2759,  0.0425, -0.4191, -0.1359, -0.0629,  0.0942, -0.0608, -0.3922,\n",
            "          0.2084, -0.1408, -0.2414, -0.0204,  0.0059, -0.0352,  0.0191,  0.0218],\n",
            "        [-0.1869, -0.0160,  0.1168,  0.0116, -0.0226, -0.1437,  0.0360,  0.0223,\n",
            "          0.1339,  0.1268,  0.1077, -0.1652,  0.2013, -0.1835, -0.0167,  0.2096],\n",
            "        [ 0.0782, -0.1589, -0.2673, -0.0680, -0.0904,  0.1165, -0.0635, -0.1919,\n",
            "         -0.1050,  0.2005, -0.1449, -0.0545,  0.0925,  0.0203,  0.1139,  0.1484],\n",
            "        [ 0.1595,  0.0643, -0.3432,  0.1120,  0.0515, -0.1801, -0.0238,  0.2495,\n",
            "          0.0111, -0.0368,  0.1770, -0.0914, -0.0333,  0.0507, -0.2133, -0.0470],\n",
            "        [-0.1760, -0.0565, -0.0034, -0.0679,  0.2087, -0.0109, -0.3103, -0.1276,\n",
            "         -0.0425,  0.2443,  0.0807, -0.1902,  0.1366, -0.1344,  0.2271,  0.0099],\n",
            "        [ 0.0740, -0.2291,  0.3031, -0.0556,  0.2903, -0.1666, -0.2427,  0.0299,\n",
            "         -0.1052,  0.2062,  0.1986,  0.2072, -0.1006, -0.2910, -0.1149,  0.2293],\n",
            "        [-0.2314,  0.0108,  0.1455,  0.0379,  0.0895,  0.1859,  0.1108,  0.0656,\n",
            "         -0.1844, -0.0440,  0.1627,  0.1713, -0.1886,  0.1660,  0.2276, -0.0430],\n",
            "        [-0.1424, -0.2437, -0.2496,  0.1048,  0.1263, -0.0228, -0.1983, -0.1492,\n",
            "          0.0542, -0.0686, -0.0583,  0.2295,  0.1212, -0.0762, -0.2098, -0.1740],\n",
            "        [-0.0499, -0.0182, -0.0033, -0.2612,  0.1046,  0.1527, -0.2250,  0.1123,\n",
            "          0.3199,  0.0036, -0.0979,  0.0189,  0.4894,  0.1434,  0.0015,  0.1857],\n",
            "        [-0.0472, -0.2177, -0.3356, -0.2372, -0.1786, -0.0646,  0.1518,  0.1087,\n",
            "          0.1342,  0.0026, -0.0035, -0.0459,  0.0608,  0.1693, -0.1012, -0.1482],\n",
            "        [ 0.2154,  0.1541, -0.2505,  0.0957, -0.0772, -0.0424, -0.0055,  0.0201,\n",
            "          0.1128, -0.0870,  0.1013, -0.2620,  0.1731,  0.1945, -0.1662, -0.1743],\n",
            "        [ 0.0804,  0.2025,  0.1082,  0.1488,  0.0771, -0.1524, -0.0055,  0.1546,\n",
            "          0.0714,  0.0475,  0.0299, -0.0967, -0.2741, -0.1917, -0.2107,  0.1779],\n",
            "        [ 0.0226,  0.2049, -0.0964, -0.1163, -0.3449,  0.1606, -0.2469, -0.1766,\n",
            "          0.0112,  0.1923,  0.1600,  0.0973,  0.0950,  0.1102,  0.2348,  0.0826],\n",
            "        [-0.1786, -0.0534, -0.1874, -0.2366, -0.2194, -0.2432, -0.1082, -0.0627,\n",
            "         -0.2210, -0.1653,  0.0558, -0.0767,  0.0716, -0.0069,  0.0766,  0.1254],\n",
            "        [ 0.0998, -0.0821, -0.0266,  0.3557, -0.1546,  0.1037, -0.1897, -0.1107,\n",
            "          0.2187, -0.1475,  0.0765, -0.0652, -0.1617, -0.2278, -0.1803, -0.0159],\n",
            "        [ 0.0723, -0.0547,  0.1122, -0.1597, -0.2257,  0.0456,  0.0558, -0.1876,\n",
            "         -0.1533,  0.0010, -0.0860,  0.1341, -0.0255, -0.1400, -0.2324, -0.0714],\n",
            "        [-0.1025,  0.2154, -0.1576, -0.0725, -0.3789, -0.1893,  0.0019, -0.0331,\n",
            "         -0.0127, -0.2737, -0.1962, -0.3930,  0.1908, -0.0846,  0.0596,  0.0310]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0779,  0.0979, -0.1855, -0.0197, -0.2061, -0.0197, -0.0312, -0.1266,\n",
            "         0.1745,  0.1747,  0.1095,  0.0302, -0.2134,  0.1202,  0.1321, -0.0621,\n",
            "        -0.0627,  0.1290, -0.1620,  0.2175, -0.1138, -0.1350,  0.0453, -0.1198,\n",
            "         0.1928,  0.0903, -0.2025, -0.2451, -0.0756, -0.0444,  0.1104,  0.2030],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.0050,  0.1012, -0.1624,  0.0061,  0.0033, -0.0260,  0.0611, -0.0235,\n",
            "          0.0087,  0.0359, -0.1329,  0.0868, -0.0292,  0.0288, -0.0205, -0.0243,\n",
            "          0.0543,  0.1526,  0.1952, -0.0964,  0.0931,  0.0370, -0.0143, -0.0043,\n",
            "          0.0086, -0.0133, -0.3197,  0.1091, -0.1526,  0.0273,  0.1383, -0.1366]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0110], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 200 0.99"
      ],
      "metadata": {
        "id": "TRlCPzkUEvi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e = experiment_actions(200, env, P_pi_e)"
      ],
      "metadata": {
        "id": "Hn4yWSa6Ey1b"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env_30, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e = experiment_actions(200, env, P_pi_e)\n",
        "model_200_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float64)\n",
        "test_200_0p99 = SCOPE_straight(model_200_0p99, 0.99, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFPqTUz9EzVg",
        "outputId": "c24dbb18-401e-4404-e503-19176586c47b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.8547, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.8546716723749704\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.8345, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.8344950296004069\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.8157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.815702575610253\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7972, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7971985257757953\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7790, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7790125020004666\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7612, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.761163863570924\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7437, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7436643420651126\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7265, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7265202843486895\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7097352689463908\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6937, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6936950996361412\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6787, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6787496091902381\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6641, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6641326426056419\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6491, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6491106577802083\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6334, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6333667722630629\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6176, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6176165169242289\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6019587691009125\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5865, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5864614333403655\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5712, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5711710016875733\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5561, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5561201093237699\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5413, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5413312509285723\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5268, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5268211222619228\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5127662288046468\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4991, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4990903180712609\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4857, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.48571725956488965\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4727, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4726511735617668\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4599, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.45988918164358644\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4474, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.44742813206934556\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4353, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4352655622205185\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4234, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4233983242252763\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4118227108286335\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4021134038855513\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3926, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.39257963185991446\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3831, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.38308203997671986\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3737, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.3736948442815689\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3645, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.36445031056541616\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3554, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.35536750421714974\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3465, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.34645815470296126\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3377, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.3377294703442143\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.32871648276595317\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.31790126888277037\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.3070625734259544\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2963, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.29627239376597064\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2856, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.28558616595403796\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2750, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.27504909881481915\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2647, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.26469327157199624\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2545, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.25454693646675536\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2446, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.24462840025074462\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2350, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.234953140051005\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2255, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.22553328412755216\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.21637794682926711\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.20765838692198108\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1994, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.19944057999559758\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1914, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.19136714645965625\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1835, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.18345732333640694\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1757, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.17572677515007384\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1682, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.16818803679903824\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1609, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.16090624467500525\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1541, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.1541089350798193\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1475, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.14753160424431366\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1412, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.14117376185585162\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1350, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.1350122598852806\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12905755269560512\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12331488088602341\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1178, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.11778112624286458\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.11245276892457491\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.10736790659156419\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.1025438984825482\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0979, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.09787412170464208\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0933, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.09334454892496756\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0890, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.088957830242839\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0847, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.08471570257624039\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0806, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.08061900739904902\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0767, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0766678274095598\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0729, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.07286188557593551\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0692, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.06919982278324037\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0657, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.06567997995547233\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0623, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.06230029651117082\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0591, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.059058377477843316\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0559, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.05594751305442548\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0530, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.052966288055453295\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0501, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.050113888317941106\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0474, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04738722108288303\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0448, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04478295871729696\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0423, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04229763834861956\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0399, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.03992773570038501\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0377, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.037669457929341316\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0355, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0355193769124232\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0335, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.03347395745564995\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.031529609108374254\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.02968271250845121\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.027932768635906338\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0263, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.026305800771803944\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0248, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.024764322857021973\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.02330437486812094\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0219, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.02192264482312758\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0206, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.020615676357044713\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.01938006119066497\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0182, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.018212120834255302\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0171, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.017108966523152948\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0161, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.016066395022520556\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.015082014883762413\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0142, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.014153956836780278\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.013279728808191522\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.012457231985769056\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.011683105457310276\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.011342913577924043\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.011180702497889685\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.011022237359410294\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010869776597278611\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010719522645914525\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010574777320221747\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010437090352892598\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010304455074789026\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010176327263684923\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010054057177073139\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009935777820803718\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009820751026385733\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00970874948631789\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009599568012298087\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00949302114531486\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009388941046875874\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00928717563506485\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009187586934257173\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009090049611678653\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008994449677683479\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008900683329802086\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008808655923198792\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008718281052589538\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00862947973253226\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008542179664715939\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008456314584310247\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008371823668269196\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008288661209704297\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008206768155038686\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008127881769166252\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008053068775143953\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007975731942808041\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007896228550827554\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007821717120735011\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00774887220816159\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007676765820170244\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007605394924886864\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007534756645308239\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007464847531560026\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007395663626410915\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007327200524725006\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007259453427351505\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007192417678624616\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007126087383820872\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007060456797068244\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006995519991076635\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006931270845352345\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006867703074766262\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006804810257151416\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006744395701342055\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006683942467567038\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006622084782085688\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006562973766531543\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006504374055503997\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0064462946883922885\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006388741330523116\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00633171551006158\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006275219631772799\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006219282434222159\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006164465507695038\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0061101379558747585\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006056278845595384\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006002893239057439\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005949985106260439\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005898682865317154\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005846501613345426\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005795741430318968\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005745371177043594\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005695388445082429\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005645809115981477\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005597565871908052\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005548486469223402\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005500687588614943\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005453322596869906\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005406428182001911\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00535991919315069\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005313930317373878\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005268645073306434\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005223825966489567\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0051793524821357765\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005135232092539864\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005091471085501814\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005048074801492975\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005005651857176431\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00496293353017183\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004921147681785879\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004879736006744593\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004838633802147718\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004797849085388216\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004758342649854319\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004717834883760589\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004678563087059537\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004639583265879986\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004600902497375698\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004562558611391957\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004524752132582197\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004487267497615992\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004450305403283982\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004413621927511726\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004380276312199833\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004347794941432448\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004312246269516688\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004277212033990483\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004240766660121044\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004203105753520934\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004167187609976871\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0041274968982973614\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004088275959400935\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004049404203066784\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004009802907216467\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003969598803202217\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003931009339283031\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0038909835262761774\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003852249326284995\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0038154266741377988\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0037782966894316958\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0037406923524199525\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0037027104211728615\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0036644387059539844\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0036259561758741343\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0035873340671417693\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0035498575816885532\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0035137252880671163\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0034771764375151324\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0034406799530181617\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0034050940073021858\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003369205994145485\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0033330940652911457\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0032975089801288247\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003263995372325778\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003229933705532338\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003194965188322567\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0031614555083920876\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003128298186928097\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003095087022228678\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0030624423837157322\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0030296016042369524\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0029968038042988312\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0029648621633291913\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0029336828362678978\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002902063357916683\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002871873313538257\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002841618716728247\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0028118252567851626\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0027819871259834672\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0027521081311857945\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0027222301530419775\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002694197551154959\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0026660688744658124\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002637505433064731\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0026084026861855005\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002580850796633104\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00255380875616087\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0025267630039775843\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00250001731427122\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0024733673118707213\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002447453594632654\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0024215791143245126\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002396174798345287\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0023707946409597946\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0023454885158656815\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0023205889623067757\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0022961210399871264\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002272196914480386\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0022482202971244496\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0022242332146298702\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0022015418178001874\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0021786352210143543\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0021552920226886076\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0021327727917707317\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002110641087452761\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0020887613356420746\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0020668416786557365\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002044915099760511\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002023322519608584\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002002763615305977\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001982121914126294\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0019612276218746844\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001940268246372342\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001920379034445509\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0019004476057686171\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018805071867076574\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018611948164111507\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018419817386779612\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018230014607385399\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018041461237785325\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0017855587760095897\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0017669611615841435\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001749272264864262\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0017315572465489608\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0017134210936991957\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0016959944185007871\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001678989113777594\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0016620447517144107\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0016450720030536927\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001628099743668732\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0016111489750585289\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015954247655366439\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001579632828789209\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015634376479176488\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015471617564655573\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015319451038816152\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001516574396806452\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015010398515153598\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014853835457157199\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014697745268949162\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001454085361399833\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014382371258495094\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014231376927888912\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014082641480695005\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013940163722198813\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013775471158843954\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001362554621608391\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013456469770667032\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013282705151685204\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013104633615438981\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0012922268404032041\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001273853847479378\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0012557244089278668\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0012373629313586227\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0012177641314448534\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011977798007275515\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011782542286178535\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011585501652845904\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011346905256367043\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011041609069554013\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0010744883525759382\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0010441761847287943\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0010143799094075097\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0009848751401308508\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000955346152842433\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000923429748031222\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000891988612060904\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008620014901299793\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008330483619741713\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000804933611751626\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007774862353237556\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007508325484410617\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007255744901805848\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007013321125494831\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006782316782719347\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006564792524678985\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006357222359547283\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006060479559767884\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005757659998306523\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005527655179251005\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005354388693546488\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005215574141305902\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005106774329698534\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000501490453558698\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004928403230214485\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00048424476755108556\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004746704877561292\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004641593668757794\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00045332896497080353\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004425779553906703\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004314530582880676\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004202141836297342\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00040927741231566267\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003990015951528856\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00038955485631928796\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00038100944125670107\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003733366079823045\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003665685855314465\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00036033234734610727\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00035458788503525316\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000348058630473583\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033947873307019547\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033025998788080327\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003205026866896507\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00031046374798354893\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003001810798512492\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028982515711268263\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00027966795437917686\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00027030744434853053\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002627508230190878\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002555573467011567\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002486300651710869\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002421377087176469\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023608910347038263\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002304596087958113\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022509120144213618\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021993870692853243\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002149928057170318\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021025006153355157\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002057025268646185\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020131042512004977\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001970658355520743\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00019297794080183142\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018914210640103555\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018551038882905365\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001820520038178839\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017876948726092996\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001756626742500793\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017273369147808137\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016997469611855585\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016734929977990464\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016485231447057835\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016249194240447365\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001602472935378069\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015810488819045652\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015605248952082668\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015406964834989092\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015220250459948174\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001504320532635276\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001487337350639054\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001470971649972191\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001455207784503063\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014400657688069777\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014254782019648297\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001411392067566479\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013977735136350703\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013845931181420874\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013718221015337258\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001359333556896158\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001347192116079215\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013353819263737756\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013238820356297005\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013126718144396013\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013017346693689578\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012910573585163182\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012806230548860037\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012704166120768427\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012604250441508081\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001250636492978868\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001241040224849837\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012316266113518632\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012223870754101974\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001213314099062881\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012043013120516517\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011951294546292964\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011860824418407979\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011771542270500585\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011683455388081289\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011596566650270851\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011510881796107951\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001142640798546647\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011343154017157597\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011261141396677496\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011180367323267924\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011100854528419645\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011022970784588333\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001094688779074053\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010872155927584015\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010798761796236049\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010726910582915247\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010656538911198648\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010587508340766908\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010519822356570929\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001045348510920827\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010388501014020814\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010324874420823071\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010262609330777083\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010201709167558936\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010142176598871864\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001008401340523783\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010027222489698721\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9718e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.971796432054721e-05\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9177e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.917734263558461e-05\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8650e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.865044255195552e-05\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8137e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.813712776023634e-05\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7637e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.763735251167343e-05\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7151e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.715105542997485e-05\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6678e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.667815116795096e-05\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6218e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.62183189122225e-05\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5771e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.577145001745294e-05\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5338e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.53376261741958e-05\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4917e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.491671238201975e-05\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4508e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.450775290575526e-05\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4059e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.405935422179418e-05\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3597e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.359653799068847e-05\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3126e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.312629750715886e-05\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2658e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.265782626688734e-05\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2200e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.219950800967883e-05\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1758e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.175833767677823e-05\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1340e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.133958048126332e-05\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0949e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.094910363344034e-05\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0593e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.059317598010678e-05\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0265e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.026539483706539e-05\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9965e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.99645076167691e-05\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9688e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.968811981540364e-05\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9432e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.943193887280256e-05\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9194e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.919390185573453e-05\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8971e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.897073091099512e-05\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8759e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.875940048325994e-05\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8557e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.855731514465743e-05\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8363e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.836257676649113e-05\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8175e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.817460024874166e-05\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7992e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.799184564323814e-05\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7813e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.781347917973461e-05\n",
            "----------------------------------------\n",
            "Epoch 501\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7639e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.763938405703171e-05\n",
            "----------------------------------------\n",
            "Epoch 502\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7470e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.746971101505755e-05\n",
            "----------------------------------------\n",
            "Epoch 503\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7305e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.730476729562923e-05\n",
            "----------------------------------------\n",
            "Epoch 504\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7145e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.714491574094922e-05\n",
            "----------------------------------------\n",
            "Epoch 505\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6990e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.69899424100473e-05\n",
            "----------------------------------------\n",
            "Epoch 506\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6840e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.684038753342556e-05\n",
            "----------------------------------------\n",
            "Epoch 507\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6697e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.669677563473562e-05\n",
            "----------------------------------------\n",
            "Epoch 508\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6559e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.65590087099747e-05\n",
            "----------------------------------------\n",
            "Epoch 509\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6431e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.64311804421734e-05\n",
            "----------------------------------------\n",
            "Epoch 510\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6310e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.630993948637582e-05\n",
            "----------------------------------------\n",
            "Epoch 511\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6193e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.61928003915945e-05\n",
            "----------------------------------------\n",
            "Epoch 512\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6079e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.607930191262107e-05\n",
            "----------------------------------------\n",
            "Epoch 513\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5969e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.596908086196596e-05\n",
            "----------------------------------------\n",
            "Epoch 514\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5862e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.586194157876907e-05\n",
            "----------------------------------------\n",
            "Epoch 515\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5758e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.575758313234516e-05\n",
            "----------------------------------------\n",
            "Epoch 516\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5656e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.565554644026795e-05\n",
            "----------------------------------------\n",
            "Epoch 517\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5556e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.555563211143476e-05\n",
            "----------------------------------------\n",
            "Epoch 518\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5458e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.545768507962494e-05\n",
            "----------------------------------------\n",
            "Epoch 519\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5362e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.53615860155631e-05\n",
            "----------------------------------------\n",
            "Epoch 520\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5267e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.526724609894265e-05\n",
            "----------------------------------------\n",
            "Epoch 521\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5175e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.517459033074577e-05\n",
            "----------------------------------------\n",
            "Epoch 522\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5084e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.508358727779532e-05\n",
            "----------------------------------------\n",
            "Epoch 523\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4994e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.499420292741217e-05\n",
            "----------------------------------------\n",
            "Epoch 524\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4906e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.490631406836577e-05\n",
            "----------------------------------------\n",
            "Epoch 525\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4820e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.48198521573866e-05\n",
            "----------------------------------------\n",
            "Epoch 526\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4735e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.473474125613863e-05\n",
            "----------------------------------------\n",
            "Epoch 527\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4651e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.465089753141982e-05\n",
            "----------------------------------------\n",
            "Epoch 528\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4568e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.456823000753702e-05\n",
            "----------------------------------------\n",
            "Epoch 529\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4487e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.448664227857084e-05\n",
            "----------------------------------------\n",
            "Epoch 530\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4406e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.440646452620853e-05\n",
            "----------------------------------------\n",
            "Epoch 531\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4327e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.432741854775503e-05\n",
            "----------------------------------------\n",
            "Epoch 532\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4249e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.424895572316617e-05\n",
            "----------------------------------------\n",
            "Epoch 533\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4171e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.417103313033832e-05\n",
            "----------------------------------------\n",
            "Epoch 534\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4094e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.409357514206891e-05\n",
            "----------------------------------------\n",
            "Epoch 535\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4017e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.401651964757775e-05\n",
            "----------------------------------------\n",
            "Epoch 536\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3940e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.39398826000485e-05\n",
            "----------------------------------------\n",
            "Epoch 537\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3864e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.386352707294488e-05\n",
            "----------------------------------------\n",
            "Epoch 538\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3787e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.378747020662781e-05\n",
            "----------------------------------------\n",
            "Epoch 539\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3712e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.371166187470494e-05\n",
            "----------------------------------------\n",
            "Epoch 540\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3636e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.363593039234458e-05\n",
            "----------------------------------------\n",
            "Epoch 541\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3561e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.356096997799295e-05\n",
            "----------------------------------------\n",
            "Epoch 542\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3486e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.348626756731773e-05\n",
            "----------------------------------------\n",
            "Epoch 543\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3412e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.34115507702473e-05\n",
            "----------------------------------------\n",
            "Epoch 544\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3338e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.333765923415715e-05\n",
            "----------------------------------------\n",
            "Epoch 545\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3264e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.326407319956006e-05\n",
            "----------------------------------------\n",
            "Epoch 546\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3191e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.319064510354874e-05\n",
            "----------------------------------------\n",
            "Epoch 547\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3117e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.31173842354559e-05\n",
            "----------------------------------------\n",
            "Epoch 548\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3044e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.3044288367534e-05\n",
            "----------------------------------------\n",
            "Epoch 549\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2971e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.297136597554558e-05\n",
            "----------------------------------------\n",
            "Epoch 550\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2899e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.289854047052946e-05\n",
            "----------------------------------------\n",
            "Epoch 551\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2826e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.282615017540665e-05\n",
            "----------------------------------------\n",
            "Epoch 552\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2754e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.275382279707811e-05\n",
            "----------------------------------------\n",
            "Epoch 553\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2682e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.268159947965978e-05\n",
            "----------------------------------------\n",
            "Epoch 554\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2610e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.2609715342976e-05\n",
            "----------------------------------------\n",
            "Epoch 555\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2538e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.253812088678584e-05\n",
            "----------------------------------------\n",
            "Epoch 556\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2467e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.246666018143786e-05\n",
            "----------------------------------------\n",
            "Epoch 557\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2395e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.239520193852635e-05\n",
            "----------------------------------------\n",
            "Epoch 558\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2324e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.232394522966604e-05\n",
            "----------------------------------------\n",
            "Epoch 559\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2253e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.225303437098097e-05\n",
            "----------------------------------------\n",
            "Epoch 560\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2182e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.218213516197201e-05\n",
            "----------------------------------------\n",
            "Epoch 561\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2111e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.211136303639088e-05\n",
            "----------------------------------------\n",
            "Epoch 562\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2041e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.20408098629851e-05\n",
            "----------------------------------------\n",
            "Epoch 563\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1970e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.197028144371378e-05\n",
            "----------------------------------------\n",
            "Epoch 564\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1900e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.18999610969623e-05\n",
            "----------------------------------------\n",
            "Epoch 565\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1830e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.182980165694709e-05\n",
            "----------------------------------------\n",
            "Epoch 566\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1760e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.175965442802085e-05\n",
            "----------------------------------------\n",
            "Epoch 567\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1690e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.168959240002508e-05\n",
            "----------------------------------------\n",
            "Epoch 568\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1620e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.161989120029467e-05\n",
            "----------------------------------------\n",
            "Epoch 569\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1550e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.155021883859295e-05\n",
            "----------------------------------------\n",
            "Epoch 570\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1481e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.148057507956001e-05\n",
            "----------------------------------------\n",
            "Epoch 571\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1411e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.14109700299364e-05\n",
            "----------------------------------------\n",
            "Epoch 572\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1342e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.13416664639278e-05\n",
            "----------------------------------------\n",
            "Epoch 573\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1273e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.127252182735469e-05\n",
            "----------------------------------------\n",
            "Epoch 574\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1203e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.120346165988403e-05\n",
            "----------------------------------------\n",
            "Epoch 575\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1134e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.113443062908621e-05\n",
            "----------------------------------------\n",
            "Epoch 576\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1066e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.106550543101298e-05\n",
            "----------------------------------------\n",
            "Epoch 577\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0997e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.099682260577192e-05\n",
            "----------------------------------------\n",
            "Epoch 578\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.092826554598626e-05\n",
            "----------------------------------------\n",
            "Epoch 579\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0860e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.085976961380725e-05\n",
            "----------------------------------------\n",
            "Epoch 580\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0792e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.079150126311066e-05\n",
            "----------------------------------------\n",
            "Epoch 581\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0723e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.072333723707361e-05\n",
            "----------------------------------------\n",
            "Epoch 582\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0655e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.065519037997213e-05\n",
            "----------------------------------------\n",
            "Epoch 583\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0587e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.058712436869413e-05\n",
            "----------------------------------------\n",
            "Epoch 584\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0519e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.051934615795742e-05\n",
            "----------------------------------------\n",
            "Epoch 585\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0452e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.045160626786896e-05\n",
            "----------------------------------------\n",
            "Epoch 586\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0384e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.038401577358519e-05\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0316e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.031647978007902e-05\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0249e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.02491419478247e-05\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0182e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.018191075322592e-05\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0115e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.011493082633144e-05\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0048e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.004806183112009e-05\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9981e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.998122930650098e-05\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9915e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.99148289766466e-05\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9849e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.984852973227115e-05\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9782e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.978218028028097e-05\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9716e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.971614917644634e-05\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9650e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.965019920845874e-05\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9584e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.958443164274485e-05\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9519e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.951878356755504e-05\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9453e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.94531375994869e-05\n",
            "----------------------------------------\n",
            "Epoch 601\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9388e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.93877841178286e-05\n",
            "----------------------------------------\n",
            "Epoch 602\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9322e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.9322464705968e-05\n",
            "----------------------------------------\n",
            "Epoch 603\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9257e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.925724218326754e-05\n",
            "----------------------------------------\n",
            "Epoch 604\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9192e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.919221080575382e-05\n",
            "----------------------------------------\n",
            "Epoch 605\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9127e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.912728412545479e-05\n",
            "----------------------------------------\n",
            "Epoch 606\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9063e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.906252054365199e-05\n",
            "----------------------------------------\n",
            "Epoch 607\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8998e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.89978091748467e-05\n",
            "----------------------------------------\n",
            "Epoch 608\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8933e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.893315825922105e-05\n",
            "----------------------------------------\n",
            "Epoch 609\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8869e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.8868732797984e-05\n",
            "----------------------------------------\n",
            "Epoch 610\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8804e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.880435738684894e-05\n",
            "----------------------------------------\n",
            "Epoch 611\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8740e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.874014359531318e-05\n",
            "----------------------------------------\n",
            "Epoch 612\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8676e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.867603733819493e-05\n",
            "----------------------------------------\n",
            "Epoch 613\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8612e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.861196749723857e-05\n",
            "----------------------------------------\n",
            "Epoch 614\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8548e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.854825663507851e-05\n",
            "----------------------------------------\n",
            "Epoch 615\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8484e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.848447603705441e-05\n",
            "----------------------------------------\n",
            "Epoch 616\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8421e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.842072258408149e-05\n",
            "----------------------------------------\n",
            "Epoch 617\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8357e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.835723162157456e-05\n",
            "----------------------------------------\n",
            "Epoch 618\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8294e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.829383167876025e-05\n",
            "----------------------------------------\n",
            "Epoch 619\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8230e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.823046770215592e-05\n",
            "----------------------------------------\n",
            "Epoch 620\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8167e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.816716925972018e-05\n",
            "----------------------------------------\n",
            "Epoch 621\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8104e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.810427547969237e-05\n",
            "----------------------------------------\n",
            "Epoch 622\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8041e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.804127199941432e-05\n",
            "----------------------------------------\n",
            "Epoch 623\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7978e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.797831514664392e-05\n",
            "----------------------------------------\n",
            "Epoch 624\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7916e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.791557922057309e-05\n",
            "----------------------------------------\n",
            "Epoch 625\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7853e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.785297924061715e-05\n",
            "----------------------------------------\n",
            "Epoch 626\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7790e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.779044294233166e-05\n",
            "----------------------------------------\n",
            "Epoch 627\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7728e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.772802723658548e-05\n",
            "----------------------------------------\n",
            "Epoch 628\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7666e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.766567362418125e-05\n",
            "----------------------------------------\n",
            "Epoch 629\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7603e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.760338771666893e-05\n",
            "----------------------------------------\n",
            "Epoch 630\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7541e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.754135776581682e-05\n",
            "----------------------------------------\n",
            "Epoch 631\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7479e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.747941058721277e-05\n",
            "----------------------------------------\n",
            "Epoch 632\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7418e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.741750380699572e-05\n",
            "----------------------------------------\n",
            "Epoch 633\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7356e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.735574758320975e-05\n",
            "----------------------------------------\n",
            "Epoch 634\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7294e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.729403497873552e-05\n",
            "----------------------------------------\n",
            "Epoch 635\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7233e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.72326171852106e-05\n",
            "----------------------------------------\n",
            "Epoch 636\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7171e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.717135198065069e-05\n",
            "----------------------------------------\n",
            "Epoch 637\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7110e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.711004071606e-05\n",
            "----------------------------------------\n",
            "Epoch 638\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7049e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.704897613239586e-05\n",
            "----------------------------------------\n",
            "Epoch 639\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6988e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.698797958170155e-05\n",
            "----------------------------------------\n",
            "Epoch 640\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.692766199002758e-05\n",
            "----------------------------------------\n",
            "Epoch 641\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6868e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.686785619342311e-05\n",
            "----------------------------------------\n",
            "Epoch 642\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6808e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.680840129182385e-05\n",
            "----------------------------------------\n",
            "Epoch 643\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6749e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.674919505809426e-05\n",
            "----------------------------------------\n",
            "Epoch 644\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6690e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.669041295195246e-05\n",
            "----------------------------------------\n",
            "Epoch 645\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6632e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.663191924715133e-05\n",
            "----------------------------------------\n",
            "Epoch 646\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6574e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.657374397508109e-05\n",
            "----------------------------------------\n",
            "Epoch 647\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6516e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.651586728813478e-05\n",
            "----------------------------------------\n",
            "Epoch 648\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6458e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.645847455847045e-05\n",
            "----------------------------------------\n",
            "Epoch 649\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6401e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.640117897393993e-05\n",
            "----------------------------------------\n",
            "Epoch 650\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6344e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.634449543611681e-05\n",
            "----------------------------------------\n",
            "Epoch 651\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6288e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.628807469075689e-05\n",
            "----------------------------------------\n",
            "Epoch 652\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6232e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.623190961624487e-05\n",
            "----------------------------------------\n",
            "Epoch 653\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6176e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.617600340950899e-05\n",
            "----------------------------------------\n",
            "Epoch 654\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6120e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.612035809976075e-05\n",
            "----------------------------------------\n",
            "Epoch 655\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6065e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.60650006824153e-05\n",
            "----------------------------------------\n",
            "Epoch 656\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6010e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.601006382067951e-05\n",
            "----------------------------------------\n",
            "Epoch 657\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5955e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.595537700272362e-05\n",
            "----------------------------------------\n",
            "Epoch 658\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5901e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.590102536981254e-05\n",
            "----------------------------------------\n",
            "Epoch 659\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5847e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.584700085705074e-05\n",
            "----------------------------------------\n",
            "Epoch 660\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5793e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.579319175714673e-05\n",
            "----------------------------------------\n",
            "Epoch 661\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5740e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.573993315995991e-05\n",
            "----------------------------------------\n",
            "Epoch 662\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5687e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.568725034162923e-05\n",
            "----------------------------------------\n",
            "Epoch 663\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5635e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.563495296705626e-05\n",
            "----------------------------------------\n",
            "Epoch 664\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5583e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.558278964112198e-05\n",
            "----------------------------------------\n",
            "Epoch 665\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5531e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.553104616145819e-05\n",
            "----------------------------------------\n",
            "Epoch 666\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5480e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.547959048376596e-05\n",
            "----------------------------------------\n",
            "Epoch 667\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5428e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.542833196344196e-05\n",
            "----------------------------------------\n",
            "Epoch 668\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5377e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.537726762170067e-05\n",
            "----------------------------------------\n",
            "Epoch 669\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5326e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.53263944058334e-05\n",
            "----------------------------------------\n",
            "Epoch 670\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5276e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.527577161651583e-05\n",
            "----------------------------------------\n",
            "Epoch 671\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5225e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.522546797149643e-05\n",
            "----------------------------------------\n",
            "Epoch 672\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5175e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.517525925411886e-05\n",
            "----------------------------------------\n",
            "Epoch 673\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5125e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.512533856614406e-05\n",
            "----------------------------------------\n",
            "Epoch 674\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5076e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.507566883216213e-05\n",
            "----------------------------------------\n",
            "Epoch 675\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5026e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.502614926838012e-05\n",
            "----------------------------------------\n",
            "Epoch 676\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4977e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.497683594369246e-05\n",
            "----------------------------------------\n",
            "Epoch 677\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.492766848678513e-05\n",
            "----------------------------------------\n",
            "Epoch 678\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4879e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.487877567595169e-05\n",
            "----------------------------------------\n",
            "Epoch 679\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4830e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.48300841867039e-05\n",
            "----------------------------------------\n",
            "Epoch 680\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4781e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.47814356545497e-05\n",
            "----------------------------------------\n",
            "Epoch 681\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4733e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.473297406011866e-05\n",
            "----------------------------------------\n",
            "Epoch 682\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4685e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.468470036065293e-05\n",
            "----------------------------------------\n",
            "Epoch 683\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4637e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.463669524411134e-05\n",
            "----------------------------------------\n",
            "Epoch 684\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4589e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.458870437657646e-05\n",
            "----------------------------------------\n",
            "Epoch 685\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4541e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.454090491363197e-05\n",
            "----------------------------------------\n",
            "Epoch 686\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4493e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.449324728676247e-05\n",
            "----------------------------------------\n",
            "Epoch 687\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4446e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.444569608043214e-05\n",
            "----------------------------------------\n",
            "Epoch 688\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4398e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.439827805483982e-05\n",
            "----------------------------------------\n",
            "Epoch 689\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4351e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.435106165701532e-05\n",
            "----------------------------------------\n",
            "Epoch 690\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4304e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.430394889765936e-05\n",
            "----------------------------------------\n",
            "Epoch 691\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4257e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.425694413848716e-05\n",
            "----------------------------------------\n",
            "Epoch 692\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4210e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.421001025948914e-05\n",
            "----------------------------------------\n",
            "Epoch 693\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4163e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.416326922399905e-05\n",
            "----------------------------------------\n",
            "Epoch 694\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4117e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.41166226281267e-05\n",
            "----------------------------------------\n",
            "Epoch 695\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4070e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.40702698167927e-05\n",
            "----------------------------------------\n",
            "Epoch 696\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4024e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.402444513899813e-05\n",
            "----------------------------------------\n",
            "Epoch 697\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3979e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.397853663994796e-05\n",
            "----------------------------------------\n",
            "Epoch 698\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3933e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.393262510319124e-05\n",
            "----------------------------------------\n",
            "Epoch 699\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3887e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.38867956721549e-05\n",
            "----------------------------------------\n",
            "Epoch 700\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3841e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.384092967432305e-05\n",
            "----------------------------------------\n",
            "Epoch 701\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3795e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.379503743927028e-05\n",
            "----------------------------------------\n",
            "Epoch 702\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3749e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.374936994324875e-05\n",
            "----------------------------------------\n",
            "Epoch 703\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3704e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.370416236765796e-05\n",
            "----------------------------------------\n",
            "Epoch 704\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3659e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.365897554814992e-05\n",
            "----------------------------------------\n",
            "Epoch 705\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3614e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.361382937793085e-05\n",
            "----------------------------------------\n",
            "Epoch 706\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3569e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.356872829362663e-05\n",
            "----------------------------------------\n",
            "Epoch 707\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3524e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.352369604188031e-05\n",
            "----------------------------------------\n",
            "Epoch 708\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3479e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.347872210452653e-05\n",
            "----------------------------------------\n",
            "Epoch 709\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3434e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.343381190395092e-05\n",
            "----------------------------------------\n",
            "Epoch 710\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3389e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.338921794002941e-05\n",
            "----------------------------------------\n",
            "Epoch 711\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3345e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.334475026805207e-05\n",
            "----------------------------------------\n",
            "Epoch 712\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.330031474525746e-05\n",
            "----------------------------------------\n",
            "Epoch 713\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3256e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.325579643007365e-05\n",
            "----------------------------------------\n",
            "Epoch 714\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3211e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.321147441559433e-05\n",
            "----------------------------------------\n",
            "Epoch 715\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3167e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.31673901865099e-05\n",
            "----------------------------------------\n",
            "Epoch 716\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3123e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.312331743455844e-05\n",
            "----------------------------------------\n",
            "Epoch 717\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3079e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.307935533437162e-05\n",
            "----------------------------------------\n",
            "Epoch 718\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3035e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.303526459552834e-05\n",
            "----------------------------------------\n",
            "Epoch 719\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2991e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.299139353457374e-05\n",
            "----------------------------------------\n",
            "Epoch 720\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2948e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.294772471202691e-05\n",
            "----------------------------------------\n",
            "Epoch 721\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2904e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.290398462527016e-05\n",
            "----------------------------------------\n",
            "Epoch 722\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2861e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.286051818357266e-05\n",
            "----------------------------------------\n",
            "Epoch 723\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2817e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.28170715621852e-05\n",
            "----------------------------------------\n",
            "Epoch 724\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2774e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.277366065767547e-05\n",
            "----------------------------------------\n",
            "Epoch 725\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2730e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.273023586741673e-05\n",
            "----------------------------------------\n",
            "Epoch 726\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2687e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.268687888914892e-05\n",
            "----------------------------------------\n",
            "Epoch 727\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2644e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.264367862974162e-05\n",
            "----------------------------------------\n",
            "Epoch 728\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2600e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.260049506115391e-05\n",
            "----------------------------------------\n",
            "Epoch 729\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2558e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.255755655945307e-05\n",
            "----------------------------------------\n",
            "Epoch 730\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2515e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.251456782847813e-05\n",
            "----------------------------------------\n",
            "Epoch 731\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2472e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.247169457300482e-05\n",
            "----------------------------------------\n",
            "Epoch 732\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2429e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.242900938247754e-05\n",
            "----------------------------------------\n",
            "Epoch 733\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2386e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.238636460542914e-05\n",
            "----------------------------------------\n",
            "Epoch 734\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2344e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.234366811998881e-05\n",
            "----------------------------------------\n",
            "Epoch 735\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2301e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.230097893721285e-05\n",
            "----------------------------------------\n",
            "Epoch 736\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2258e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.22584062940956e-05\n",
            "----------------------------------------\n",
            "Epoch 737\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2216e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.221595982763161e-05\n",
            "----------------------------------------\n",
            "Epoch 738\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2174e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.217353508631529e-05\n",
            "----------------------------------------\n",
            "Epoch 739\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2131e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.213115733253307e-05\n",
            "----------------------------------------\n",
            "Epoch 740\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2089e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.208897539836721e-05\n",
            "----------------------------------------\n",
            "Epoch 741\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2047e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.204681938003631e-05\n",
            "----------------------------------------\n",
            "Epoch 742\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2004e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.200449733333167e-05\n",
            "----------------------------------------\n",
            "Epoch 743\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1963e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.196262037955988e-05\n",
            "----------------------------------------\n",
            "Epoch 744\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1921e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.192073434863781e-05\n",
            "----------------------------------------\n",
            "Epoch 745\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1879e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.187877877945702e-05\n",
            "----------------------------------------\n",
            "Epoch 746\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1837e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.183682124364233e-05\n",
            "----------------------------------------\n",
            "Epoch 747\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1795e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.179481177623264e-05\n",
            "----------------------------------------\n",
            "Epoch 748\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1753e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.175310520061581e-05\n",
            "----------------------------------------\n",
            "Epoch 749\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1711e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.171135208038667e-05\n",
            "----------------------------------------\n",
            "Epoch 750\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1670e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.166974000224407e-05\n",
            "----------------------------------------\n",
            "Epoch 751\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1628e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.16282361466964e-05\n",
            "----------------------------------------\n",
            "Epoch 752\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1587e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.158668163504469e-05\n",
            "----------------------------------------\n",
            "Epoch 753\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1545e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.154515974602277e-05\n",
            "----------------------------------------\n",
            "Epoch 754\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1504e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.150367589475269e-05\n",
            "----------------------------------------\n",
            "Epoch 755\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1462e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.146231263796181e-05\n",
            "----------------------------------------\n",
            "Epoch 756\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1421e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.142082155075568e-05\n",
            "----------------------------------------\n",
            "Epoch 757\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1380e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.137963229987375e-05\n",
            "----------------------------------------\n",
            "Epoch 758\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1338e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.13384081020667e-05\n",
            "----------------------------------------\n",
            "Epoch 759\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1297e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.129708171149402e-05\n",
            "----------------------------------------\n",
            "Epoch 760\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1256e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.125573500221475e-05\n",
            "----------------------------------------\n",
            "Epoch 761\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1215e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.121485843271929e-05\n",
            "----------------------------------------\n",
            "Epoch 762\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1174e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.117389043379512e-05\n",
            "----------------------------------------\n",
            "Epoch 763\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1133e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.113279923851174e-05\n",
            "----------------------------------------\n",
            "Epoch 764\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1092e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.109157661547698e-05\n",
            "----------------------------------------\n",
            "Epoch 765\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1051e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.105073100339374e-05\n",
            "----------------------------------------\n",
            "Epoch 766\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1010e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.101001933086154e-05\n",
            "----------------------------------------\n",
            "Epoch 767\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0969e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.096932921913845e-05\n",
            "----------------------------------------\n",
            "Epoch 768\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.092833140996792e-05\n",
            "----------------------------------------\n",
            "Epoch 769\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0887e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.088744398199539e-05\n",
            "----------------------------------------\n",
            "Epoch 770\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0847e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.084687646017949e-05\n",
            "----------------------------------------\n",
            "Epoch 771\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0806e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.080640963826513e-05\n",
            "----------------------------------------\n",
            "Epoch 772\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0766e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.076578818928316e-05\n",
            "----------------------------------------\n",
            "Epoch 773\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0725e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.072503237948853e-05\n",
            "----------------------------------------\n",
            "Epoch 774\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0685e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.068456421559013e-05\n",
            "----------------------------------------\n",
            "Epoch 775\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0644e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.064428617174603e-05\n",
            "----------------------------------------\n",
            "Epoch 776\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0604e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.060396011712034e-05\n",
            "----------------------------------------\n",
            "Epoch 777\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0563e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.056344883070356e-05\n",
            "----------------------------------------\n",
            "Epoch 778\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0523e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.05229575459881e-05\n",
            "----------------------------------------\n",
            "Epoch 779\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0483e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.048282489795915e-05\n",
            "----------------------------------------\n",
            "Epoch 780\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0442e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.044194587160469e-05\n",
            "----------------------------------------\n",
            "Epoch 781\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0400e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.040044298914236e-05\n",
            "----------------------------------------\n",
            "Epoch 782\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0359e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.035888653185844e-05\n",
            "----------------------------------------\n",
            "Epoch 783\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0317e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.031714620957267e-05\n",
            "----------------------------------------\n",
            "Epoch 784\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0276e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.027555083311591e-05\n",
            "----------------------------------------\n",
            "Epoch 785\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0234e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.023393576855524e-05\n",
            "----------------------------------------\n",
            "Epoch 786\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0192e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.019195336515679e-05\n",
            "----------------------------------------\n",
            "Epoch 787\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0150e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.015012689966169e-05\n",
            "----------------------------------------\n",
            "Epoch 788\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0108e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.010831522111086e-05\n",
            "----------------------------------------\n",
            "Epoch 789\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0066e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.006646607402812e-05\n",
            "----------------------------------------\n",
            "Epoch 790\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0025e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.002475000513466e-05\n",
            "----------------------------------------\n",
            "Epoch 791\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9983e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.998284953674483e-05\n",
            "----------------------------------------\n",
            "Epoch 792\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9941e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.99412013432495e-05\n",
            "----------------------------------------\n",
            "Epoch 793\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9899e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.989949691870092e-05\n",
            "----------------------------------------\n",
            "Epoch 794\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9858e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.985772516945986e-05\n",
            "----------------------------------------\n",
            "Epoch 795\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9816e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.981585795748717e-05\n",
            "----------------------------------------\n",
            "Epoch 796\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9774e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.977422904280194e-05\n",
            "----------------------------------------\n",
            "Epoch 797\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9733e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.973252650350853e-05\n",
            "----------------------------------------\n",
            "Epoch 798\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9691e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.969086189223287e-05\n",
            "----------------------------------------\n",
            "Epoch 799\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9649e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.964947443171891e-05\n",
            "----------------------------------------\n",
            "Epoch 800\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9608e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.960792717960807e-05\n",
            "----------------------------------------\n",
            "Epoch 801\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9566e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.95662744421895e-05\n",
            "----------------------------------------\n",
            "Epoch 802\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9525e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.95247819575715e-05\n",
            "----------------------------------------\n",
            "Epoch 803\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9483e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.948342652339858e-05\n",
            "----------------------------------------\n",
            "Epoch 804\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9442e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.944199818752428e-05\n",
            "----------------------------------------\n",
            "Epoch 805\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9401e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.940080004375677e-05\n",
            "----------------------------------------\n",
            "Epoch 806\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9359e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.935938987605281e-05\n",
            "----------------------------------------\n",
            "Epoch 807\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9318e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.931795999867337e-05\n",
            "----------------------------------------\n",
            "Epoch 808\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9277e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.927685546350298e-05\n",
            "----------------------------------------\n",
            "Epoch 809\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9236e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.923569743238552e-05\n",
            "----------------------------------------\n",
            "Epoch 810\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9194e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.919435741421716e-05\n",
            "----------------------------------------\n",
            "Epoch 811\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9153e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.915322921044821e-05\n",
            "----------------------------------------\n",
            "Epoch 812\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9112e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.911223639449644e-05\n",
            "----------------------------------------\n",
            "Epoch 813\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9071e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.907111736062383e-05\n",
            "----------------------------------------\n",
            "Epoch 814\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9030e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.903020941565885e-05\n",
            "----------------------------------------\n",
            "Epoch 815\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8989e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.898902656062401e-05\n",
            "----------------------------------------\n",
            "Epoch 816\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8948e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.894825659258152e-05\n",
            "----------------------------------------\n",
            "Epoch 817\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8907e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.89073684897917e-05\n",
            "----------------------------------------\n",
            "Epoch 818\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8866e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.886646639393106e-05\n",
            "----------------------------------------\n",
            "Epoch 819\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8826e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.882570615993206e-05\n",
            "----------------------------------------\n",
            "Epoch 820\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8785e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.878511052529032e-05\n",
            "----------------------------------------\n",
            "Epoch 821\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8744e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.87443744520686e-05\n",
            "----------------------------------------\n",
            "Epoch 822\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8704e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.870385021399202e-05\n",
            "----------------------------------------\n",
            "Epoch 823\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8663e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.866333771684233e-05\n",
            "----------------------------------------\n",
            "Epoch 824\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8623e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.862269535514759e-05\n",
            "----------------------------------------\n",
            "Epoch 825\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8582e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.85822115549493e-05\n",
            "----------------------------------------\n",
            "Epoch 826\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8542e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.854185539938882e-05\n",
            "----------------------------------------\n",
            "Epoch 827\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8501e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.850134441875238e-05\n",
            "----------------------------------------\n",
            "Epoch 828\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8461e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.846109214844832e-05\n",
            "----------------------------------------\n",
            "Epoch 829\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8421e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.842086307994197e-05\n",
            "----------------------------------------\n",
            "Epoch 830\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8381e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.838055537026003e-05\n",
            "----------------------------------------\n",
            "Epoch 831\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8340e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.834008429315148e-05\n",
            "----------------------------------------\n",
            "Epoch 832\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.829993387423964e-05\n",
            "----------------------------------------\n",
            "Epoch 833\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8260e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.825990117838436e-05\n",
            "----------------------------------------\n",
            "Epoch 834\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8220e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.821981150192269e-05\n",
            "----------------------------------------\n",
            "Epoch 835\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8180e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.81797591385016e-05\n",
            "----------------------------------------\n",
            "Epoch 836\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8140e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.813976753061587e-05\n",
            "----------------------------------------\n",
            "Epoch 837\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8100e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.809985320032082e-05\n",
            "----------------------------------------\n",
            "Epoch 838\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8060e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.805997832282596e-05\n",
            "----------------------------------------\n",
            "Epoch 839\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8020e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.802005518375531e-05\n",
            "----------------------------------------\n",
            "Epoch 840\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7980e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.798020485112395e-05\n",
            "----------------------------------------\n",
            "Epoch 841\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7941e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.794068231846866e-05\n",
            "----------------------------------------\n",
            "Epoch 842\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7901e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.790099538589011e-05\n",
            "----------------------------------------\n",
            "Epoch 843\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7861e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.78611669673766e-05\n",
            "----------------------------------------\n",
            "Epoch 844\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7822e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.782166560645713e-05\n",
            "----------------------------------------\n",
            "Epoch 845\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7782e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.778223863089558e-05\n",
            "----------------------------------------\n",
            "Epoch 846\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7743e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.774256601037013e-05\n",
            "----------------------------------------\n",
            "Epoch 847\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7703e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.770300833185501e-05\n",
            "----------------------------------------\n",
            "Epoch 848\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7664e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.766367350624933e-05\n",
            "----------------------------------------\n",
            "Epoch 849\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7624e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.762419945269224e-05\n",
            "----------------------------------------\n",
            "Epoch 850\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7585e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.758497198482006e-05\n",
            "----------------------------------------\n",
            "Epoch 851\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7546e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.754574391137882e-05\n",
            "----------------------------------------\n",
            "Epoch 852\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7506e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.750636262256495e-05\n",
            "----------------------------------------\n",
            "Epoch 853\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7467e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.746729937916169e-05\n",
            "----------------------------------------\n",
            "Epoch 854\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7428e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.742822992405257e-05\n",
            "----------------------------------------\n",
            "Epoch 855\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7389e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.738911163743782e-05\n",
            "----------------------------------------\n",
            "Epoch 856\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7350e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.734984963249413e-05\n",
            "----------------------------------------\n",
            "Epoch 857\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7311e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.731110867152707e-05\n",
            "----------------------------------------\n",
            "Epoch 858\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7272e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.727227518297046e-05\n",
            "----------------------------------------\n",
            "Epoch 859\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7233e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.723333355156245e-05\n",
            "----------------------------------------\n",
            "Epoch 860\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7194e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.719424898851742e-05\n",
            "----------------------------------------\n",
            "Epoch 861\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7155e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.715530174201452e-05\n",
            "----------------------------------------\n",
            "Epoch 862\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7117e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.711666135414095e-05\n",
            "----------------------------------------\n",
            "Epoch 863\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7078e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.707789471002316e-05\n",
            "----------------------------------------\n",
            "Epoch 864\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7039e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.7039035552051e-05\n",
            "----------------------------------------\n",
            "Epoch 865\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7001e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.700058118220002e-05\n",
            "----------------------------------------\n",
            "Epoch 866\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6962e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.696208024428752e-05\n",
            "----------------------------------------\n",
            "Epoch 867\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6923e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.692347863332894e-05\n",
            "----------------------------------------\n",
            "Epoch 868\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6885e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.688476200216631e-05\n",
            "----------------------------------------\n",
            "Epoch 869\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6847e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.684687467738607e-05\n",
            "----------------------------------------\n",
            "Epoch 870\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6809e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.680891160757381e-05\n",
            "----------------------------------------\n",
            "Epoch 871\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6771e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.6770828808024e-05\n",
            "----------------------------------------\n",
            "Epoch 872\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6733e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.673271440938649e-05\n",
            "----------------------------------------\n",
            "Epoch 873\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6694e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.669449742087043e-05\n",
            "----------------------------------------\n",
            "Epoch 874\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6657e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.665686114893137e-05\n",
            "----------------------------------------\n",
            "Epoch 875\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6619e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.661921922402521e-05\n",
            "----------------------------------------\n",
            "Epoch 876\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6581e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.658148754150641e-05\n",
            "----------------------------------------\n",
            "Epoch 877\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6544e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.654362013388895e-05\n",
            "----------------------------------------\n",
            "Epoch 878\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6506e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.650563585559169e-05\n",
            "----------------------------------------\n",
            "Epoch 879\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6468e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.646817479547013e-05\n",
            "----------------------------------------\n",
            "Epoch 880\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6431e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.643086098749567e-05\n",
            "----------------------------------------\n",
            "Epoch 881\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6393e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.63934056004345e-05\n",
            "----------------------------------------\n",
            "Epoch 882\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6356e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.635581800848889e-05\n",
            "----------------------------------------\n",
            "Epoch 883\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6318e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.631816350856613e-05\n",
            "----------------------------------------\n",
            "Epoch 884\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6281e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.628072534957856e-05\n",
            "----------------------------------------\n",
            "Epoch 885\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6244e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.62435946638251e-05\n",
            "----------------------------------------\n",
            "Epoch 886\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6206e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.620632569490642e-05\n",
            "----------------------------------------\n",
            "Epoch 887\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6169e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.61689286859026e-05\n",
            "----------------------------------------\n",
            "Epoch 888\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6132e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.613175814804443e-05\n",
            "----------------------------------------\n",
            "Epoch 889\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6095e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.609474918101735e-05\n",
            "----------------------------------------\n",
            "Epoch 890\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6058e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.60576312456152e-05\n",
            "----------------------------------------\n",
            "Epoch 891\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6020e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.602042781242605e-05\n",
            "----------------------------------------\n",
            "Epoch 892\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5984e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.598364643184979e-05\n",
            "----------------------------------------\n",
            "Epoch 893\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5947e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.594687070891443e-05\n",
            "----------------------------------------\n",
            "Epoch 894\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5910e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.590991284813077e-05\n",
            "----------------------------------------\n",
            "Epoch 895\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5873e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.587285543576676e-05\n",
            "----------------------------------------\n",
            "Epoch 896\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5836e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.583609680503256e-05\n",
            "----------------------------------------\n",
            "Epoch 897\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5800e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.580030724201949e-05\n",
            "----------------------------------------\n",
            "Epoch 898\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5764e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.576446841211593e-05\n",
            "----------------------------------------\n",
            "Epoch 899\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5729e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.572853013109186e-05\n",
            "----------------------------------------\n",
            "Epoch 900\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5693e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.569280611101695e-05\n",
            "----------------------------------------\n",
            "Epoch 901\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5657e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.565729036783484e-05\n",
            "----------------------------------------\n",
            "Epoch 902\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5622e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.562165867010835e-05\n",
            "----------------------------------------\n",
            "Epoch 903\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5586e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.558593185319648e-05\n",
            "----------------------------------------\n",
            "Epoch 904\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5551e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.555080362916665e-05\n",
            "----------------------------------------\n",
            "Epoch 905\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5516e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.551557346028762e-05\n",
            "----------------------------------------\n",
            "Epoch 906\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5480e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.548020045314145e-05\n",
            "----------------------------------------\n",
            "Epoch 907\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5445e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.544480302715971e-05\n",
            "----------------------------------------\n",
            "Epoch 908\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5409e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.540947445347577e-05\n",
            "----------------------------------------\n",
            "Epoch 909\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5374e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.53744990720556e-05\n",
            "----------------------------------------\n",
            "Epoch 910\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5339e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.533940155876152e-05\n",
            "----------------------------------------\n",
            "Epoch 911\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5304e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.530425233983515e-05\n",
            "----------------------------------------\n",
            "Epoch 912\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5269e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.526930560256859e-05\n",
            "----------------------------------------\n",
            "Epoch 913\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5234e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.523443227173981e-05\n",
            "----------------------------------------\n",
            "Epoch 914\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5200e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.519954124792607e-05\n",
            "----------------------------------------\n",
            "Epoch 915\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5165e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.516481694590605e-05\n",
            "----------------------------------------\n",
            "Epoch 916\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5130e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.51300498295321e-05\n",
            "----------------------------------------\n",
            "Epoch 917\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5095e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.509522727352372e-05\n",
            "----------------------------------------\n",
            "Epoch 918\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5061e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.506060290116982e-05\n",
            "----------------------------------------\n",
            "Epoch 919\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5026e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.502606874122263e-05\n",
            "----------------------------------------\n",
            "Epoch 920\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4991e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.499145377947555e-05\n",
            "----------------------------------------\n",
            "Epoch 921\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4957e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.495699044441372e-05\n",
            "----------------------------------------\n",
            "Epoch 922\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4923e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.49225162463289e-05\n",
            "----------------------------------------\n",
            "Epoch 923\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4888e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.488793437359755e-05\n",
            "----------------------------------------\n",
            "Epoch 924\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4854e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.485377565372958e-05\n",
            "----------------------------------------\n",
            "Epoch 925\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4820e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.481952046111364e-05\n",
            "----------------------------------------\n",
            "Epoch 926\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4785e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.478514833724923e-05\n",
            "----------------------------------------\n",
            "Epoch 927\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4751e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.475067002185372e-05\n",
            "----------------------------------------\n",
            "Epoch 928\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4717e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.471672365422545e-05\n",
            "----------------------------------------\n",
            "Epoch 929\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4683e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.468274492986852e-05\n",
            "----------------------------------------\n",
            "Epoch 930\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4649e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.464861330768735e-05\n",
            "----------------------------------------\n",
            "Epoch 931\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4614e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.461436480983595e-05\n",
            "----------------------------------------\n",
            "Epoch 932\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4580e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.458005300784663e-05\n",
            "----------------------------------------\n",
            "Epoch 933\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4546e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.454631637651863e-05\n",
            "----------------------------------------\n",
            "Epoch 934\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4513e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.451254209531439e-05\n",
            "----------------------------------------\n",
            "Epoch 935\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4479e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.44786260391356e-05\n",
            "----------------------------------------\n",
            "Epoch 936\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4445e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.444460904647601e-05\n",
            "----------------------------------------\n",
            "Epoch 937\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4410e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.4410482830042e-05\n",
            "----------------------------------------\n",
            "Epoch 938\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4377e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.437671234459959e-05\n",
            "----------------------------------------\n",
            "Epoch 939\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4343e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.434325304540378e-05\n",
            "----------------------------------------\n",
            "Epoch 940\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4310e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.430969739458132e-05\n",
            "----------------------------------------\n",
            "Epoch 941\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4276e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.427605505972907e-05\n",
            "----------------------------------------\n",
            "Epoch 942\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4242e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.424231495354138e-05\n",
            "----------------------------------------\n",
            "Epoch 943\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4209e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.42090608627282e-05\n",
            "----------------------------------------\n",
            "Epoch 944\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4176e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.417581531506657e-05\n",
            "----------------------------------------\n",
            "Epoch 945\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4142e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.414246625805484e-05\n",
            "----------------------------------------\n",
            "Epoch 946\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4109e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.410897623089364e-05\n",
            "----------------------------------------\n",
            "Epoch 947\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4076e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.407554713324534e-05\n",
            "----------------------------------------\n",
            "Epoch 948\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4043e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.404284724234842e-05\n",
            "----------------------------------------\n",
            "Epoch 949\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4010e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.401010000111365e-05\n",
            "----------------------------------------\n",
            "Epoch 950\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3977e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.397724566338711e-05\n",
            "----------------------------------------\n",
            "Epoch 951\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3944e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.394429921539483e-05\n",
            "----------------------------------------\n",
            "Epoch 952\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3911e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.391127441358725e-05\n",
            "----------------------------------------\n",
            "Epoch 953\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3878e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.387825697206434e-05\n",
            "----------------------------------------\n",
            "Epoch 954\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3846e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.384571352277782e-05\n",
            "----------------------------------------\n",
            "Epoch 955\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3813e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.3813021719726e-05\n",
            "----------------------------------------\n",
            "Epoch 956\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3780e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.378026261122327e-05\n",
            "----------------------------------------\n",
            "Epoch 957\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3748e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.374791493868998e-05\n",
            "----------------------------------------\n",
            "Epoch 958\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3715e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.371548793600908e-05\n",
            "----------------------------------------\n",
            "Epoch 959\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3683e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.368297611047616e-05\n",
            "----------------------------------------\n",
            "Epoch 960\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3650e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.36503739928302e-05\n",
            "----------------------------------------\n",
            "Epoch 961\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3618e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.361790158879536e-05\n",
            "----------------------------------------\n",
            "Epoch 962\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3586e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.35856512491698e-05\n",
            "----------------------------------------\n",
            "Epoch 963\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3553e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.355326459861853e-05\n",
            "----------------------------------------\n",
            "Epoch 964\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3521e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.35208018510986e-05\n",
            "----------------------------------------\n",
            "Epoch 965\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3489e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.348858431387677e-05\n",
            "----------------------------------------\n",
            "Epoch 966\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3456e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.345641255059946e-05\n",
            "----------------------------------------\n",
            "Epoch 967\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3424e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.342418436515275e-05\n",
            "----------------------------------------\n",
            "Epoch 968\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3392e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.339214610752716e-05\n",
            "----------------------------------------\n",
            "Epoch 969\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3360e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.336005173854665e-05\n",
            "----------------------------------------\n",
            "Epoch 970\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3328e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.332791494602804e-05\n",
            "----------------------------------------\n",
            "Epoch 971\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3296e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.329586610943645e-05\n",
            "----------------------------------------\n",
            "Epoch 972\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3264e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.326378799914014e-05\n",
            "----------------------------------------\n",
            "Epoch 973\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3232e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.323163705128207e-05\n",
            "----------------------------------------\n",
            "Epoch 974\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3199e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.319920692997565e-05\n",
            "----------------------------------------\n",
            "Epoch 975\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3167e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.316664450574696e-05\n",
            "----------------------------------------\n",
            "Epoch 976\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3134e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.313394682684595e-05\n",
            "----------------------------------------\n",
            "Epoch 977\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3101e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.310131156741689e-05\n",
            "----------------------------------------\n",
            "Epoch 978\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3069e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.306868202019133e-05\n",
            "----------------------------------------\n",
            "Epoch 979\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3036e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.30359033929156e-05\n",
            "----------------------------------------\n",
            "Epoch 980\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3003e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.300332755139826e-05\n",
            "----------------------------------------\n",
            "Epoch 981\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2971e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.297070660687398e-05\n",
            "----------------------------------------\n",
            "Epoch 982\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2938e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.293795938141911e-05\n",
            "----------------------------------------\n",
            "Epoch 983\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2905e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.290510293071546e-05\n",
            "----------------------------------------\n",
            "Epoch 984\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2873e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.287269141890785e-05\n",
            "----------------------------------------\n",
            "Epoch 985\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2840e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.284016167924761e-05\n",
            "----------------------------------------\n",
            "Epoch 986\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2807e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.280749246085571e-05\n",
            "----------------------------------------\n",
            "Epoch 987\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2775e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.277472342909968e-05\n",
            "----------------------------------------\n",
            "Epoch 988\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2742e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.274196287951634e-05\n",
            "----------------------------------------\n",
            "Epoch 989\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2709e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.270948634130596e-05\n",
            "----------------------------------------\n",
            "Epoch 990\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2677e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.267691117380659e-05\n",
            "----------------------------------------\n",
            "Epoch 991\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2644e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.264430784199565e-05\n",
            "----------------------------------------\n",
            "Epoch 992\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2612e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.261202512170919e-05\n",
            "----------------------------------------\n",
            "Epoch 993\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2580e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.257962337063057e-05\n",
            "----------------------------------------\n",
            "Epoch 994\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2547e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.254714607148184e-05\n",
            "----------------------------------------\n",
            "Epoch 995\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2515e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.251456215273072e-05\n",
            "----------------------------------------\n",
            "Epoch 996\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2482e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.248226805508457e-05\n",
            "----------------------------------------\n",
            "Epoch 997\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2450e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.245003856723117e-05\n",
            "----------------------------------------\n",
            "Epoch 998\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2418e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.241771750427889e-05\n",
            "----------------------------------------\n",
            "Epoch 999\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2385e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.238530851327873e-05\n",
            "----------------------------------------\n",
            "Epoch 1000\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2353e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.235286385014605e-05\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1982, -0.5572],\n",
            "        [-0.1288,  0.6843],\n",
            "        [-0.1759,  0.5148],\n",
            "        [ 0.1354,  0.2921],\n",
            "        [ 0.0147,  0.1771],\n",
            "        [-0.6556,  0.0107]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.4311,  0.6651, -0.2020,  0.5516, -0.4184,  1.0147],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.2854, -0.1002, -0.0428, -0.3139,  0.2698, -0.3971],\n",
            "        [ 0.2810, -0.1355, -0.1690, -0.0417,  0.1544, -0.1611],\n",
            "        [ 0.1248, -0.3361,  0.2905, -0.2386, -0.5225, -0.8673],\n",
            "        [ 0.0696, -0.1192, -0.2622, -0.3630, -0.4198,  0.3015],\n",
            "        [-0.0504,  0.0689, -0.1116,  0.1144, -0.6136, -0.3159],\n",
            "        [-0.2525, -0.3236, -0.1373, -0.1378, -0.2818, -0.2362]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.4125,  0.1437, -0.1493,  0.1047, -0.0062,  0.3237],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.3169,  0.3006, -0.3145, -0.4081,  0.0387,  0.2194]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0140], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_200_0p99 = train_var_scope(model_200_0p99, 200, 0.001, test_200_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5TXDNed9lBv",
        "outputId": "a3e112b9-3cde-44fb-c52a-ccd925e732c1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2321e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.232071548283213e-05\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8212e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.821238477719147e-05\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4394e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.439401945160914e-05\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0930e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.093024913095342e-05\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7785e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.778548904449979e-05\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4622e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4622360365619785e-05\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1637e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.163712912528531e-05\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8728e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.872768128666346e-05\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9401e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.940123982244951e-05\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4341e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.434085554924648e-05\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4416e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.441581653301738e-05\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2003e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.2002592960711154e-05\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9325e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9324880394725342e-05\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8260e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.826008145046087e-05\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6655e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6654770480795158e-05\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4882e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4882377958571897e-05\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3413e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3412574584680357e-05\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2282e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.228214661454187e-05\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1096e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1095740576177908e-05\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9732e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9731898146340064e-05\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8462e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.846166132217096e-05\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7457e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.745727241245481e-05\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6586e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.658622499752148e-05\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5694e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.569448938710995e-05\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4832e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4831801610583826e-05\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4172e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4171757183129453e-05\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3447e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3446537497075548e-05\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2688e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2688020337093774e-05\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1887e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.188671872960388e-05\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1173e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1173157717969415e-05\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0627e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0627027705963712e-05\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0176e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0176497106586096e-05\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7312e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.731234013682844e-06\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3134e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.313408623644975e-06\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9891e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.989130458391421e-06\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7417e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.74169899224684e-06\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4942e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.49423565511665e-06\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2226e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.22256456031814e-06\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7415e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.74154972183705e-06\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1792e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.179246606933622e-06\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6720e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.671963247185429e-06\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1794e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.1793651527326965e-06\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7239e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.723899093810125e-06\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3452e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.345220389815732e-06\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0412e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.04117343967594e-06\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7811e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.781139465130999e-06\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5570e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.55701526538185e-06\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3869e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.386887215283719e-06\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2724e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.272380360992422e-06\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1881e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.188135022804692e-06\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1156e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.115572063188474e-06\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0591e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.059125669463513e-06\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0228e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.022809203595509e-06\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9924e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.992423520053543e-06\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9525e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.952535016769134e-06\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9046e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.904606334132071e-06\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8552e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8551802709118265e-06\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8025e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8025362456450284e-06\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7381e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.7381477724112374e-06\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6642e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.6641787715576744e-06\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5884e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.588425868337358e-06\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5131e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.5130708766717514e-06\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4344e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.4343960164209754e-06\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3534e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.3534373587515606e-06\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2765e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.2764955832449052e-06\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2060e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.206018049482695e-06\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1392e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.139198962697873e-06\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0755e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0754769723086325e-06\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0183e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.018287735407156e-06\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9689e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9689023498630194e-06\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9244e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9244430417502362e-06\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8832e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8832480728302296e-06\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8471e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.847067127363581e-06\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8161e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8161061856503806e-06\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7880e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.787970151392337e-06\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7612e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.761247115220838e-06\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7367e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7367417045850254e-06\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7145e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7144980849099483e-06\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6928e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6928448014164476e-06\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6710e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6710407284137763e-06\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6499e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6498825943202615e-06\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6295e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.629492171779276e-06\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6089e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.608948923006397e-06\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5881e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5881206262751213e-06\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5678e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5678181528272734e-06\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5482e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5482001563681935e-06\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5287e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5287279986501263e-06\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5096e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5095712984026917e-06\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4913e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.491331441947872e-06\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4740e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4739896222317836e-06\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4572e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.457217900286923e-06\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4413e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.441342888793847e-06\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4266e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4266289316713183e-06\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4126e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4126474266256146e-06\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3992e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.399240460662034e-06\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3867e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.386696964481814e-06\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3750e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3750263241011085e-06\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3638e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3638338599968297e-06\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3530e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3530333904979355e-06\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3428e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3427912684184003e-06\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3329e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.332925437130794e-06\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3230e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.323005556056758e-06\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3132e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3132345676878474e-06\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3037e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.303730947046211e-06\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2943e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.294327325274627e-06\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2850e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2849878033793764e-06\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2758e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.275845989347572e-06\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2669e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2668898882774385e-06\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2580e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.258024029193613e-06\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2493e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2493056076170312e-06\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2408e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2408059588411795e-06\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2325e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2324621972205252e-06\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2242e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2242467217121105e-06\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2162e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2162296678170867e-06\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2084e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.208432399093976e-06\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2008e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2007662587121027e-06\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1932e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1932456163666733e-06\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1859e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1858942998587142e-06\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1787e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.17866634190406e-06\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1715e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1715366384167817e-06\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1645e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1645245303434507e-06\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1576e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1576197295609702e-06\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1508e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.15078833358545e-06\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1440e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.144038688734293e-06\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1374e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.137378277180507e-06\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1308e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1307823284916546e-06\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1242e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1242462436466606e-06\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1178e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1177854794923314e-06\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1114e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.111391574104614e-06\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1051e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1050539609173344e-06\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0988e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.098783865981421e-06\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0926e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0925783522228365e-06\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0864e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.08643391770894e-06\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0804e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0803504347891387e-06\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0743e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0743335448577e-06\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0684e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0683753499056466e-06\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0625e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0624733502552397e-06\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0566e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0566320355733708e-06\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0508e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.050846219446491e-06\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0451e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.045110378020883e-06\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0394e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0394270573886586e-06\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0338e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0337944284764476e-06\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0282e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.028206947796103e-06\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0227e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0226652794487827e-06\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0172e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0171694556371917e-06\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0117e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0117152581233164e-06\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0063e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.006302387649375e-06\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0009e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.000932092002731e-06\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9956e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9956018978720763e-06\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9903e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9903109398601224e-06\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9851e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9850604943223607e-06\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9798e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9798491225865887e-06\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9747e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9746756428191184e-06\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9695e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9695409995541253e-06\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9644e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.964444419430508e-06\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9594e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9593845626157954e-06\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9544e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9543617785214914e-06\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9494e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9493754821316875e-06\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9444e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9444243041901704e-06\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9395e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9395082148359967e-06\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9346e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9346268358555923e-06\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9298e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9297789961677606e-06\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9250e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.924964460907087e-06\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9201e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.920134717357947e-06\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9153e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9153403017164248e-06\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9106e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.910565030908935e-06\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9058e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.90580979004132e-06\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9011e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9010773847426175e-06\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8964e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8963655378845105e-06\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8917e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8916745921999245e-06\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8870e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8870063951529825e-06\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8824e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8823607310205955e-06\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8777e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8777372385904874e-06\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8731e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8731361227469885e-06\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8686e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.868562676277342e-06\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8640e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.86401293933565e-06\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8595e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8594864823457134e-06\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8550e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8549834311021532e-06\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8505e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8505037548690575e-06\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8460e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8460474310255552e-06\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8416e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.841614492540779e-06\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8372e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8372048612368845e-06\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8328e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8328184747169835e-06\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8285e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8284553193490085e-06\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8241e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8241153015093954e-06\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8198e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8197872260624523e-06\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8155e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8154502718086458e-06\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8111e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.811132235138781e-06\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8068e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8068334997762367e-06\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8026e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.802554426585657e-06\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7983e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7982952841613823e-06\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7941e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7940563131123993e-06\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7898e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7898377309640536e-06\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7856e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7856396864458774e-06\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7815e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.781462313106846e-06\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7773e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7773057250698368e-06\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7732e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7731699862984152e-06\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7691e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.769055151931568e-06\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7650e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7649612586442072e-06\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7609e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7608883084495522e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1982, -0.5572],\n",
            "        [-0.1224,  0.6697],\n",
            "        [-0.1859,  0.4811],\n",
            "        [ 0.1263,  0.2894],\n",
            "        [ 0.0221,  0.1914],\n",
            "        [-0.5981,  0.0634]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.4311,  0.6609, -0.2139,  0.5443, -0.4112,  1.0631],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.2854, -0.1002, -0.0428, -0.3139,  0.2459, -0.3971],\n",
            "        [ 0.2810, -0.1530, -0.1758, -0.0745,  0.1052, -0.1795],\n",
            "        [ 0.1248, -0.3361,  0.2486, -0.2877, -0.5554, -0.9408],\n",
            "        [ 0.0696, -0.1333, -0.2595, -0.3630, -0.3887,  0.1157],\n",
            "        [-0.0504,  0.0526, -0.1121,  0.1065, -0.6129, -0.3498],\n",
            "        [-0.2525, -0.3633, -0.1271, -0.1265, -0.2754, -0.2697]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.4361,  0.1258, -0.1636,  0.0014, -0.0254,  0.3282],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.3004,  0.2740, -0.2649, -0.2538, -0.0028,  0.1882]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0124], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 400 0.99"
      ],
      "metadata": {
        "id": "-Y6XSrxLTUPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_400 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_400 = experiment_actions(400, env, P_pi_b_400)\n",
        "P_pi_e_400 = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e_400 = experiment_actions(400, env, P_pi_e_400)\n",
        "model_400_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float64)\n",
        "test_400_0p99 = SCOPE_straight(model_400_0p99, 0.99, 1000, pi_b_400, P_pi_b_400, P_pi_e_400, dtype = torch.float64)\n",
        "model_400_0p99 = train_var_scope(model_400_0p99, 5, 0.001, test_400_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-GtA_2_H3jW",
        "outputId": "255985ec-858b-495f-a37b-6c1d83b80245"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0864, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.08636927251674584\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2360, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.23601228060459742\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.22842130839536168\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.22034274292801542\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.21219201524204384\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.2227, -0.2377],\n",
            "        [-0.1161, -0.0580],\n",
            "        [-0.1448,  0.0938],\n",
            "        [-0.1531,  0.6014],\n",
            "        [ 0.6863, -0.3983],\n",
            "        [-0.6208,  0.5967]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.1459,  0.6348,  0.5511, -0.0894, -0.6099, -0.4201],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.0188,  0.1783,  0.1906, -0.1831, -0.2326,  0.3907],\n",
            "        [ 0.1501,  0.2778,  0.3853,  0.2220,  0.2562,  0.2344],\n",
            "        [-0.2534,  0.3682,  0.3991,  0.0664, -0.1327,  0.1305],\n",
            "        [ 0.3641,  0.1544,  0.0996,  0.0388,  0.3387,  0.2223],\n",
            "        [-0.1971,  0.1551, -0.1208, -0.2238,  0.3284,  0.2085],\n",
            "        [-0.2006,  0.0626,  0.0105, -0.3599, -0.2018,  0.0474]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0877, -0.3765,  0.2807, -0.3098,  0.2580, -0.0114],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.3840,  0.2713,  0.0393, -0.2318,  0.2767,  0.1556]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.2633], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 600 0.99"
      ],
      "metadata": {
        "id": "pGLbkJw_OMtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_600 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_600 = experiment_actions(600, env_30, P_pi_b_600)\n",
        "P_pi_e_600 = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e_600 = experiment_actions(600, env, P_pi_e_600)\n",
        "model_600_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float32)\n",
        "test_600_0p99 = SCOPE_straight(model_600_0p99, 0.99, 10000, pi_b_600, P_pi_b_600, P_pi_e_600, dtype = torch.float32)\n",
        "model_600_0p99 = train_var_scope(model_600_0p99, 5, 0.001, test_600_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DJzov1IOPEV",
        "outputId": "2289774b-c244-4899-98bb-4aa0a28de6b0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0505, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.05046245828270912\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0493, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0493154413998127\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0481, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04812745749950409\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0469, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.046937569975852966\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0458, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04576045647263527\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.1204,  0.1797],\n",
            "        [ 0.1732,  0.2432],\n",
            "        [ 0.6242,  0.4461],\n",
            "        [ 0.4436,  0.0618],\n",
            "        [ 0.2962, -0.5830],\n",
            "        [-0.3988, -0.6057]])\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.5419,  0.4819,  0.6672, -0.3882, -0.3168, -0.5845])\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.3440, -0.1163, -0.2793,  0.0047, -0.1040, -0.2861],\n",
            "        [-0.2082, -0.2452, -0.2654, -0.3990, -0.1743, -0.2673],\n",
            "        [-0.1590, -0.3511, -0.3919,  0.1778, -0.1089, -0.2762],\n",
            "        [ 0.3015,  0.0899, -0.3342,  0.2264, -0.1954, -0.0921],\n",
            "        [ 0.3359,  0.2783,  0.3255, -0.1074, -0.0552,  0.3129],\n",
            "        [ 0.0065,  0.2449,  0.0709,  0.2463, -0.0068,  0.1182]])\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.3040, -0.2149, -0.0412, -0.2949, -0.2522,  0.2680])\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1696, -0.0297, -0.3140, -0.0297, -0.3058,  0.3434]])\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0148])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 800 0.99"
      ],
      "metadata": {
        "id": "ariP9U-abrzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_800 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_800 = experiment_actions(800, env_30, P_pi_b_800)\n",
        "P_pi_e_800 = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e_800 = experiment_actions(800, env_30, P_pi_e_800)\n",
        "model_800_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float32)\n",
        "test_800_0p99 = SCOPE_straight(model_800_0p99, 0.99, 10000, pi_b_800, P_pi_b_800, P_pi_e_800, dtype = torch.float32)\n",
        "model_800_0p99 = train_var_scope(model_800_0p99, 5, 0.001, test_800_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY3ZZMqFbucT",
        "outputId": "d170bc23-4df3-467c-92a6-82dbe78457c8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1004, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.10040785372257233\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1327, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.13271035254001617\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1297, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12969112396240234\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1267, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12670785188674927\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1238, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12376594543457031\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.1256,  0.1763],\n",
            "        [ 0.1731,  0.2431],\n",
            "        [ 0.6243,  0.4461],\n",
            "        [ 0.4445,  0.0656],\n",
            "        [ 0.2962, -0.5871],\n",
            "        [-0.3988, -0.6057]])\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.5420,  0.4819,  0.6672, -0.3851, -0.3175, -0.5845])\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 3.4210e-01, -1.1714e-01, -2.7928e-01,  1.6665e-04, -1.0937e-01,\n",
            "         -2.8613e-01],\n",
            "        [-2.0815e-01, -2.4523e-01, -2.6536e-01, -3.9900e-01, -1.7434e-01,\n",
            "         -2.6726e-01],\n",
            "        [-1.5169e-01, -3.5114e-01, -3.9192e-01,  1.8578e-01, -1.1592e-01,\n",
            "         -2.7624e-01],\n",
            "        [ 2.9939e-01,  9.2404e-02, -3.3420e-01,  2.2824e-01, -1.9231e-01,\n",
            "         -9.2125e-02],\n",
            "        [ 3.3559e-01,  2.7832e-01,  3.2552e-01, -1.0750e-01, -5.3136e-02,\n",
            "          3.1286e-01],\n",
            "        [ 1.6141e-02,  2.4356e-01,  7.9191e-02,  2.5596e-01, -3.4911e-03,\n",
            "          1.1824e-01]])\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.2993, -0.2149, -0.0318, -0.2958, -0.2523,  0.2699])\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1668, -0.0297, -0.3204, -0.0275, -0.3058,  0.3439]])\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0079])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 1000 0.99"
      ],
      "metadata": {
        "id": "AZrEQ4ieTxeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_1000 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_1000 = experiment_actions(1000, env_30, P_pi_b_1000)\n",
        "P_pi_e_1000 = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e_1000 = experiment_actions(1000, env, P_pi_e_1000)\n",
        "model_1000_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float32)\n",
        "test_1000_0p99 = SCOPE_straight(model_1000_0p99, 0.90, 10000, pi_b_1000, P_pi_b_1000, P_pi_e_1000, dtype = torch.float32)\n",
        "model_1000_0p99 = train_var_scope(model_1000_0p99, 5, 0.001, test_1000_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e06BDW8QSg_g",
        "outputId": "775bd8ae-65b2-4ede-9674-30b8610a6f67"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0071, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0071372101083397865\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0059, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005885153077542782\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0057, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005744975060224533\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0056, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005605767946690321\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0055, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005469260271638632\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.3398,  0.4284],\n",
            "        [ 0.6470, -0.5601],\n",
            "        [-0.0836, -0.5419],\n",
            "        [ 0.2371, -0.0722],\n",
            "        [-0.2191, -0.1823],\n",
            "        [-0.6192, -0.4586]])\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.4420,  0.4668,  0.2511,  0.5432, -0.0262, -0.6044])\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1204, -0.0890, -0.2383,  0.3484,  0.3641, -0.3094],\n",
            "        [-0.3600, -0.0599,  0.1120,  0.2181,  0.0257,  0.3971],\n",
            "        [-0.0396, -0.1132, -0.0198, -0.3503,  0.3299,  0.3989],\n",
            "        [-0.3419, -0.0945, -0.0509,  0.2863, -0.0306,  0.4073],\n",
            "        [ 0.2843,  0.4049,  0.2897, -0.2459,  0.1344,  0.0443],\n",
            "        [-0.0682,  0.2438, -0.2887,  0.2774,  0.4038, -0.2734]])\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.1609,  0.3603,  0.3371, -0.4036,  0.0650,  0.0022])\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.3125, -0.0285,  0.1303,  0.3379,  0.3765, -0.1660]])\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1458])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tM7NaSOMSktR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}