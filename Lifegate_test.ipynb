{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMA99ro2xL9pJ2EGZkIa0YB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajagota7/Reward-Shaping/blob/main/Lifegate_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zZ2S2CI8K_jT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "jsHzrhmfpiTr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "# np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "from scipy.optimize import minimize\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import torch\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deadend dependencies"
      ],
      "metadata": {
        "id": "UMj8NNrGfwu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/med-deadend.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KStXBTWK3f64",
        "outputId": "36a6b60a-fba7-4c0b-90c5-319c05077d64"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'med-deadend' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# shaping dependencies"
      ],
      "metadata": {
        "id": "AsZMw4C0f2K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ajagota7/Shaping.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu7X59dK3hqk",
        "outputId": "868c39fe-bb41-4ce2-c8c5-55324fb582a5"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Shaping' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping"
      ],
      "metadata": {
        "id": "5SkpvWFqz631"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull origin main"
      ],
      "metadata": {
        "id": "8QRHhC-G0AiH"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/"
      ],
      "metadata": {
        "id": "hZ8dnFnidxL_"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/Shaping/lifegate_1.zip', 'r') as zip_ref:\n",
        "    # zip_ref.extractall('/content/med-deadend/lifegate/results/lifegate_1')\n",
        "    zip_ref.extractall('/content/Shaping/')"
      ],
      "metadata": {
        "id": "2noY6FOTdsmY"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/med-deadend/lifegate')\n",
        "sys.path.append('/content/Shaping/')\n",
        "\n"
      ],
      "metadata": {
        "id": "id2reVHQ3heg"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import q_networks"
      ],
      "metadata": {
        "id": "DgppFp3cDm4L"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/med-deadend/lifegate\n",
        "\n",
        "\n",
        "# results_dir = 'results/lifegate_1/'\n",
        "results_dir = '/content/Shaping/'\n",
        "# Load the Q tables from the primary learning agent, Q_D and Q_R value functions\n",
        "with open(results_dir+'tabular_qnet.pkl', 'rb') as fq:\n",
        "    ai = pickle.load(fq)\n",
        "\n",
        "with open(results_dir+'tabular_qd.pkl', 'rb') as fd:\n",
        "    ai_d = pickle.load(fd)\n",
        "\n",
        "with open(results_dir+'tabular_qr.pkl', 'rb') as fr:\n",
        "    ai_r = pickle.load(fr)"
      ],
      "metadata": {
        "id": "7lv4ZIBkeLW3"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.zeros((10, 10, 5))\n",
        "q_d = np.zeros_like(q_table)\n",
        "q_r = np.zeros_like(q_table)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        for a in range(5):\n",
        "            key = tuple([j, i, a])\n",
        "            try:\n",
        "                q_table[i,j,a] = ai.q[key]\n",
        "                q_d[i,j,a] = ai_d.q[key]\n",
        "                q_r[i,j,a] = ai_r.q[key]\n",
        "            except:\n",
        "                pass"
      ],
      "metadata": {
        "id": "Rk0Z42sNebl4"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import random\n",
        "from lifegate import LifeGate\n",
        "params = yaml.safe_load(open(results_dir+'config.yaml', 'r'))\n",
        "np.random.seed(seed=params['random_seed'])\n",
        "random.seed(params['random_seed'])\n",
        "random_state = np.random.RandomState(params['random_seed'])"
      ],
      "metadata": {
        "id": "4uTTjsWNfK21"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = LifeGate(max_steps=params['episode_max_len'], state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.0)"
      ],
      "metadata": {
        "id": "XUoJuLN0fabn"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_30 = LifeGate(max_steps=30, state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.1)"
      ],
      "metadata": {
        "id": "7wG_zU6SM3xY"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZp-8-f7far2"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Shaping\n",
        "from Shaping import *\n",
        "# %cd /content/Shaping\n",
        "\n",
        "from choose_actions import action_probs_top_n_epsilon\n",
        "from shaping_features import *\n",
        "from gen_policies import *\n",
        "from IS import *\n",
        "from subset_policies import *\n",
        "from v_pi_e import *\n",
        "from optimization import *\n",
        "from neural_net import *\n",
        "from prep_variance import *\n",
        "from SCOPE_variance import SCOPE_variance"
      ],
      "metadata": {
        "id": "hS65UmL5Yu_K"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from policies import P_pi_b_good_stoch"
      ],
      "metadata": {
        "id": "RBqL-PfTiMGS"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_good_stoch = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_good_stoch[2,9,3] = 0.5\n",
        "P_pi_b_good_stoch[2,9,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,8,3] = 0.5\n",
        "P_pi_b_good_stoch[2,8,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,7,3] = 0.5\n",
        "P_pi_b_good_stoch[2,7,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,9,3] = 0.5\n",
        "P_pi_b_good_stoch[1,9,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,8,3] = 0.5\n",
        "P_pi_b_good_stoch[1,8,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,7,3] = 0.5\n",
        "P_pi_b_good_stoch[1,7,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,6,3] = 1\n",
        "P_pi_b_good_stoch[1,6,3] = 1\n",
        "P_pi_b_good_stoch[1,5,3] = 1\n",
        "\n",
        "\n",
        "P_pi_b_good_stoch[0,9,1] = 1\n",
        "P_pi_b_good_stoch[0,8,1] = 1\n",
        "P_pi_b_good_stoch[0,7,1] = 1\n",
        "P_pi_b_good_stoch[0,6,1] = 1\n",
        "P_pi_b_good_stoch[0,5,1] = 1\n",
        "\n",
        "P_pi_b_good_stoch[0,4,1] = 0.5\n",
        "P_pi_b_good_stoch[0,4,4] = 0.5\n",
        "P_pi_b_good_stoch[0,4,1] = 0.5\n",
        "P_pi_b_good_stoch[0,4,4] = 0.5\n",
        "P_pi_b_good_stoch[0,3,1] = 0.5\n",
        "P_pi_b_good_stoch[0,3,4] = 0.5\n",
        "P_pi_b_good_stoch[0,2,1] = 0.5\n",
        "P_pi_b_good_stoch[0,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,4,1] = 0.5\n",
        "P_pi_b_good_stoch[1,4,4] = 0.5\n",
        "P_pi_b_good_stoch[1,4,1] = 0.5\n",
        "P_pi_b_good_stoch[1,4,4] = 0.5\n",
        "P_pi_b_good_stoch[1,3,1] = 0.5\n",
        "P_pi_b_good_stoch[1,3,4] = 0.5\n",
        "P_pi_b_good_stoch[1,2,1] = 0.5\n",
        "P_pi_b_good_stoch[1,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,4,1] = 0.5\n",
        "P_pi_b_good_stoch[2,4,4] = 0.5\n",
        "P_pi_b_good_stoch[2,4,1] = 0.5\n",
        "P_pi_b_good_stoch[2,4,4] = 0.5\n",
        "P_pi_b_good_stoch[2,3,1] = 0.5\n",
        "P_pi_b_good_stoch[2,3,4] = 0.5\n",
        "P_pi_b_good_stoch[2,2,1] = 0.5\n",
        "P_pi_b_good_stoch[2,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[3,4,1] = 0.5\n",
        "P_pi_b_good_stoch[3,4,4] = 0.5\n",
        "P_pi_b_good_stoch[3,4,1] = 0.5\n",
        "P_pi_b_good_stoch[3,4,4] = 0.5\n",
        "P_pi_b_good_stoch[3,3,1] = 0.5\n",
        "P_pi_b_good_stoch[3,3,4] = 0.5\n",
        "P_pi_b_good_stoch[3,2,1] = 0.5\n",
        "P_pi_b_good_stoch[3,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[4,4,1] = 0.5\n",
        "P_pi_b_good_stoch[4,4,4] = 0.5\n",
        "P_pi_b_good_stoch[4,4,1] = 0.5\n",
        "P_pi_b_good_stoch[4,4,4] = 0.5\n",
        "P_pi_b_good_stoch[4,3,1] = 0.5\n",
        "P_pi_b_good_stoch[4,3,4] = 0.5\n",
        "P_pi_b_good_stoch[4,2,1] = 0.5\n",
        "P_pi_b_good_stoch[4,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[0,1,4] = 1\n",
        "P_pi_b_good_stoch[1,1,4] = 1\n",
        "P_pi_b_good_stoch[2,1,4] = 1\n",
        "P_pi_b_good_stoch[3,1,4] = 1\n",
        "P_pi_b_good_stoch[4,1,4] = 1\n",
        "\n",
        "P_pi_b_good_stoch[5,4,1] = 1\n",
        "P_pi_b_good_stoch[5,3,1] = 1\n",
        "P_pi_b_good_stoch[5,2,1] = 1\n",
        "P_pi_b_good_stoch[5,1,1] = 1\n",
        "\n"
      ],
      "metadata": {
        "id": "E640w5DNjFUO"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating policies"
      ],
      "metadata": {
        "id": "0fwQz6Zfke5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## interm updates"
      ],
      "metadata": {
        "id": "d4uOoMlDEv-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_actions(nb_episodes, env, action_probs):\n",
        "    \"\"\"\n",
        "    Run the experiment for a specified number of episodes.\n",
        "\n",
        "    Parameters:\n",
        "    - nb_episodes: Number of episodes\n",
        "    - env: Experiment environment\n",
        "    - action_probs: Action probabilities\n",
        "\n",
        "    Returns:\n",
        "    - policies: List of policies (pi_b or pi_e)\n",
        "    \"\"\"\n",
        "    # Define the dtype for the structured array\n",
        "    dtype = [\n",
        "        ('state_last', np.float64, (2,)),\n",
        "        ('action', np.int64),\n",
        "        ('reward', np.float64),\n",
        "        ('state', np.float64, (2,)),\n",
        "        ('timestep', np.int64),\n",
        "        ('psi', np.float64)\n",
        "    ]\n",
        "\n",
        "    policies = []\n",
        "    for i in range(nb_episodes):\n",
        "        trajectory = np.empty(0, dtype=dtype)\n",
        "        s = env.reset()\n",
        "        env.render()\n",
        "        term = False\n",
        "        timestep = 0\n",
        "        while not term:\n",
        "            state_last = s\n",
        "            print(s)\n",
        "            action = choose_action(tuple(s), action_probs)\n",
        "            print(action)\n",
        "            s, r, term, _ = env.step(action)\n",
        "\n",
        "            psi = smallest_distance_to_deadend(state_last, env)\n",
        "            data_point = np.array([(state_last, action, r, s, timestep, psi)], dtype=dtype)\n",
        "            trajectory = np.append(trajectory, data_point)\n",
        "            timestep += 1\n",
        "\n",
        "        policies.append(trajectory)\n",
        "\n",
        "    with open('policies.pkl', 'wb') as f:\n",
        "        pickle.dump(policies, f)\n",
        "\n",
        "    return policies"
      ],
      "metadata": {
        "id": "Xh2UezkqHisR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_good = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_good[2,9,3] = 1\n",
        "P_pi_b_good[1,9,3] = 1\n",
        "P_pi_b_good[0,9,1] = 1\n",
        "P_pi_b_good[0,8,1] = 1\n",
        "P_pi_b_good[0,7,1] = 1\n",
        "P_pi_b_good[0,6,1] = 1\n",
        "P_pi_b_good[0,5,1] = 1\n",
        "P_pi_b_good[0,4,4] = 1\n",
        "P_pi_b_good[1,4,4] = 1\n",
        "P_pi_b_good[2,4,4] = 1\n",
        "P_pi_b_good[3,4,4] = 1\n",
        "P_pi_b_good[4,4,4] = 1\n",
        "P_pi_b_good[5,4,1] = 1\n",
        "P_pi_b_good[5,5,1] = 1\n",
        "P_pi_b_good[5,4,1] = 1\n",
        "P_pi_b_good[5,3,1] = 1\n",
        "P_pi_b_good[5,2,1] = 1\n",
        "P_pi_b_good[5,1,1] = 1"
      ],
      "metadata": {
        "id": "PYLauaUbIq6C"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_good_stoch = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_good_stoch[2,9,3] = 0.5\n",
        "P_pi_b_good_stoch[2,9,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,8,3] = 0.5\n",
        "P_pi_b_good_stoch[2,8,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,7,3] = 0.5\n",
        "P_pi_b_good_stoch[2,7,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,9,3] = 0.5\n",
        "P_pi_b_good_stoch[1,9,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,8,3] = 0.5\n",
        "P_pi_b_good_stoch[1,8,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,7,3] = 0.5\n",
        "P_pi_b_good_stoch[1,7,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,6,3] = 1\n",
        "P_pi_b_good_stoch[1,6,3] = 1\n",
        "P_pi_b_good_stoch[1,5,3] = 1\n",
        "\n",
        "\n",
        "P_pi_b_good_stoch[0,9,1] = 1\n",
        "P_pi_b_good_stoch[0,8,1] = 1\n",
        "P_pi_b_good_stoch[0,7,1] = 1\n",
        "P_pi_b_good_stoch[0,6,1] = 1\n",
        "P_pi_b_good_stoch[0,5,1] = 1\n",
        "\n",
        "P_pi_b_good_stoch[0,4,1] = 0.5\n",
        "P_pi_b_good_stoch[0,4,4] = 0.5\n",
        "P_pi_b_good_stoch[0,4,1] = 0.5\n",
        "P_pi_b_good_stoch[0,4,4] = 0.5\n",
        "P_pi_b_good_stoch[0,3,1] = 0.5\n",
        "P_pi_b_good_stoch[0,3,4] = 0.5\n",
        "P_pi_b_good_stoch[0,2,1] = 0.5\n",
        "P_pi_b_good_stoch[0,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,4,1] = 0.5\n",
        "P_pi_b_good_stoch[1,4,4] = 0.5\n",
        "P_pi_b_good_stoch[1,4,1] = 0.5\n",
        "P_pi_b_good_stoch[1,4,4] = 0.5\n",
        "P_pi_b_good_stoch[1,3,1] = 0.5\n",
        "P_pi_b_good_stoch[1,3,4] = 0.5\n",
        "P_pi_b_good_stoch[1,2,1] = 0.5\n",
        "P_pi_b_good_stoch[1,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,4,1] = 0.5\n",
        "P_pi_b_good_stoch[2,4,4] = 0.5\n",
        "P_pi_b_good_stoch[2,4,1] = 0.5\n",
        "P_pi_b_good_stoch[2,4,4] = 0.5\n",
        "P_pi_b_good_stoch[2,3,1] = 0.5\n",
        "P_pi_b_good_stoch[2,3,4] = 0.5\n",
        "P_pi_b_good_stoch[2,2,1] = 0.5\n",
        "P_pi_b_good_stoch[2,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[3,4,1] = 0.5\n",
        "P_pi_b_good_stoch[3,4,4] = 0.5\n",
        "P_pi_b_good_stoch[3,4,1] = 0.5\n",
        "P_pi_b_good_stoch[3,4,4] = 0.5\n",
        "P_pi_b_good_stoch[3,3,1] = 0.5\n",
        "P_pi_b_good_stoch[3,3,4] = 0.5\n",
        "P_pi_b_good_stoch[3,2,1] = 0.5\n",
        "P_pi_b_good_stoch[3,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[4,4,1] = 0.5\n",
        "P_pi_b_good_stoch[4,4,4] = 0.5\n",
        "P_pi_b_good_stoch[4,4,1] = 0.5\n",
        "P_pi_b_good_stoch[4,4,4] = 0.5\n",
        "P_pi_b_good_stoch[4,3,1] = 0.5\n",
        "P_pi_b_good_stoch[4,3,4] = 0.5\n",
        "P_pi_b_good_stoch[4,2,1] = 0.5\n",
        "P_pi_b_good_stoch[4,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[0,1,4] = 1\n",
        "P_pi_b_good_stoch[1,1,4] = 1\n",
        "P_pi_b_good_stoch[2,1,4] = 1\n",
        "P_pi_b_good_stoch[3,1,4] = 1\n",
        "P_pi_b_good_stoch[4,1,4] = 1\n",
        "\n",
        "P_pi_b_good_stoch[5,4,1] = 1\n",
        "P_pi_b_good_stoch[5,3,1] = 1\n",
        "P_pi_b_good_stoch[5,2,1] = 1\n",
        "P_pi_b_good_stoch[5,1,1] = 1\n",
        "\n"
      ],
      "metadata": {
        "id": "t5GNtT3tPttg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_bad = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_bad[2,9,4] = 1\n",
        "\n",
        "P_pi_b_bad[3,9,1] = 1\n",
        "P_pi_b_bad[3,8,1] = 1\n",
        "P_pi_b_bad[3,7,1] = 1\n",
        "P_pi_b_bad[3,6,4] = 1\n",
        "\n",
        "P_pi_b_bad[4,6,2] = 1\n",
        "P_pi_b_bad[4,7,2] = 1\n",
        "P_pi_b_bad[4,8,2] = 1\n",
        "P_pi_b_bad[4,9,4] = 1\n",
        "\n",
        "P_pi_b_bad[5,9,1] = 1\n",
        "P_pi_b_bad[5,8,1] = 1\n",
        "P_pi_b_bad[5,7,1] = 1\n",
        "P_pi_b_bad[5,6,4] = 1\n",
        "\n",
        "P_pi_b_bad[6,6,4] = 1\n",
        "P_pi_b_bad[7,6,4] = 1\n",
        "P_pi_b_bad[8,6,4] = 1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kuKtHy7UgHwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.main_deaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B0ogRtNlRu6",
        "outputId": "01841628-6c3d-4127-e489-96b0ebdb6cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 0],\n",
              " [9, 1],\n",
              " [9, 2],\n",
              " [9, 3],\n",
              " [9, 4],\n",
              " [9, 5],\n",
              " [9, 6],\n",
              " [9, 7],\n",
              " [9, 8],\n",
              " [9, 9],\n",
              " [8, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gen Policies"
      ],
      "metadata": {
        "id": "RBlY1w9aJppv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env, P_pi_e)"
      ],
      "metadata": {
        "id": "wW1SGejBZZlb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env_30, P_pi_b)\n",
        "\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env_30, P_pi_e)"
      ],
      "metadata": {
        "id": "1KqavLn-NERh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep"
      ],
      "metadata": {
        "id": "03SCZEAMnGeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(200, env, P_pi_e)"
      ],
      "metadata": {
        "id": "rgnL6zIcmmz6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi_e_good_stoch = experiment_actions(1000, env, P_pi_b_good_stoch)"
      ],
      "metadata": {
        "id": "OX9C8RYwjRpl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[8, 8], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "2Xqh735Bmm0D"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "j9pQwTQtmm0D"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()"
      ],
      "metadata": {
        "id": "Lezerfi0mm0D"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_var(model, 1000, 0.001, padded_state_tensors, states_first_tensor, states_last_tensor, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a862f1-9573-4902-9b07-86d037b922c2",
        "id": "FwOFIQCbmm0D"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Total Loss: 4.166754824500192e-09\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "Var loss:  tensor(4.1114e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 3.9296372151202696e-08\n",
            "E_s_wdiff_all_sq: 5.792835891474171e-09\n",
            "E_IS_SCOPE: -7.114857995551485e-07\n",
            "E_IS_E_SCOPE: -6.913721605724364e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002756426858443197\n",
            "Total Loss: 4.111359074793774e-09\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "Var loss:  tensor(4.0533e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 3.9330444975395375e-08\n",
            "E_s_wdiff_all_sq: 5.742982776456884e-09\n",
            "E_IS_SCOPE: -7.112463410905398e-07\n",
            "E_IS_E_SCOPE: -6.910617020819273e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002755189093646647\n",
            "Total Loss: 4.0532849622030744e-09\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "Var loss:  tensor(3.9970e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 3.941336867096971e-08\n",
            "E_s_wdiff_all_sq: 5.7662415691460765e-09\n",
            "E_IS_SCOPE: -7.109692675008428e-07\n",
            "E_IS_E_SCOPE: -6.907266424523504e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002753853246739851\n",
            "Total Loss: 3.996977785328298e-09\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "Var loss:  tensor(3.9391e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 3.952390890869752e-08\n",
            "E_s_wdiff_all_sq: 6.047896117923769e-09\n",
            "E_IS_SCOPE: -7.1045441122305e-07\n",
            "E_IS_E_SCOPE: -6.90268393200979e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027520262559867148\n",
            "Total Loss: 3.939077527121232e-09\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "Var loss:  tensor(3.8826e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 3.965284999479533e-08\n",
            "E_s_wdiff_all_sq: 6.3620287453532875e-09\n",
            "E_IS_SCOPE: -7.10033565404609e-07\n",
            "E_IS_E_SCOPE: -6.899119047320666e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027506049745894107\n",
            "Total Loss: 3.882600684846833e-09\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "Var loss:  tensor(3.8247e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 3.977299631353697e-08\n",
            "E_s_wdiff_all_sq: 6.447965018032859e-09\n",
            "E_IS_SCOPE: -7.100344975560125e-07\n",
            "E_IS_E_SCOPE: -6.898667656010976e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027504250097020962\n",
            "Total Loss: 3.824668166163847e-09\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "Var loss:  tensor(3.7675e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 3.988518531169854e-08\n",
            "E_s_wdiff_all_sq: 6.4469658186363085e-09\n",
            "E_IS_SCOPE: -7.102498668036588e-07\n",
            "E_IS_E_SCOPE: -6.899969651310056e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027509441013023393\n",
            "Total Loss: 3.7675169282453055e-09\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "Var loss:  tensor(3.7359e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.010462508012404e-08\n",
            "E_s_wdiff_all_sq: 6.692409277783357e-09\n",
            "E_IS_SCOPE: -7.102017330061355e-07\n",
            "E_IS_E_SCOPE: -6.899460183365905e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027507409818820247\n",
            "Total Loss: 3.735887243739998e-09\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "Var loss:  tensor(3.6650e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.01043625586384e-08\n",
            "E_s_wdiff_all_sq: 6.69094131769345e-09\n",
            "E_IS_SCOPE: -7.097136772921469e-07\n",
            "E_IS_E_SCOPE: -6.894219015929347e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027486513844820126\n",
            "Total Loss: 3.6649706230098913e-09\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "Var loss:  tensor(3.6163e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.019158269589633e-08\n",
            "E_s_wdiff_all_sq: 7.047948969507643e-09\n",
            "E_IS_SCOPE: -7.088686043075698e-07\n",
            "E_IS_E_SCOPE: -6.886873909938912e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027457229692832603\n",
            "Total Loss: 3.6163078795210177e-09\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "Var loss:  tensor(3.5693e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.022340175868731e-08\n",
            "E_s_wdiff_all_sq: 7.276024706182015e-09\n",
            "E_IS_SCOPE: -7.082681951136063e-07\n",
            "E_IS_E_SCOPE: -6.881616261488276e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027436268010792085\n",
            "Total Loss: 3.5693399034375355e-09\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "Var loss:  tensor(3.5186e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.016352367820866e-08\n",
            "E_s_wdiff_all_sq: 7.104731849313592e-09\n",
            "E_IS_SCOPE: -7.081950169609409e-07\n",
            "E_IS_E_SCOPE: -6.880073851326031e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027430118586443805\n",
            "Total Loss: 3.5186289527090677e-09\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "Var loss:  tensor(3.4698e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.0073711350126875e-08\n",
            "E_s_wdiff_all_sq: 6.8824130528601144e-09\n",
            "E_IS_SCOPE: -7.082042251373988e-07\n",
            "E_IS_E_SCOPE: -6.87925936619862e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002742687132135413\n",
            "Total Loss: 3.469822042682652e-09\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "Var loss:  tensor(3.4187e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.00047678744195e-08\n",
            "E_s_wdiff_all_sq: 6.946826760699025e-09\n",
            "E_IS_SCOPE: -7.078582568159302e-07\n",
            "E_IS_E_SCOPE: -6.876210637744188e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002741471636708328\n",
            "Total Loss: 3.4186558111872093e-09\n",
            "----------------------------------------\n",
            "Epoch 601\n",
            "Var loss:  tensor(3.3686e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 3.997335414265464e-08\n",
            "E_s_wdiff_all_sq: 7.113137966305431e-09\n",
            "E_IS_SCOPE: -7.073711479790296e-07\n",
            "E_IS_E_SCOPE: -6.872077816621355e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002739823925129273\n",
            "Total Loss: 3.3685843230506832e-09\n",
            "----------------------------------------\n",
            "Epoch 602\n",
            "Var loss:  tensor(3.3165e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 3.9966937280180803e-08\n",
            "E_s_wdiff_all_sq: 7.092024184315585e-09\n",
            "E_IS_SCOPE: -7.07104081611171e-07\n",
            "E_IS_E_SCOPE: -6.869073126027179e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027386259871260647\n",
            "Total Loss: 3.3164758594485525e-09\n",
            "----------------------------------------\n",
            "Epoch 603\n",
            "Var loss:  tensor(3.2649e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.0001295036048683e-08\n",
            "E_s_wdiff_all_sq: 7.028975560204206e-09\n",
            "E_IS_SCOPE: -7.069188062217566e-07\n",
            "E_IS_E_SCOPE: -6.866475422458522e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002737590310496998\n",
            "Total Loss: 3.2648923045249735e-09\n",
            "----------------------------------------\n",
            "Epoch 604\n",
            "Var loss:  tensor(3.2126e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.009011874045615e-08\n",
            "E_s_wdiff_all_sq: 7.209589635165083e-09\n",
            "E_IS_SCOPE: -7.065192933606201e-07\n",
            "E_IS_E_SCOPE: -6.86267758440367e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002736076153084333\n",
            "Total Loss: 3.2125600452744006e-09\n",
            "----------------------------------------\n",
            "Epoch 605\n",
            "Var loss:  tensor(3.1605e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.0216330945811706e-08\n",
            "E_s_wdiff_all_sq: 7.532515936768676e-09\n",
            "E_IS_SCOPE: -7.060708863969825e-07\n",
            "E_IS_E_SCOPE: -6.858916814006175e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027345767741501987\n",
            "Total Loss: 3.1605057968024595e-09\n",
            "----------------------------------------\n",
            "Epoch 606\n",
            "Var loss:  tensor(3.1081e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.0334082378353605e-08\n",
            "E_s_wdiff_all_sq: 7.682785307715485e-09\n",
            "E_IS_SCOPE: -7.059589169152527e-07\n",
            "E_IS_E_SCOPE: -6.857697477018076e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027340906375344707\n",
            "Total Loss: 3.1080594242372335e-09\n",
            "----------------------------------------\n",
            "Epoch 607\n",
            "Var loss:  tensor(3.0553e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.043679945819831e-08\n",
            "E_s_wdiff_all_sq: 7.676517738612887e-09\n",
            "E_IS_SCOPE: -7.061504884038536e-07\n",
            "E_IS_E_SCOPE: -6.858804316035599e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027345319224125527\n",
            "Total Loss: 3.0552688994875893e-09\n",
            "----------------------------------------\n",
            "Epoch 608\n",
            "Var loss:  tensor(3.0025e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.058019904325012e-08\n",
            "E_s_wdiff_all_sq: 7.816843656988396e-09\n",
            "E_IS_SCOPE: -7.06262155418203e-07\n",
            "E_IS_E_SCOPE: -6.859641935434701e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027348658723082104\n",
            "Total Loss: 3.002532417285329e-09\n",
            "----------------------------------------\n",
            "Epoch 609\n",
            "Var loss:  tensor(2.9943e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.0950888925868386e-08\n",
            "E_s_wdiff_all_sq: 8.269569962058328e-09\n",
            "E_IS_SCOPE: -7.060409904657788e-07\n",
            "E_IS_E_SCOPE: -6.857799508561199e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002734131316419435\n",
            "Total Loss: 2.994340524981969e-09\n",
            "----------------------------------------\n",
            "Epoch 610\n",
            "Var loss:  tensor(2.9094e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.090447828440774e-08\n",
            "E_s_wdiff_all_sq: 8.147202830152618e-09\n",
            "E_IS_SCOPE: -7.057282998150772e-07\n",
            "E_IS_E_SCOPE: -6.853868091843128e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002732563902622436\n",
            "Total Loss: 2.9093949732159778e-09\n",
            "----------------------------------------\n",
            "Epoch 611\n",
            "Var loss:  tensor(2.8657e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.1057283086196676e-08\n",
            "E_s_wdiff_all_sq: 8.491536901498872e-09\n",
            "E_IS_SCOPE: -7.049791427095529e-07\n",
            "E_IS_E_SCOPE: -6.847115830066948e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027298718480711372\n",
            "Total Loss: 2.8657275594710615e-09\n",
            "----------------------------------------\n",
            "Epoch 612\n",
            "Var loss:  tensor(2.8230e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.115811698584689e-08\n",
            "E_s_wdiff_all_sq: 8.857614042101435e-09\n",
            "E_IS_SCOPE: -7.043218018325041e-07\n",
            "E_IS_E_SCOPE: -6.841655117877005e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027276947205260933\n",
            "Total Loss: 2.8230236346279054e-09\n",
            "----------------------------------------\n",
            "Epoch 613\n",
            "Var loss:  tensor(2.7772e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.111286085016819e-08\n",
            "E_s_wdiff_all_sq: 8.775096256928591e-09\n",
            "E_IS_SCOPE: -7.042244002649378e-07\n",
            "E_IS_E_SCOPE: -6.840265760237644e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002727140798495165\n",
            "Total Loss: 2.7772168913825832e-09\n",
            "----------------------------------------\n",
            "Epoch 614\n",
            "Var loss:  tensor(2.7321e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.0984895164262865e-08\n",
            "E_s_wdiff_all_sq: 8.460637120315824e-09\n",
            "E_IS_SCOPE: -7.044105214293661e-07\n",
            "E_IS_E_SCOPE: -6.840968827628499e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027274211039442363\n",
            "Total Loss: 2.732081491404219e-09\n",
            "----------------------------------------\n",
            "Epoch 615\n",
            "Var loss:  tensor(2.6859e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.088891245700473e-08\n",
            "E_s_wdiff_all_sq: 8.413197020475477e-09\n",
            "E_IS_SCOPE: -7.042952488784241e-07\n",
            "E_IS_E_SCOPE: -6.839828126717835e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027269663186915293\n",
            "Total Loss: 2.6859438037373876e-09\n",
            "----------------------------------------\n",
            "Epoch 616\n",
            "Var loss:  tensor(2.6395e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.084773959575549e-08\n",
            "E_s_wdiff_all_sq: 8.590554566598158e-09\n",
            "E_IS_SCOPE: -7.038944204420539e-07\n",
            "E_IS_E_SCOPE: -6.836680509011564e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002725711397177407\n",
            "Total Loss: 2.639546727851906e-09\n",
            "----------------------------------------\n",
            "Epoch 617\n",
            "Var loss:  tensor(2.5922e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.0816480969676694e-08\n",
            "E_s_wdiff_all_sq: 8.607425982079794e-09\n",
            "E_IS_SCOPE: -7.036292459759239e-07\n",
            "E_IS_E_SCOPE: -6.834032659537788e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027246557279123054\n",
            "Total Loss: 2.592195723796167e-09\n",
            "----------------------------------------\n",
            "Epoch 618\n",
            "Var loss:  tensor(2.5440e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.0798600741427346e-08\n",
            "E_s_wdiff_all_sq: 8.478657005942875e-09\n",
            "E_IS_SCOPE: -7.035138065244259e-07\n",
            "E_IS_E_SCOPE: -6.832082677084488e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027238782907642264\n",
            "Total Loss: 2.5439668840198074e-09\n",
            "----------------------------------------\n",
            "Epoch 619\n",
            "Var loss:  tensor(2.4961e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.0841321166745035e-08\n",
            "E_s_wdiff_all_sq: 8.554794667676217e-09\n",
            "E_IS_SCOPE: -7.03215968825296e-07\n",
            "E_IS_E_SCOPE: -6.829031937724766e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027226619936107097\n",
            "Total Loss: 2.49607717391938e-09\n",
            "----------------------------------------\n",
            "Epoch 620\n",
            "Var loss:  tensor(2.4476e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.093204138291784e-08\n",
            "E_s_wdiff_all_sq: 8.84641322617788e-09\n",
            "E_IS_SCOPE: -7.027755392809083e-07\n",
            "E_IS_E_SCOPE: -6.825389506472096e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00272120979522792\n",
            "Total Loss: 2.4475516698319116e-09\n",
            "----------------------------------------\n",
            "Epoch 621\n",
            "Var loss:  tensor(2.3994e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.100034616893076e-08\n",
            "E_s_wdiff_all_sq: 8.996198684950774e-09\n",
            "E_IS_SCOPE: -7.026091589811779e-07\n",
            "E_IS_E_SCOPE: -6.823892568042506e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002720612981886558\n",
            "Total Loss: 2.3994439106151142e-09\n",
            "----------------------------------------\n",
            "Epoch 622\n",
            "Var loss:  tensor(2.3502e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.102439905900158e-08\n",
            "E_s_wdiff_all_sq: 8.913070705528641e-09\n",
            "E_IS_SCOPE: -7.028145301190358e-07\n",
            "E_IS_E_SCOPE: -6.825164077716308e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027211199191940617\n",
            "Total Loss: 2.3501844391524325e-09\n",
            "----------------------------------------\n",
            "Epoch 623\n",
            "Var loss:  tensor(2.3363e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.1221250977101906e-08\n",
            "E_s_wdiff_all_sq: 9.02269606685016e-09\n",
            "E_IS_SCOPE: -7.02891343073787e-07\n",
            "E_IS_E_SCOPE: -6.825426637232734e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002721224598865054\n",
            "Total Loss: 2.3362969897142942e-09\n",
            "----------------------------------------\n",
            "Epoch 624\n",
            "Var loss:  tensor(2.2669e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.111938408892827e-08\n",
            "E_s_wdiff_all_sq: 8.890801741386608e-09\n",
            "E_IS_SCOPE: -7.025288545316589e-07\n",
            "E_IS_E_SCOPE: -6.821304740023431e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002719581242533486\n",
            "Total Loss: 2.266922069399735e-09\n",
            "----------------------------------------\n",
            "Epoch 625\n",
            "Var loss:  tensor(2.2258e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.124308254992385e-08\n",
            "E_s_wdiff_all_sq: 9.364692874031644e-09\n",
            "E_IS_SCOPE: -7.016591806263158e-07\n",
            "E_IS_E_SCOPE: -6.814153300698246e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027167300401628055\n",
            "Total Loss: 2.2257893433991875e-09\n",
            "----------------------------------------\n",
            "Epoch 626\n",
            "Var loss:  tensor(2.1884e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.130737225911933e-08\n",
            "E_s_wdiff_all_sq: 9.634587195743374e-09\n",
            "E_IS_SCOPE: -7.011465412562382e-07\n",
            "E_IS_E_SCOPE: -6.809867738637489e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027150214324054415\n",
            "Total Loss: 2.188351058886826e-09\n",
            "----------------------------------------\n",
            "Epoch 627\n",
            "Var loss:  tensor(2.1449e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.122467468772751e-08\n",
            "E_s_wdiff_all_sq: 9.337715389199894e-09\n",
            "E_IS_SCOPE: -7.013124457212453e-07\n",
            "E_IS_E_SCOPE: -6.810238793459405e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00271516936799432\n",
            "Total Loss: 2.1449273284074207e-09\n",
            "----------------------------------------\n",
            "Epoch 628\n",
            "Var loss:  tensor(2.1056e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.1157466710487834e-08\n",
            "E_s_wdiff_all_sq: 9.09506734417175e-09\n",
            "E_IS_SCOPE: -7.014702426655331e-07\n",
            "E_IS_E_SCOPE: -6.810742836444125e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027153703245413325\n",
            "Total Loss: 2.1055821045644074e-09\n",
            "----------------------------------------\n",
            "Epoch 629\n",
            "Var loss:  tensor(2.0615e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.120556867371254e-08\n",
            "E_s_wdiff_all_sq: 9.351012820767661e-09\n",
            "E_IS_SCOPE: -7.011087422756402e-07\n",
            "E_IS_E_SCOPE: -6.807946812966498e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027142555798856916\n",
            "Total Loss: 2.0615346754537754e-09\n",
            "----------------------------------------\n",
            "Epoch 630\n",
            "Var loss:  tensor(2.0203e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.131516021767044e-08\n",
            "E_s_wdiff_all_sq: 9.681035971538516e-09\n",
            "E_IS_SCOPE: -7.006571162938821e-07\n",
            "E_IS_E_SCOPE: -6.804326760532395e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002712812303698512\n",
            "Total Loss: 2.020344545336191e-09\n",
            "----------------------------------------\n",
            "Epoch 631\n",
            "Var loss:  tensor(1.9750e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.138985590282095e-08\n",
            "E_s_wdiff_all_sq: 9.65516640816648e-09\n",
            "E_IS_SCOPE: -7.005617032968272e-07\n",
            "E_IS_E_SCOPE: -6.802643142891957e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027121410633524135\n",
            "Total Loss: 1.9750122598807974e-09\n",
            "----------------------------------------\n",
            "Epoch 632\n",
            "Var loss:  tensor(1.9320e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.149857424668432e-08\n",
            "E_s_wdiff_all_sq: 9.620694984831664e-09\n",
            "E_IS_SCOPE: -7.004966228700054e-07\n",
            "E_IS_E_SCOPE: -6.801061557711215e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027115105022567075\n",
            "Total Loss: 1.932045844574429e-09\n",
            "----------------------------------------\n",
            "Epoch 633\n",
            "Var loss:  tensor(1.8865e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.1707930420161776e-08\n",
            "E_s_wdiff_all_sq: 9.984634855024184e-09\n",
            "E_IS_SCOPE: -7.000887738133598e-07\n",
            "E_IS_E_SCOPE: -6.797528418742569e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002710101877538621\n",
            "Total Loss: 1.8865324674213117e-09\n",
            "----------------------------------------\n",
            "Epoch 634\n",
            "Var loss:  tensor(1.8427e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.194579141781874e-08\n",
            "E_s_wdiff_all_sq: 1.0442729906617873e-08\n",
            "E_IS_SCOPE: -6.996881872529198e-07\n",
            "E_IS_E_SCOPE: -6.794404681006423e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027088564767131793\n",
            "Total Loss: 1.8427239871354357e-09\n",
            "----------------------------------------\n",
            "Epoch 635\n",
            "Var loss:  tensor(1.7969e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.208468609509983e-08\n",
            "E_s_wdiff_all_sq: 1.0529549729948237e-08\n",
            "E_IS_SCOPE: -6.997624370639297e-07\n",
            "E_IS_E_SCOPE: -6.794657692484036e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027089573496832174\n",
            "Total Loss: 1.7969015145888996e-09\n",
            "----------------------------------------\n",
            "Epoch 636\n",
            "Var loss:  tensor(1.7520e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.217571146455548e-08\n",
            "E_s_wdiff_all_sq: 1.0453271140350494e-08\n",
            "E_IS_SCOPE: -7.000895083644732e-07\n",
            "E_IS_E_SCOPE: -6.796867449510907e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002709838356175359\n",
            "Total Loss: 1.752014277929699e-09\n",
            "----------------------------------------\n",
            "Epoch 637\n",
            "Var loss:  tensor(1.7526e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.25515540851215e-08\n",
            "E_s_wdiff_all_sq: 1.0830602926828206e-08\n",
            "E_IS_SCOPE: -6.999989251158366e-07\n",
            "E_IS_E_SCOPE: -6.795971857845822e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002709481293357297\n",
            "Total Loss: 1.7525732762742586e-09\n",
            "----------------------------------------\n",
            "Epoch 638\n",
            "Var loss:  tensor(1.6738e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.246401969024014e-08\n",
            "E_s_wdiff_all_sq: 1.0782183080374358e-08\n",
            "E_IS_SCOPE: -6.995901728398235e-07\n",
            "E_IS_E_SCOPE: -6.791686111737231e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00270777261222203\n",
            "Total Loss: 1.6738140581547353e-09\n",
            "----------------------------------------\n",
            "Epoch 639\n",
            "Var loss:  tensor(1.6381e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.264773010976104e-08\n",
            "E_s_wdiff_all_sq: 1.1235227191514345e-08\n",
            "E_IS_SCOPE: -6.987877654418023e-07\n",
            "E_IS_E_SCOPE: -6.784830278920638e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002705039265004663\n",
            "Total Loss: 1.6381285992592324e-09\n",
            "----------------------------------------\n",
            "Epoch 640\n",
            "Var loss:  tensor(1.6031e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.271963564274009e-08\n",
            "E_s_wdiff_all_sq: 1.1451631181267463e-08\n",
            "E_IS_SCOPE: -6.983286067209949e-07\n",
            "E_IS_E_SCOPE: -6.780786237366741e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027034269488902\n",
            "Total Loss: 1.6031392733204748e-09\n",
            "----------------------------------------\n",
            "Epoch 641\n",
            "Var loss:  tensor(1.5646e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.260561682027522e-08\n",
            "E_s_wdiff_all_sq: 1.1185631994160472e-08\n",
            "E_IS_SCOPE: -6.984046245758136e-07\n",
            "E_IS_E_SCOPE: -6.780593919172892e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027033502736832533\n",
            "Total Loss: 1.564620289555403e-09\n",
            "----------------------------------------\n",
            "Epoch 642\n",
            "Var loss:  tensor(1.5276e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.247625516605723e-08\n",
            "E_s_wdiff_all_sq: 1.0950934613163291e-08\n",
            "E_IS_SCOPE: -6.984879026094402e-07\n",
            "E_IS_E_SCOPE: -6.780714831949605e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002703398480314105\n",
            "Total Loss: 1.5275825044241356e-09\n",
            "----------------------------------------\n",
            "Epoch 643\n",
            "Var loss:  tensor(1.4882e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.2445558417270797e-08\n",
            "E_s_wdiff_all_sq: 1.1078062518583369e-08\n",
            "E_IS_SCOPE: -6.98217820807065e-07\n",
            "E_IS_E_SCOPE: -6.778606015947007e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002702557717928726\n",
            "Total Loss: 1.4881582544485044e-09\n",
            "----------------------------------------\n",
            "Epoch 644\n",
            "Var loss:  tensor(1.4497e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.245465246993052e-08\n",
            "E_s_wdiff_all_sq: 1.123110589682696e-08\n",
            "E_IS_SCOPE: -6.978950372463915e-07\n",
            "E_IS_E_SCOPE: -6.775905433715171e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027014810246769896\n",
            "Total Loss: 1.4496596038441569e-09\n",
            "----------------------------------------\n",
            "Epoch 645\n",
            "Var loss:  tensor(1.4086e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.243886090820251e-08\n",
            "E_s_wdiff_all_sq: 1.1140398750195821e-08\n",
            "E_IS_SCOPE: -6.977836500631776e-07\n",
            "E_IS_E_SCOPE: -6.774211516426251e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0027008056779712014\n",
            "Total Loss: 1.4085660973911288e-09\n",
            "----------------------------------------\n",
            "Epoch 646\n",
            "Var loss:  tensor(1.3683e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.2480863672570955e-08\n",
            "E_s_wdiff_all_sq: 1.111337751792446e-08\n",
            "E_IS_SCOPE: -6.976266852776048e-07\n",
            "E_IS_E_SCOPE: -6.772095467260571e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002699962031801064\n",
            "Total Loss: 1.3683098320408019e-09\n",
            "----------------------------------------\n",
            "Epoch 647\n",
            "Var loss:  tensor(1.3266e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.2635069210368815e-08\n",
            "E_s_wdiff_all_sq: 1.1410978753048282e-08\n",
            "E_IS_SCOPE: -6.972246693393337e-07\n",
            "E_IS_E_SCOPE: -6.768583733942495e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002698561941286916\n",
            "Total Loss: 1.3265993476417492e-09\n",
            "----------------------------------------\n",
            "Epoch 648\n",
            "Var loss:  tensor(1.2858e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.2811389723743914e-08\n",
            "E_s_wdiff_all_sq: 1.1741838009458173e-08\n",
            "E_IS_SCOPE: -6.968992056825003e-07\n",
            "E_IS_E_SCOPE: -6.765897672630625e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002697491037370662\n",
            "Total Loss: 1.2857756558997875e-09\n",
            "----------------------------------------\n",
            "Epoch 649\n",
            "Var loss:  tensor(1.2435e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.2904256007997805e-08\n",
            "E_s_wdiff_all_sq: 1.178562657135637e-08\n",
            "E_IS_SCOPE: -6.969663231081682e-07\n",
            "E_IS_E_SCOPE: -6.766112280235617e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002697576599127435\n",
            "Total Loss: 1.2435400479177259e-09\n",
            "----------------------------------------\n",
            "Epoch 650\n",
            "Var loss:  tensor(1.2254e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.308829467362887e-08\n",
            "E_s_wdiff_all_sq: 1.1841943953832787e-08\n",
            "E_IS_SCOPE: -6.971199815031641e-07\n",
            "E_IS_E_SCOPE: -6.766919468577736e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026978984164861487\n",
            "Total Loss: 1.2253822095045853e-09\n",
            "----------------------------------------\n",
            "Epoch 651\n",
            "Var loss:  tensor(1.1760e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.301955093967782e-08\n",
            "E_s_wdiff_all_sq: 1.1670828540557182e-08\n",
            "E_IS_SCOPE: -6.967849954899047e-07\n",
            "E_IS_E_SCOPE: -6.762810901967977e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002696260374922042\n",
            "Total Loss: 1.1760125933960902e-09\n",
            "----------------------------------------\n",
            "Epoch 652\n",
            "Var loss:  tensor(1.1406e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.32258591655085e-08\n",
            "E_s_wdiff_all_sq: 1.2272054509071966e-08\n",
            "E_IS_SCOPE: -6.958963750882304e-07\n",
            "E_IS_E_SCOPE: -6.755722275726639e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026934342154560733\n",
            "Total Loss: 1.1406104057930088e-09\n",
            "----------------------------------------\n",
            "Epoch 653\n",
            "Var loss:  tensor(1.1110e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.33155338779822e-08\n",
            "E_s_wdiff_all_sq: 1.2595145084820076e-08\n",
            "E_IS_SCOPE: -6.954113084825674e-07\n",
            "E_IS_E_SCOPE: -6.7518904998535e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002691906527398239\n",
            "Total Loss: 1.110972579217152e-09\n",
            "----------------------------------------\n",
            "Epoch 654\n",
            "Var loss:  tensor(1.0732e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.3120030370273195e-08\n",
            "E_s_wdiff_all_sq: 1.212291192956534e-08\n",
            "E_IS_SCOPE: -6.957281697327018e-07\n",
            "E_IS_E_SCOPE: -6.753486689046536e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026925429109574493\n",
            "Total Loss: 1.0732175651010272e-09\n",
            "----------------------------------------\n",
            "Epoch 655\n",
            "Var loss:  tensor(1.0416e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.295998227221115e-08\n",
            "E_s_wdiff_all_sq: 1.1747809447871487e-08\n",
            "E_IS_SCOPE: -6.959836865351546e-07\n",
            "E_IS_E_SCOPE: -6.754808259990222e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026930698071578256\n",
            "Total Loss: 1.041552532564658e-09\n",
            "----------------------------------------\n",
            "Epoch 656\n",
            "Var loss:  tensor(1.0032e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.3022042753942405e-08\n",
            "E_s_wdiff_all_sq: 1.2068755389357031e-08\n",
            "E_IS_SCOPE: -6.955720841285909e-07\n",
            "E_IS_E_SCOPE: -6.751794850587654e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026918683930589635\n",
            "Total Loss: 1.0031900054235438e-09\n",
            "----------------------------------------\n",
            "Epoch 657\n",
            "Var loss:  tensor(9.6901e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.314309073031592e-08\n",
            "E_s_wdiff_all_sq: 1.2435001656319327e-08\n",
            "E_IS_SCOPE: -6.950832831212286e-07\n",
            "E_IS_E_SCOPE: -6.74796194408979e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026903402542331444\n",
            "Total Loss: 9.690124299868747e-10\n",
            "----------------------------------------\n",
            "Epoch 658\n",
            "Var loss:  tensor(9.2899e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.314179864303849e-08\n",
            "E_s_wdiff_all_sq: 1.2283261436928026e-08\n",
            "E_IS_SCOPE: -6.95043998295124e-07\n",
            "E_IS_E_SCOPE: -6.746616740309934e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026898039358737524\n",
            "Total Loss: 9.289894583389008e-10\n",
            "----------------------------------------\n",
            "Epoch 659\n",
            "Var loss:  tensor(8.9290e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.3183809038395044e-08\n",
            "E_s_wdiff_all_sq: 1.216463238598814e-08\n",
            "E_IS_SCOPE: -6.950018454996854e-07\n",
            "E_IS_E_SCOPE: -6.74521157205073e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026892437103177946\n",
            "Total Loss: 8.929008436714338e-10\n",
            "----------------------------------------\n",
            "Epoch 660\n",
            "Var loss:  tensor(8.5280e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.339594662350076e-08\n",
            "E_s_wdiff_all_sq: 1.2586471815074266e-08\n",
            "E_IS_SCOPE: -6.94550055112347e-07\n",
            "E_IS_E_SCOPE: -6.741541693004727e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002687780568793371\n",
            "Total Loss: 8.528039651673911e-10\n",
            "----------------------------------------\n",
            "Epoch 661\n",
            "Var loss:  tensor(8.1562e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.36193939639239e-08\n",
            "E_s_wdiff_all_sq: 1.303906897126952e-08\n",
            "E_IS_SCOPE: -6.9419388752061e-07\n",
            "E_IS_E_SCOPE: -6.738939824488667e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026867432316443215\n",
            "Total Loss: 8.156156296572957e-10\n",
            "----------------------------------------\n",
            "Epoch 662\n",
            "Var loss:  tensor(7.7486e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.3658856905435566e-08\n",
            "E_s_wdiff_all_sq: 1.2959023055921977e-08\n",
            "E_IS_SCOPE: -6.944355646266784e-07\n",
            "E_IS_E_SCOPE: -6.740555280375284e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002687387296628196\n",
            "Total Loss: 7.748614517032393e-10\n",
            "----------------------------------------\n",
            "Epoch 663\n",
            "Var loss:  tensor(7.5219e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.3743024011091543e-08\n",
            "E_s_wdiff_all_sq: 1.2832665779744684e-08\n",
            "E_IS_SCOPE: -6.94811242289783e-07\n",
            "E_IS_E_SCOPE: -6.743146054626695e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026884202106125885\n",
            "Total Loss: 7.521853576095052e-10\n",
            "----------------------------------------\n",
            "Epoch 664\n",
            "Var loss:  tensor(7.1306e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.3712308661585705e-08\n",
            "E_s_wdiff_all_sq: 1.2734929473392267e-08\n",
            "E_IS_SCOPE: -6.944280985972438e-07\n",
            "E_IS_E_SCOPE: -6.738783910439481e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026866810703804907\n",
            "Total Loss: 7.130648620916297e-10\n",
            "----------------------------------------\n",
            "Epoch 665\n",
            "Var loss:  tensor(6.8057e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.3981835669637474e-08\n",
            "E_s_wdiff_all_sq: 1.3480095077687064e-08\n",
            "E_IS_SCOPE: -6.93445605758535e-07\n",
            "E_IS_E_SCOPE: -6.731174692022815e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026836473563822166\n",
            "Total Loss: 6.805682599332134e-10\n",
            "----------------------------------------\n",
            "Epoch 666\n",
            "Var loss:  tensor(6.5385e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.406464328238417e-08\n",
            "E_s_wdiff_all_sq: 1.3752647783948806e-08\n",
            "E_IS_SCOPE: -6.930097170697308e-07\n",
            "E_IS_E_SCOPE: -6.727630949010875e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026822345039454847\n",
            "Total Loss: 6.538519416384501e-10\n",
            "----------------------------------------\n",
            "Epoch 667\n",
            "Var loss:  tensor(6.1871e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.3806585087309383e-08\n",
            "E_s_wdiff_all_sq: 1.3139871944151855e-08\n",
            "E_IS_SCOPE: -6.934191937628916e-07\n",
            "E_IS_E_SCOPE: -6.729776419013945e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002683089879888819\n",
            "Total Loss: 6.187102006529572e-10\n",
            "----------------------------------------\n",
            "Epoch 668\n",
            "Var loss:  tensor(5.8990e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.364106844600898e-08\n",
            "E_s_wdiff_all_sq: 1.2803533451432188e-08\n",
            "E_IS_SCOPE: -6.936207732437152e-07\n",
            "E_IS_E_SCOPE: -6.730794051781795e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002683495599189262\n",
            "Total Loss: 5.898996439949162e-10\n",
            "----------------------------------------\n",
            "Epoch 669\n",
            "Var loss:  tensor(5.5389e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.373357452536292e-08\n",
            "E_s_wdiff_all_sq: 1.323427191840742e-08\n",
            "E_IS_SCOPE: -6.931325104175272e-07\n",
            "E_IS_E_SCOPE: -6.727422526459686e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026821514081035104\n",
            "Total Loss: 5.538878443280781e-10\n",
            "----------------------------------------\n",
            "Epoch 670\n",
            "Var loss:  tensor(5.2279e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.3825039377063214e-08\n",
            "E_s_wdiff_all_sq: 1.352612324192494e-08\n",
            "E_IS_SCOPE: -6.927425866455905e-07\n",
            "E_IS_E_SCOPE: -6.724369742179802e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026809342956621973\n",
            "Total Loss: 5.227920604074606e-10\n",
            "----------------------------------------\n",
            "Epoch 671\n",
            "Var loss:  tensor(4.8511e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.374942928578607e-08\n",
            "E_s_wdiff_all_sq: 1.3213129456581522e-08\n",
            "E_IS_SCOPE: -6.928682517063337e-07\n",
            "E_IS_E_SCOPE: -6.724251051525754e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002680886974967885\n",
            "Total Loss: 4.851075021775366e-10\n",
            "----------------------------------------\n",
            "Epoch 672\n",
            "Var loss:  tensor(4.5206e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.378189716679668e-08\n",
            "E_s_wdiff_all_sq: 1.3112613318460514e-08\n",
            "E_IS_SCOPE: -6.92840688229294e-07\n",
            "E_IS_E_SCOPE: -6.72314527286687e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002680446112843451\n",
            "Total Loss: 4.5206274361169306e-10\n",
            "----------------------------------------\n",
            "Epoch 673\n",
            "Var loss:  tensor(4.1398e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4038931940541046e-08\n",
            "E_s_wdiff_all_sq: 1.3653484057673413e-08\n",
            "E_IS_SCOPE: -6.923325453323887e-07\n",
            "E_IS_E_SCOPE: -6.719292628343876e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002678910104678121\n",
            "Total Loss: 4.1398366735506834e-10\n",
            "----------------------------------------\n",
            "Epoch 674\n",
            "Var loss:  tensor(3.7982e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4268223964556676e-08\n",
            "E_s_wdiff_all_sq: 1.4077664563049514e-08\n",
            "E_IS_SCOPE: -6.920436543987101e-07\n",
            "E_IS_E_SCOPE: -6.71720736375921e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002678078731991177\n",
            "Total Loss: 3.7982413641820235e-10\n",
            "----------------------------------------\n",
            "Epoch 675\n",
            "Var loss:  tensor(3.4115e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4278598693326596e-08\n",
            "E_s_wdiff_all_sq: 1.3891309888337933e-08\n",
            "E_IS_SCOPE: -6.923964472126508e-07\n",
            "E_IS_E_SCOPE: -6.719558252985869e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002679016006381893\n",
            "Total Loss: 3.4114575735051934e-10\n",
            "----------------------------------------\n",
            "Epoch 676\n",
            "Var loss:  tensor(3.5692e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.457680070731708e-08\n",
            "E_s_wdiff_all_sq: 1.3968815039653698e-08\n",
            "E_IS_SCOPE: -6.925870649831797e-07\n",
            "E_IS_E_SCOPE: -6.720439796055151e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026793674681750658\n",
            "Total Loss: 3.569156928239376e-10\n",
            "----------------------------------------\n",
            "Epoch 677\n",
            "Var loss:  tensor(2.8363e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4406668138129046e-08\n",
            "E_s_wdiff_all_sq: 1.3843234248575421e-08\n",
            "E_IS_SCOPE: -6.922534694952929e-07\n",
            "E_IS_E_SCOPE: -6.716960176724423e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002677980181164198\n",
            "Total Loss: 2.83631024342133e-10\n",
            "----------------------------------------\n",
            "Epoch 678\n",
            "Var loss:  tensor(2.5579e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.470694846263799e-08\n",
            "E_s_wdiff_all_sq: 1.4602062956052558e-08\n",
            "E_IS_SCOPE: -6.912977906286985e-07\n",
            "E_IS_E_SCOPE: -6.709556923352841e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002675028583226498\n",
            "Total Loss: 2.557897002462036e-10\n",
            "----------------------------------------\n",
            "Epoch 679\n",
            "Var loss:  tensor(2.3015e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4753740008894125e-08\n",
            "E_s_wdiff_all_sq: 1.4761513983469079e-08\n",
            "E_IS_SCOPE: -6.909911320867016e-07\n",
            "E_IS_E_SCOPE: -6.706925446231204e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026739794414430834\n",
            "Total Loss: 2.3015187875223628e-10\n",
            "----------------------------------------\n",
            "Epoch 680\n",
            "Var loss:  tensor(1.9920e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.447013350623615e-08\n",
            "E_s_wdiff_all_sq: 1.412105930298778e-08\n",
            "E_IS_SCOPE: -6.914432655800307e-07\n",
            "E_IS_E_SCOPE: -6.709507794233877e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002675008995972228\n",
            "Total Loss: 1.9920267045205544e-10\n",
            "----------------------------------------\n",
            "Epoch 681\n",
            "Var loss:  tensor(1.7177e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.431928849082601e-08\n",
            "E_s_wdiff_all_sq: 1.386954854477351e-08\n",
            "E_IS_SCOPE: -6.916039977987898e-07\n",
            "E_IS_E_SCOPE: -6.710474641621564e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026753944676847757\n",
            "Total Loss: 1.717734532751021e-10\n",
            "----------------------------------------\n",
            "Epoch 682\n",
            "Var loss:  tensor(1.3983e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4426496052382195e-08\n",
            "E_s_wdiff_all_sq: 1.430981976500748e-08\n",
            "E_IS_SCOPE: -6.911603379897107e-07\n",
            "E_IS_E_SCOPE: -6.707543668725913e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026742259201395207\n",
            "Total Loss: 1.3983483362536856e-10\n",
            "----------------------------------------\n",
            "Epoch 683\n",
            "Var loss:  tensor(1.1024e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4488450496966154e-08\n",
            "E_s_wdiff_all_sq: 1.4494368650214536e-08\n",
            "E_IS_SCOPE: -6.908990711583418e-07\n",
            "E_IS_E_SCOPE: -6.705396022366206e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002673369676506073\n",
            "Total Loss: 1.1024478379873061e-10\n",
            "----------------------------------------\n",
            "Epoch 684\n",
            "Var loss:  tensor(7.6182e-11, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.44061057352354e-08\n",
            "E_s_wdiff_all_sq: 1.4163673939611993e-08\n",
            "E_IS_SCOPE: -6.910514621332854e-07\n",
            "E_IS_E_SCOPE: -6.705507867793944e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002673414268081868\n",
            "Total Loss: 7.618186833065264e-11\n",
            "----------------------------------------\n",
            "Epoch 685\n",
            "Var loss:  tensor(4.4756e-11, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.448210503270165e-08\n",
            "E_s_wdiff_all_sq: 1.4180952135454944e-08\n",
            "E_IS_SCOPE: -6.909366557797345e-07\n",
            "E_IS_E_SCOPE: -6.703909069908569e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026727768444649237\n",
            "Total Loss: 4.4756099981130104e-11\n",
            "----------------------------------------\n",
            "Epoch 686\n",
            "Var loss:  tensor(1.0125e-11, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4771719156895084e-08\n",
            "E_s_wdiff_all_sq: 1.4766241781121726e-08\n",
            "E_IS_SCOPE: -6.90423415582489e-07\n",
            "E_IS_E_SCOPE: -6.700081892123832e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026712509896157565\n",
            "Total Loss: 1.0125416051219784e-11\n",
            "----------------------------------------\n",
            "Epoch 687\n",
            "Var loss:  tensor(-2.2228e-11, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.496635694011742e-08\n",
            "E_s_wdiff_all_sq: 1.50820717292923e-08\n",
            "E_IS_SCOPE: -6.902530407780185e-07\n",
            "E_IS_E_SCOPE: -6.698822337882963e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026707488188114936\n",
            "Total Loss: -2.2227988130009514e-11\n",
            "----------------------------------------\n",
            "Epoch 688\n",
            "Var loss:  tensor(-1.1428e-11, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.518865859671392e-08\n",
            "E_s_wdiff_all_sq: 1.5035464530423722e-08\n",
            "E_IS_SCOPE: -6.904662294805462e-07\n",
            "E_IS_E_SCOPE: -6.69966367906946e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026710842525439794\n",
            "Total Loss: -1.1428300420593328e-11\n",
            "----------------------------------------\n",
            "Epoch 689\n",
            "Var loss:  tensor(-6.9398e-11, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4845450362436015e-08\n",
            "E_s_wdiff_all_sq: 1.4445357448020271e-08\n",
            "E_IS_SCOPE: -6.904586241851954e-07\n",
            "E_IS_E_SCOPE: -6.698063284823101e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002670446192474984\n",
            "Total Loss: -6.939771086533155e-11\n",
            "----------------------------------------\n",
            "Epoch 690\n",
            "Var loss:  tensor(-1.0111e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.511935565131102e-08\n",
            "E_s_wdiff_all_sq: 1.522975138124148e-08\n",
            "E_IS_SCOPE: -6.894821468580382e-07\n",
            "E_IS_E_SCOPE: -6.69069237732253e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026675074904901003\n",
            "Total Loss: -1.0111320101151788e-10\n",
            "----------------------------------------\n",
            "Epoch 691\n",
            "Var loss:  tensor(-1.1888e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.524606379578499e-08\n",
            "E_s_wdiff_all_sq: 1.5695301761389584e-08\n",
            "E_IS_SCOPE: -6.889454543460984e-07\n",
            "E_IS_E_SCOPE: -6.686930838779273e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002666007805304466\n",
            "Total Loss: -1.1887812145721907e-10\n",
            "----------------------------------------\n",
            "Epoch 692\n",
            "Var loss:  tensor(-1.5237e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.484543798723579e-08\n",
            "E_s_wdiff_all_sq: 1.488671104342367e-08\n",
            "E_IS_SCOPE: -6.895413361488008e-07\n",
            "E_IS_E_SCOPE: -6.690682379435324e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026675035044394038\n",
            "Total Loss: -1.5236868623527492e-10\n",
            "----------------------------------------\n",
            "Epoch 693\n",
            "Var loss:  tensor(-1.7295e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4540983029728566e-08\n",
            "E_s_wdiff_all_sq: 1.4257530045852623e-08\n",
            "E_IS_SCOPE: -6.900257024486057e-07\n",
            "E_IS_E_SCOPE: -6.69379950191513e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026687462678328965\n",
            "Total Loss: -1.729507498198311e-10\n",
            "----------------------------------------\n",
            "Epoch 694\n",
            "Var loss:  tensor(-2.0657e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.467368283437113e-08\n",
            "E_s_wdiff_all_sq: 1.4766101632998391e-08\n",
            "E_IS_SCOPE: -6.895281207194058e-07\n",
            "E_IS_E_SCOPE: -6.69053492985849e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002667444717870168\n",
            "Total Loss: -2.0657348525130632e-10\n",
            "----------------------------------------\n",
            "Epoch 695\n",
            "Var loss:  tensor(-2.3097e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.488031851874847e-08\n",
            "E_s_wdiff_all_sq: 1.528459525382889e-08\n",
            "E_IS_SCOPE: -6.889815507681096e-07\n",
            "E_IS_E_SCOPE: -6.686506516745812e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026658386326480652\n",
            "Total Loss: -2.3097414164734334e-10\n",
            "----------------------------------------\n",
            "Epoch 696\n",
            "Var loss:  tensor(-2.6632e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4803050149314416e-08\n",
            "E_s_wdiff_all_sq: 1.4936173582593934e-08\n",
            "E_IS_SCOPE: -6.891254783934986e-07\n",
            "E_IS_E_SCOPE: -6.686413300386815e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002665801468282729\n",
            "Total Loss: -2.6631936242406644e-10\n",
            "----------------------------------------\n",
            "Epoch 697\n",
            "Var loss:  tensor(-2.9315e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.481672361316895e-08\n",
            "E_s_wdiff_all_sq: 1.4730799256971054e-08\n",
            "E_IS_SCOPE: -6.891906315105092e-07\n",
            "E_IS_E_SCOPE: -6.685835426670674e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002665571076212756\n",
            "Total Loss: -2.9315255019617535e-10\n",
            "----------------------------------------\n",
            "Epoch 698\n",
            "Var loss:  tensor(-3.2820e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.514365027312256e-08\n",
            "E_s_wdiff_all_sq: 1.5385645384964503e-08\n",
            "E_IS_SCOPE: -6.886452753039501e-07\n",
            "E_IS_E_SCOPE: -6.68184621009712e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026639806182315747\n",
            "Total Loss: -3.2820291982857296e-10\n",
            "----------------------------------------\n",
            "Epoch 699\n",
            "Var loss:  tensor(-3.5680e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.542510713766615e-08\n",
            "E_s_wdiff_all_sq: 1.5922124576449505e-08\n",
            "E_IS_SCOPE: -6.883381141792037e-07\n",
            "E_IS_E_SCOPE: -6.679906719907871e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002663207364236952\n",
            "Total Loss: -3.5680103512705247e-10\n",
            "----------------------------------------\n",
            "Epoch 700\n",
            "Var loss:  tensor(-3.5518e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.555558876435272e-08\n",
            "E_s_wdiff_all_sq: 1.575803257958862e-08\n",
            "E_IS_SCOPE: -6.886964876873686e-07\n",
            "E_IS_E_SCOPE: -6.682025696351326e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026640521774814302\n",
            "Total Loss: -3.551791392185533e-10\n",
            "----------------------------------------\n",
            "Epoch 701\n",
            "Var loss:  tensor(-3.9891e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.515636315688293e-08\n",
            "E_s_wdiff_all_sq: 1.4966147766921107e-08\n",
            "E_IS_SCOPE: -6.888784599751925e-07\n",
            "E_IS_E_SCOPE: -6.681663445749461e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00266390775204092\n",
            "Total Loss: -3.9891463004135197e-10\n",
            "----------------------------------------\n",
            "Epoch 702\n",
            "Var loss:  tensor(-4.3232e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.545561411754372e-08\n",
            "E_s_wdiff_all_sq: 1.5807688534957205e-08\n",
            "E_IS_SCOPE: -6.878983771169666e-07\n",
            "E_IS_E_SCOPE: -6.674407059872676e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026610147086025735\n",
            "Total Loss: -4.323158963217693e-10\n",
            "----------------------------------------\n",
            "Epoch 703\n",
            "Var loss:  tensor(-4.4526e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.567216755802402e-08\n",
            "E_s_wdiff_all_sq: 1.6461677466854188e-08\n",
            "E_IS_SCOPE: -6.872356471195825e-07\n",
            "E_IS_E_SCOPE: -6.669902195663117e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00265921866742403\n",
            "Total Loss: -4.4526423488207394e-10\n",
            "----------------------------------------\n",
            "Epoch 704\n",
            "Var loss:  tensor(-4.7956e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5249162380015815e-08\n",
            "E_s_wdiff_all_sq: 1.5598393006834125e-08\n",
            "E_IS_SCOPE: -6.878621490407481e-07\n",
            "E_IS_E_SCOPE: -6.673794339033869e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002660770423357501\n",
            "Total Loss: -4.795601210511233e-10\n",
            "----------------------------------------\n",
            "Epoch 705\n",
            "Var loss:  tensor(-4.9624e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4910165393590237e-08\n",
            "E_s_wdiff_all_sq: 1.4851953528623779e-08\n",
            "E_IS_SCOPE: -6.884284689237595e-07\n",
            "E_IS_E_SCOPE: -6.677336943535235e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002662182821882244\n",
            "Total Loss: -4.962364950160474e-10\n",
            "----------------------------------------\n",
            "Epoch 706\n",
            "Var loss:  tensor(-5.3057e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.509915717465442e-08\n",
            "E_s_wdiff_all_sq: 1.5461967854944995e-08\n",
            "E_IS_SCOPE: -6.878598982940572e-07\n",
            "E_IS_E_SCOPE: -6.673584665669431e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002660686828829663\n",
            "Total Loss: -5.305733540293874e-10\n",
            "----------------------------------------\n",
            "Epoch 707\n",
            "Var loss:  tensor(-5.5161e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.537569055704467e-08\n",
            "E_s_wdiff_all_sq: 1.611666203487152e-08\n",
            "E_IS_SCOPE: -6.872303694456274e-07\n",
            "E_IS_E_SCOPE: -6.669074996149767e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026588888718253757\n",
            "Total Loss: -5.516103586386686e-10\n",
            "----------------------------------------\n",
            "Epoch 708\n",
            "Var loss:  tensor(-5.8705e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5258803782509506e-08\n",
            "E_s_wdiff_all_sq: 1.5684133251203998e-08\n",
            "E_IS_SCOPE: -6.874651935164965e-07\n",
            "E_IS_E_SCOPE: -6.669667839610224e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026591252321722983\n",
            "Total Loss: -5.870477991529067e-10\n",
            "----------------------------------------\n",
            "Epoch 709\n",
            "Var loss:  tensor(-6.1087e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.522434100140135e-08\n",
            "E_s_wdiff_all_sq: 1.5368416131427014e-08\n",
            "E_IS_SCOPE: -6.876580558221689e-07\n",
            "E_IS_E_SCOPE: -6.670071098736903e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026592860072730444\n",
            "Total Loss: -6.108662464934615e-10\n",
            "----------------------------------------\n",
            "Epoch 710\n",
            "Var loss:  tensor(-6.4594e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5579323567706384e-08\n",
            "E_s_wdiff_all_sq: 1.6090477711063245e-08\n",
            "E_IS_SCOPE: -6.871166239912971e-07\n",
            "E_IS_E_SCOPE: -6.666316806585098e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026577892111461785\n",
            "Total Loss: -6.459400284419556e-10\n",
            "----------------------------------------\n",
            "Epoch 711\n",
            "Var loss:  tensor(-6.7213e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5900383431909e-08\n",
            "E_s_wdiff_all_sq: 1.670328454742634e-08\n",
            "E_IS_SCOPE: -6.86800650804752e-07\n",
            "E_IS_E_SCOPE: -6.664484853419057e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002657058831012546\n",
            "Total Loss: -6.721312607205459e-10\n",
            "----------------------------------------\n",
            "Epoch 712\n",
            "Var loss:  tensor(-6.4739e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.613779252831958e-08\n",
            "E_s_wdiff_all_sq: 1.6573189376159784e-08\n",
            "E_IS_SCOPE: -6.871379330490044e-07\n",
            "E_IS_E_SCOPE: -6.666143860206077e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002657720259274612\n",
            "Total Loss: -6.473901241439589e-10\n",
            "----------------------------------------\n",
            "Epoch 713\n",
            "Var loss:  tensor(-7.1066e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.559244807398638e-08\n",
            "E_s_wdiff_all_sq: 1.5623053702863593e-08\n",
            "E_IS_SCOPE: -6.874452007447146e-07\n",
            "E_IS_E_SCOPE: -6.666876220730954e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026580122435829133\n",
            "Total Loss: -7.106621916260474e-10\n",
            "----------------------------------------\n",
            "Epoch 714\n",
            "Var loss:  tensor(-7.4476e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.596733385693897e-08\n",
            "E_s_wdiff_all_sq: 1.6601320684909574e-08\n",
            "E_IS_SCOPE: -6.863633357686165e-07\n",
            "E_IS_E_SCOPE: -6.658903996077475e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002654833802880557\n",
            "Total Loss: -7.447583692192232e-10\n",
            "----------------------------------------\n",
            "Epoch 715\n",
            "Var loss:  tensor(-7.5467e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.623558229756796e-08\n",
            "E_s_wdiff_all_sq: 1.732752506526003e-08\n",
            "E_IS_SCOPE: -6.856505515222518e-07\n",
            "E_IS_E_SCOPE: -6.65401636337621e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026528851559982736\n",
            "Total Loss: -7.54672356463953e-10\n",
            "----------------------------------------\n",
            "Epoch 716\n",
            "Var loss:  tensor(-7.8955e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5761935635053614e-08\n",
            "E_s_wdiff_all_sq: 1.6353904104118714e-08\n",
            "E_IS_SCOPE: -6.863441783255811e-07\n",
            "E_IS_E_SCOPE: -6.65827839137784e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002654584380977972\n",
            "Total Loss: -7.895460641698926e-10\n",
            "----------------------------------------\n",
            "Epoch 717\n",
            "Var loss:  tensor(-8.0379e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.540544268320313e-08\n",
            "E_s_wdiff_all_sq: 1.5577395543292168e-08\n",
            "E_IS_SCOPE: -6.869247747796281e-07\n",
            "E_IS_E_SCOPE: -6.661913052470693e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026560334814811487\n",
            "Total Loss: -8.037911447169866e-10\n",
            "----------------------------------------\n",
            "Epoch 718\n",
            "Var loss:  tensor(-8.3831e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.564419722904447e-08\n",
            "E_s_wdiff_all_sq: 1.6297217824763657e-08\n",
            "E_IS_SCOPE: -6.862894635971544e-07\n",
            "E_IS_E_SCOPE: -6.657792664749306e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026543907269662684\n",
            "Total Loss: -8.383140596771254e-10\n",
            "----------------------------------------\n",
            "Epoch 719\n",
            "Var loss:  tensor(-8.5720e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.593225931805981e-08\n",
            "E_s_wdiff_all_sq: 1.6955260440893863e-08\n",
            "E_IS_SCOPE: -6.856780104845638e-07\n",
            "E_IS_E_SCOPE: -6.653433601289127e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026526528149870892\n",
            "Total Loss: -8.572010536467128e-10\n",
            "----------------------------------------\n",
            "Epoch 720\n",
            "Var loss:  tensor(-8.9263e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.576310358270074e-08\n",
            "E_s_wdiff_all_sq: 1.6403514907298762e-08\n",
            "E_IS_SCOPE: -6.85999993143673e-07\n",
            "E_IS_E_SCOPE: -6.65456332341726e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002653103223116625\n",
            "Total Loss: -8.926321480025651e-10\n",
            "----------------------------------------\n",
            "Epoch 721\n",
            "Var loss:  tensor(-9.1469e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5723090889119156e-08\n",
            "E_s_wdiff_all_sq: 1.6091089836434428e-08\n",
            "E_IS_SCOPE: -6.8618471280083e-07\n",
            "E_IS_E_SCOPE: -6.654938167857705e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002653252669585879\n",
            "Total Loss: -9.146901969447546e-10\n",
            "----------------------------------------\n",
            "Epoch 722\n",
            "Var loss:  tensor(-9.4947e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6136138070490924e-08\n",
            "E_s_wdiff_all_sq: 1.6935642375214332e-08\n",
            "E_IS_SCOPE: -6.855546713641746e-07\n",
            "E_IS_E_SCOPE: -6.650621362103126e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026515316053019556\n",
            "Total Loss: -9.49473831957527e-10\n",
            "----------------------------------------\n",
            "Epoch 723\n",
            "Var loss:  tensor(-9.3509e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6683622209544935e-08\n",
            "E_s_wdiff_all_sq: 1.7713641967527146e-08\n",
            "E_IS_SCOPE: -6.850806044775047e-07\n",
            "E_IS_E_SCOPE: -6.647105170115118e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026501297371637933\n",
            "Total Loss: -9.350939094783946e-10\n",
            "----------------------------------------\n",
            "Epoch 724\n",
            "Var loss:  tensor(-9.8827e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.614043194367931e-08\n",
            "E_s_wdiff_all_sq: 1.6650299826918905e-08\n",
            "E_IS_SCOPE: -6.853377735703531e-07\n",
            "E_IS_E_SCOPE: -6.646810221881406e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002650012144457633\n",
            "Total Loss: -9.882698671749656e-10\n",
            "----------------------------------------\n",
            "Epoch 725\n",
            "Var loss:  tensor(-1.0075e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.617729142243404e-08\n",
            "E_s_wdiff_all_sq: 1.6777436307643785e-08\n",
            "E_IS_SCOPE: -6.848818840536761e-07\n",
            "E_IS_E_SCOPE: -6.64260645826732e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002648336148866081\n",
            "Total Loss: -1.0075205586083694e-09\n",
            "----------------------------------------\n",
            "Epoch 726\n",
            "Var loss:  tensor(-1.0272e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6451787643118705e-08\n",
            "E_s_wdiff_all_sq: 1.762017957211205e-08\n",
            "E_IS_SCOPE: -6.840752749895304e-07\n",
            "E_IS_E_SCOPE: -6.637283384391656e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026462138962448285\n",
            "Total Loss: -1.0271642492335246e-09\n",
            "----------------------------------------\n",
            "Epoch 727\n",
            "Var loss:  tensor(-1.0507e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.621014081156504e-08\n",
            "E_s_wdiff_all_sq: 1.7288473272605174e-08\n",
            "E_IS_SCOPE: -6.842831152285339e-07\n",
            "E_IS_E_SCOPE: -6.638793564261417e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002646815988806763\n",
            "Total Loss: -1.0507492853352376e-09\n",
            "----------------------------------------\n",
            "Epoch 728\n",
            "Var loss:  tensor(-1.0713e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.57123735182923e-08\n",
            "E_s_wdiff_all_sq: 1.6257868294826778e-08\n",
            "E_IS_SCOPE: -6.850642491049871e-07\n",
            "E_IS_E_SCOPE: -6.643837788525748e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026488270670704146\n",
            "Total Loss: -1.0713345008692966e-09\n",
            "----------------------------------------\n",
            "Epoch 729\n",
            "Var loss:  tensor(-1.0967e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.572576227427802e-08\n",
            "E_s_wdiff_all_sq: 1.635889366141297e-08\n",
            "E_IS_SCOPE: -6.849278347082779e-07\n",
            "E_IS_E_SCOPE: -6.642785108821404e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002648407374931236\n",
            "Total Loss: -1.0966782589205612e-09\n",
            "----------------------------------------\n",
            "Epoch 730\n",
            "Var loss:  tensor(-1.1206e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.614043444551513e-08\n",
            "E_s_wdiff_all_sq: 1.725791311252921e-08\n",
            "E_IS_SCOPE: -6.841232967395024e-07\n",
            "E_IS_E_SCOPE: -6.637042032611739e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026461176718715557\n",
            "Total Loss: -1.1205648431813103e-09\n",
            "----------------------------------------\n",
            "Epoch 731\n",
            "Var loss:  tensor(-1.1495e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.629369419848977e-08\n",
            "E_s_wdiff_all_sq: 1.7363507154590826e-08\n",
            "E_IS_SCOPE: -6.839240224396589e-07\n",
            "E_IS_E_SCOPE: -6.634666397378e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026451705315124873\n",
            "Total Loss: -1.1494775793293381e-09\n",
            "----------------------------------------\n",
            "Epoch 732\n",
            "Var loss:  tensor(-1.1748e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.628844903550208e-08\n",
            "E_s_wdiff_all_sq: 1.6997223502931545e-08\n",
            "E_IS_SCOPE: -6.84143998885481e-07\n",
            "E_IS_E_SCOPE: -6.63493438437694e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002645277375062708\n",
            "Total Loss: -1.1747945825138217e-09\n",
            "----------------------------------------\n",
            "Epoch 733\n",
            "Var loss:  tensor(-1.2042e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.66184653289611e-08\n",
            "E_s_wdiff_all_sq: 1.747017582579969e-08\n",
            "E_IS_SCOPE: -6.838459781956156e-07\n",
            "E_IS_E_SCOPE: -6.632521784536802e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026443154973104237\n",
            "Total Loss: -1.2042092002197447e-09\n",
            "----------------------------------------\n",
            "Epoch 734\n",
            "Var loss:  tensor(-1.2307e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.7043936106288196e-08\n",
            "E_s_wdiff_all_sq: 1.8266013677750237e-08\n",
            "E_IS_SCOPE: -6.834795447705216e-07\n",
            "E_IS_E_SCOPE: -6.630577025842243e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026435401428190836\n",
            "Total Loss: -1.2306611635672244e-09\n",
            "----------------------------------------\n",
            "Epoch 735\n",
            "Var loss:  tensor(-1.2461e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.687383164083402e-08\n",
            "E_s_wdiff_all_sq: 1.7778517908001676e-08\n",
            "E_IS_SCOPE: -6.83379579371509e-07\n",
            "E_IS_E_SCOPE: -6.627913173255296e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026424780932839224\n",
            "Total Loss: -1.2461095786369343e-09\n",
            "----------------------------------------\n",
            "Epoch 736\n",
            "Var loss:  tensor(-1.2625e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6812785391827844e-08\n",
            "E_s_wdiff_all_sq: 1.77057462262426e-08\n",
            "E_IS_SCOPE: -6.832040235141292e-07\n",
            "E_IS_E_SCOPE: -6.626016993143854e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026417221065540984\n",
            "Total Loss: -1.2625084534124963e-09\n",
            "----------------------------------------\n",
            "Epoch 737\n",
            "Var loss:  tensor(-1.2830e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.688379998818234e-08\n",
            "E_s_wdiff_all_sq: 1.8118380906938945e-08\n",
            "E_IS_SCOPE: -6.82834140161084e-07\n",
            "E_IS_E_SCOPE: -6.623923746322949e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026408875514349404\n",
            "Total Loss: -1.2830111958449718e-09\n",
            "----------------------------------------\n",
            "Epoch 738\n",
            "Var loss:  tensor(-1.3032e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6635279595428845e-08\n",
            "E_s_wdiff_all_sq: 1.785966161722405e-08\n",
            "E_IS_SCOPE: -6.830397844668174e-07\n",
            "E_IS_E_SCOPE: -6.625828028207756e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002641646768255152\n",
            "Total Loss: -1.303244533389432e-09\n",
            "----------------------------------------\n",
            "Epoch 739\n",
            "Var loss:  tensor(-1.3244e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.618338315116329e-08\n",
            "E_s_wdiff_all_sq: 1.7078611477021376e-08\n",
            "E_IS_SCOPE: -6.836213450462233e-07\n",
            "E_IS_E_SCOPE: -6.629891995776233e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026432670286585095\n",
            "Total Loss: -1.3244184825685072e-09\n",
            "----------------------------------------\n",
            "Epoch 740\n",
            "Var loss:  tensor(-1.3472e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6065153973003676e-08\n",
            "E_s_wdiff_all_sq: 1.6979869996783715e-08\n",
            "E_IS_SCOPE: -6.836050214122502e-07\n",
            "E_IS_E_SCOPE: -6.629712133346811e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002643195319431619\n",
            "Total Loss: -1.3472313984287073e-09\n",
            "----------------------------------------\n",
            "Epoch 741\n",
            "Var loss:  tensor(-1.3721e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.626230432066901e-08\n",
            "E_s_wdiff_all_sq: 1.7500429186961346e-08\n",
            "E_IS_SCOPE: -6.83039591857508e-07\n",
            "E_IS_E_SCOPE: -6.625550356626086e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002641536063565379\n",
            "Total Loss: -1.3721364756016125e-09\n",
            "----------------------------------------\n",
            "Epoch 742\n",
            "Var loss:  tensor(-1.3984e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.633249377989908e-08\n",
            "E_s_wdiff_all_sq: 1.7600657805775947e-08\n",
            "E_IS_SCOPE: -6.827819658594509e-07\n",
            "E_IS_E_SCOPE: -6.622992755611281e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002640516375395616\n",
            "Total Loss: -1.3984438420328383e-09\n",
            "----------------------------------------\n",
            "Epoch 743\n",
            "Var loss:  tensor(-1.4242e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6266433786607597e-08\n",
            "E_s_wdiff_all_sq: 1.7331376228601522e-08\n",
            "E_IS_SCOPE: -6.828753821228499e-07\n",
            "E_IS_E_SCOPE: -6.622781801874841e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026404322703971546\n",
            "Total Loss: -1.4242455322358775e-09\n",
            "----------------------------------------\n",
            "Epoch 744\n",
            "Var loss:  tensor(-1.4513e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.637671801251631e-08\n",
            "E_s_wdiff_all_sq: 1.7514128328601176e-08\n",
            "E_IS_SCOPE: -6.827687607369113e-07\n",
            "E_IS_E_SCOPE: -6.621942532449806e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002640097662653805\n",
            "Total Loss: -1.4513245194568564e-09\n",
            "----------------------------------------\n",
            "Epoch 745\n",
            "Var loss:  tensor(-1.4788e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6566628623720536e-08\n",
            "E_s_wdiff_all_sq: 1.7936239567205412e-08\n",
            "E_IS_SCOPE: -6.82661709587889e-07\n",
            "E_IS_E_SCOPE: -6.621895697180397e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002640078989932819\n",
            "Total Loss: -1.4787899026937835e-09\n",
            "----------------------------------------\n",
            "Epoch 746\n",
            "Var loss:  tensor(-1.4330e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.695405132951117e-08\n",
            "E_s_wdiff_all_sq: 1.8177029467770898e-08\n",
            "E_IS_SCOPE: -6.82793694730584e-07\n",
            "E_IS_E_SCOPE: -6.622711278023302e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026404041532918344\n",
            "Total Loss: -1.4330112142778725e-09\n",
            "----------------------------------------\n",
            "Epoch 747\n",
            "Var loss:  tensor(-1.5139e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.618623009216792e-08\n",
            "E_s_wdiff_all_sq: 1.7060645327544953e-08\n",
            "E_IS_SCOPE: -6.832914746077281e-07\n",
            "E_IS_E_SCOPE: -6.625542045062208e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002641532749833757\n",
            "Total Loss: -1.5138546579020865e-09\n",
            "----------------------------------------\n",
            "Epoch 748\n",
            "Var loss:  tensor(-1.5378e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6386080811895144e-08\n",
            "E_s_wdiff_all_sq: 1.7658345968148795e-08\n",
            "E_IS_SCOPE: -6.826164382210747e-07\n",
            "E_IS_E_SCOPE: -6.620661002188407e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026395867302452017\n",
            "Total Loss: -1.537840380232232e-09\n",
            "----------------------------------------\n",
            "Epoch 749\n",
            "Var loss:  tensor(-1.5491e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.657832975776171e-08\n",
            "E_s_wdiff_all_sq: 1.8254472319888313e-08\n",
            "E_IS_SCOPE: -6.820977562849704e-07\n",
            "E_IS_E_SCOPE: -6.617437180779228e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002638301427129767\n",
            "Total Loss: -1.5491181957322054e-09\n",
            "----------------------------------------\n",
            "Epoch 750\n",
            "Var loss:  tensor(-1.5752e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.616649995367131e-08\n",
            "E_s_wdiff_all_sq: 1.7491511989392572e-08\n",
            "E_IS_SCOPE: -6.826825081083501e-07\n",
            "E_IS_E_SCOPE: -6.621398404548502e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002639880724679279\n",
            "Total Loss: -1.5752465622315768e-09\n",
            "----------------------------------------\n",
            "Epoch 751\n",
            "Var loss:  tensor(-1.5902e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.581368860486302e-08\n",
            "E_s_wdiff_all_sq: 1.6797772202232285e-08\n",
            "E_IS_SCOPE: -6.832441522051358e-07\n",
            "E_IS_E_SCOPE: -6.625235359703414e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026414104776613613\n",
            "Total Loss: -1.590215286468368e-09\n",
            "----------------------------------------\n",
            "Epoch 752\n",
            "Var loss:  tensor(-1.6176e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.598281802496085e-08\n",
            "E_s_wdiff_all_sq: 1.732964136691641e-08\n",
            "E_IS_SCOPE: -6.82842005810711e-07\n",
            "E_IS_E_SCOPE: -6.62289067839351e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026404756783006585\n",
            "Total Loss: -1.6175985041860677e-09\n",
            "----------------------------------------\n",
            "Epoch 753\n",
            "Var loss:  tensor(-1.6366e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.619230942145812e-08\n",
            "E_s_wdiff_all_sq: 1.78308032267455e-08\n",
            "E_IS_SCOPE: -6.824463005626696e-07\n",
            "E_IS_E_SCOPE: -6.620296948356832e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002639441585876293\n",
            "Total Loss: -1.6366044787706525e-09\n",
            "----------------------------------------\n",
            "Epoch 754\n",
            "Var loss:  tensor(-1.6654e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6019077249571255e-08\n",
            "E_s_wdiff_all_sq: 1.7358317696018174e-08\n",
            "E_IS_SCOPE: -6.827984360974939e-07\n",
            "E_IS_E_SCOPE: -6.622177985136413e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026401915351216693\n",
            "Total Loss: -1.6654148336626165e-09\n",
            "----------------------------------------\n",
            "Epoch 755\n",
            "Var loss:  tensor(-1.6872e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.597440490251721e-08\n",
            "E_s_wdiff_all_sq: 1.7125656079605778e-08\n",
            "E_IS_SCOPE: -6.830294700948759e-07\n",
            "E_IS_E_SCOPE: -6.623439641331277e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026406945439525088\n",
            "Total Loss: -1.6871623200953977e-09\n",
            "----------------------------------------\n",
            "Epoch 756\n",
            "Var loss:  tensor(-1.6570e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.665293079956549e-08\n",
            "E_s_wdiff_all_sq: 1.808803633966245e-08\n",
            "E_IS_SCOPE: -6.824066314261236e-07\n",
            "E_IS_E_SCOPE: -6.618781251522949e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00263883729375977\n",
            "Total Loss: -1.6570173072647767e-09\n",
            "----------------------------------------\n",
            "Epoch 757\n",
            "Var loss:  tensor(-1.7262e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.632321602331091e-08\n",
            "E_s_wdiff_all_sq: 1.7795516925660052e-08\n",
            "E_IS_SCOPE: -6.820688189315084e-07\n",
            "E_IS_E_SCOPE: -6.615243334774208e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026374267641918613\n",
            "Total Loss: -1.726171030034713e-09\n",
            "----------------------------------------\n",
            "Epoch 758\n",
            "Var loss:  tensor(-1.7391e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6284322587690076e-08\n",
            "E_s_wdiff_all_sq: 1.779581393390963e-08\n",
            "E_IS_SCOPE: -6.817332945267368e-07\n",
            "E_IS_E_SCOPE: -6.612019344579197e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026361413937833205\n",
            "Total Loss: -1.7391107033643028e-09\n",
            "----------------------------------------\n",
            "Epoch 759\n",
            "Var loss:  tensor(-1.7559e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.616302177982792e-08\n",
            "E_s_wdiff_all_sq: 1.7775182839730395e-08\n",
            "E_IS_SCOPE: -6.816614908062012e-07\n",
            "E_IS_E_SCOPE: -6.611720488705283e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026360222431428063\n",
            "Total Loss: -1.7559441507586178e-09\n",
            "----------------------------------------\n",
            "Epoch 760\n",
            "Var loss:  tensor(-1.7743e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.587480874470271e-08\n",
            "E_s_wdiff_all_sq: 1.7453461572777392e-08\n",
            "E_IS_SCOPE: -6.819791683496633e-07\n",
            "E_IS_E_SCOPE: -6.614638019699329e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637185431545659\n",
            "Total Loss: -1.774284807046088e-09\n",
            "----------------------------------------\n",
            "Epoch 761\n",
            "Var loss:  tensor(-1.7925e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.555422798287168e-08\n",
            "E_s_wdiff_all_sq: 1.7013804740375065e-08\n",
            "E_IS_SCOPE: -6.824394611272777e-07\n",
            "E_IS_E_SCOPE: -6.618554321668741e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026387468192540274\n",
            "Total Loss: -1.7925338978208558e-09\n",
            "----------------------------------------\n",
            "Epoch 762\n",
            "Var loss:  tensor(-1.8121e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5428205066283906e-08\n",
            "E_s_wdiff_all_sq: 1.68958099379084e-08\n",
            "E_IS_SCOPE: -6.826137443011229e-07\n",
            "E_IS_E_SCOPE: -6.620239520015562e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002639418689810854\n",
            "Total Loss: -1.8120886902683658e-09\n",
            "----------------------------------------\n",
            "Epoch 763\n",
            "Var loss:  tensor(-1.8341e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5506656380383354e-08\n",
            "E_s_wdiff_all_sq: 1.707966058939037e-08\n",
            "E_IS_SCOPE: -6.824816290155896e-07\n",
            "E_IS_E_SCOPE: -6.619335139560198e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026390581229961078\n",
            "Total Loss: -1.8341335476573125e-09\n",
            "----------------------------------------\n",
            "Epoch 764\n",
            "Var loss:  tensor(-1.8581e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.564973370465603e-08\n",
            "E_s_wdiff_all_sq: 1.725148348545071e-08\n",
            "E_IS_SCOPE: -6.823174847985446e-07\n",
            "E_IS_E_SCOPE: -6.617717652591069e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026384132482413594\n",
            "Total Loss: -1.8580880791805017e-09\n",
            "----------------------------------------\n",
            "Epoch 765\n",
            "Var loss:  tensor(-1.8820e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5820678887303653e-08\n",
            "E_s_wdiff_all_sq: 1.7407408503635566e-08\n",
            "E_IS_SCOPE: -6.82199057343209e-07\n",
            "E_IS_E_SCOPE: -6.616338469726429e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026378633827842876\n",
            "Total Loss: -1.8820495769745566e-09\n",
            "----------------------------------------\n",
            "Epoch 766\n",
            "Var loss:  tensor(-1.9063e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6038189619951754e-08\n",
            "E_s_wdiff_all_sq: 1.7690871490247702e-08\n",
            "E_IS_SCOPE: -6.820986597786127e-07\n",
            "E_IS_E_SCOPE: -6.615543082885873e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637546270558024\n",
            "Total Loss: -1.9062840698573997e-09\n",
            "----------------------------------------\n",
            "Epoch 767\n",
            "Var loss:  tensor(-1.8842e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.64832018043546e-08\n",
            "E_s_wdiff_all_sq: 1.8157758615023164e-08\n",
            "E_IS_SCOPE: -6.819868460441695e-07\n",
            "E_IS_E_SCOPE: -6.61464465396949e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026371880765582146\n",
            "Total Loss: -1.8842173246202405e-09\n",
            "----------------------------------------\n",
            "Epoch 768\n",
            "Var loss:  tensor(-1.9374e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6040654298996374e-08\n",
            "E_s_wdiff_all_sq: 1.7518043624315417e-08\n",
            "E_IS_SCOPE: -6.820615680962332e-07\n",
            "E_IS_E_SCOPE: -6.614140184344742e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026369869499143863\n",
            "Total Loss: -1.9373878683476913e-09\n",
            "----------------------------------------\n",
            "Epoch 769\n",
            "Var loss:  tensor(-1.9545e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6128392850873944e-08\n",
            "E_s_wdiff_all_sq: 1.7888351385652738e-08\n",
            "E_IS_SCOPE: -6.816008481990709e-07\n",
            "E_IS_E_SCOPE: -6.610860398444275e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002635679334354844\n",
            "Total Loss: -1.9544744635760707e-09\n",
            "----------------------------------------\n",
            "Epoch 770\n",
            "Var loss:  tensor(-1.9678e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6085747994521946e-08\n",
            "E_s_wdiff_all_sq: 1.8075701030844483e-08\n",
            "E_IS_SCOPE: -6.814834879509227e-07\n",
            "E_IS_E_SCOPE: -6.610770207536518e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026356433762045584\n",
            "Total Loss: -1.967786650375011e-09\n",
            "----------------------------------------\n",
            "Epoch 771\n",
            "Var loss:  tensor(-1.9876e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5627967140661404e-08\n",
            "E_s_wdiff_all_sq: 1.732793904709717e-08\n",
            "E_IS_SCOPE: -6.82169502164891e-07\n",
            "E_IS_E_SCOPE: -6.616081559815336e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637760955550517\n",
            "Total Loss: -1.9875634926610476e-09\n",
            "----------------------------------------\n",
            "Epoch 772\n",
            "Var loss:  tensor(-2.0025e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5308680676769375e-08\n",
            "E_s_wdiff_all_sq: 1.6792086693877505e-08\n",
            "E_IS_SCOPE: -6.826941902382301e-07\n",
            "E_IS_E_SCOPE: -6.620171056427308e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026393913941104696\n",
            "Total Loss: -2.0024744276172935e-09\n",
            "----------------------------------------\n",
            "Epoch 773\n",
            "Var loss:  tensor(-2.0242e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.544197840467824e-08\n",
            "E_s_wdiff_all_sq: 1.7195776534744253e-08\n",
            "E_IS_SCOPE: -6.824243836503851e-07\n",
            "E_IS_E_SCOPE: -6.61871615180387e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002638811339198048\n",
            "Total Loss: -2.024234289572494e-09\n",
            "----------------------------------------\n",
            "Epoch 774\n",
            "Var loss:  tensor(-2.0445e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.565361097693046e-08\n",
            "E_s_wdiff_all_sq: 1.7588611940980324e-08\n",
            "E_IS_SCOPE: -6.821010817477116e-07\n",
            "E_IS_E_SCOPE: -6.616287988433574e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026378432564327496\n",
            "Total Loss: -2.0444659922688603e-09\n",
            "----------------------------------------\n",
            "Epoch 775\n",
            "Var loss:  tensor(-2.0690e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.567834759263247e-08\n",
            "E_s_wdiff_all_sq: 1.741747506557907e-08\n",
            "E_IS_SCOPE: -6.822036446763418e-07\n",
            "E_IS_E_SCOPE: -6.616211798977062e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637812880511323\n",
            "Total Loss: -2.0689562497282516e-09\n",
            "----------------------------------------\n",
            "Epoch 776\n",
            "Var loss:  tensor(-2.0907e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.58294933160399e-08\n",
            "E_s_wdiff_all_sq: 1.751555485414283e-08\n",
            "E_IS_SCOPE: -6.821826448394939e-07\n",
            "E_IS_E_SCOPE: -6.615627947459636e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026375801051559135\n",
            "Total Loss: -2.0906609446741536e-09\n",
            "----------------------------------------\n",
            "Epoch 777\n",
            "Var loss:  tensor(-2.0889e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.63254985701042e-08\n",
            "E_s_wdiff_all_sq: 1.824736162466627e-08\n",
            "E_IS_SCOPE: -6.818143113296473e-07\n",
            "E_IS_E_SCOPE: -6.613132200316525e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026365850774632367\n",
            "Total Loss: -2.088944870062319e-09\n",
            "----------------------------------------\n",
            "Epoch 778\n",
            "Var loss:  tensor(-2.1218e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.611136518040116e-08\n",
            "E_s_wdiff_all_sq: 1.791537316400737e-08\n",
            "E_IS_SCOPE: -6.815834291312904e-07\n",
            "E_IS_E_SCOPE: -6.610069884486055e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026353641648946494\n",
            "Total Loss: -2.1217885684865225e-09\n",
            "----------------------------------------\n",
            "Epoch 779\n",
            "Var loss:  tensor(-2.1345e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.609662529791503e-08\n",
            "E_s_wdiff_all_sq: 1.801784427277236e-08\n",
            "E_IS_SCOPE: -6.813001468354639e-07\n",
            "E_IS_E_SCOPE: -6.607759575500741e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002634443069412131\n",
            "Total Loss: -2.1344967651472352e-09\n",
            "----------------------------------------\n",
            "Epoch 780\n",
            "Var loss:  tensor(-2.1492e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.598168474334162e-08\n",
            "E_s_wdiff_all_sq: 1.806934957610547e-08\n",
            "E_IS_SCOPE: -6.812913098108544e-07\n",
            "E_IS_E_SCOPE: -6.608429941921932e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002634710337334351\n",
            "Total Loss: -2.1491952895965984e-09\n",
            "----------------------------------------\n",
            "Epoch 781\n",
            "Var loss:  tensor(-2.1660e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.558539743209528e-08\n",
            "E_s_wdiff_all_sq: 1.7526663565053453e-08\n",
            "E_IS_SCOPE: -6.818495859025145e-07\n",
            "E_IS_E_SCOPE: -6.61319651685692e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002636610719779994\n",
            "Total Loss: -2.166033786113585e-09\n",
            "----------------------------------------\n",
            "Epoch 782\n",
            "Var loss:  tensor(-2.1811e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5233787351703454e-08\n",
            "E_s_wdiff_all_sq: 1.699049342299252e-08\n",
            "E_IS_SCOPE: -6.824040528876562e-07\n",
            "E_IS_E_SCOPE: -6.61774288515662e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00263842330819537\n",
            "Total Loss: -2.1811340347879884e-09\n",
            "----------------------------------------\n",
            "Epoch 783\n",
            "Var loss:  tensor(-2.2001e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.52297435151552e-08\n",
            "E_s_wdiff_all_sq: 1.710773424506904e-08\n",
            "E_IS_SCOPE: -6.823728237210308e-07\n",
            "E_IS_E_SCOPE: -6.617942236872283e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026385027875922367\n",
            "Total Loss: -2.2000900170290866e-09\n",
            "----------------------------------------\n",
            "Epoch 784\n",
            "Var loss:  tensor(-2.2206e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.540694851625926e-08\n",
            "E_s_wdiff_all_sq: 1.7445560625600037e-08\n",
            "E_IS_SCOPE: -6.820839328880524e-07\n",
            "E_IS_E_SCOPE: -6.615753791682394e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637630277901559\n",
            "Total Loss: -2.2206187684774155e-09\n",
            "----------------------------------------\n",
            "Epoch 785\n",
            "Var loss:  tensor(-2.2436e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.553029111231939e-08\n",
            "E_s_wdiff_all_sq: 1.750513126935923e-08\n",
            "E_IS_SCOPE: -6.819831137484967e-07\n",
            "E_IS_E_SCOPE: -6.614311659241506e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026370553151217153\n",
            "Total Loss: -2.2436350252422498e-09\n",
            "----------------------------------------\n",
            "Epoch 786\n",
            "Var loss:  tensor(-2.2651e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.570223176464307e-08\n",
            "E_s_wdiff_all_sq: 1.763737291577048e-08\n",
            "E_IS_SCOPE: -6.818998928643518e-07\n",
            "E_IS_E_SCOPE: -6.61317340552815e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002636601505540401\n",
            "Total Loss: -2.2651449937115453e-09\n",
            "----------------------------------------\n",
            "Epoch 787\n",
            "Var loss:  tensor(-2.2883e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.597093899561868e-08\n",
            "E_s_wdiff_all_sq: 1.805980346823714e-08\n",
            "E_IS_SCOPE: -6.817573226624194e-07\n",
            "E_IS_E_SCOPE: -6.612400613200512e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026362934015047774\n",
            "Total Loss: -2.288286376865329e-09\n",
            "----------------------------------------\n",
            "Epoch 788\n",
            "Var loss:  tensor(-2.2476e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.648639002581452e-08\n",
            "E_s_wdiff_all_sq: 1.856899202691198e-08\n",
            "E_IS_SCOPE: -6.816937878865685e-07\n",
            "E_IS_E_SCOPE: -6.611937373475879e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00263610871278115\n",
            "Total Loss: -2.247602298569168e-09\n",
            "----------------------------------------\n",
            "Epoch 789\n",
            "Var loss:  tensor(-2.3156e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.582331656319036e-08\n",
            "E_s_wdiff_all_sq: 1.761665993142656e-08\n",
            "E_IS_SCOPE: -6.820896989576056e-07\n",
            "E_IS_E_SCOPE: -6.614109958222013e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026369748990825383\n",
            "Total Loss: -2.3156488585552052e-09\n",
            "----------------------------------------\n",
            "Epoch 790\n",
            "Var loss:  tensor(-2.3326e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5917108938774876e-08\n",
            "E_s_wdiff_all_sq: 1.8010695046215167e-08\n",
            "E_IS_SCOPE: -6.816751685371385e-07\n",
            "E_IS_E_SCOPE: -6.611381359995753e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00263588703615347\n",
            "Total Loss: -2.3325504020770678e-09\n",
            "----------------------------------------\n",
            "Epoch 791\n",
            "Var loss:  tensor(-2.3424e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.595707450288441e-08\n",
            "E_s_wdiff_all_sq: 1.83505980800375e-08\n",
            "E_IS_SCOPE: -6.814845654633106e-07\n",
            "E_IS_E_SCOPE: -6.610925590760421e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026357053258340263\n",
            "Total Loss: -2.342435571200564e-09\n",
            "----------------------------------------\n",
            "Epoch 792\n",
            "Var loss:  tensor(-2.3616e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.551391287407481e-08\n",
            "E_s_wdiff_all_sq: 1.7580287533476036e-08\n",
            "E_IS_SCOPE: -6.822007296130797e-07\n",
            "E_IS_E_SCOPE: -6.616355550117045e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637870192553343\n",
            "Total Loss: -2.361623081662285e-09\n",
            "----------------------------------------\n",
            "Epoch 793\n",
            "Var loss:  tensor(-2.3742e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5215630250565455e-08\n",
            "E_s_wdiff_all_sq: 1.7021050618768533e-08\n",
            "E_IS_SCOPE: -6.827454147575888e-07\n",
            "E_IS_E_SCOPE: -6.62043498244642e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002639496618591467\n",
            "Total Loss: -2.374152613607443e-09\n",
            "----------------------------------------\n",
            "Epoch 794\n",
            "Var loss:  tensor(-2.3958e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.543335462572955e-08\n",
            "E_s_wdiff_all_sq: 1.7567701891092424e-08\n",
            "E_IS_SCOPE: -6.823755112511331e-07\n",
            "E_IS_E_SCOPE: -6.618272444362658e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002638634437786913\n",
            "Total Loss: -2.395780114607816e-09\n",
            "----------------------------------------\n",
            "Epoch 795\n",
            "Var loss:  tensor(-2.4137e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.568494354843803e-08\n",
            "E_s_wdiff_all_sq: 1.8025485562381497e-08\n",
            "E_IS_SCOPE: -6.820262177172582e-07\n",
            "E_IS_E_SCOPE: -6.615720724983983e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637617094562568\n",
            "Total Loss: -2.413731671173586e-09\n",
            "----------------------------------------\n",
            "Epoch 796\n",
            "Var loss:  tensor(-2.4371e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5646856242875884e-08\n",
            "E_s_wdiff_all_sq: 1.7726792248737227e-08\n",
            "E_IS_SCOPE: -6.822588716424896e-07\n",
            "E_IS_E_SCOPE: -6.61662716114803e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637978480966379\n",
            "Total Loss: -2.4371462807448956e-09\n",
            "----------------------------------------\n",
            "Epoch 797\n",
            "Var loss:  tensor(-2.4447e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.582933024075186e-08\n",
            "E_s_wdiff_all_sq: 1.782496437404455e-08\n",
            "E_IS_SCOPE: -6.822724215648534e-07\n",
            "E_IS_E_SCOPE: -6.616303411612442e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026378494054892054\n",
            "Total Loss: -2.444694160021456e-09\n",
            "----------------------------------------\n",
            "Epoch 798\n",
            "Var loss:  tensor(-2.4615e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5919164523287864e-08\n",
            "E_s_wdiff_all_sq: 1.8034084855255753e-08\n",
            "E_IS_SCOPE: -6.814894017926301e-07\n",
            "E_IS_E_SCOPE: -6.608985813283564e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026349319573009075\n",
            "Total Loss: -2.461460480025753e-09\n",
            "----------------------------------------\n",
            "Epoch 799\n",
            "Var loss:  tensor(-2.4694e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.615557594553501e-08\n",
            "E_s_wdiff_all_sq: 1.8682067731911915e-08\n",
            "E_IS_SCOPE: -6.806829167062356e-07\n",
            "E_IS_E_SCOPE: -6.602938937551391e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002632521132620893\n",
            "Total Loss: -2.469436908080237e-09\n",
            "----------------------------------------\n",
            "Epoch 800\n",
            "Var loss:  tensor(-2.4843e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5830961091185796e-08\n",
            "E_s_wdiff_all_sq: 1.8270133759430123e-08\n",
            "E_IS_SCOPE: -6.809477564661555e-07\n",
            "E_IS_E_SCOPE: -6.605076286903978e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002633373270947734\n",
            "Total Loss: -2.4843274392699953e-09\n",
            "----------------------------------------\n",
            "Epoch 801\n",
            "Var loss:  tensor(-2.4979e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5226406465423734e-08\n",
            "E_s_wdiff_all_sq: 1.7293054827960907e-08\n",
            "E_IS_SCOPE: -6.818226370164293e-07\n",
            "E_IS_E_SCOPE: -6.611894432106522e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002636091592516467\n",
            "Total Loss: -2.497935193602022e-09\n",
            "----------------------------------------\n",
            "Epoch 802\n",
            "Var loss:  tensor(-2.5138e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.499785090829791e-08\n",
            "E_s_wdiff_all_sq: 1.7142584621983466e-08\n",
            "E_IS_SCOPE: -6.821151215318902e-07\n",
            "E_IS_E_SCOPE: -6.61513051581351e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026373817844788866\n",
            "Total Loss: -2.5137728342747537e-09\n",
            "----------------------------------------\n",
            "Epoch 803\n",
            "Var loss:  tensor(-2.5279e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.505335398885973e-08\n",
            "E_s_wdiff_all_sq: 1.7456116712029344e-08\n",
            "E_IS_SCOPE: -6.819874205489546e-07\n",
            "E_IS_E_SCOPE: -6.615072770014411e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026373587618464065\n",
            "Total Loss: -2.5279490377069867e-09\n",
            "----------------------------------------\n",
            "Epoch 804\n",
            "Var loss:  tensor(-2.5493e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.501831156588355e-08\n",
            "E_s_wdiff_all_sq: 1.7296840777889325e-08\n",
            "E_IS_SCOPE: -6.821265979165597e-07\n",
            "E_IS_E_SCOPE: -6.615736633090653e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637623436954552\n",
            "Total Loss: -2.549297646504955e-09\n",
            "----------------------------------------\n",
            "Epoch 805\n",
            "Var loss:  tensor(-2.5691e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5111354911954614e-08\n",
            "E_s_wdiff_all_sq: 1.7228516498768574e-08\n",
            "E_IS_SCOPE: -6.821511959388353e-07\n",
            "E_IS_E_SCOPE: -6.615076704842499e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026373603306202803\n",
            "Total Loss: -2.569111715495441e-09\n",
            "----------------------------------------\n",
            "Epoch 806\n",
            "Var loss:  tensor(-2.5918e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.554815078904199e-08\n",
            "E_s_wdiff_all_sq: 1.790624550811204e-08\n",
            "E_IS_SCOPE: -6.816621198686711e-07\n",
            "E_IS_E_SCOPE: -6.61127715377343e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026358454902471683\n",
            "Total Loss: -2.591802921237041e-09\n",
            "----------------------------------------\n",
            "Epoch 807\n",
            "Var loss:  tensor(-2.6115e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.593602919861045e-08\n",
            "E_s_wdiff_all_sq: 1.8495020016102782e-08\n",
            "E_IS_SCOPE: -6.814002781621853e-07\n",
            "E_IS_E_SCOPE: -6.60956463065265e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026351627255952166\n",
            "Total Loss: -2.611520230843636e-09\n",
            "----------------------------------------\n",
            "Epoch 808\n",
            "Var loss:  tensor(-2.5963e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.617130987581561e-08\n",
            "E_s_wdiff_all_sq: 1.850074913689122e-08\n",
            "E_IS_SCOPE: -6.817424870777932e-07\n",
            "E_IS_E_SCOPE: -6.61191524098951e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002636099888795553\n",
            "Total Loss: -2.59626443827063e-09\n",
            "----------------------------------------\n",
            "Epoch 809\n",
            "Var loss:  tensor(-2.6328e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.570181514869847e-08\n",
            "E_s_wdiff_all_sq: 1.771418376681098e-08\n",
            "E_IS_SCOPE: -6.820248668300682e-07\n",
            "E_IS_E_SCOPE: -6.612971150810939e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026365208687478656\n",
            "Total Loss: -2.6327713355714855e-09\n",
            "----------------------------------------\n",
            "Epoch 810\n",
            "Var loss:  tensor(-2.6524e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.597762260975064e-08\n",
            "E_s_wdiff_all_sq: 1.853300510080178e-08\n",
            "E_IS_SCOPE: -6.813387503165117e-07\n",
            "E_IS_E_SCOPE: -6.608727126968466e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026348288218338593\n",
            "Total Loss: -2.6523569498916096e-09\n",
            "----------------------------------------\n",
            "Epoch 811\n",
            "Var loss:  tensor(-2.6592e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5950087117723547e-08\n",
            "E_s_wdiff_all_sq: 1.8733898543088586e-08\n",
            "E_IS_SCOPE: -6.812978105400851e-07\n",
            "E_IS_E_SCOPE: -6.609425852280659e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002635107396142609\n",
            "Total Loss: -2.659161268913667e-09\n",
            "----------------------------------------\n",
            "Epoch 812\n",
            "Var loss:  tensor(-2.6782e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5305768342174405e-08\n",
            "E_s_wdiff_all_sq: 1.7532405571254016e-08\n",
            "E_IS_SCOPE: -6.823643597163937e-07\n",
            "E_IS_E_SCOPE: -6.617210236637267e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026382109469276498\n",
            "Total Loss: -2.6782085539238987e-09\n",
            "----------------------------------------\n",
            "Epoch 813\n",
            "Var loss:  tensor(-2.6895e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.506822715602019e-08\n",
            "E_s_wdiff_all_sq: 1.713467450958702e-08\n",
            "E_IS_SCOPE: -6.827929787527341e-07\n",
            "E_IS_E_SCOPE: -6.620638974917028e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026395779482076957\n",
            "Total Loss: -2.6895090951398774e-09\n",
            "----------------------------------------\n",
            "Epoch 814\n",
            "Var loss:  tensor(-2.7094e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.543776237746571e-08\n",
            "E_s_wdiff_all_sq: 1.802182769715199e-08\n",
            "E_IS_SCOPE: -6.8215481429828e-07\n",
            "E_IS_E_SCOPE: -6.616745844465531e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026380257987356883\n",
            "Total Loss: -2.709424242650545e-09\n",
            "----------------------------------------\n",
            "Epoch 815\n",
            "Var loss:  tensor(-2.7285e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5616063097486835e-08\n",
            "E_s_wdiff_all_sq: 1.8271042692689723e-08\n",
            "E_IS_SCOPE: -6.819433022929677e-07\n",
            "E_IS_E_SCOPE: -6.614890146276833e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026372859517154877\n",
            "Total Loss: -2.7284541452821767e-09\n",
            "----------------------------------------\n",
            "Epoch 816\n",
            "Var loss:  tensor(-2.7488e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.550413643531881e-08\n",
            "E_s_wdiff_all_sq: 1.7752207213446637e-08\n",
            "E_IS_SCOPE: -6.823268455963799e-07\n",
            "E_IS_E_SCOPE: -6.616589391454052e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026379634225933563\n",
            "Total Loss: -2.748782899587689e-09\n",
            "----------------------------------------\n",
            "Epoch 817\n",
            "Var loss:  tensor(-2.7485e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.589161106780881e-08\n",
            "E_s_wdiff_all_sq: 1.821612169211666e-08\n",
            "E_IS_SCOPE: -6.820656507516757e-07\n",
            "E_IS_E_SCOPE: -6.614361224167217e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637075076127474\n",
            "Total Loss: -2.7484665137262457e-09\n",
            "----------------------------------------\n",
            "Epoch 818\n",
            "Var loss:  tensor(-2.7741e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.601058168350372e-08\n",
            "E_s_wdiff_all_sq: 1.856296897594818e-08\n",
            "E_IS_SCOPE: -6.812091497183096e-07\n",
            "E_IS_E_SCOPE: -6.606807647435157e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002634063545873736\n",
            "Total Loss: -2.7740564615428136e-09\n",
            "----------------------------------------\n",
            "Epoch 819\n",
            "Var loss:  tensor(-2.7804e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.611581427948683e-08\n",
            "E_s_wdiff_all_sq: 1.8905375167537145e-08\n",
            "E_IS_SCOPE: -6.80675714390459e-07\n",
            "E_IS_E_SCOPE: -6.602627509392433e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026323969695447986\n",
            "Total Loss: -2.7803870099922426e-09\n",
            "----------------------------------------\n",
            "Epoch 820\n",
            "Var loss:  tensor(-2.7945e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.571981375724778e-08\n",
            "E_s_wdiff_all_sq: 1.83433427191315e-08\n",
            "E_IS_SCOPE: -6.811050071608549e-07\n",
            "E_IS_E_SCOPE: -6.60601955906379e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002633749343469077\n",
            "Total Loss: -2.794530690346214e-09\n",
            "----------------------------------------\n",
            "Epoch 821\n",
            "Var loss:  tensor(-2.8071e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5225915990640965e-08\n",
            "E_s_wdiff_all_sq: 1.7636908420638952e-08\n",
            "E_IS_SCOPE: -6.818216168597116e-07\n",
            "E_IS_E_SCOPE: -6.612060235434605e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026361576965300234\n",
            "Total Loss: -2.807078282010734e-09\n",
            "----------------------------------------\n",
            "Epoch 822\n",
            "Var loss:  tensor(-2.8209e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5035738598312975e-08\n",
            "E_s_wdiff_all_sq: 1.7561743723284034e-08\n",
            "E_IS_SCOPE: -6.820866234464861e-07\n",
            "E_IS_E_SCOPE: -6.615216435905459e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026374160399005877\n",
            "Total Loss: -2.820864056361846e-09\n",
            "----------------------------------------\n",
            "Epoch 823\n",
            "Var loss:  tensor(-2.8350e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.500096780679983e-08\n",
            "E_s_wdiff_all_sq: 1.7624102132448083e-08\n",
            "E_IS_SCOPE: -6.821608277665316e-07\n",
            "E_IS_E_SCOPE: -6.616373645522384e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637877406997912\n",
            "Total Loss: -2.834959973744972e-09\n",
            "----------------------------------------\n",
            "Epoch 824\n",
            "Var loss:  tensor(-2.8546e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.498864608535716e-08\n",
            "E_s_wdiff_all_sq: 1.747792321664679e-08\n",
            "E_IS_SCOPE: -6.822833470836338e-07\n",
            "E_IS_E_SCOPE: -6.616831240441583e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002638059845197987\n",
            "Total Loss: -2.8546224297512086e-09\n",
            "----------------------------------------\n",
            "Epoch 825\n",
            "Var loss:  tensor(-2.8747e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5215657865113394e-08\n",
            "E_s_wdiff_all_sq: 1.770279898737277e-08\n",
            "E_IS_SCOPE: -6.820758544943746e-07\n",
            "E_IS_E_SCOPE: -6.614645057148598e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026371882373014133\n",
            "Total Loss: -2.874737900799131e-09\n",
            "----------------------------------------\n",
            "Epoch 826\n",
            "Var loss:  tensor(-2.8950e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.565785639368138e-08\n",
            "E_s_wdiff_all_sq: 1.8370230266612447e-08\n",
            "E_IS_SCOPE: -6.816014889343402e-07\n",
            "E_IS_E_SCOPE: -6.610926109367993e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026357055325973186\n",
            "Total Loss: -2.895029087523385e-09\n",
            "----------------------------------------\n",
            "Epoch 827\n",
            "Var loss:  tensor(-2.9036e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.599373831010547e-08\n",
            "E_s_wdiff_all_sq: 1.8748139148529062e-08\n",
            "E_IS_SCOPE: -6.815050124931298e-07\n",
            "E_IS_E_SCOPE: -6.610128800085334e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026353876539139494\n",
            "Total Loss: -2.903565027126969e-09\n",
            "----------------------------------------\n",
            "Epoch 828\n",
            "Var loss:  tensor(-2.9113e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5742202321273375e-08\n",
            "E_s_wdiff_all_sq: 1.8135527309667075e-08\n",
            "E_IS_SCOPE: -6.814799748937786e-07\n",
            "E_IS_E_SCOPE: -6.608034301041146e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026345525995467613\n",
            "Total Loss: -2.9113137872322583e-09\n",
            "----------------------------------------\n",
            "Epoch 829\n",
            "Var loss:  tensor(-2.9268e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.590831071048354e-08\n",
            "E_s_wdiff_all_sq: 1.8681667601077057e-08\n",
            "E_IS_SCOPE: -6.809257058472433e-07\n",
            "E_IS_E_SCOPE: -6.604314513782154e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026330695601516126\n",
            "Total Loss: -2.926765048159982e-09\n",
            "----------------------------------------\n",
            "Epoch 830\n",
            "Var loss:  tensor(-2.9346e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.584468316616745e-08\n",
            "E_s_wdiff_all_sq: 1.8893050350397577e-08\n",
            "E_IS_SCOPE: -6.80885413913723e-07\n",
            "E_IS_E_SCOPE: -6.605247451520197e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002633441512449528\n",
            "Total Loss: -2.9346039271471055e-09\n",
            "----------------------------------------\n",
            "Epoch 831\n",
            "Var loss:  tensor(-2.9524e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.516746952405167e-08\n",
            "E_s_wdiff_all_sq: 1.7765830862017897e-08\n",
            "E_IS_SCOPE: -6.8195669634405e-07\n",
            "E_IS_E_SCOPE: -6.613621468363028e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026367801434004075\n",
            "Total Loss: -2.952359572971183e-09\n",
            "----------------------------------------\n",
            "Epoch 832\n",
            "Var loss:  tensor(-2.9611e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.477535525112959e-08\n",
            "E_s_wdiff_all_sq: 1.7126823218975465e-08\n",
            "E_IS_SCOPE: -6.82644516978986e-07\n",
            "E_IS_E_SCOPE: -6.619221628216824e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002639012867237566\n",
            "Total Loss: -2.961075501963606e-09\n",
            "----------------------------------------\n",
            "Epoch 833\n",
            "Var loss:  tensor(-2.9798e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.502150295500436e-08\n",
            "E_s_wdiff_all_sq: 1.777851276890024e-08\n",
            "E_IS_SCOPE: -6.822298626183035e-07\n",
            "E_IS_E_SCOPE: -6.617009342567036e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026381308526105124\n",
            "Total Loss: -2.9797657566063423e-09\n",
            "----------------------------------------\n",
            "Epoch 834\n",
            "Var loss:  tensor(-2.9976e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5275123720340426e-08\n",
            "E_s_wdiff_all_sq: 1.8167799511969212e-08\n",
            "E_IS_SCOPE: -6.819113324515119e-07\n",
            "E_IS_E_SCOPE: -6.614413110929054e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637095762824463\n",
            "Total Loss: -2.997617728352122e-09\n",
            "----------------------------------------\n",
            "Epoch 835\n",
            "Var loss:  tensor(-3.0188e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.530880757689409e-08\n",
            "E_s_wdiff_all_sq: 1.788614495146297e-08\n",
            "E_IS_SCOPE: -6.82079572840857e-07\n",
            "E_IS_E_SCOPE: -6.6144128633318e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026370956641100863\n",
            "Total Loss: -3.018809609433559e-09\n",
            "----------------------------------------\n",
            "Epoch 836\n",
            "Var loss:  tensor(-3.0381e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5633432212284596e-08\n",
            "E_s_wdiff_all_sq: 1.826852532997187e-08\n",
            "E_IS_SCOPE: -6.818560356372699e-07\n",
            "E_IS_E_SCOPE: -6.612369600576373e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026362810371032288\n",
            "Total Loss: -3.038143496462792e-09\n",
            "----------------------------------------\n",
            "Epoch 837\n",
            "Var loss:  tensor(-2.9970e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6495986717968476e-08\n",
            "E_s_wdiff_all_sq: 1.9429133092449548e-08\n",
            "E_IS_SCOPE: -6.812158536572025e-07\n",
            "E_IS_E_SCOPE: -6.607663857116611e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002634404907516135\n",
            "Total Loss: -2.9969814850741803e-09\n",
            "----------------------------------------\n",
            "Epoch 838\n",
            "Var loss:  tensor(-3.0607e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.592293946188842e-08\n",
            "E_s_wdiff_all_sq: 1.860833278456378e-08\n",
            "E_IS_SCOPE: -6.814253451638406e-07\n",
            "E_IS_E_SCOPE: -6.60820146293531e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026346192452060832\n",
            "Total Loss: -3.060690282805048e-09\n",
            "----------------------------------------\n",
            "Epoch 839\n",
            "Var loss:  tensor(-3.0706e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5841956635178215e-08\n",
            "E_s_wdiff_all_sq: 1.8601436808823654e-08\n",
            "E_IS_SCOPE: -6.81325987498092e-07\n",
            "E_IS_E_SCOPE: -6.607528656795013e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00263435100459395\n",
            "Total Loss: -3.070623030337306e-09\n",
            "----------------------------------------\n",
            "Epoch 840\n",
            "Var loss:  tensor(-3.0816e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.578465401644415e-08\n",
            "E_s_wdiff_all_sq: 1.8823213992246033e-08\n",
            "E_IS_SCOPE: -6.813052652943204e-07\n",
            "E_IS_E_SCOPE: -6.608662053055135e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026348028775606126\n",
            "Total Loss: -3.081579172926146e-09\n",
            "----------------------------------------\n",
            "Epoch 841\n",
            "Var loss:  tensor(-3.0952e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.534513532071848e-08\n",
            "E_s_wdiff_all_sq: 1.8192083242395877e-08\n",
            "E_IS_SCOPE: -6.820113620755844e-07\n",
            "E_IS_E_SCOPE: -6.614696932149424e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637208919309413\n",
            "Total Loss: -3.0951848624716957e-09\n",
            "----------------------------------------\n",
            "Epoch 842\n",
            "Var loss:  tensor(-3.1056e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4957304071001625e-08\n",
            "E_s_wdiff_all_sq: 1.7510995308856084e-08\n",
            "E_IS_SCOPE: -6.827166589522987e-07\n",
            "E_IS_E_SCOPE: -6.62023162332592e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026394155414851527\n",
            "Total Loss: -3.1055836967785777e-09\n",
            "----------------------------------------\n",
            "Epoch 843\n",
            "Var loss:  tensor(-3.1233e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5095565609508186e-08\n",
            "E_s_wdiff_all_sq: 1.7845777811907333e-08\n",
            "E_IS_SCOPE: -6.825332131691291e-07\n",
            "E_IS_E_SCOPE: -6.619291336687123e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026390406592591066\n",
            "Total Loss: -3.123270422743494e-09\n",
            "----------------------------------------\n",
            "Epoch 844\n",
            "Var loss:  tensor(-3.1406e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5435444380213534e-08\n",
            "E_s_wdiff_all_sq: 1.841904142676545e-08\n",
            "E_IS_SCOPE: -6.820730642111162e-07\n",
            "E_IS_E_SCOPE: -6.615769999503877e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637636739786634\n",
            "Total Loss: -3.1406247875192815e-09\n",
            "----------------------------------------\n",
            "Epoch 845\n",
            "Var loss:  tensor(-3.1615e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.557008624867549e-08\n",
            "E_s_wdiff_all_sq: 1.8403945179031725e-08\n",
            "E_IS_SCOPE: -6.82046645407627e-07\n",
            "E_IS_E_SCOPE: -6.614652846187668e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026371913427079823\n",
            "Total Loss: -3.1614797275870227e-09\n",
            "----------------------------------------\n",
            "Epoch 846\n",
            "Var loss:  tensor(-3.1333e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.603404647664126e-08\n",
            "E_s_wdiff_all_sq: 1.874718764538969e-08\n",
            "E_IS_SCOPE: -6.81827361305852e-07\n",
            "E_IS_E_SCOPE: -6.611997228720219e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002636132576426886\n",
            "Total Loss: -3.1333172559192532e-09\n",
            "----------------------------------------\n",
            "Epoch 847\n",
            "Var loss:  tensor(-3.1773e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.588150321526713e-08\n",
            "E_s_wdiff_all_sq: 1.8662476742257868e-08\n",
            "E_IS_SCOPE: -6.812726028758831e-07\n",
            "E_IS_E_SCOPE: -6.606568682579594e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026339682731416738\n",
            "Total Loss: -3.1773419823484347e-09\n",
            "----------------------------------------\n",
            "Epoch 848\n",
            "Var loss:  tensor(-3.1841e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6118635234496436e-08\n",
            "E_s_wdiff_all_sq: 1.9341629652243642e-08\n",
            "E_IS_SCOPE: -6.804947139006991e-07\n",
            "E_IS_E_SCOPE: -6.600966306414201e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002631734665684786\n",
            "Total Loss: -3.1840601558157604e-09\n",
            "----------------------------------------\n",
            "Epoch 849\n",
            "Var loss:  tensor(-3.1971e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5735645588011155e-08\n",
            "E_s_wdiff_all_sq: 1.8885765632117705e-08\n",
            "E_IS_SCOPE: -6.808748008526655e-07\n",
            "E_IS_E_SCOPE: -6.604337670451687e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026330787924680834\n",
            "Total Loss: -3.1970868786106165e-09\n",
            "----------------------------------------\n",
            "Epoch 850\n",
            "Var loss:  tensor(-3.2083e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.502147897119817e-08\n",
            "E_s_wdiff_all_sq: 1.773804399225934e-08\n",
            "E_IS_SCOPE: -6.819612929524325e-07\n",
            "E_IS_E_SCOPE: -6.612978632717401e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026365238517039495\n",
            "Total Loss: -3.2083236019562444e-09\n",
            "----------------------------------------\n",
            "Epoch 851\n",
            "Var loss:  tensor(-3.2211e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4784905436126835e-08\n",
            "E_s_wdiff_all_sq: 1.757250300901226e-08\n",
            "E_IS_SCOPE: -6.823305470378403e-07\n",
            "E_IS_E_SCOPE: -6.616962639092566e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026381122324347587\n",
            "Total Loss: -3.221063049563484e-09\n",
            "----------------------------------------\n",
            "Epoch 852\n",
            "Var loss:  tensor(-3.2328e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.491709466859302e-08\n",
            "E_s_wdiff_all_sq: 1.7987248669430706e-08\n",
            "E_IS_SCOPE: -6.82151664480689e-07\n",
            "E_IS_E_SCOPE: -6.616527716093244e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026379388332866513\n",
            "Total Loss: -3.232838963077276e-09\n",
            "----------------------------------------\n",
            "Epoch 853\n",
            "Var loss:  tensor(-3.2540e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4951832780323905e-08\n",
            "E_s_wdiff_all_sq: 1.787400634364431e-08\n",
            "E_IS_SCOPE: -6.822139433518414e-07\n",
            "E_IS_E_SCOPE: -6.616304640580024e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637849895465436\n",
            "Total Loss: -3.2540313705086262e-09\n",
            "----------------------------------------\n",
            "Epoch 854\n",
            "Var loss:  tensor(-3.2723e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.514756312367122e-08\n",
            "E_s_wdiff_all_sq: 1.7918900848771202e-08\n",
            "E_IS_SCOPE: -6.82113721784864e-07\n",
            "E_IS_E_SCOPE: -6.614456680695545e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002637113133624363\n",
            "Total Loss: -3.2723443752294496e-09\n",
            "----------------------------------------\n",
            "Epoch 855\n",
            "Var loss:  tensor(-3.2933e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5706951208040544e-08\n",
            "E_s_wdiff_all_sq: 1.8771833949658695e-08\n",
            "E_IS_SCOPE: -6.814966616018244e-07\n",
            "E_IS_E_SCOPE: -6.60964901991987e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026351963706934714\n",
            "Total Loss: -3.2933011808033434e-09\n",
            "----------------------------------------\n",
            "Epoch 856\n",
            "Var loss:  tensor(-3.2411e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.653789564099516e-08\n",
            "E_s_wdiff_all_sq: 1.9693708881417933e-08\n",
            "E_IS_SCOPE: -6.809763845608037e-07\n",
            "E_IS_E_SCOPE: -6.605162073410494e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002633407473110352\n",
            "Total Loss: -3.241066899441609e-09\n",
            "----------------------------------------\n",
            "Epoch 857\n",
            "Var loss:  tensor(-3.3074e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.580857346990037e-08\n",
            "E_s_wdiff_all_sq: 1.8563959020637683e-08\n",
            "E_IS_SCOPE: -6.813485630421719e-07\n",
            "E_IS_E_SCOPE: -6.606550035756576e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002633960838852773\n",
            "Total Loss: -3.3074037032765244e-09\n",
            "----------------------------------------\n",
            "Epoch 858\n",
            "Var loss:  tensor(-3.3228e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.59021501050103e-08\n",
            "E_s_wdiff_all_sq: 1.8982211122942467e-08\n",
            "E_IS_SCOPE: -6.808908301840639e-07\n",
            "E_IS_E_SCOPE: -6.603518967963245e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026327523845423796\n",
            "Total Loss: -3.322827012921187e-09\n",
            "----------------------------------------\n",
            "Epoch 859\n",
            "Var loss:  tensor(-3.3293e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.587542455020245e-08\n",
            "E_s_wdiff_all_sq: 1.930384510138448e-08\n",
            "E_IS_SCOPE: -6.807748011270205e-07\n",
            "E_IS_E_SCOPE: -6.604068070982033e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002632971306043035\n",
            "Total Loss: -3.3293078283271062e-09\n",
            "----------------------------------------\n",
            "Epoch 860\n",
            "Var loss:  tensor(-3.3468e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.518752705720316e-08\n",
            "E_s_wdiff_all_sq: 1.816773697321518e-08\n",
            "E_IS_SCOPE: -6.818346667873346e-07\n",
            "E_IS_E_SCOPE: -6.612338009618846e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026362684421263444\n",
            "Total Loss: -3.3468407864227722e-09\n",
            "----------------------------------------\n",
            "Epoch 861\n",
            "Var loss:  tensor(-3.3538e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.478156070564051e-08\n",
            "E_s_wdiff_all_sq: 1.7460595186005156e-08\n",
            "E_IS_SCOPE: -6.825430084238396e-07\n",
            "E_IS_E_SCOPE: -6.617880782224247e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026384782862813537\n",
            "Total Loss: -3.3537941027049703e-09\n",
            "----------------------------------------\n",
            "Epoch 862\n",
            "Var loss:  tensor(-3.3733e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5103503127529924e-08\n",
            "E_s_wdiff_all_sq: 1.821712303109256e-08\n",
            "E_IS_SCOPE: -6.82017253390085e-07\n",
            "E_IS_E_SCOPE: -6.614698609963852e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026372095882360802\n",
            "Total Loss: -3.3733039104726582e-09\n",
            "----------------------------------------\n",
            "Epoch 863\n",
            "Var loss:  tensor(-3.3905e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.543559994919764e-08\n",
            "E_s_wdiff_all_sq: 1.8716769815500585e-08\n",
            "E_IS_SCOPE: -6.815829140955788e-07\n",
            "E_IS_E_SCOPE: -6.61110693237423e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026357776247959114\n",
            "Total Loss: -3.3905108021251394e-09\n",
            "----------------------------------------\n",
            "Epoch 864\n",
            "Var loss:  tensor(-3.4112e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.547094050018169e-08\n",
            "E_s_wdiff_all_sq: 1.8410058383601197e-08\n",
            "E_IS_SCOPE: -6.817410574300414e-07\n",
            "E_IS_E_SCOPE: -6.610874422544449e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002635684925613588\n",
            "Total Loss: -3.4112474541229463e-09\n",
            "----------------------------------------\n",
            "Epoch 865\n",
            "Var loss:  tensor(-3.3679e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6179746814392135e-08\n",
            "E_s_wdiff_all_sq: 1.9112942272910097e-08\n",
            "E_IS_SCOPE: -6.812269600981505e-07\n",
            "E_IS_E_SCOPE: -6.605920464583543e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002633709835559668\n",
            "Total Loss: -3.3679219576207636e-09\n",
            "----------------------------------------\n",
            "Epoch 866\n",
            "Var loss:  tensor(-3.4297e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.60557279029687e-08\n",
            "E_s_wdiff_all_sq: 1.9221598686908012e-08\n",
            "E_IS_SCOPE: -6.805197930074242e-07\n",
            "E_IS_E_SCOPE: -6.599703110607022e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026312310430269834\n",
            "Total Loss: -3.429733896893885e-09\n",
            "----------------------------------------\n",
            "Epoch 867\n",
            "Var loss:  tensor(-3.4347e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.617419610689668e-08\n",
            "E_s_wdiff_all_sq: 1.963028210028e-08\n",
            "E_IS_SCOPE: -6.799392308295415e-07\n",
            "E_IS_E_SCOPE: -6.595323564244968e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026294849647339018\n",
            "Total Loss: -3.4347340229830597e-09\n",
            "----------------------------------------\n",
            "Epoch 868\n",
            "Var loss:  tensor(-3.4489e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.568252860007294e-08\n",
            "E_s_wdiff_all_sq: 1.895872591853696e-08\n",
            "E_IS_SCOPE: -6.804807774376859e-07\n",
            "E_IS_E_SCOPE: -6.599768713421874e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026312571981676096\n",
            "Total Loss: -3.4489087289713746e-09\n",
            "----------------------------------------\n",
            "Epoch 869\n",
            "Var loss:  tensor(-3.4597e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.507037177785844e-08\n",
            "E_s_wdiff_all_sq: 1.806943323048924e-08\n",
            "E_IS_SCOPE: -6.813740586633707e-07\n",
            "E_IS_E_SCOPE: -6.607261950259201e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002634244671550683\n",
            "Total Loss: -3.4596879470424503e-09\n",
            "----------------------------------------\n",
            "Epoch 870\n",
            "Var loss:  tensor(-3.4714e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.487280203913836e-08\n",
            "E_s_wdiff_all_sq: 1.799381312060506e-08\n",
            "E_IS_SCOPE: -6.816613329115407e-07\n",
            "E_IS_E_SCOPE: -6.61068566514543e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026356096700574554\n",
            "Total Loss: -3.4714430949727096e-09\n",
            "----------------------------------------\n",
            "Epoch 871\n",
            "Var loss:  tensor(-3.4841e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.490323235476786e-08\n",
            "E_s_wdiff_all_sq: 1.8144765211367648e-08\n",
            "E_IS_SCOPE: -6.816510450781006e-07\n",
            "E_IS_E_SCOPE: -6.611122096097842e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002635783670410332\n",
            "Total Loss: -3.4841030127430082e-09\n",
            "----------------------------------------\n",
            "Epoch 872\n",
            "Var loss:  tensor(-3.5039e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.496196252817928e-08\n",
            "E_s_wdiff_all_sq: 1.805056771262153e-08\n",
            "E_IS_SCOPE: -6.816825228502791e-07\n",
            "E_IS_E_SCOPE: -6.610573298560994e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026355648707020586\n",
            "Total Loss: -3.503890392312158e-09\n",
            "----------------------------------------\n",
            "Epoch 873\n",
            "Var loss:  tensor(-3.5231e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5298765142688056e-08\n",
            "E_s_wdiff_all_sq: 1.8401632571872193e-08\n",
            "E_IS_SCOPE: -6.813305067870873e-07\n",
            "E_IS_E_SCOPE: -6.607028272071369e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026341515065565015\n",
            "Total Loss: -3.523125808595328e-09\n",
            "----------------------------------------\n",
            "Epoch 874\n",
            "Var loss:  tensor(-3.5204e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.597750550059595e-08\n",
            "E_s_wdiff_all_sq: 1.9320666007368714e-08\n",
            "E_IS_SCOPE: -6.806362305524102e-07\n",
            "E_IS_E_SCOPE: -6.601300609130105e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026318679486020797\n",
            "Total Loss: -3.5203990050826403e-09\n",
            "----------------------------------------\n",
            "Epoch 875\n",
            "Var loss:  tensor(-3.5369e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.591696859903285e-08\n",
            "E_s_wdiff_all_sq: 1.9091073536231875e-08\n",
            "E_IS_SCOPE: -6.800933374412448e-07\n",
            "E_IS_E_SCOPE: -6.594943859535072e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026293335805272007\n",
            "Total Loss: -3.536907132184796e-09\n",
            "----------------------------------------\n",
            "Epoch 876\n",
            "Var loss:  tensor(-3.5443e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6031370075425064e-08\n",
            "E_s_wdiff_all_sq: 1.943753575017029e-08\n",
            "E_IS_SCOPE: -6.795199435200732e-07\n",
            "E_IS_E_SCOPE: -6.590333303421041e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026274954011167727\n",
            "Total Loss: -3.544291250194076e-09\n",
            "----------------------------------------\n",
            "Epoch 877\n",
            "Var loss:  tensor(-3.5555e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.581648189119309e-08\n",
            "E_s_wdiff_all_sq: 1.9385483429394743e-08\n",
            "E_IS_SCOPE: -6.795962895913086e-07\n",
            "E_IS_E_SCOPE: -6.59185503350722e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026281020986264575\n",
            "Total Loss: -3.5554732388854526e-09\n",
            "----------------------------------------\n",
            "Epoch 878\n",
            "Var loss:  tensor(-3.5699e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5106698301615023e-08\n",
            "E_s_wdiff_all_sq: 1.8352555310868334e-08\n",
            "E_IS_SCOPE: -6.805896566009965e-07\n",
            "E_IS_E_SCOPE: -6.600101070009254e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026313897051842756\n",
            "Total Loss: -3.5698554289057852e-09\n",
            "----------------------------------------\n",
            "Epoch 879\n",
            "Var loss:  tensor(-3.5781e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.462629006281027e-08\n",
            "E_s_wdiff_all_sq: 1.7684683493646412e-08\n",
            "E_IS_SCOPE: -6.813270581158432e-07\n",
            "E_IS_E_SCOPE: -6.606496360035965e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002633939438917055\n",
            "Total Loss: -3.57813687484011e-09\n",
            "----------------------------------------\n",
            "Epoch 880\n",
            "Var loss:  tensor(-3.5918e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4694364820603845e-08\n",
            "E_s_wdiff_all_sq: 1.798871501601307e-08\n",
            "E_IS_SCOPE: -6.811957700668037e-07\n",
            "E_IS_E_SCOPE: -6.60629508085621e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026338591910608695\n",
            "Total Loss: -3.5917733772849625e-09\n",
            "----------------------------------------\n",
            "Epoch 881\n",
            "Var loss:  tensor(-3.6104e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.491173135142184e-08\n",
            "E_s_wdiff_all_sq: 1.8277521899336924e-08\n",
            "E_IS_SCOPE: -6.809175589132674e-07\n",
            "E_IS_E_SCOPE: -6.603777210135102e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002632855342934268\n",
            "Total Loss: -3.610365566940107e-09\n",
            "----------------------------------------\n",
            "Epoch 882\n",
            "Var loss:  tensor(-3.6306e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5144204786686815e-08\n",
            "E_s_wdiff_all_sq: 1.835489014408658e-08\n",
            "E_IS_SCOPE: -6.80733176367026e-07\n",
            "E_IS_E_SCOPE: -6.601056785837215e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026317707388630184\n",
            "Total Loss: -3.6305801435191414e-09\n",
            "----------------------------------------\n",
            "Epoch 883\n",
            "Var loss:  tensor(-3.6489e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5624657198460944e-08\n",
            "E_s_wdiff_all_sq: 1.8957442743375554e-08\n",
            "E_IS_SCOPE: -6.80253571960557e-07\n",
            "E_IS_E_SCOPE: -6.59677949097574e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002630065427149586\n",
            "Total Loss: -3.648930490390902e-09\n",
            "----------------------------------------\n",
            "Epoch 884\n",
            "Var loss:  tensor(-3.6198e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.638590629328745e-08\n",
            "E_s_wdiff_all_sq: 1.989802156689114e-08\n",
            "E_IS_SCOPE: -6.797222791206737e-07\n",
            "E_IS_E_SCOPE: -6.592508635094107e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026283626825885486\n",
            "Total Loss: -3.6198457156400936e-09\n",
            "----------------------------------------\n",
            "Epoch 885\n",
            "Var loss:  tensor(-3.6640e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5902685117583896e-08\n",
            "E_s_wdiff_all_sq: 1.911924609867861e-08\n",
            "E_IS_SCOPE: -6.798306867754372e-07\n",
            "E_IS_E_SCOPE: -6.59189430832206e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00262811775707507\n",
            "Total Loss: -3.6639720870678368e-09\n",
            "----------------------------------------\n",
            "Epoch 886\n",
            "Var loss:  tensor(-3.6764e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.592033082892542e-08\n",
            "E_s_wdiff_all_sq: 1.938039823585656e-08\n",
            "E_IS_SCOPE: -6.795362808297136e-07\n",
            "E_IS_E_SCOPE: -6.590105477376954e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026274045693097103\n",
            "Total Loss: -3.676432810478097e-09\n",
            "----------------------------------------\n",
            "Epoch 887\n",
            "Var loss:  tensor(-3.6850e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.576225749967816e-08\n",
            "E_s_wdiff_all_sq: 1.944643543041423e-08\n",
            "E_IS_SCOPE: -6.796555564586184e-07\n",
            "E_IS_E_SCOPE: -6.592375748263363e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002628309702030423\n",
            "Total Loss: -3.685040414810658e-09\n",
            "----------------------------------------\n",
            "Epoch 888\n",
            "Var loss:  tensor(-3.6983e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.511664201332606e-08\n",
            "E_s_wdiff_all_sq: 1.841759532407639e-08\n",
            "E_IS_SCOPE: -6.806596095795976e-07\n",
            "E_IS_E_SCOPE: -6.600434026134667e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026315224512303433\n",
            "Total Loss: -3.6982664625226914e-09\n",
            "----------------------------------------\n",
            "Epoch 889\n",
            "Var loss:  tensor(-3.7064e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.479150971256194e-08\n",
            "E_s_wdiff_all_sq: 1.7889224246790256e-08\n",
            "E_IS_SCOPE: -6.812215875213235e-07\n",
            "E_IS_E_SCOPE: -6.604996964580994e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026333416459859526\n",
            "Total Loss: -3.7063958801868e-09\n",
            "----------------------------------------\n",
            "Epoch 890\n",
            "Var loss:  tensor(-3.7234e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.509807936349024e-08\n",
            "E_s_wdiff_all_sq: 1.854619761563453e-08\n",
            "E_IS_SCOPE: -6.807375408516468e-07\n",
            "E_IS_E_SCOPE: -6.601823272181503e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026320763287705252\n",
            "Total Loss: -3.7234447386475334e-09\n",
            "----------------------------------------\n",
            "Epoch 891\n",
            "Var loss:  tensor(-3.7419e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.541701984624046e-08\n",
            "E_s_wdiff_all_sq: 1.8963070420621138e-08\n",
            "E_IS_SCOPE: -6.803149061627106e-07\n",
            "E_IS_E_SCOPE: -6.597994083209213e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026305496720823917\n",
            "Total Loss: -3.7419454774698026e-09\n",
            "----------------------------------------\n",
            "Epoch 892\n",
            "Var loss:  tensor(-3.7602e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5554811099602197e-08\n",
            "E_s_wdiff_all_sq: 1.886018449078909e-08\n",
            "E_IS_SCOPE: -6.802785778417897e-07\n",
            "E_IS_E_SCOPE: -6.596336133235542e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026298886651605047\n",
            "Total Loss: -3.760201647168194e-09\n",
            "----------------------------------------\n",
            "Epoch 893\n",
            "Var loss:  tensor(-3.7183e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.629689797995108e-08\n",
            "E_s_wdiff_all_sq: 1.9654072463801455e-08\n",
            "E_IS_SCOPE: -6.796880084271114e-07\n",
            "E_IS_E_SCOPE: -6.59089874252561e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002627720835640106\n",
            "Total Loss: -3.7183420524619886e-09\n",
            "----------------------------------------\n",
            "Epoch 894\n",
            "Var loss:  tensor(-3.7758e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.606201935636651e-08\n",
            "E_s_wdiff_all_sq: 1.9526123730862248e-08\n",
            "E_IS_SCOPE: -6.791438019419704e-07\n",
            "E_IS_E_SCOPE: -6.585703908909429e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002625649711038715\n",
            "Total Loss: -3.7758256960610115e-09\n",
            "----------------------------------------\n",
            "Epoch 895\n",
            "Var loss:  tensor(-3.7820e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.612306414013827e-08\n",
            "E_s_wdiff_all_sq: 1.9853406442536165e-08\n",
            "E_IS_SCOPE: -6.786369013163098e-07\n",
            "E_IS_E_SCOPE: -6.581935458632389e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026241472702187465\n",
            "Total Loss: -3.781952428050057e-09\n",
            "----------------------------------------\n",
            "Epoch 896\n",
            "Var loss:  tensor(-3.7943e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.567194738964788e-08\n",
            "E_s_wdiff_all_sq: 1.9305818218422185e-08\n",
            "E_IS_SCOPE: -6.791019365551399e-07\n",
            "E_IS_E_SCOPE: -6.586041522407559e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002625784313929472\n",
            "Total Loss: -3.7943386770528e-09\n",
            "----------------------------------------\n",
            "Epoch 897\n",
            "Var loss:  tensor(-3.8041e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5042213697619974e-08\n",
            "E_s_wdiff_all_sq: 1.8382460446367387e-08\n",
            "E_IS_SCOPE: -6.800183810926916e-07\n",
            "E_IS_E_SCOPE: -6.593688850233145e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026288332217414834\n",
            "Total Loss: -3.804138107012144e-09\n",
            "----------------------------------------\n",
            "Epoch 898\n",
            "Var loss:  tensor(-3.8143e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.483071108140739e-08\n",
            "E_s_wdiff_all_sq: 1.8226325546589353e-08\n",
            "E_IS_SCOPE: -6.803526847147365e-07\n",
            "E_IS_E_SCOPE: -6.597258112398297e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026302562483916606\n",
            "Total Loss: -3.81426063450623e-09\n",
            "----------------------------------------\n",
            "Epoch 899\n",
            "Var loss:  tensor(-3.8270e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.494133619185176e-08\n",
            "E_s_wdiff_all_sq: 1.8489480271466084e-08\n",
            "E_IS_SCOPE: -6.802366991392407e-07\n",
            "E_IS_E_SCOPE: -6.596797197895295e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002630072486709028\n",
            "Total Loss: -3.8270019985473144e-09\n",
            "----------------------------------------\n",
            "Epoch 900\n",
            "Var loss:  tensor(-3.8465e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.509345673939757e-08\n",
            "E_s_wdiff_all_sq: 1.8541817988600918e-08\n",
            "E_IS_SCOPE: -6.801398444588506e-07\n",
            "E_IS_E_SCOPE: -6.595232356380346e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026294486011337916\n",
            "Total Loss: -3.846478110346152e-09\n",
            "----------------------------------------\n",
            "Epoch 901\n",
            "Var loss:  tensor(-3.8646e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.544629899756861e-08\n",
            "E_s_wdiff_all_sq: 1.888109503768713e-08\n",
            "E_IS_SCOPE: -6.79799993875165e-07\n",
            "E_IS_E_SCOPE: -6.591675170313907e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026280303890950114\n",
            "Total Loss: -3.864648947177625e-09\n",
            "----------------------------------------\n",
            "Epoch 902\n",
            "Var loss:  tensor(-3.8386e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.625160107782654e-08\n",
            "E_s_wdiff_all_sq: 1.9867366363477414e-08\n",
            "E_IS_SCOPE: -6.7907210467968e-07\n",
            "E_IS_E_SCOPE: -6.585431413067854e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026255410698611606\n",
            "Total Loss: -3.838591250950548e-09\n",
            "----------------------------------------\n",
            "Epoch 903\n",
            "Var loss:  tensor(-3.8762e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.601838996466856e-08\n",
            "E_s_wdiff_all_sq: 1.9495847077902344e-08\n",
            "E_IS_SCOPE: -6.786642848589014e-07\n",
            "E_IS_E_SCOPE: -6.580473872343732e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002623564551397866\n",
            "Total Loss: -3.876151581800564e-09\n",
            "----------------------------------------\n",
            "Epoch 904\n",
            "Var loss:  tensor(-3.8835e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6123888599387156e-08\n",
            "E_s_wdiff_all_sq: 1.98688674805125e-08\n",
            "E_IS_SCOPE: -6.781044601717063e-07\n",
            "E_IS_E_SCOPE: -6.576176545967023e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026218512533335565\n",
            "Total Loss: -3.883489250644023e-09\n",
            "----------------------------------------\n",
            "Epoch 905\n",
            "Var loss:  tensor(-3.8939e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5844326221535996e-08\n",
            "E_s_wdiff_all_sq: 1.9704061165291758e-08\n",
            "E_IS_SCOPE: -6.782908031709242e-07\n",
            "E_IS_E_SCOPE: -6.578561751882083e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026228022094209043\n",
            "Total Loss: -3.893890128697957e-09\n",
            "----------------------------------------\n",
            "Epoch 906\n",
            "Var loss:  tensor(-3.9063e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.510376345898643e-08\n",
            "E_s_wdiff_all_sq: 1.859947586616825e-08\n",
            "E_IS_SCOPE: -6.793478203474636e-07\n",
            "E_IS_E_SCOPE: -6.587249766986323e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026262660281202365\n",
            "Total Loss: -3.906298924355003e-09\n",
            "----------------------------------------\n",
            "Epoch 907\n",
            "Var loss:  tensor(-3.9142e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.470511352208712e-08\n",
            "E_s_wdiff_all_sq: 1.8077422566925153e-08\n",
            "E_IS_SCOPE: -6.799743120075529e-07\n",
            "E_IS_E_SCOPE: -6.59285803659398e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026285019852295218\n",
            "Total Loss: -3.9142249606581255e-09\n",
            "----------------------------------------\n",
            "Epoch 908\n",
            "Var loss:  tensor(-3.9272e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.485461774132337e-08\n",
            "E_s_wdiff_all_sq: 1.848743089420646e-08\n",
            "E_IS_SCOPE: -6.797620497708504e-07\n",
            "E_IS_E_SCOPE: -6.591972965610145e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00262814911689455\n",
            "Total Loss: -3.92721879206517e-09\n",
            "----------------------------------------\n",
            "Epoch 909\n",
            "Var loss:  tensor(-3.9465e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5079146545081825e-08\n",
            "E_s_wdiff_all_sq: 1.871746729341213e-08\n",
            "E_IS_SCOPE: -6.795336620004241e-07\n",
            "E_IS_E_SCOPE: -6.589620337645815e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026272111492877206\n",
            "Total Loss: -3.946476439526201e-09\n",
            "----------------------------------------\n",
            "Epoch 910\n",
            "Var loss:  tensor(-3.9650e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.535317220333684e-08\n",
            "E_s_wdiff_all_sq: 1.884337411055775e-08\n",
            "E_IS_SCOPE: -6.79340317469973e-07\n",
            "E_IS_E_SCOPE: -6.586853644009996e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002626108098126311\n",
            "Total Loss: -3.965007264678104e-09\n",
            "----------------------------------------\n",
            "Epoch 911\n",
            "Var loss:  tensor(-3.9513e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.609896298745062e-08\n",
            "E_s_wdiff_all_sq: 1.974464554634831e-08\n",
            "E_IS_SCOPE: -6.786751183238909e-07\n",
            "E_IS_E_SCOPE: -6.581047368899241e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026237931983407103\n",
            "Total Loss: -3.9513446463419575e-09\n",
            "----------------------------------------\n",
            "Epoch 912\n",
            "Var loss:  tensor(-3.9770e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.611387775267556e-08\n",
            "E_s_wdiff_all_sq: 1.975300892018799e-08\n",
            "E_IS_SCOPE: -6.77998005799549e-07\n",
            "E_IS_E_SCOPE: -6.574114980238014e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002621029329126892\n",
            "Total Loss: -3.977045938518135e-09\n",
            "----------------------------------------\n",
            "Epoch 913\n",
            "Var loss:  tensor(-3.9826e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6259431808524e-08\n",
            "E_s_wdiff_all_sq: 2.0162043061230803e-08\n",
            "E_IS_SCOPE: -6.774505964638907e-07\n",
            "E_IS_E_SCOPE: -6.5699307152608e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002619361107433313\n",
            "Total Loss: -3.982560347838846e-09\n",
            "----------------------------------------\n",
            "Epoch 914\n",
            "Var loss:  tensor(-3.9949e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5879884998199675e-08\n",
            "E_s_wdiff_all_sq: 1.9767625415449886e-08\n",
            "E_IS_SCOPE: -6.778543985753832e-07\n",
            "E_IS_E_SCOPE: -6.573832749209222e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026209168066343167\n",
            "Total Loss: -3.994886945682746e-09\n",
            "----------------------------------------\n",
            "Epoch 915\n",
            "Var loss:  tensor(-4.0061e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5162496490043484e-08\n",
            "E_s_wdiff_all_sq: 1.8724500978635722e-08\n",
            "E_IS_SCOPE: -6.789241556286609e-07\n",
            "E_IS_E_SCOPE: -6.582845804658882e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002624510215442897\n",
            "Total Loss: -4.006054033648242e-09\n",
            "----------------------------------------\n",
            "Epoch 916\n",
            "Var loss:  tensor(-4.0146e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.482175706038399e-08\n",
            "E_s_wdiff_all_sq: 1.8357284604409837e-08\n",
            "E_IS_SCOPE: -6.794817190196357e-07\n",
            "E_IS_E_SCOPE: -6.588246231163296e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026266633077299062\n",
            "Total Loss: -4.014618570148422e-09\n",
            "----------------------------------------\n",
            "Epoch 917\n",
            "Var loss:  tensor(-4.0266e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4906655118874475e-08\n",
            "E_s_wdiff_all_sq: 1.8620836897053938e-08\n",
            "E_IS_SCOPE: -6.794039349624061e-07\n",
            "E_IS_E_SCOPE: -6.588301885948464e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026266854966974966\n",
            "Total Loss: -4.026573732809505e-09\n",
            "----------------------------------------\n",
            "Epoch 918\n",
            "Var loss:  tensor(-4.0465e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.508370483361426e-08\n",
            "E_s_wdiff_all_sq: 1.873791499597492e-08\n",
            "E_IS_SCOPE: -6.792589628985475e-07\n",
            "E_IS_E_SCOPE: -6.586452751946921e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026259482667485073\n",
            "Total Loss: -4.046484789581916e-09\n",
            "----------------------------------------\n",
            "Epoch 919\n",
            "Var loss:  tensor(-4.0653e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.544609003445543e-08\n",
            "E_s_wdiff_all_sq: 1.905281101263639e-08\n",
            "E_IS_SCOPE: -6.789117466580841e-07\n",
            "E_IS_E_SCOPE: -6.582648969757106e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002624431739472808\n",
            "Total Loss: -4.065319562438264e-09\n",
            "----------------------------------------\n",
            "Epoch 920\n",
            "Var loss:  tensor(-4.0400e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6303045740356326e-08\n",
            "E_s_wdiff_all_sq: 2.0085904513411248e-08\n",
            "E_IS_SCOPE: -6.78128571868654e-07\n",
            "E_IS_E_SCOPE: -6.575824365012874e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002621710842553892\n",
            "Total Loss: -4.040028727298597e-09\n",
            "----------------------------------------\n",
            "Epoch 921\n",
            "Var loss:  tensor(-4.0752e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.61576609336123e-08\n",
            "E_s_wdiff_all_sq: 1.9844676120575186e-08\n",
            "E_IS_SCOPE: -6.776196321555214e-07\n",
            "E_IS_E_SCOPE: -6.570079725655442e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026194205162839153\n",
            "Total Loss: -4.07523358642771e-09\n",
            "----------------------------------------\n",
            "Epoch 922\n",
            "Var loss:  tensor(-4.0818e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.629574558656643e-08\n",
            "E_s_wdiff_all_sq: 2.026175976665177e-08\n",
            "E_IS_SCOPE: -6.770674387251272e-07\n",
            "E_IS_E_SCOPE: -6.565919956640409e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026177620608684605\n",
            "Total Loss: -4.081799521768519e-09\n",
            "----------------------------------------\n",
            "Epoch 923\n",
            "Var loss:  tensor(-4.0935e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.595584994337907e-08\n",
            "E_s_wdiff_all_sq: 1.9983629995422482e-08\n",
            "E_IS_SCOPE: -6.774059520659625e-07\n",
            "E_IS_E_SCOPE: -6.569555587192222e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026192115478845556\n",
            "Total Loss: -4.09346596503472e-09\n",
            "----------------------------------------\n",
            "Epoch 924\n",
            "Var loss:  tensor(-4.1053e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.517463286874481e-08\n",
            "E_s_wdiff_all_sq: 1.88265090498029e-08\n",
            "E_IS_SCOPE: -6.785823679551384e-07\n",
            "E_IS_E_SCOPE: -6.579380940955693e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00262312881134291\n",
            "Total Loss: -4.1053231197065935e-09\n",
            "----------------------------------------\n",
            "Epoch 925\n",
            "Var loss:  tensor(-4.1130e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.478913284715518e-08\n",
            "E_s_wdiff_all_sq: 1.8357888763754265e-08\n",
            "E_IS_SCOPE: -6.792406813252736e-07\n",
            "E_IS_E_SCOPE: -6.585510321159861e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002625572529673482\n",
            "Total Loss: -4.112953554684661e-09\n",
            "----------------------------------------\n",
            "Epoch 926\n",
            "Var loss:  tensor(-4.1251e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.493598765557239e-08\n",
            "E_s_wdiff_all_sq: 1.874460013248445e-08\n",
            "E_IS_SCOPE: -6.790913297625674e-07\n",
            "E_IS_E_SCOPE: -6.585155251913768e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00262543096736271\n",
            "Total Loss: -4.125120838803864e-09\n",
            "----------------------------------------\n",
            "Epoch 927\n",
            "Var loss:  tensor(-4.1454e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.51586940916925e-08\n",
            "E_s_wdiff_all_sq: 1.8931822061509994e-08\n",
            "E_IS_SCOPE: -6.789074688773194e-07\n",
            "E_IS_E_SCOPE: -6.583037853930484e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00262458678343342\n",
            "Total Loss: -4.1453941578702074e-09\n",
            "----------------------------------------\n",
            "Epoch 928\n",
            "Var loss:  tensor(-4.1639e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.550439533485181e-08\n",
            "E_s_wdiff_all_sq: 1.917131329220294e-08\n",
            "E_IS_SCOPE: -6.786265791257058e-07\n",
            "E_IS_E_SCOPE: -6.579605161228664e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002623218205567594\n",
            "Total Loss: -4.163943182540429e-09\n",
            "----------------------------------------\n",
            "Epoch 929\n",
            "Var loss:  tensor(-4.1544e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.593500219792697e-08\n",
            "E_s_wdiff_all_sq: 1.9603866375074853e-08\n",
            "E_IS_SCOPE: -6.773853165433904e-07\n",
            "E_IS_E_SCOPE: -6.567250187060686e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002618292409509536\n",
            "Total Loss: -4.154359071302149e-09\n",
            "----------------------------------------\n",
            "Epoch 930\n",
            "Var loss:  tensor(-4.1532e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.656454372192118e-08\n",
            "E_s_wdiff_all_sq: 2.0835365528317063e-08\n",
            "E_IS_SCOPE: -6.760080097094315e-07\n",
            "E_IS_E_SCOPE: -6.556492745103591e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00261400353245754\n",
            "Total Loss: -4.153191424051212e-09\n",
            "----------------------------------------\n",
            "Epoch 931\n",
            "Var loss:  tensor(-4.1657e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6184948792694794e-08\n",
            "E_s_wdiff_all_sq: 2.0356561061472497e-08\n",
            "E_IS_SCOPE: -6.762987713132917e-07\n",
            "E_IS_E_SCOPE: -6.558842002295399e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026149401561734167\n",
            "Total Loss: -4.165653655791894e-09\n",
            "----------------------------------------\n",
            "Epoch 932\n",
            "Var loss:  tensor(-4.1776e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.520621047025745e-08\n",
            "E_s_wdiff_all_sq: 1.883054221011455e-08\n",
            "E_IS_SCOPE: -6.776752016559485e-07\n",
            "E_IS_E_SCOPE: -6.569810215469719e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026193130654554157\n",
            "Total Loss: -4.1775911773206645e-09\n",
            "----------------------------------------\n",
            "Epoch 933\n",
            "Var loss:  tensor(-4.1905e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.480993228323619e-08\n",
            "E_s_wdiff_all_sq: 1.8576661958682398e-08\n",
            "E_IS_SCOPE: -6.782318494731677e-07\n",
            "E_IS_E_SCOPE: -6.576024049854822e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026217904547646454\n",
            "Total Loss: -4.1905178703275966e-09\n",
            "----------------------------------------\n",
            "Epoch 934\n",
            "Var loss:  tensor(-4.1956e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.476668231526002e-08\n",
            "E_s_wdiff_all_sq: 1.8783187330176437e-08\n",
            "E_IS_SCOPE: -6.783306543269313e-07\n",
            "E_IS_E_SCOPE: -6.578235696599454e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026226722146670467\n",
            "Total Loss: -4.195573568398524e-09\n",
            "----------------------------------------\n",
            "Epoch 935\n",
            "Var loss:  tensor(-4.2162e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.462245629760716e-08\n",
            "E_s_wdiff_all_sq: 1.8322745775993835e-08\n",
            "E_IS_SCOPE: -6.787179841400939e-07\n",
            "E_IS_E_SCOPE: -6.580424757773338e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002623544969943955\n",
            "Total Loss: -4.216205423417422e-09\n",
            "----------------------------------------\n",
            "Epoch 936\n",
            "Var loss:  tensor(-4.2358e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.497069380179799e-08\n",
            "E_s_wdiff_all_sq: 1.86093801332754e-08\n",
            "E_IS_SCOPE: -6.784200633940651e-07\n",
            "E_IS_E_SCOPE: -6.577039778445393e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002622195414889974\n",
            "Total Loss: -4.235756650039554e-09\n",
            "----------------------------------------\n",
            "Epoch 937\n",
            "Var loss:  tensor(-4.2555e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.585565534685175e-08\n",
            "E_s_wdiff_all_sq: 1.9954911597082425e-08\n",
            "E_IS_SCOPE: -6.774019424313112e-07\n",
            "E_IS_E_SCOPE: -6.56906280177999e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002619015079611289\n",
            "Total Loss: -4.255479976365602e-09\n",
            "----------------------------------------\n",
            "Epoch 938\n",
            "Var loss:  tensor(-4.2003e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.679174894619388e-08\n",
            "E_s_wdiff_all_sq: 2.085020566408078e-08\n",
            "E_IS_SCOPE: -6.768875467819628e-07\n",
            "E_IS_E_SCOPE: -6.56399062643867e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026169928575521923\n",
            "Total Loss: -4.200324213589087e-09\n",
            "----------------------------------------\n",
            "Epoch 939\n",
            "Var loss:  tensor(-4.2568e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.605400827728123e-08\n",
            "E_s_wdiff_all_sq: 1.9616049368565642e-08\n",
            "E_IS_SCOPE: -6.773249423865861e-07\n",
            "E_IS_E_SCOPE: -6.565600057973369e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00261763452069139\n",
            "Total Loss: -4.256813489293214e-09\n",
            "----------------------------------------\n",
            "Epoch 940\n",
            "Var loss:  tensor(-4.2772e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6361772853505115e-08\n",
            "E_s_wdiff_all_sq: 2.050523272478787e-08\n",
            "E_IS_SCOPE: -6.766587522484032e-07\n",
            "E_IS_E_SCOPE: -6.561743406999061e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002616096915196772\n",
            "Total Loss: -4.277182187787351e-09\n",
            "----------------------------------------\n",
            "Epoch 941\n",
            "Var loss:  tensor(-4.2813e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.618634670856547e-08\n",
            "E_s_wdiff_all_sq: 2.0579017150364194e-08\n",
            "E_IS_SCOPE: -6.769062598087309e-07\n",
            "E_IS_E_SCOPE: -6.565443787745366e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026175722174228747\n",
            "Total Loss: -4.281331729698066e-09\n",
            "----------------------------------------\n",
            "Epoch 942\n",
            "Var loss:  tensor(-4.2961e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5148625038598e-08\n",
            "E_s_wdiff_all_sq: 1.8787675386580743e-08\n",
            "E_IS_SCOPE: -6.785921654079448e-07\n",
            "E_IS_E_SCOPE: -6.578461080470775e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026227620728059477\n",
            "Total Loss: -4.296064289228083e-09\n",
            "----------------------------------------\n",
            "Epoch 943\n",
            "Var loss:  tensor(-4.3034e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.487201243905142e-08\n",
            "E_s_wdiff_all_sq: 1.8415771097475967e-08\n",
            "E_IS_SCOPE: -6.791523537547928e-07\n",
            "E_IS_E_SCOPE: -6.583550024794812e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026247909804791004\n",
            "Total Loss: -4.303360428558465e-09\n",
            "----------------------------------------\n",
            "Epoch 944\n",
            "Var loss:  tensor(-4.3167e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.544410545365946e-08\n",
            "E_s_wdiff_all_sq: 1.9607978881550727e-08\n",
            "E_IS_SCOPE: -6.78350831686936e-07\n",
            "E_IS_E_SCOPE: -6.578568658641156e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026228049630718756\n",
            "Total Loss: -4.31670429304241e-09\n",
            "----------------------------------------\n",
            "Epoch 945\n",
            "Var loss:  tensor(-4.3011e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5906935633305e-08\n",
            "E_s_wdiff_all_sq: 1.9884583243938843e-08\n",
            "E_IS_SCOPE: -6.780164370132217e-07\n",
            "E_IS_E_SCOPE: -6.574371543984493e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002621131618348534\n",
            "Total Loss: -4.301112059689084e-09\n",
            "----------------------------------------\n",
            "Epoch 946\n",
            "Var loss:  tensor(-4.3162e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.559312451566097e-08\n",
            "E_s_wdiff_all_sq: 1.899375562185024e-08\n",
            "E_IS_SCOPE: -6.77610355933127e-07\n",
            "E_IS_E_SCOPE: -6.567350302560274e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002618332324488436\n",
            "Total Loss: -4.3161816798988796e-09\n",
            "----------------------------------------\n",
            "Epoch 947\n",
            "Var loss:  tensor(-4.3308e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.653695102867963e-08\n",
            "E_s_wdiff_all_sq: 2.0882951592124195e-08\n",
            "E_IS_SCOPE: -6.755320381829362e-07\n",
            "E_IS_E_SCOPE: -6.551221091982198e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026119017807410445\n",
            "Total Loss: -4.330757752387709e-09\n",
            "----------------------------------------\n",
            "Epoch 948\n",
            "Var loss:  tensor(-4.3244e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.665693917264439e-08\n",
            "E_s_wdiff_all_sq: 2.134446632722831e-08\n",
            "E_IS_SCOPE: -6.749539186046061e-07\n",
            "E_IS_E_SCOPE: -6.547179434174242e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002610290415000593\n",
            "Total Loss: -4.32437674845797e-09\n",
            "----------------------------------------\n",
            "Epoch 949\n",
            "Var loss:  tensor(-4.3457e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.531924862939397e-08\n",
            "E_s_wdiff_all_sq: 1.9050285234274364e-08\n",
            "E_IS_SCOPE: -6.767276988270449e-07\n",
            "E_IS_E_SCOPE: -6.560028287199309e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002615413115276687\n",
            "Total Loss: -4.3456760386187175e-09\n",
            "----------------------------------------\n",
            "Epoch 950\n",
            "Var loss:  tensor(-4.3586e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4728891262456565e-08\n",
            "E_s_wdiff_all_sq: 1.8413911169330542e-08\n",
            "E_IS_SCOPE: -6.775481138542354e-07\n",
            "E_IS_E_SCOPE: -6.567937893507372e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026185665907144605\n",
            "Total Loss: -4.358568133380661e-09\n",
            "----------------------------------------\n",
            "Epoch 951\n",
            "Var loss:  tensor(-4.3600e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4938436214279346e-08\n",
            "E_s_wdiff_all_sq: 1.9314556442536276e-08\n",
            "E_IS_SCOPE: -6.772145227862292e-07\n",
            "E_IS_E_SCOPE: -6.568050371219671e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002618611434375348\n",
            "Total Loss: -4.359990776291605e-09\n",
            "----------------------------------------\n",
            "Epoch 952\n",
            "Var loss:  tensor(-4.3849e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.463243726938914e-08\n",
            "E_s_wdiff_all_sq: 1.86315865478371e-08\n",
            "E_IS_SCOPE: -6.778735264422428e-07\n",
            "E_IS_E_SCOPE: -6.572631128297805e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00262043773322888\n",
            "Total Loss: -4.384875722882871e-09\n",
            "----------------------------------------\n",
            "Epoch 953\n",
            "Var loss:  tensor(-4.3957e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.462616518615931e-08\n",
            "E_s_wdiff_all_sq: 1.814437763672424e-08\n",
            "E_IS_SCOPE: -6.782404897021569e-07\n",
            "E_IS_E_SCOPE: -6.573842142739822e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026209205517344985\n",
            "Total Loss: -4.395662526424697e-09\n",
            "----------------------------------------\n",
            "Epoch 954\n",
            "Var loss:  tensor(-4.4255e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.567509976482006e-08\n",
            "E_s_wdiff_all_sq: 1.9870875603332125e-08\n",
            "E_IS_SCOPE: -6.76970559759998e-07\n",
            "E_IS_E_SCOPE: -6.564381229550716e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026171485868352667\n",
            "Total Loss: -4.425548667875309e-09\n",
            "----------------------------------------\n",
            "Epoch 955\n",
            "Var loss:  tensor(-4.3658e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.692864217669172e-08\n",
            "E_s_wdiff_all_sq: 2.1349048643723692e-08\n",
            "E_IS_SCOPE: -6.760263097103621e-07\n",
            "E_IS_E_SCOPE: -6.556360601188328e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002613950848091871\n",
            "Total Loss: -4.365804869601122e-09\n",
            "----------------------------------------\n",
            "Epoch 956\n",
            "Var loss:  tensor(-4.4200e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.605100209751241e-08\n",
            "E_s_wdiff_all_sq: 1.9694288372702027e-08\n",
            "E_IS_SCOPE: -6.766893324439138e-07\n",
            "E_IS_E_SCOPE: -6.558834175475921e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026149370357042025\n",
            "Total Loss: -4.420015287343507e-09\n",
            "----------------------------------------\n",
            "Epoch 957\n",
            "Var loss:  tensor(-4.4427e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.636874830402669e-08\n",
            "E_s_wdiff_all_sq: 2.0530041378612526e-08\n",
            "E_IS_SCOPE: -6.760089041521158e-07\n",
            "E_IS_E_SCOPE: -6.554506742697696e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002613211734539613\n",
            "Total Loss: -4.442652058788729e-09\n",
            "----------------------------------------\n",
            "Epoch 958\n",
            "Var loss:  tensor(-4.4409e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.645949140208816e-08\n",
            "E_s_wdiff_all_sq: 2.1154737033476832e-08\n",
            "E_IS_SCOPE: -6.758566846368391e-07\n",
            "E_IS_E_SCOPE: -6.555662953870278e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026136727035678564\n",
            "Total Loss: -4.44092335052178e-09\n",
            "----------------------------------------\n",
            "Epoch 959\n",
            "Var loss:  tensor(-4.4648e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5281655717793634e-08\n",
            "E_s_wdiff_all_sq: 1.916086607218193e-08\n",
            "E_IS_SCOPE: -6.776941787951872e-07\n",
            "E_IS_E_SCOPE: -6.569838550749469e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026193243624283912\n",
            "Total Loss: -4.46475701437933e-09\n",
            "----------------------------------------\n",
            "Epoch 960\n",
            "Var loss:  tensor(-4.4645e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.476416682013486e-08\n",
            "E_s_wdiff_all_sq: 1.831113278920305e-08\n",
            "E_IS_SCOPE: -6.786489099329614e-07\n",
            "E_IS_E_SCOPE: -6.577725859668715e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002622468948135726\n",
            "Total Loss: -4.464513120758318e-09\n",
            "----------------------------------------\n",
            "Epoch 961\n",
            "Var loss:  tensor(-4.4816e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5388747265589575e-08\n",
            "E_s_wdiff_all_sq: 1.9697189675640448e-08\n",
            "E_IS_SCOPE: -6.77745587055282e-07\n",
            "E_IS_E_SCOPE: -6.572414394081779e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026203513236150327\n",
            "Total Loss: -4.481636923769788e-09\n",
            "----------------------------------------\n",
            "Epoch 962\n",
            "Var loss:  tensor(-4.4573e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.598131204921221e-08\n",
            "E_s_wdiff_all_sq: 2.019946355804656e-08\n",
            "E_IS_SCOPE: -6.772628505441154e-07\n",
            "E_IS_E_SCOPE: -6.567257064989948e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00261829515166637\n",
            "Total Loss: -4.457338818585915e-09\n",
            "----------------------------------------\n",
            "Epoch 963\n",
            "Var loss:  tensor(-4.4780e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.551077417381511e-08\n",
            "E_s_wdiff_all_sq: 1.8982660082297423e-08\n",
            "E_IS_SCOPE: -6.770792543896932e-07\n",
            "E_IS_E_SCOPE: -6.561586380068529e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002616034310239051\n",
            "Total Loss: -4.478017893673421e-09\n",
            "----------------------------------------\n",
            "Epoch 964\n",
            "Var loss:  tensor(-4.4970e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6529723750655614e-08\n",
            "E_s_wdiff_all_sq: 2.096792181049878e-08\n",
            "E_IS_SCOPE: -6.749161717645498e-07\n",
            "E_IS_E_SCOPE: -6.54469225380632e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002609298802789558\n",
            "Total Loss: -4.496990047189027e-09\n",
            "----------------------------------------\n",
            "Epoch 965\n",
            "Var loss:  tensor(-4.4840e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.685348020703065e-08\n",
            "E_s_wdiff_all_sq: 2.1771441056306186e-08\n",
            "E_IS_SCOPE: -6.741065828710435e-07\n",
            "E_IS_E_SCOPE: -6.539060237952854e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002607053378306047\n",
            "Total Loss: -4.483978220301956e-09\n",
            "----------------------------------------\n",
            "Epoch 966\n",
            "Var loss:  tensor(-4.5102e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.546522717324014e-08\n",
            "E_s_wdiff_all_sq: 1.9356426505872863e-08\n",
            "E_IS_SCOPE: -6.75983416413642e-07\n",
            "E_IS_E_SCOPE: -6.552563854409133e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026124371257591384\n",
            "Total Loss: -4.510160497600569e-09\n",
            "----------------------------------------\n",
            "Epoch 967\n",
            "Var loss:  tensor(-4.5215e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4829102719684174e-08\n",
            "E_s_wdiff_all_sq: 1.8603942168135395e-08\n",
            "E_IS_SCOPE: -6.769449281211148e-07\n",
            "E_IS_E_SCOPE: -6.561540351066862e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026160159589683906\n",
            "Total Loss: -4.521524696818671e-09\n",
            "----------------------------------------\n",
            "Epoch 968\n",
            "Var loss:  tensor(-4.5232e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.510883958249752e-08\n",
            "E_s_wdiff_all_sq: 1.9663024212306902e-08\n",
            "E_IS_SCOPE: -6.765694972680839e-07\n",
            "E_IS_E_SCOPE: -6.56167429359743e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026160693604227445\n",
            "Total Loss: -4.523219666001523e-09\n",
            "----------------------------------------\n",
            "Epoch 969\n",
            "Var loss:  tensor(-4.5490e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4775926341925224e-08\n",
            "E_s_wdiff_all_sq: 1.893900096137888e-08\n",
            "E_IS_SCOPE: -6.773113879985431e-07\n",
            "E_IS_E_SCOPE: -6.567008535140885e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026181960654737013\n",
            "Total Loss: -4.549042807873198e-09\n",
            "----------------------------------------\n",
            "Epoch 970\n",
            "Var loss:  tensor(-4.5581e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.471099004488338e-08\n",
            "E_s_wdiff_all_sq: 1.8315519316636975e-08\n",
            "E_IS_SCOPE: -6.778088546735758e-07\n",
            "E_IS_E_SCOPE: -6.569145274227949e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026190479604942052\n",
            "Total Loss: -4.558082992825648e-09\n",
            "----------------------------------------\n",
            "Epoch 971\n",
            "Var loss:  tensor(-4.5708e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5953628462322186e-08\n",
            "E_s_wdiff_all_sq: 2.027356122785849e-08\n",
            "E_IS_SCOPE: -6.76368342658894e-07\n",
            "E_IS_E_SCOPE: -6.558253409496732e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026147054905198866\n",
            "Total Loss: -4.570835403488385e-09\n",
            "----------------------------------------\n",
            "Epoch 972\n",
            "Var loss:  tensor(-4.5831e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.644539742973695e-08\n",
            "E_s_wdiff_all_sq: 2.0889689430317676e-08\n",
            "E_IS_SCOPE: -6.751251689692038e-07\n",
            "E_IS_E_SCOPE: -6.546382086901246e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026099725211708824\n",
            "Total Loss: -4.583111778249701e-09\n",
            "----------------------------------------\n",
            "Epoch 973\n",
            "Var loss:  tensor(-4.5797e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6470142763662344e-08\n",
            "E_s_wdiff_all_sq: 2.073951399525869e-08\n",
            "E_IS_SCOPE: -6.74860330860824e-07\n",
            "E_IS_E_SCOPE: -6.542876177994635e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026085747527872906\n",
            "Total Loss: -4.5796965738278445e-09\n",
            "----------------------------------------\n",
            "Epoch 974\n",
            "Var loss:  tensor(-4.5934e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6279381578241844e-08\n",
            "E_s_wdiff_all_sq: 2.0661312308441988e-08\n",
            "E_IS_SCOPE: -6.750246396311468e-07\n",
            "E_IS_E_SCOPE: -6.545013380421079e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00260942683253625\n",
            "Total Loss: -4.59343312778829e-09\n",
            "----------------------------------------\n",
            "Epoch 975\n",
            "Var loss:  tensor(-4.6076e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5753330072375186e-08\n",
            "E_s_wdiff_all_sq: 2.0165094884688325e-08\n",
            "E_IS_SCOPE: -6.757918072941982e-07\n",
            "E_IS_E_SCOPE: -6.552763485187191e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026125167164151976\n",
            "Total Loss: -4.60758158278202e-09\n",
            "----------------------------------------\n",
            "Epoch 976\n",
            "Var loss:  tensor(-4.6163e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.499849550504477e-08\n",
            "E_s_wdiff_all_sq: 1.909318111623322e-08\n",
            "E_IS_SCOPE: -6.770228126623699e-07\n",
            "E_IS_E_SCOPE: -6.563444570375956e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002616775150840335\n",
            "Total Loss: -4.616296080247304e-09\n",
            "----------------------------------------\n",
            "Epoch 977\n",
            "Var loss:  tensor(-4.6252e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.473355898213498e-08\n",
            "E_s_wdiff_all_sq: 1.873886114921422e-08\n",
            "E_IS_SCOPE: -6.775680878533581e-07\n",
            "E_IS_E_SCOPE: -6.568406052361962e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026187532406425893\n",
            "Total Loss: -4.625166620913293e-09\n",
            "----------------------------------------\n",
            "Epoch 978\n",
            "Var loss:  tensor(-4.6440e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5092834990485645e-08\n",
            "E_s_wdiff_all_sq: 1.9328010627274917e-08\n",
            "E_IS_SCOPE: -6.771831909904449e-07\n",
            "E_IS_E_SCOPE: -6.565612143373458e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026176393390111466\n",
            "Total Loss: -4.644028162497812e-09\n",
            "----------------------------------------\n",
            "Epoch 979\n",
            "Var loss:  tensor(-4.6254e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.586181377418783e-08\n",
            "E_s_wdiff_all_sq: 2.008498383776731e-08\n",
            "E_IS_SCOPE: -6.765131495477751e-07\n",
            "E_IS_E_SCOPE: -6.55894467900288e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.00261498109227851\n",
            "Total Loss: -4.6254325780642346e-09\n",
            "----------------------------------------\n",
            "Epoch 980\n",
            "Var loss:  tensor(-4.6514e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5906545585826316e-08\n",
            "E_s_wdiff_all_sq: 1.987827978054319e-08\n",
            "E_IS_SCOPE: -6.756923021569279e-07\n",
            "E_IS_E_SCOPE: -6.549349294080684e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026111555149375388\n",
            "Total Loss: -4.651378911946225e-09\n",
            "----------------------------------------\n",
            "Epoch 981\n",
            "Var loss:  tensor(-4.6525e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.675656211201936e-08\n",
            "E_s_wdiff_all_sq: 2.1413489164009946e-08\n",
            "E_IS_SCOPE: -6.740641148187001e-07\n",
            "E_IS_E_SCOPE: -6.536487883980239e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026060278082897952\n",
            "Total Loss: -4.652479112853381e-09\n",
            "----------------------------------------\n",
            "Epoch 982\n",
            "Var loss:  tensor(-4.6583e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6669722974865655e-08\n",
            "E_s_wdiff_all_sq: 2.1445434654580203e-08\n",
            "E_IS_SCOPE: -6.74032952402891e-07\n",
            "E_IS_E_SCOPE: -6.536741209979981e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026061288066564423\n",
            "Total Loss: -4.658273709010853e-09\n",
            "----------------------------------------\n",
            "Epoch 983\n",
            "Var loss:  tensor(-4.6753e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5533271796210016e-08\n",
            "E_s_wdiff_all_sq: 1.961265504078867e-08\n",
            "E_IS_SCOPE: -6.757264369553742e-07\n",
            "E_IS_E_SCOPE: -6.550109319177951e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002611458528814965\n",
            "Total Loss: -4.675292539247268e-09\n",
            "----------------------------------------\n",
            "Epoch 984\n",
            "Var loss:  tensor(-4.6885e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.500844698189871e-08\n",
            "E_s_wdiff_all_sq: 1.9122015216934586e-08\n",
            "E_IS_SCOPE: -6.766317466538731e-07\n",
            "E_IS_E_SCOPE: -6.559267460704385e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002615109781890586\n",
            "Total Loss: -4.688468621415417e-09\n",
            "----------------------------------------\n",
            "Epoch 985\n",
            "Var loss:  tensor(-4.6909e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5028109480924995e-08\n",
            "E_s_wdiff_all_sq: 1.951484462730701e-08\n",
            "E_IS_SCOPE: -6.76772877491835e-07\n",
            "E_IS_E_SCOPE: -6.562532693271101e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026164115951916173\n",
            "Total Loss: -4.6908506953423304e-09\n",
            "----------------------------------------\n",
            "Epoch 986\n",
            "Var loss:  tensor(-4.7127e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.483289541180184e-08\n",
            "E_s_wdiff_all_sq: 1.8965979447311795e-08\n",
            "E_IS_SCOPE: -6.77336038664712e-07\n",
            "E_IS_E_SCOPE: -6.566286568397266e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002617908225054821\n",
            "Total Loss: -4.7127469049913444e-09\n",
            "----------------------------------------\n",
            "Epoch 987\n",
            "Var loss:  tensor(-4.6960e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.537285471088272e-08\n",
            "E_s_wdiff_all_sq: 1.9310431748290972e-08\n",
            "E_IS_SCOPE: -6.770100482665371e-07\n",
            "E_IS_E_SCOPE: -6.562132788763958e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002616252157541801\n",
            "Total Loss: -4.696015037201068e-09\n",
            "----------------------------------------\n",
            "Epoch 988\n",
            "Var loss:  tensor(-4.7307e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.595447393246796e-08\n",
            "E_s_wdiff_all_sq: 2.0250797987363095e-08\n",
            "E_IS_SCOPE: -6.75320984993924e-07\n",
            "E_IS_E_SCOPE: -6.546862672530308e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026101641255210826\n",
            "Total Loss: -4.730658756191924e-09\n",
            "----------------------------------------\n",
            "Epoch 989\n",
            "Var loss:  tensor(-4.7182e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6782115987349185e-08\n",
            "E_s_wdiff_all_sq: 2.164800585621697e-08\n",
            "E_IS_SCOPE: -6.736872094528268e-07\n",
            "E_IS_E_SCOPE: -6.533435130328892e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002604810708059752\n",
            "Total Loss: -4.718181928253333e-09\n",
            "----------------------------------------\n",
            "Epoch 990\n",
            "Var loss:  tensor(-4.7302e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6301415597397087e-08\n",
            "E_s_wdiff_all_sq: 2.082612715451138e-08\n",
            "E_IS_SCOPE: -6.741158079977294e-07\n",
            "E_IS_E_SCOPE: -6.535955131133016e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026058154054276693\n",
            "Total Loss: -4.7302005454803085e-09\n",
            "----------------------------------------\n",
            "Epoch 991\n",
            "Var loss:  tensor(-4.7435e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.546194245095392e-08\n",
            "E_s_wdiff_all_sq: 1.9639424494421014e-08\n",
            "E_IS_SCOPE: -6.752594873747723e-07\n",
            "E_IS_E_SCOPE: -6.545589243120891e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026096564228355215\n",
            "Total Loss: -4.743507388344146e-09\n",
            "----------------------------------------\n",
            "Epoch 992\n",
            "Var loss:  tensor(-4.7576e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5089909956484966e-08\n",
            "E_s_wdiff_all_sq: 1.9575175020428302e-08\n",
            "E_IS_SCOPE: -6.758091716399854e-07\n",
            "E_IS_E_SCOPE: -6.552554497224081e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002612433395149538\n",
            "Total Loss: -4.757608118608382e-09\n",
            "----------------------------------------\n",
            "Epoch 993\n",
            "Var loss:  tensor(-4.7641e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4651371249853494e-08\n",
            "E_s_wdiff_all_sq: 1.905195608983997e-08\n",
            "E_IS_SCOPE: -6.766199159080747e-07\n",
            "E_IS_E_SCOPE: -6.560205954249681e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002615483949229431\n",
            "Total Loss: -4.764125025710447e-09\n",
            "----------------------------------------\n",
            "Epoch 994\n",
            "Var loss:  tensor(-4.7779e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.4373137388958314e-08\n",
            "E_s_wdiff_all_sq: 1.8365458300070828e-08\n",
            "E_IS_SCOPE: -6.773297155224801e-07\n",
            "E_IS_E_SCOPE: -6.565193515711407e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002617472436639722\n",
            "Total Loss: -4.777948033301429e-09\n",
            "----------------------------------------\n",
            "Epoch 995\n",
            "Var loss:  tensor(-4.7621e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.5255992990063244e-08\n",
            "E_s_wdiff_all_sq: 1.9470485120276112e-08\n",
            "E_IS_SCOPE: -6.764888420220966e-07\n",
            "E_IS_E_SCOPE: -6.557974651853798e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.002614594352829103\n",
            "Total Loss: -4.7621450231569905e-09\n",
            "----------------------------------------\n",
            "Epoch 996\n",
            "Var loss:  tensor(-4.8008e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.570227391543894e-08\n",
            "E_s_wdiff_all_sq: 2.0099377951356974e-08\n",
            "E_IS_SCOPE: -6.750596617934711e-07\n",
            "E_IS_E_SCOPE: -6.544402406133325e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026091832436224024\n",
            "Total Loss: -4.800845615705498e-09\n",
            "----------------------------------------\n",
            "Epoch 997\n",
            "Var loss:  tensor(-4.7924e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.636537680687223e-08\n",
            "E_s_wdiff_all_sq: 2.105120740915125e-08\n",
            "E_IS_SCOPE: -6.737542273222462e-07\n",
            "E_IS_E_SCOPE: -6.532834013018585e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026045710490173873\n",
            "Total Loss: -4.792381862564924e-09\n",
            "----------------------------------------\n",
            "Epoch 998\n",
            "Var loss:  tensor(-4.7980e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.6281675491590714e-08\n",
            "E_s_wdiff_all_sq: 2.0933794629512204e-08\n",
            "E_IS_SCOPE: -6.737249767920731e-07\n",
            "E_IS_E_SCOPE: -6.532345026518187e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026043760953296372\n",
            "Total Loss: -4.7979666379405085e-09\n",
            "----------------------------------------\n",
            "Epoch 999\n",
            "Var loss:  tensor(-4.8148e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.562170825826564e-08\n",
            "E_s_wdiff_all_sq: 2.0051771988584153e-08\n",
            "E_IS_SCOPE: -6.746892542083622e-07\n",
            "E_IS_E_SCOPE: -6.540793295348265e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026077443297536696\n",
            "Total Loss: -4.814812296900222e-09\n",
            "----------------------------------------\n",
            "Epoch 1000\n",
            "Var loss:  tensor(-4.8278e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.374671514893177e-08\n",
            "E_IS_all_sq: 6.291161436844222e-08\n",
            "E_s_wdiff_sq: 4.502306884790439e-08\n",
            "E_s_wdiff_all_sq: 1.9429938448019326e-08\n",
            "E_IS_SCOPE: -6.756909341723481e-07\n",
            "E_IS_E_SCOPE: -6.550629177868525e-07\n",
            "E_IS: 0.00025082187777074436\n",
            "E_SCOPE: -0.0026116657909147447\n",
            "Total Loss: -4.827801590616627e-09\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.4573,  0.2568],\n",
            "        [-0.0830, -0.4241],\n",
            "        [ 0.1754,  0.2775],\n",
            "        [-0.4887,  0.5079],\n",
            "        [ 0.6727, -0.6158],\n",
            "        [-0.2990,  0.1529],\n",
            "        [-0.0317,  0.4354],\n",
            "        [ 0.2761, -0.4366]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.3072,  0.3239, -0.7056,  0.5402,  0.6997,  0.1661, -0.3479, -0.3437],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.1177,  0.0226,  0.2511,  0.0524, -0.4379, -0.0397, -0.1629, -0.1094],\n",
            "        [ 0.1210,  0.2065, -0.1662, -0.2443, -0.1081,  0.0472, -0.2305, -0.1789],\n",
            "        [ 0.2774,  0.0041, -0.2399, -0.1035, -0.0220, -0.0405, -0.3433,  0.0976],\n",
            "        [ 0.2834, -0.0532, -0.2815, -0.2821,  0.0138, -0.4006, -0.1723,  0.1818],\n",
            "        [-0.0119, -0.0168,  0.0012, -0.0064, -0.0127,  0.1508,  0.0228, -0.2504],\n",
            "        [ 0.0135, -0.3344,  0.2633, -0.2499, -0.0705, -0.0942,  0.2626,  0.0910],\n",
            "        [-0.2540, -0.2092, -0.2452,  0.0642, -0.2258, -0.0479, -0.1195,  0.4236],\n",
            "        [ 0.1239,  0.2618, -0.0755,  0.1644,  0.1064,  0.1432, -0.1347,  0.2933]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0589, -0.0234, -0.1930, -0.0387, -0.3503,  0.1054,  0.2729,  0.0262],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 1.8757e-04, -1.5763e-01,  2.5176e-01, -1.3413e-01,  6.6350e-02,\n",
            "          8.0018e-04,  2.7777e-03,  4.3166e-04]], dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0003], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "# Loop through all combinations from [0,0] to [9,9]\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        # Prepare input data\n",
        "        input_data = torch.tensor([i, j], dtype=torch.float64)\n",
        "\n",
        "        # Pass input through the model\n",
        "        output = model(input_data)\n",
        "\n",
        "        print(f'Input: [{i}, {j}], Output: {output.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrrRKkHjp9UJ",
        "outputId": "3bbad3ff-166b-4d70-e7fa-c59a28581734"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0, 0], Output: 0.06775303778119961\n",
            "Input: [0, 1], Output: 0.028200246904630123\n",
            "Input: [0, 2], Output: 0.01263827581676874\n",
            "Input: [0, 3], Output: 0.011927602790611601\n",
            "Input: [0, 4], Output: 0.011371536162119528\n",
            "Input: [0, 5], Output: 0.01128098303661075\n",
            "Input: [0, 6], Output: 0.010378263149354023\n",
            "Input: [0, 7], Output: 0.008702436212780327\n",
            "Input: [0, 8], Output: 0.007026347318158026\n",
            "Input: [0, 9], Output: 0.0053502584235357205\n",
            "Input: [1, 0], Output: 0.010022568274758292\n",
            "Input: [1, 1], Output: 0.014780578449504199\n",
            "Input: [1, 2], Output: 0.013573993061469235\n",
            "Input: [1, 3], Output: 0.012367407673434272\n",
            "Input: [1, 4], Output: 0.011371536162119528\n",
            "Input: [1, 5], Output: 0.010621668924219924\n",
            "Input: [1, 6], Output: 0.00951645833363329\n",
            "Input: [1, 7], Output: 0.007840369439010987\n",
            "Input: [1, 8], Output: 0.0061642805443886855\n",
            "Input: [1, 9], Output: 0.004488191649766382\n",
            "Input: [2, 0], Output: 0.0021070281609961786\n",
            "Input: [2, 1], Output: 0.009698782624385798\n",
            "Input: [2, 2], Output: 0.013522079291189948\n",
            "Input: [2, 3], Output: 0.011922584991102325\n",
            "Input: [2, 4], Output: 0.010865074699085823\n",
            "Input: [2, 5], Output: 0.009962354811829097\n",
            "Input: [2, 6], Output: 0.00865439155986395\n",
            "Input: [2, 7], Output: 0.006978302665241645\n",
            "Input: [2, 8], Output: 0.005302213770619346\n",
            "Input: [2, 9], Output: 0.00362612487599704\n",
            "Input: [3, 0], Output: -0.03903924025006073\n",
            "Input: [3, 1], Output: 0.002910437984906103\n",
            "Input: [3, 2], Output: 0.005174594239867605\n",
            "Input: [3, 3], Output: 0.009825206007129873\n",
            "Input: [3, 4], Output: 0.010205760586694994\n",
            "Input: [3, 5], Output: 0.009303040699438268\n",
            "Input: [3, 6], Output: 0.00779232478609461\n",
            "Input: [3, 7], Output: 0.006116235891472308\n",
            "Input: [3, 8], Output: 0.004440146996850004\n",
            "Input: [3, 9], Output: 0.002764058102227702\n",
            "Input: [4, 0], Output: -0.10775738312244355\n",
            "Input: [4, 1], Output: -0.04820384035680663\n",
            "Input: [4, 2], Output: -0.015402117715448076\n",
            "Input: [4, 3], Output: -0.004995034912843775\n",
            "Input: [4, 4], Output: 0.0048684559531261\n",
            "Input: [4, 5], Output: 0.008273423765220975\n",
            "Input: [4, 6], Output: 0.00693025801232527\n",
            "Input: [4, 7], Output: 0.005254169117702968\n",
            "Input: [4, 8], Output: 0.003578080223080665\n",
            "Input: [4, 9], Output: 0.0019019913284583616\n",
            "Input: [5, 0], Output: -0.18825060831882773\n",
            "Input: [5, 1], Output: -0.10276275990761918\n",
            "Input: [5, 2], Output: -0.05761945249733198\n",
            "Input: [5, 3], Output: -0.037324910661181626\n",
            "Input: [5, 4], Output: -0.023104231884580204\n",
            "Input: [5, 5], Output: -0.007932266802255242\n",
            "Input: [5, 6], Output: 0.005504327290203423\n",
            "Input: [5, 7], Output: 0.0043222312340672475\n",
            "Input: [5, 8], Output: 0.0027160134493113275\n",
            "Input: [5, 9], Output: 0.0010399245546890215\n",
            "Input: [6, 0], Output: -0.268743833515212\n",
            "Input: [6, 1], Output: -0.1592063192563959\n",
            "Input: [6, 2], Output: -0.11217837204814457\n",
            "Input: [6, 3], Output: -0.06703506463785738\n",
            "Input: [6, 4], Output: -0.056385393938641615\n",
            "Input: [6, 5], Output: -0.041213428856316625\n",
            "Input: [6, 6], Output: -0.026543222212866112\n",
            "Input: [6, 7], Output: -0.009896316969180034\n",
            "Input: [6, 8], Output: 0.0014640642752733555\n",
            "Input: [6, 9], Output: 0.00017785778091967963\n",
            "Input: [7, 0], Output: -0.34923705871159627\n",
            "Input: [7, 1], Output: -0.2396995444527801\n",
            "Input: [7, 2], Output: -0.1667372915989571\n",
            "Input: [7, 3], Output: -0.1215939841886699\n",
            "Input: [7, 4], Output: -0.08683487404241666\n",
            "Input: [7, 5], Output: -0.07449459091037801\n",
            "Input: [7, 6], Output: -0.05960503385852996\n",
            "Input: [7, 7], Output: -0.04546259851565076\n",
            "Input: [7, 8], Output: -0.028449620924258734\n",
            "Input: [7, 9], Output: -0.014500262590237973\n",
            "Input: [8, 0], Output: -0.4297302839079805\n",
            "Input: [8, 1], Output: -0.3201927696491643\n",
            "Input: [8, 2], Output: -0.22129621114976963\n",
            "Input: [8, 3], Output: -0.17615290373948245\n",
            "Input: [8, 4], Output: -0.13100959632919523\n",
            "Input: [8, 5], Output: -0.10777575296443939\n",
            "Input: [8, 6], Output: -0.09266684550419382\n",
            "Input: [8, 7], Output: -0.07852441016131467\n",
            "Input: [8, 8], Output: -0.06433608386127015\n",
            "Input: [8, 9], Output: -0.047002924879337514\n",
            "Input: [9, 0], Output: -0.5102235091043648\n",
            "Input: [9, 1], Output: -0.40068599484554845\n",
            "Input: [9, 2], Output: -0.29114848058673226\n",
            "Input: [9, 3], Output: -0.23071182329029494\n",
            "Input: [9, 4], Output: -0.18556851588000775\n",
            "Input: [9, 5], Output: -0.1404252084697206\n",
            "Input: [9, 6], Output: -0.12588494993617586\n",
            "Input: [9, 7], Output: -0.11158622180697855\n",
            "Input: [9, 8], Output: -0.09744378646409943\n",
            "Input: [9, 9], Output: -0.08288938781634893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary to store data\n",
        "data = {}\n",
        "\n",
        "# Loop through all combinations from [0,0] to [9,9]\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        # Prepare input data\n",
        "        input_data = torch.tensor([i, j], dtype=torch.float64)\n",
        "\n",
        "        # Pass input through the model\n",
        "        output = model(input_data)\n",
        "\n",
        "        # Store data in the dictionary\n",
        "        data[(i, j)] = output.item()\n",
        "\n",
        "# Print the data dictionary\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz53AxNHNESW",
        "outputId": "3214edbf-eea5-4431-a241-fec126635c9c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): -3.368640975410679e-05, (0, 1): 0.0009587350763431133, (0, 2): -0.00656201713019363, (0, 3): 0.00020130020531102265, (0, 4): 0.0003952626126235373, (0, 5): 5.816993607958852e-05, (0, 6): 0.0007493224003926424, (0, 7): 8.903815742228061e-05, (0, 8): 0.0006857653425778212, (0, 9): 0.0008211926104799657, (1, 0): 0.0006255839241807318, (1, 1): -0.0003148176929531077, (1, 2): -0.00014133178663107735, (1, 3): 0.00019126126374143583, (1, 4): -1.9924782108122943e-05, (1, 5): 0.00022886075879583883, (1, 6): 0.00048809215937646095, (1, 7): 0.0003816380003595345, (1, 8): 0.0004968720494240354, (1, 9): 0.00021601796908033176, (2, 0): -0.041717162352524186, (2, 1): 0.014734684319286694, (2, 2): -0.00013645001845232922, (2, 3): 5.350453655626514e-06, (2, 4): 0.0002541530833755753, (2, 5): 0.0007029428249840971, (2, 6): 0.0004846211815045778, (2, 7): -6.0734812536053636e-05, (2, 8): 0.0003742016337027595, (2, 9): 0.0007081982695200609, (3, 0): -0.032470587932310536, (3, 1): -0.00014538120799070973, (3, 2): -0.029499090523334662, (3, 3): 0.05371560515239943, (3, 4): 0.03266616756166363, (3, 5): 0.0005876043626496207, (3, 6): 0.00033797282648581893, (3, 7): 0.00042283108743054325, (3, 8): 0.001575708195595621, (3, 9): 0.0007197139422875367, (4, 0): -0.017270901760626303, (4, 1): -0.007302905665875, (4, 2): -0.03643116588647697, (4, 3): -0.05703203700718681, (4, 4): -0.051950076491311746, (4, 5): 0.0007519979459506996, (4, 6): -0.0013429313194630115, (4, 7): 5.531129693533266e-05, (4, 8): 0.0001788689400448236, (4, 9): 0.04178948771057985, (5, 0): 0.17814459575501335, (5, 1): -0.0035321445219985903, (5, 2): 0.011217531194315669, (5, 3): 0.021699084014259414, (5, 4): -0.04355110551152646, (5, 5): 0.0007117596533409533, (5, 6): 0.00071489203388533, (5, 7): 0.0012460419689238422, (5, 8): 0.0009606723817811693, (5, 9): 0.0008377433590793469, (6, 0): 0.05600042519857522, (6, 1): 0.03277016948803621, (6, 2): -0.01220298204879878, (6, 3): 0.0002677840333543472, (6, 4): -0.07560867923889494, (6, 5): 0.10407915254966173, (6, 6): -0.0003148176929531077, (6, 7): 0.09276209278839419, (6, 8): 0.0018951039094210352, (6, 9): 0.0016949499633284427, (7, 0): -0.03851314860979528, (7, 1): 0.047390614887879184, (7, 2): -0.2348208031237275, (7, 3): -0.03312795576266509, (7, 4): 0.055769129176130805, (7, 5): -0.07688557257686206, (7, 6): 0.0010299402992866215, (7, 7): -0.052894070212567174, (7, 8): 0.0013745870546531139, (7, 9): 0.0019033791079664556, (8, 0): -0.040525364353543425, (8, 1): 0.06316954183140466, (8, 2): 0.05527154160329756, (8, 3): 0.012296931522322042, (8, 4): -0.054052929476531356, (8, 5): 0.0003355466478917485, (8, 6): -0.0003148176929531077, (8, 7): -0.05870967054253013, (8, 8): -0.0003148176929531077, (8, 9): 0.13161954710274895, (9, 0): 0.05765121109244087, (9, 1): 0.03780469109724866, (9, 2): 0.024243464715637795, (9, 3): 0.04816379803206551, (9, 4): -0.04190411388838589, (9, 5): -0.07495194826860611, (9, 6): -0.0723675374168004, (9, 7): -0.0785781861846043, (9, 8): 0.0007444131753352166, (9, 9): 0.11093472114115824}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ADOaZvm_I5GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_good = CustomizableFeatureNet(input_dim=2, hidden_dims=[4, 4], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "41oZaQcKrkpO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_good = SCOPE_variance(model_good, 0.9, 10000, pi_b, P_pi_b, P_pi_b_good_stoch, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "UaqVVzD1pSkZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing_good.prepare()"
      ],
      "metadata": {
        "id": "1njU39SapSk9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_good = train_var(model_good, 1000, 0.0001, padded_state_tensors, states_first_tensor, states_last_tensor, testing_good)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d658ace-72ca-4c69-ba98-26cfe3b74fa4",
        "id": "SEK7Yz9jpSk-"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Total Loss: 1.220620748460072e-06\n",
            "----------------------------------------\n",
            "Epoch 586\n",
            "Var loss:  tensor(1.2206e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5562233679977613e-06\n",
            "E_s_wdiff_all_sq: 3.1776854353241395e-06\n",
            "E_IS_SCOPE: -5.951069556562356e-07\n",
            "E_IS_E_SCOPE: -2.1734634906898502e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.073765939290693e-05\n",
            "Total Loss: 1.2205913885803742e-06\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "Var loss:  tensor(1.2206e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5150039493234197e-06\n",
            "E_s_wdiff_all_sq: 3.1366042444230602e-06\n",
            "E_IS_SCOPE: -6.122355179077019e-07\n",
            "E_IS_E_SCOPE: -2.345400982835786e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.791569834595912e-05\n",
            "Total Loss: 1.2205835347333666e-06\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "Var loss:  tensor(1.2206e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5215972007796607e-06\n",
            "E_s_wdiff_all_sq: 3.1432370960038643e-06\n",
            "E_IS_SCOPE: -5.991624135314315e-07\n",
            "E_IS_E_SCOPE: -2.214711400641352e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.245967534573103e-05\n",
            "Total Loss: 1.2205522269224565e-06\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "Var loss:  tensor(1.2205e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.536747591226775e-06\n",
            "E_s_wdiff_all_sq: 3.1582879018422565e-06\n",
            "E_IS_SCOPE: -5.883761551299721e-07\n",
            "E_IS_E_SCOPE: -2.106310360491271e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.793415343054442e-05\n",
            "Total Loss: 1.2205441203040818e-06\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "Var loss:  tensor(1.2205e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5428671673448716e-06\n",
            "E_s_wdiff_all_sq: 3.1644241795457347e-06\n",
            "E_IS_SCOPE: -5.917394967587322e-07\n",
            "E_IS_E_SCOPE: -2.140018554871244e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.93414016652176e-05\n",
            "Total Loss: 1.2205423743371756e-06\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "Var loss:  tensor(1.2205e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.53504708506725e-06\n",
            "E_s_wdiff_all_sq: 3.15653863412919e-06\n",
            "E_IS_SCOPE: -6.088210634138846e-07\n",
            "E_IS_E_SCOPE: -2.3104524710516955e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.64566693941789e-05\n",
            "Total Loss: 1.2205314874018832e-06\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "Var loss:  tensor(1.2205e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5654719362174374e-06\n",
            "E_s_wdiff_all_sq: 3.186826481047071e-06\n",
            "E_IS_SCOPE: -5.968765170007093e-07\n",
            "E_IS_E_SCOPE: -2.190262055617925e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.143896515178557e-05\n",
            "Total Loss: 1.2205195013737862e-06\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "Var loss:  tensor(1.2205e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5776277932265108e-06\n",
            "E_s_wdiff_all_sq: 3.1988988505119224e-06\n",
            "E_IS_SCOPE: -5.873618125854011e-07\n",
            "E_IS_E_SCOPE: -2.0947178727436716e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.745019075564149e-05\n",
            "Total Loss: 1.220523561173775e-06\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "Var loss:  tensor(1.2205e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.546580309604093e-06\n",
            "E_s_wdiff_all_sq: 3.167956702640163e-06\n",
            "E_IS_SCOPE: -5.972271391503082e-07\n",
            "E_IS_E_SCOPE: -2.193776469580344e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.158568475322062e-05\n",
            "Total Loss: 1.220499291660635e-06\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "Var loss:  tensor(1.2205e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5208574220228334e-06\n",
            "E_s_wdiff_all_sq: 3.142325647570769e-06\n",
            "E_IS_SCOPE: -6.020764627809721e-07\n",
            "E_IS_E_SCOPE: -2.2426606790399891e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.362650060618576e-05\n",
            "Total Loss: 1.220485653779371e-06\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "Var loss:  tensor(1.2205e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5285672410505535e-06\n",
            "E_s_wdiff_all_sq: 3.1500433531739415e-06\n",
            "E_IS_SCOPE: -5.916171144541729e-07\n",
            "E_IS_E_SCOPE: -2.1379417955477344e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.925470120719525e-05\n",
            "Total Loss: 1.220452687159066e-06\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "Var loss:  tensor(1.2205e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5536855851341434e-06\n",
            "E_s_wdiff_all_sq: 3.1751240070530135e-06\n",
            "E_IS_SCOPE: -5.795878572137672e-07\n",
            "E_IS_E_SCOPE: -2.017694576711024e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.423462553880357e-05\n",
            "Total Loss: 1.2204994480770543e-06\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "Var loss:  tensor(1.2204e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.538404688480448e-06\n",
            "E_s_wdiff_all_sq: 3.1598542405294905e-06\n",
            "E_IS_SCOPE: -6.017665591710391e-07\n",
            "E_IS_E_SCOPE: -2.2392102995787174e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.348245431432292e-05\n",
            "Total Loss: 1.2204340586058766e-06\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "Var loss:  tensor(1.2204e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.553161418140009e-06\n",
            "E_s_wdiff_all_sq: 3.174534234718337e-06\n",
            "E_IS_SCOPE: -6.031025982736415e-07\n",
            "E_IS_E_SCOPE: -2.2522115331139687e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.402522924717208e-05\n",
            "Total Loss: 1.2204389625784366e-06\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "Var loss:  tensor(1.2204e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5721644422028172e-06\n",
            "E_s_wdiff_all_sq: 3.193451930249194e-06\n",
            "E_IS_SCOPE: -5.934582783625011e-07\n",
            "E_IS_E_SCOPE: -2.1553190177698397e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.99801647256479e-05\n",
            "Total Loss: 1.2204344278638434e-06\n",
            "----------------------------------------\n",
            "Epoch 601\n",
            "Var loss:  tensor(1.2204e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5602184403821887e-06\n",
            "E_s_wdiff_all_sq: 3.1815359995703532e-06\n",
            "E_IS_SCOPE: -5.937667606628224e-07\n",
            "E_IS_E_SCOPE: -2.1584809978136217e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.011217093115762e-05\n",
            "Total Loss: 1.2204197881301686e-06\n",
            "----------------------------------------\n",
            "Epoch 602\n",
            "Var loss:  tensor(1.2204e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5302420318980093e-06\n",
            "E_s_wdiff_all_sq: 3.151659530710224e-06\n",
            "E_IS_SCOPE: -6.007079928557186e-07\n",
            "E_IS_E_SCOPE: -2.228298648233752e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.302691516798126e-05\n",
            "Total Loss: 1.2204009142043504e-06\n",
            "----------------------------------------\n",
            "Epoch 603\n",
            "Var loss:  tensor(1.2204e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5220171474957493e-06\n",
            "E_s_wdiff_all_sq: 3.143476671518868e-06\n",
            "E_IS_SCOPE: -5.968522276021201e-07\n",
            "E_IS_E_SCOPE: -2.1898040364345755e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.14198437868157e-05\n",
            "Total Loss: 1.2203714971408087e-06\n",
            "----------------------------------------\n",
            "Epoch 604\n",
            "Var loss:  tensor(1.2204e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.546662465509338e-06\n",
            "E_s_wdiff_all_sq: 3.168073315117121e-06\n",
            "E_IS_SCOPE: -5.807081088178141e-07\n",
            "E_IS_E_SCOPE: -2.028265728630245e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.467594952991074e-05\n",
            "Total Loss: 1.2204007475638906e-06\n",
            "----------------------------------------\n",
            "Epoch 605\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5434708959827505e-06\n",
            "E_s_wdiff_all_sq: 3.1648411378505987e-06\n",
            "E_IS_SCOPE: -5.92738801371205e-07\n",
            "E_IS_E_SCOPE: -2.1481058904646804e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.967903140025422e-05\n",
            "Total Loss: 1.2203480025639324e-06\n",
            "----------------------------------------\n",
            "Epoch 606\n",
            "Var loss:  tensor(1.2204e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.552227109346498e-06\n",
            "E_s_wdiff_all_sq: 3.1735381197043715e-06\n",
            "E_IS_SCOPE: -5.99584748006697e-07\n",
            "E_IS_E_SCOPE: -2.2162796385787354e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.252514607501581e-05\n",
            "Total Loss: 1.2203500904257334e-06\n",
            "----------------------------------------\n",
            "Epoch 607\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5698506663225056e-06\n",
            "E_s_wdiff_all_sq: 3.1910879573979234e-06\n",
            "E_IS_SCOPE: -5.953421026778623e-07\n",
            "E_IS_E_SCOPE: -2.1734261131221945e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.073609895583614e-05\n",
            "Total Loss: 1.2203383952745492e-06\n",
            "----------------------------------------\n",
            "Epoch 608\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.574266855867769e-06\n",
            "E_s_wdiff_all_sq: 3.1954829921945184e-06\n",
            "E_IS_SCOPE: -5.895755820865656e-07\n",
            "E_IS_E_SCOPE: -2.1155876616393213e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.832146179586232e-05\n",
            "Total Loss: 1.2203249009092379e-06\n",
            "----------------------------------------\n",
            "Epoch 609\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5509160478446545e-06\n",
            "E_s_wdiff_all_sq: 3.172227127407188e-06\n",
            "E_IS_SCOPE: -5.937615079606262e-07\n",
            "E_IS_E_SCOPE: -2.1577939621229713e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.008348859498954e-05\n",
            "Total Loss: 1.2202993660220631e-06\n",
            "----------------------------------------\n",
            "Epoch 610\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.542692134091948e-06\n",
            "E_s_wdiff_all_sq: 3.1641012527804496e-06\n",
            "E_IS_SCOPE: -5.872683034422956e-07\n",
            "E_IS_E_SCOPE: -2.0934313067149786e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.739647925296473e-05\n",
            "Total Loss: 1.2203152048511564e-06\n",
            "----------------------------------------\n",
            "Epoch 611\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5204327420807e-06\n",
            "E_s_wdiff_all_sq: 3.141872877496929e-06\n",
            "E_IS_SCOPE: -5.984017300757129e-07\n",
            "E_IS_E_SCOPE: -2.2047536570430085e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.204395989855707e-05\n",
            "Total Loss: 1.2202818049222008e-06\n",
            "----------------------------------------\n",
            "Epoch 612\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5430455519501316e-06\n",
            "E_s_wdiff_all_sq: 3.164367570371433e-06\n",
            "E_IS_SCOPE: -5.895476217598181e-07\n",
            "E_IS_E_SCOPE: -2.115603859260281e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.832213801343851e-05\n",
            "Total Loss: 1.2202781789923722e-06\n",
            "----------------------------------------\n",
            "Epoch 613\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5594684718006266e-06\n",
            "E_s_wdiff_all_sq: 3.1807133830496364e-06\n",
            "E_IS_SCOPE: -5.896802586755673e-07\n",
            "E_IS_E_SCOPE: -2.1165231156529966e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.836051508938861e-05\n",
            "Total Loss: 1.2202738636117087e-06\n",
            "----------------------------------------\n",
            "Epoch 614\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5563104525699536e-06\n",
            "E_s_wdiff_all_sq: 3.1775498099067786e-06\n",
            "E_IS_SCOPE: -6.000107504012033e-07\n",
            "E_IS_E_SCOPE: -2.219742523825783e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.266971445787997e-05\n",
            "Total Loss: 1.220262315707179e-06\n",
            "----------------------------------------\n",
            "Epoch 615\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5622746783675886e-06\n",
            "E_s_wdiff_all_sq: 3.1834919581903977e-06\n",
            "E_IS_SCOPE: -5.964348381799758e-07\n",
            "E_IS_E_SCOPE: -2.1837568255878513e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.116738509108072e-05\n",
            "Total Loss: 1.2202390780160626e-06\n",
            "----------------------------------------\n",
            "Epoch 616\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.56680090595654e-06\n",
            "E_s_wdiff_all_sq: 3.1880086913441593e-06\n",
            "E_IS_SCOPE: -5.860586379254745e-07\n",
            "E_IS_E_SCOPE: -2.0798339530878167e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.682881752441427e-05\n",
            "Total Loss: 1.2202163984602478e-06\n",
            "----------------------------------------\n",
            "Epoch 617\n",
            "Var loss:  tensor(1.2203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5692354949610206e-06\n",
            "E_s_wdiff_all_sq: 3.1904909232112496e-06\n",
            "E_IS_SCOPE: -5.743846046734237e-07\n",
            "E_IS_E_SCOPE: -1.9636745872525094e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.197940136554664e-05\n",
            "Total Loss: 1.2202849489346789e-06\n",
            "----------------------------------------\n",
            "Epoch 618\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5115937525424087e-06\n",
            "E_s_wdiff_all_sq: 3.1329323164232217e-06\n",
            "E_IS_SCOPE: -6.085801164475182e-07\n",
            "E_IS_E_SCOPE: -2.3058022543610086e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.626253234978399e-05\n",
            "Total Loss: 1.2202363231776054e-06\n",
            "----------------------------------------\n",
            "Epoch 619\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.546182324393367e-06\n",
            "E_s_wdiff_all_sq: 3.167406944604259e-06\n",
            "E_IS_SCOPE: -5.893759363180078e-07\n",
            "E_IS_E_SCOPE: -2.11302640613627e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.821453461238323e-05\n",
            "Total Loss: 1.2202034574615998e-06\n",
            "----------------------------------------\n",
            "Epoch 620\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.577015784685503e-06\n",
            "E_s_wdiff_all_sq: 3.198079924608576e-06\n",
            "E_IS_SCOPE: -5.769689472171645e-07\n",
            "E_IS_E_SCOPE: -1.9882898249227768e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.300703723850593e-05\n",
            "Total Loss: 1.2202305997084066e-06\n",
            "----------------------------------------\n",
            "Epoch 621\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.555497208115007e-06\n",
            "E_s_wdiff_all_sq: 3.1766447694591633e-06\n",
            "E_IS_SCOPE: -5.967901767432524e-07\n",
            "E_IS_E_SCOPE: -2.186735874618798e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.12917543006132e-05\n",
            "Total Loss: 1.2201939291743508e-06\n",
            "----------------------------------------\n",
            "Epoch 622\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5471047457703325e-06\n",
            "E_s_wdiff_all_sq: 3.1682640122270664e-06\n",
            "E_IS_SCOPE: -6.023684226822157e-07\n",
            "E_IS_E_SCOPE: -2.242560625400993e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.362232357121133e-05\n",
            "Total Loss: 1.220190682340287e-06\n",
            "----------------------------------------\n",
            "Epoch 623\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.570245464289226e-06\n",
            "E_s_wdiff_all_sq: 3.191350585440389e-06\n",
            "E_IS_SCOPE: -5.820605110372326e-07\n",
            "E_IS_E_SCOPE: -2.039029762925488e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.512532596607315e-05\n",
            "Total Loss: 1.2201544784407223e-06\n",
            "----------------------------------------\n",
            "Epoch 624\n",
            "Var loss:  tensor(1.2201e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.561812652169563e-06\n",
            "E_s_wdiff_all_sq: 3.1829723526389347e-06\n",
            "E_IS_SCOPE: -5.810823873407698e-07\n",
            "E_IS_E_SCOPE: -2.0293774292558478e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.472236075933552e-05\n",
            "Total Loss: 1.2201256797815112e-06\n",
            "----------------------------------------\n",
            "Epoch 625\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5668443535292903e-06\n",
            "E_s_wdiff_all_sq: 3.18811097888105e-06\n",
            "E_IS_SCOPE: -5.743355865287588e-07\n",
            "E_IS_E_SCOPE: -1.962901744964813e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.194713677929258e-05\n",
            "Total Loss: 1.2202172196649387e-06\n",
            "----------------------------------------\n",
            "Epoch 626\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5152206376189334e-06\n",
            "E_s_wdiff_all_sq: 3.1365624304428225e-06\n",
            "E_IS_SCOPE: -6.133995981196644e-07\n",
            "E_IS_E_SCOPE: -2.3539140561245724e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.827110175980693e-05\n",
            "Total Loss: 1.2202164912429494e-06\n",
            "----------------------------------------\n",
            "Epoch 627\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5427363012067386e-06\n",
            "E_s_wdiff_all_sq: 3.1640045667943013e-06\n",
            "E_IS_SCOPE: -6.038419302464572e-07\n",
            "E_IS_E_SCOPE: -2.257655720586727e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.425251294928638e-05\n",
            "Total Loss: 1.2201536871181221e-06\n",
            "----------------------------------------\n",
            "Epoch 628\n",
            "Var loss:  tensor(1.2201e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5984988380623875e-06\n",
            "E_s_wdiff_all_sq: 3.2195352802893697e-06\n",
            "E_IS_SCOPE: -5.711438636837396e-07\n",
            "E_IS_E_SCOPE: -1.9294764525962065e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.055169912550052e-05\n",
            "Total Loss: 1.2201457900060333e-06\n",
            "----------------------------------------\n",
            "Epoch 629\n",
            "Var loss:  tensor(1.2202e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5967395824147603e-06\n",
            "E_s_wdiff_all_sq: 3.217650396476885e-06\n",
            "E_IS_SCOPE: -5.66525989032629e-07\n",
            "E_IS_E_SCOPE: -1.882750376633433e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.860098093601231e-05\n",
            "Total Loss: 1.220161952280557e-06\n",
            "----------------------------------------\n",
            "Epoch 630\n",
            "Var loss:  tensor(1.2201e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5235944732517075e-06\n",
            "E_s_wdiff_all_sq: 3.1447833186294007e-06\n",
            "E_IS_SCOPE: -6.043687341855287e-07\n",
            "E_IS_E_SCOPE: -2.2623502957101415e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.444850186760385e-05\n",
            "Total Loss: 1.2201184144745308e-06\n",
            "----------------------------------------\n",
            "Epoch 631\n",
            "Var loss:  tensor(1.2201e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5093563641259753e-06\n",
            "E_s_wdiff_all_sq: 3.130533750485239e-06\n",
            "E_IS_SCOPE: -6.101253455309987e-07\n",
            "E_IS_E_SCOPE: -2.320015053260063e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.685588766081015e-05\n",
            "Total Loss: 1.2201496023120039e-06\n",
            "----------------------------------------\n",
            "Epoch 632\n",
            "Var loss:  tensor(1.2201e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5742735899491356e-06\n",
            "E_s_wdiff_all_sq: 3.1951961489868827e-06\n",
            "E_IS_SCOPE: -5.734347361595894e-07\n",
            "E_IS_E_SCOPE: -1.9517438099111987e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.148131579138093e-05\n",
            "Total Loss: 1.2201313997065674e-06\n",
            "----------------------------------------\n",
            "Epoch 633\n",
            "Var loss:  tensor(1.2201e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.588042216643527e-06\n",
            "E_s_wdiff_all_sq: 3.2088853717444406e-06\n",
            "E_IS_SCOPE: -5.735533295519161e-07\n",
            "E_IS_E_SCOPE: -1.9523926084703155e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.150840180544279e-05\n",
            "Total Loss: 1.2201033765705715e-06\n",
            "----------------------------------------\n",
            "Epoch 634\n",
            "Var loss:  tensor(1.2201e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5521650133868612e-06\n",
            "E_s_wdiff_all_sq: 3.173081341085476e-06\n",
            "E_IS_SCOPE: -6.009104066293362e-07\n",
            "E_IS_E_SCOPE: -2.2263341575014188e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.294490169422633e-05\n",
            "Total Loss: 1.2201043596242504e-06\n",
            "----------------------------------------\n",
            "Epoch 635\n",
            "Var loss:  tensor(1.2200e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5639981770879417e-06\n",
            "E_s_wdiff_all_sq: 3.184918943161435e-06\n",
            "E_IS_SCOPE: -5.888297261767806e-07\n",
            "E_IS_E_SCOPE: -2.1052296034103873e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.788903403088035e-05\n",
            "Total Loss: 1.220040371336276e-06\n",
            "----------------------------------------\n",
            "Epoch 636\n",
            "Var loss:  tensor(1.2200e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5868773813089285e-06\n",
            "E_s_wdiff_all_sq: 3.207726156210453e-06\n",
            "E_IS_SCOPE: -5.651853060626167e-07\n",
            "E_IS_E_SCOPE: -1.8684507789766722e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.800400195422e-05\n",
            "Total Loss: 1.2200454378498304e-06\n",
            "----------------------------------------\n",
            "Epoch 637\n",
            "Var loss:  tensor(1.2200e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5552186269706314e-06\n",
            "E_s_wdiff_all_sq: 3.1762971461484675e-06\n",
            "E_IS_SCOPE: -5.802593572698538e-07\n",
            "E_IS_E_SCOPE: -2.020007892629498e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.433120175127635e-05\n",
            "Total Loss: 1.2199790138896088e-06\n",
            "----------------------------------------\n",
            "Epoch 638\n",
            "Var loss:  tensor(1.2200e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5454098011480277e-06\n",
            "E_s_wdiff_all_sq: 3.1665773749903384e-06\n",
            "E_IS_SCOPE: -5.899883813400173e-07\n",
            "E_IS_E_SCOPE: -2.1177398113362224e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.841130964791802e-05\n",
            "Total Loss: 1.2199782948261527e-06\n",
            "----------------------------------------\n",
            "Epoch 639\n",
            "Var loss:  tensor(1.2200e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5502366142970616e-06\n",
            "E_s_wdiff_all_sq: 3.1713399077809598e-06\n",
            "E_IS_SCOPE: -5.980025780591513e-07\n",
            "E_IS_E_SCOPE: -2.1974559934138452e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.173929735438116e-05\n",
            "Total Loss: 1.2199574181618228e-06\n",
            "----------------------------------------\n",
            "Epoch 640\n",
            "Var loss:  tensor(1.2200e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5923639416035915e-06\n",
            "E_s_wdiff_all_sq: 3.213315166396665e-06\n",
            "E_IS_SCOPE: -5.792428127055042e-07\n",
            "E_IS_E_SCOPE: -2.0090945032418509e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.387559004520431e-05\n",
            "Total Loss: 1.2199567195255412e-06\n",
            "----------------------------------------\n",
            "Epoch 641\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.578932541797613e-06\n",
            "E_s_wdiff_all_sq: 3.1999526104533897e-06\n",
            "E_IS_SCOPE: -5.863711134084219e-07\n",
            "E_IS_E_SCOPE: -2.080564900547384e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.685933308720353e-05\n",
            "Total Loss: 1.2199253537181098e-06\n",
            "----------------------------------------\n",
            "Epoch 642\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5556368597711293e-06\n",
            "E_s_wdiff_all_sq: 3.1768204561454422e-06\n",
            "E_IS_SCOPE: -5.899964518936646e-07\n",
            "E_IS_E_SCOPE: -2.1177295554793523e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.841088148685092e-05\n",
            "Total Loss: 1.2199440800154814e-06\n",
            "----------------------------------------\n",
            "Epoch 643\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.524318268381274e-06\n",
            "E_s_wdiff_all_sq: 3.1455770573083993e-06\n",
            "E_IS_SCOPE: -5.99501448217499e-07\n",
            "E_IS_E_SCOPE: -2.213123810519893e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.23933967023061e-05\n",
            "Total Loss: 1.2199377458231097e-06\n",
            "----------------------------------------\n",
            "Epoch 644\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.529646424444101e-06\n",
            "E_s_wdiff_all_sq: 3.1508252251516116e-06\n",
            "E_IS_SCOPE: -5.938206482496674e-07\n",
            "E_IS_E_SCOPE: -2.1556847900642062e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.999543497150377e-05\n",
            "Total Loss: 1.2198915298872505e-06\n",
            "----------------------------------------\n",
            "Epoch 645\n",
            "Var loss:  tensor(1.2200e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5822934866990786e-06\n",
            "E_s_wdiff_all_sq: 3.2031770557517637e-06\n",
            "E_IS_SCOPE: -5.661793152667555e-07\n",
            "E_IS_E_SCOPE: -1.8781101519666076e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.840726103819552e-05\n",
            "Total Loss: 1.2199544998883783e-06\n",
            "----------------------------------------\n",
            "Epoch 646\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.56493769445362e-06\n",
            "E_s_wdiff_all_sq: 3.1859123394861044e-06\n",
            "E_IS_SCOPE: -5.882841495783714e-07\n",
            "E_IS_E_SCOPE: -2.0992203057619882e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.763815813370209e-05\n",
            "Total Loss: 1.2198757860444248e-06\n",
            "----------------------------------------\n",
            "Epoch 647\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5523636789445826e-06\n",
            "E_s_wdiff_all_sq: 3.173301870875599e-06\n",
            "E_IS_SCOPE: -6.043649907342706e-07\n",
            "E_IS_E_SCOPE: -2.2600359825128065e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.43518840207765e-05\n",
            "Total Loss: 1.2199136921842568e-06\n",
            "----------------------------------------\n",
            "Epoch 648\n",
            "Var loss:  tensor(1.2198e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5950569215538088e-06\n",
            "E_s_wdiff_all_sq: 3.215892718685643e-06\n",
            "E_IS_SCOPE: -5.76259293500982e-07\n",
            "E_IS_E_SCOPE: -1.9781187082323993e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.258241390075478e-05\n",
            "Total Loss: 1.2198440265939348e-06\n",
            "----------------------------------------\n",
            "Epoch 649\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6106240875242745e-06\n",
            "E_s_wdiff_all_sq: 3.2313869202273657e-06\n",
            "E_IS_SCOPE: -5.577375228185977e-07\n",
            "E_IS_E_SCOPE: -1.7930100869251185e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.485450721963562e-05\n",
            "Total Loss: 1.2199388081259903e-06\n",
            "----------------------------------------\n",
            "Epoch 650\n",
            "Var loss:  tensor(1.2198e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5519213334487653e-06\n",
            "E_s_wdiff_all_sq: 3.1728758694594436e-06\n",
            "E_IS_SCOPE: -5.864211324612197e-07\n",
            "E_IS_E_SCOPE: -2.080314929957884e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.684889732589194e-05\n",
            "Total Loss: 1.219840854139713e-06\n",
            "----------------------------------------\n",
            "Epoch 651\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.527381174313586e-06\n",
            "E_s_wdiff_all_sq: 3.1483486699808534e-06\n",
            "E_IS_SCOPE: -5.989928638546263e-07\n",
            "E_IS_E_SCOPE: -2.206336312444627e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.211003252751245e-05\n",
            "Total Loss: 1.2198887081936598e-06\n",
            "----------------------------------------\n",
            "Epoch 652\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5641656759531655e-06\n",
            "E_s_wdiff_all_sq: 3.184982903741109e-06\n",
            "E_IS_SCOPE: -5.796620763771867e-07\n",
            "E_IS_E_SCOPE: -2.0122344442585807e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.400667616637003e-05\n",
            "Total Loss: 1.2198801773906532e-06\n",
            "----------------------------------------\n",
            "Epoch 653\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5846964121301465e-06\n",
            "E_s_wdiff_all_sq: 3.205390501580495e-06\n",
            "E_IS_SCOPE: -5.739209457625286e-07\n",
            "E_IS_E_SCOPE: -1.954267511125625e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.158667516004987e-05\n",
            "Total Loss: 1.2198921903309733e-06\n",
            "----------------------------------------\n",
            "Epoch 654\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5636477000621314e-06\n",
            "E_s_wdiff_all_sq: 3.1843884239483533e-06\n",
            "E_IS_SCOPE: -5.911366434691263e-07\n",
            "E_IS_E_SCOPE: -2.1265823805990372e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.878046884537608e-05\n",
            "Total Loss: 1.2198771343765856e-06\n",
            "----------------------------------------\n",
            "Epoch 655\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5633877601741374e-06\n",
            "E_s_wdiff_all_sq: 3.1841206293166373e-06\n",
            "E_IS_SCOPE: -5.882681929307354e-07\n",
            "E_IS_E_SCOPE: -2.0977513136308235e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.757683071402402e-05\n",
            "Total Loss: 1.2198556768034481e-06\n",
            "----------------------------------------\n",
            "Epoch 656\n",
            "Var loss:  tensor(1.2198e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5806819328944473e-06\n",
            "E_s_wdiff_all_sq: 3.2013563449823257e-06\n",
            "E_IS_SCOPE: -5.706272861571135e-07\n",
            "E_IS_E_SCOPE: -1.9209545751992769e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.01959281581284e-05\n",
            "Total Loss: 1.2198365997190031e-06\n",
            "----------------------------------------\n",
            "Epoch 657\n",
            "Var loss:  tensor(1.2198e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5661260742239216e-06\n",
            "E_s_wdiff_all_sq: 3.1868814192073846e-06\n",
            "E_IS_SCOPE: -5.761816944191698e-07\n",
            "E_IS_E_SCOPE: -1.9766944620647082e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.252295453361602e-05\n",
            "Total Loss: 1.2197948276723923e-06\n",
            "----------------------------------------\n",
            "Epoch 658\n",
            "Var loss:  tensor(1.2198e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.550080269968149e-06\n",
            "E_s_wdiff_all_sq: 3.170910846023112e-06\n",
            "E_IS_SCOPE: -5.890269433824869e-07\n",
            "E_IS_E_SCOPE: -2.105403305746548e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.789628574846467e-05\n",
            "Total Loss: 1.2197708674106268e-06\n",
            "----------------------------------------\n",
            "Epoch 659\n",
            "Var loss:  tensor(1.2197e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5748137848449574e-06\n",
            "E_s_wdiff_all_sq: 3.1956205275659895e-06\n",
            "E_IS_SCOPE: -5.799431706596859e-07\n",
            "E_IS_E_SCOPE: -2.014177463003087e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.40877932285099e-05\n",
            "Total Loss: 1.2197170776414665e-06\n",
            "----------------------------------------\n",
            "Epoch 660\n",
            "Var loss:  tensor(1.2199e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.624213785507277e-06\n",
            "E_s_wdiff_all_sq: 3.2448890924261887e-06\n",
            "E_IS_SCOPE: -5.533341687658574e-07\n",
            "E_IS_E_SCOPE: -1.748181823919067e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.298301884302264e-05\n",
            "Total Loss: 1.2198673894144407e-06\n",
            "----------------------------------------\n",
            "Epoch 661\n",
            "Var loss:  tensor(1.2197e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5572577341008257e-06\n",
            "E_s_wdiff_all_sq: 3.178132752847488e-06\n",
            "E_IS_SCOPE: -5.985300800639945e-07\n",
            "E_IS_E_SCOPE: -2.2004244137929195e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.186322283941699e-05\n",
            "Total Loss: 1.219724372965185e-06\n",
            "----------------------------------------\n",
            "Epoch 662\n",
            "Var loss:  tensor(1.2197e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5627026732515485e-06\n",
            "E_s_wdiff_all_sq: 3.1835691198116602e-06\n",
            "E_IS_SCOPE: -5.90158475934336e-07\n",
            "E_IS_E_SCOPE: -2.1166156934589126e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.836438002360836e-05\n",
            "Total Loss: 1.219714409344252e-06\n",
            "----------------------------------------\n",
            "Epoch 663\n",
            "Var loss:  tensor(1.2197e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.576668924449519e-06\n",
            "E_s_wdiff_all_sq: 3.1974453596347343e-06\n",
            "E_IS_SCOPE: -5.739758979695586e-07\n",
            "E_IS_E_SCOPE: -1.954509238066188e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.159676676586376e-05\n",
            "Total Loss: 1.2197482855701591e-06\n",
            "----------------------------------------\n",
            "Epoch 664\n",
            "Var loss:  tensor(1.2197e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.546674512082311e-06\n",
            "E_s_wdiff_all_sq: 3.1675588495817686e-06\n",
            "E_IS_SCOPE: -5.887538243080154e-07\n",
            "E_IS_E_SCOPE: -2.1026707305073647e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.778220631608377e-05\n",
            "Total Loss: 1.2197168290672378e-06\n",
            "----------------------------------------\n",
            "Epoch 665\n",
            "Var loss:  tensor(1.2197e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5336998846438235e-06\n",
            "E_s_wdiff_all_sq: 3.154583661844317e-06\n",
            "E_IS_SCOPE: -5.976183454960581e-07\n",
            "E_IS_E_SCOPE: -2.1913375269252274e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.148386388120379e-05\n",
            "Total Loss: 1.2197217062736896e-06\n",
            "----------------------------------------\n",
            "Epoch 666\n",
            "Var loss:  tensor(1.2197e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.57090264856663e-06\n",
            "E_s_wdiff_all_sq: 3.1916560911594924e-06\n",
            "E_IS_SCOPE: -5.777363522016898e-07\n",
            "E_IS_E_SCOPE: -1.9916600220079374e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.314773608001405e-05\n",
            "Total Loss: 1.2196805264865995e-06\n",
            "----------------------------------------\n",
            "Epoch 667\n",
            "Var loss:  tensor(1.2197e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.588483321378186e-06\n",
            "E_s_wdiff_all_sq: 3.209159633100291e-06\n",
            "E_IS_SCOPE: -5.710962375954719e-07\n",
            "E_IS_E_SCOPE: -1.924773297244225e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.035535200017357e-05\n",
            "Total Loss: 1.219660541617049e-06\n",
            "----------------------------------------\n",
            "Epoch 668\n",
            "Var loss:  tensor(1.2196e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.568552931739409e-06\n",
            "E_s_wdiff_all_sq: 3.1893110617449107e-06\n",
            "E_IS_SCOPE: -5.865067815961236e-07\n",
            "E_IS_E_SCOPE: -2.079107469886854e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.67984883352993e-05\n",
            "Total Loss: 1.219624469860875e-06\n",
            "----------------------------------------\n",
            "Epoch 669\n",
            "Var loss:  tensor(1.2197e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.59482861897707e-06\n",
            "E_s_wdiff_all_sq: 3.2155962263739488e-06\n",
            "E_IS_SCOPE: -5.690189543670389e-07\n",
            "E_IS_E_SCOPE: -1.9044211422967388e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.950569111953438e-05\n",
            "Total Loss: 1.2196533814096452e-06\n",
            "----------------------------------------\n",
            "Epoch 670\n",
            "Var loss:  tensor(1.2196e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5778447816160894e-06\n",
            "E_s_wdiff_all_sq: 3.1986430731893157e-06\n",
            "E_IS_SCOPE: -5.801804265986009e-07\n",
            "E_IS_E_SCOPE: -2.01596463362131e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.416240394984384e-05\n",
            "Total Loss: 1.2196084510350875e-06\n",
            "----------------------------------------\n",
            "Epoch 671\n",
            "Var loss:  tensor(1.2196e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5725636164524287e-06\n",
            "E_s_wdiff_all_sq: 3.1933123392035284e-06\n",
            "E_IS_SCOPE: -5.833326386280311e-07\n",
            "E_IS_E_SCOPE: -2.047131439184517e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.546355439459396e-05\n",
            "Total Loss: 1.2195869569109935e-06\n",
            "----------------------------------------\n",
            "Epoch 672\n",
            "Var loss:  tensor(1.2196e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.586258411224999e-06\n",
            "E_s_wdiff_all_sq: 3.2069412267582643e-06\n",
            "E_IS_SCOPE: -5.722022398188952e-07\n",
            "E_IS_E_SCOPE: -1.9355661210745972e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.080593034059793e-05\n",
            "Total Loss: 1.2196005981251165e-06\n",
            "----------------------------------------\n",
            "Epoch 673\n",
            "Var loss:  tensor(1.2196e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.563195265540342e-06\n",
            "E_s_wdiff_all_sq: 3.1839738406983692e-06\n",
            "E_IS_SCOPE: -5.83797097698567e-07\n",
            "E_IS_E_SCOPE: -2.0518977297863002e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.566253728758699e-05\n",
            "Total Loss: 1.2195814444833523e-06\n",
            "----------------------------------------\n",
            "Epoch 674\n",
            "Var loss:  tensor(1.2196e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5459519401005472e-06\n",
            "E_s_wdiff_all_sq: 3.166791331822164e-06\n",
            "E_IS_SCOPE: -5.92518129621593e-07\n",
            "E_IS_E_SCOPE: -2.1393900305485145e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.931516205909572e-05\n",
            "Total Loss: 1.2195770242261542e-06\n",
            "----------------------------------------\n",
            "Epoch 675\n",
            "Var loss:  tensor(1.2195e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5642759155229254e-06\n",
            "E_s_wdiff_all_sq: 3.1850778101909746e-06\n",
            "E_IS_SCOPE: -5.807330250244539e-07\n",
            "E_IS_E_SCOPE: -2.0211925581521859e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.438065911605502e-05\n",
            "Total Loss: 1.2195452359947333e-06\n",
            "----------------------------------------\n",
            "Epoch 676\n",
            "Var loss:  tensor(1.2195e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.574236748749679e-06\n",
            "E_s_wdiff_all_sq: 3.1950185922206313e-06\n",
            "E_IS_SCOPE: -5.771473042954983e-07\n",
            "E_IS_E_SCOPE: -1.9851043867541954e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.287405170422112e-05\n",
            "Total Loss: 1.2195190943701432e-06\n",
            "----------------------------------------\n",
            "Epoch 677\n",
            "Var loss:  tensor(1.2196e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.59139280428765e-06\n",
            "E_s_wdiff_all_sq: 3.212200206705861e-06\n",
            "E_IS_SCOPE: -5.694466577662054e-07\n",
            "E_IS_E_SCOPE: -1.9085142517409357e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.967657007480385e-05\n",
            "Total Loss: 1.2195768014788194e-06\n",
            "----------------------------------------\n",
            "Epoch 678\n",
            "Var loss:  tensor(1.2196e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5537224454492285e-06\n",
            "E_s_wdiff_all_sq: 3.1745544893358092e-06\n",
            "E_IS_SCOPE: -5.984533080798017e-07\n",
            "E_IS_E_SCOPE: -2.1986106092518158e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.178750020622763e-05\n",
            "Total Loss: 1.2195581308854329e-06\n",
            "----------------------------------------\n",
            "Epoch 679\n",
            "Var loss:  tensor(1.2195e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5682463602524374e-06\n",
            "E_s_wdiff_all_sq: 3.188982627044434e-06\n",
            "E_IS_SCOPE: -5.904421373988759e-07\n",
            "E_IS_E_SCOPE: -2.1177460424384543e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.841156978370331e-05\n",
            "Total Loss: 1.219503335979195e-06\n",
            "----------------------------------------\n",
            "Epoch 680\n",
            "Var loss:  tensor(1.2195e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6155710320916148e-06\n",
            "E_s_wdiff_all_sq: 3.236061744821983e-06\n",
            "E_IS_SCOPE: -5.553721008985097e-07\n",
            "E_IS_E_SCOPE: -1.765996797610965e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.372675759082004e-05\n",
            "Total Loss: 1.2195391140760595e-06\n",
            "----------------------------------------\n",
            "Epoch 681\n",
            "Var loss:  tensor(1.2195e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5836099507931597e-06\n",
            "E_s_wdiff_all_sq: 3.2043109087182646e-06\n",
            "E_IS_SCOPE: -5.681683343021874e-07\n",
            "E_IS_E_SCOPE: -1.8947237324368878e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.910084407396598e-05\n",
            "Total Loss: 1.2194817890391522e-06\n",
            "----------------------------------------\n",
            "Epoch 682\n",
            "Var loss:  tensor(1.2195e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5324727324924267e-06\n",
            "E_s_wdiff_all_sq: 3.1532559459987934e-06\n",
            "E_IS_SCOPE: -5.978171641490976e-07\n",
            "E_IS_E_SCOPE: -2.1917298389081657e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.150024210482526e-05\n",
            "Total Loss: 1.2195030950583244e-06\n",
            "----------------------------------------\n",
            "Epoch 683\n",
            "Var loss:  tensor(1.2195e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.569586818216576e-06\n",
            "E_s_wdiff_all_sq: 3.190263782856726e-06\n",
            "E_IS_SCOPE: -5.775068630240861e-07\n",
            "E_IS_E_SCOPE: -1.9878877113006083e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.299024981647567e-05\n",
            "Total Loss: 1.2194615206530528e-06\n",
            "----------------------------------------\n",
            "Epoch 684\n",
            "Var loss:  tensor(1.2195e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6031080807676252e-06\n",
            "E_s_wdiff_all_sq: 3.223613912352546e-06\n",
            "E_IS_SCOPE: -5.642466096731407e-07\n",
            "E_IS_E_SCOPE: -1.8545666229310025e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.742436681076053e-05\n",
            "Total Loss: 1.2194889427362523e-06\n",
            "----------------------------------------\n",
            "Epoch 685\n",
            "Var loss:  tensor(1.2194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5774072849818908e-06\n",
            "E_s_wdiff_all_sq: 3.198006511039246e-06\n",
            "E_IS_SCOPE: -5.864417422126102e-07\n",
            "E_IS_E_SCOPE: -2.0767901988447372e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.670174700449649e-05\n",
            "Total Loss: 1.2194499983676255e-06\n",
            "----------------------------------------\n",
            "Epoch 686\n",
            "Var loss:  tensor(1.2194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5709435320320144e-06\n",
            "E_s_wdiff_all_sq: 3.191554632056711e-06\n",
            "E_IS_SCOPE: -5.88522180423886e-07\n",
            "E_IS_E_SCOPE: -2.0975878156380532e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.757000500692428e-05\n",
            "Total Loss: 1.2194367713363964e-06\n",
            "----------------------------------------\n",
            "Epoch 687\n",
            "Var loss:  tensor(1.2194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5931497373392683e-06\n",
            "E_s_wdiff_all_sq: 3.213706323303667e-06\n",
            "E_IS_SCOPE: -5.658122116648819e-07\n",
            "E_IS_E_SCOPE: -1.8700724983279608e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.807170542324924e-05\n",
            "Total Loss: 1.2194081594526825e-06\n",
            "----------------------------------------\n",
            "Epoch 688\n",
            "Var loss:  tensor(1.2194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5859056444363837e-06\n",
            "E_s_wdiff_all_sq: 3.206551329629014e-06\n",
            "E_IS_SCOPE: -5.624231725689302e-07\n",
            "E_IS_E_SCOPE: -1.836701204759832e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.667852210903378e-05\n",
            "Total Loss: 1.2194228797027292e-06\n",
            "----------------------------------------\n",
            "Epoch 689\n",
            "Var loss:  tensor(1.2194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5456009160682665e-06\n",
            "E_s_wdiff_all_sq: 3.166330113420226e-06\n",
            "E_IS_SCOPE: -5.888027745503691e-07\n",
            "E_IS_E_SCOPE: -2.1007174565886448e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.770066112137632e-05\n",
            "Total Loss: 1.2193834139462857e-06\n",
            "----------------------------------------\n",
            "Epoch 690\n",
            "Var loss:  tensor(1.2194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5714599514920496e-06\n",
            "E_s_wdiff_all_sq: 3.1920902676059177e-06\n",
            "E_IS_SCOPE: -5.801898564323204e-07\n",
            "E_IS_E_SCOPE: -2.0140248706542727e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.40814228097603e-05\n",
            "Total Loss: 1.2193696142335984e-06\n",
            "----------------------------------------\n",
            "Epoch 691\n",
            "Var loss:  tensor(1.2194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6056097838601254e-06\n",
            "E_s_wdiff_all_sq: 3.2260867953583343e-06\n",
            "E_IS_SCOPE: -5.679164916230242e-07\n",
            "E_IS_E_SCOPE: -1.890555758659808e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.892683968577945e-05\n",
            "Total Loss: 1.2193758260689573e-06\n",
            "----------------------------------------\n",
            "Epoch 692\n",
            "Var loss:  tensor(1.2193e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.59261427515274e-06\n",
            "E_s_wdiff_all_sq: 3.213136341414813e-06\n",
            "E_IS_SCOPE: -5.792116613714228e-07\n",
            "E_IS_E_SCOPE: -2.0035845270146073e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.364555979702565e-05\n",
            "Total Loss: 1.2193461854792572e-06\n",
            "----------------------------------------\n",
            "Epoch 693\n",
            "Var loss:  tensor(1.2193e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5742941100807725e-06\n",
            "E_s_wdiff_all_sq: 3.1948778957630395e-06\n",
            "E_IS_SCOPE: -5.843895167738697e-07\n",
            "E_IS_E_SCOPE: -2.0555968777889055e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.58169691577068e-05\n",
            "Total Loss: 1.219331225409028e-06\n",
            "----------------------------------------\n",
            "Epoch 694\n",
            "Var loss:  tensor(1.2193e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.585573493879745e-06\n",
            "E_s_wdiff_all_sq: 3.2061668731385296e-06\n",
            "E_IS_SCOPE: -5.65959514828094e-07\n",
            "E_IS_E_SCOPE: -1.87131720791955e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.812366950520807e-05\n",
            "Total Loss: 1.2193257017501907e-06\n",
            "----------------------------------------\n",
            "Epoch 695\n",
            "Var loss:  tensor(1.2193e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.577797772026435e-06\n",
            "E_s_wdiff_all_sq: 3.198368159479838e-06\n",
            "E_IS_SCOPE: -5.649146065626106e-07\n",
            "E_IS_E_SCOPE: -1.8607158406334006e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.768108408427495e-05\n",
            "Total Loss: 1.2193182366293082e-06\n",
            "----------------------------------------\n",
            "Epoch 696\n",
            "Var loss:  tensor(1.2193e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.550691386589422e-06\n",
            "E_s_wdiff_all_sq: 3.1713462821463334e-06\n",
            "E_IS_SCOPE: -5.865826039802506e-07\n",
            "E_IS_E_SCOPE: -2.0777570126682657e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.674210950600225e-05\n",
            "Total Loss: 1.2193059680974939e-06\n",
            "----------------------------------------\n",
            "Epoch 697\n",
            "Var loss:  tensor(1.2193e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.571862992350776e-06\n",
            "E_s_wdiff_all_sq: 3.1924328640892154e-06\n",
            "E_IS_SCOPE: -5.842046564807481e-07\n",
            "E_IS_E_SCOPE: -2.053469720417044e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.572816468415118e-05\n",
            "Total Loss: 1.2192894284647268e-06\n",
            "----------------------------------------\n",
            "Epoch 698\n",
            "Var loss:  tensor(1.2193e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6163427867122315e-06\n",
            "E_s_wdiff_all_sq: 3.236743337273812e-06\n",
            "E_IS_SCOPE: -5.644992994504611e-07\n",
            "E_IS_E_SCOPE: -1.8555163484709085e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.746401591134394e-05\n",
            "Total Loss: 1.2192787893129329e-06\n",
            "----------------------------------------\n",
            "Epoch 699\n",
            "Var loss:  tensor(1.2193e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.610162536211029e-06\n",
            "E_s_wdiff_all_sq: 3.230628017265698e-06\n",
            "E_IS_SCOPE: -5.672048270669363e-07\n",
            "E_IS_E_SCOPE: -1.8828137259079367e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.860362563877236e-05\n",
            "Total Loss: 1.2192622790743e-06\n",
            "----------------------------------------\n",
            "Epoch 700\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5721059090609845e-06\n",
            "E_s_wdiff_all_sq: 3.1926562430757202e-06\n",
            "E_IS_SCOPE: -5.820549320361919e-07\n",
            "E_IS_E_SCOPE: -2.031651353347499e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.481729244353331e-05\n",
            "Total Loss: 1.219244741663634e-06\n",
            "----------------------------------------\n",
            "Epoch 701\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5670956451043484e-06\n",
            "E_s_wdiff_all_sq: 3.18766456380567e-06\n",
            "E_IS_SCOPE: -5.75329278372e-07\n",
            "E_IS_E_SCOPE: -1.964428832967921e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.201088958290881e-05\n",
            "Total Loss: 1.2192329602295165e-06\n",
            "----------------------------------------\n",
            "Epoch 702\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.572844591186869e-06\n",
            "E_s_wdiff_all_sq: 3.1933882093978197e-06\n",
            "E_IS_SCOPE: -5.69758308476852e-07\n",
            "E_IS_E_SCOPE: -1.9085479634577203e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.967797747009173e-05\n",
            "Total Loss: 1.2192240266081424e-06\n",
            "----------------------------------------\n",
            "Epoch 703\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.571255493250457e-06\n",
            "E_s_wdiff_all_sq: 3.1918093489136696e-06\n",
            "E_IS_SCOPE: -5.778629378983654e-07\n",
            "E_IS_E_SCOPE: -1.9895160553128807e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.305822985156388e-05\n",
            "Total Loss: 1.2191981486838861e-06\n",
            "----------------------------------------\n",
            "Epoch 704\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6042879546225413e-06\n",
            "E_s_wdiff_all_sq: 3.2247900391375886e-06\n",
            "E_IS_SCOPE: -5.655777601159425e-07\n",
            "E_IS_E_SCOPE: -1.866569777884058e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.792547400231724e-05\n",
            "Total Loss: 1.2192310199111323e-06\n",
            "----------------------------------------\n",
            "Epoch 705\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.584748457712321e-06\n",
            "E_s_wdiff_all_sq: 3.205218137417471e-06\n",
            "E_IS_SCOPE: -5.836812820793086e-07\n",
            "E_IS_E_SCOPE: -2.0472400591600368e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.546808905661345e-05\n",
            "Total Loss: 1.2191904370494935e-06\n",
            "----------------------------------------\n",
            "Epoch 706\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6054850680099476e-06\n",
            "E_s_wdiff_all_sq: 3.2258608986541912e-06\n",
            "E_IS_SCOPE: -5.663897142004616e-07\n",
            "E_IS_E_SCOPE: -1.8738357477207463e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.822881339542169e-05\n",
            "Total Loss: 1.219186559580236e-06\n",
            "----------------------------------------\n",
            "Epoch 707\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.588095195190695e-06\n",
            "E_s_wdiff_all_sq: 3.208527407747821e-06\n",
            "E_IS_SCOPE: -5.687042922261909e-07\n",
            "E_IS_E_SCOPE: -1.8972033901335897e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.920436471577024e-05\n",
            "Total Loss: 1.2191745500984633e-06\n",
            "----------------------------------------\n",
            "Epoch 708\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5550919501535305e-06\n",
            "E_s_wdiff_all_sq: 3.1756280367260108e-06\n",
            "E_IS_SCOPE: -5.838888219249095e-07\n",
            "E_IS_E_SCOPE: -2.0495278739996866e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.556360065115525e-05\n",
            "Total Loss: 1.2191665134588912e-06\n",
            "----------------------------------------\n",
            "Epoch 709\n",
            "Var loss:  tensor(1.2191e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5708404660425768e-06\n",
            "E_s_wdiff_all_sq: 3.1913399250534327e-06\n",
            "E_IS_SCOPE: -5.748115477677699e-07\n",
            "E_IS_E_SCOPE: -1.9583878058306236e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.175868904440637e-05\n",
            "Total Loss: 1.2191296757009834e-06\n",
            "----------------------------------------\n",
            "Epoch 710\n",
            "Var loss:  tensor(1.2192e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6113140917605784e-06\n",
            "E_s_wdiff_all_sq: 3.2316826507679284e-06\n",
            "E_IS_SCOPE: -5.549535230951003e-07\n",
            "E_IS_E_SCOPE: -1.7593922479312405e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.345103113769606e-05\n",
            "Total Loss: 1.2191775134699523e-06\n",
            "----------------------------------------\n",
            "Epoch 711\n",
            "Var loss:  tensor(1.2191e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.597464454654642e-06\n",
            "E_s_wdiff_all_sq: 3.217827644402305e-06\n",
            "E_IS_SCOPE: -5.704603546445968e-07\n",
            "E_IS_E_SCOPE: -1.9141512848253083e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.991190468713452e-05\n",
            "Total Loss: 1.2191210270094589e-06\n",
            "----------------------------------------\n",
            "Epoch 712\n",
            "Var loss:  tensor(1.2191e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.581450073667833e-06\n",
            "E_s_wdiff_all_sq: 3.201815629448758e-06\n",
            "E_IS_SCOPE: -5.824994135218623e-07\n",
            "E_IS_E_SCOPE: -2.0346638809889322e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.494305931664206e-05\n",
            "Total Loss: 1.21914306245439e-06\n",
            "----------------------------------------\n",
            "Epoch 713\n",
            "Var loss:  tensor(1.2191e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.594005434723827e-06\n",
            "E_s_wdiff_all_sq: 3.214312103022009e-06\n",
            "E_IS_SCOPE: -5.710479787448407e-07\n",
            "E_IS_E_SCOPE: -1.919794519548424e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.014749820521003e-05\n",
            "Total Loss: 1.2191309472030753e-06\n",
            "----------------------------------------\n",
            "Epoch 714\n",
            "Var loss:  tensor(1.2191e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5964757309154343e-06\n",
            "E_s_wdiff_all_sq: 3.216747007194208e-06\n",
            "E_IS_SCOPE: -5.638070563869721e-07\n",
            "E_IS_E_SCOPE: -1.8471988728683205e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.711677830120267e-05\n",
            "Total Loss: 1.2191290546021998e-06\n",
            "----------------------------------------\n",
            "Epoch 715\n",
            "Var loss:  tensor(1.2191e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5726583552127475e-06\n",
            "E_s_wdiff_all_sq: 3.193007874524986e-06\n",
            "E_IS_SCOPE: -5.750021796411103e-07\n",
            "E_IS_E_SCOPE: -1.9594204447234064e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.180179960804388e-05\n",
            "Total Loss: 1.2191048794314747e-06\n",
            "----------------------------------------\n",
            "Epoch 716\n",
            "Var loss:  tensor(1.2191e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.573130167535131e-06\n",
            "E_s_wdiff_all_sq: 3.193484769420094e-06\n",
            "E_IS_SCOPE: -5.744574920734729e-07\n",
            "E_IS_E_SCOPE: -1.9538712864650183e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.157013359013108e-05\n",
            "Total Loss: 1.2190793403423473e-06\n",
            "----------------------------------------\n",
            "Epoch 717\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5963290587450196e-06\n",
            "E_s_wdiff_all_sq: 3.216628842358845e-06\n",
            "E_IS_SCOPE: -5.629207757799015e-07\n",
            "E_IS_E_SCOPE: -1.8380791384509875e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.673604802491398e-05\n",
            "Total Loss: 1.2190491615978232e-06\n",
            "----------------------------------------\n",
            "Epoch 718\n",
            "Var loss:  tensor(1.2191e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.613533557917696e-06\n",
            "E_s_wdiff_all_sq: 3.233852456569998e-06\n",
            "E_IS_SCOPE: -5.561862556536848e-07\n",
            "E_IS_E_SCOPE: -1.770985568345796e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.39350285747429e-05\n",
            "Total Loss: 1.2190803727907403e-06\n",
            "----------------------------------------\n",
            "Epoch 719\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5786362392348685e-06\n",
            "E_s_wdiff_all_sq: 3.1990186749885022e-06\n",
            "E_IS_SCOPE: -5.832101383073728e-07\n",
            "E_IS_E_SCOPE: -2.0413313550508086e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.522141273413864e-05\n",
            "Total Loss: 1.2190382277230358e-06\n",
            "----------------------------------------\n",
            "Epoch 720\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5956993856502917e-06\n",
            "E_s_wdiff_all_sq: 3.216024665553129e-06\n",
            "E_IS_SCOPE: -5.732284352735988e-07\n",
            "E_IS_E_SCOPE: -1.9410934192900551e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.103668374638808e-05\n",
            "Total Loss: 1.2190112024892304e-06\n",
            "----------------------------------------\n",
            "Epoch 721\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.610609469264225e-06\n",
            "E_s_wdiff_all_sq: 3.2308614554540083e-06\n",
            "E_IS_SCOPE: -5.604968623565873e-07\n",
            "E_IS_E_SCOPE: -1.8134696507396707e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.570865220099119e-05\n",
            "Total Loss: 1.2190228883262294e-06\n",
            "----------------------------------------\n",
            "Epoch 722\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5753389458266174e-06\n",
            "E_s_wdiff_all_sq: 3.195735916460395e-06\n",
            "E_IS_SCOPE: -5.77645151767845e-07\n",
            "E_IS_E_SCOPE: -1.9854901939102323e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.289015836461168e-05\n",
            "Total Loss: 1.2189854336938327e-06\n",
            "----------------------------------------\n",
            "Epoch 723\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5748182545206216e-06\n",
            "E_s_wdiff_all_sq: 3.1952791101355286e-06\n",
            "E_IS_SCOPE: -5.731148852933324e-07\n",
            "E_IS_E_SCOPE: -1.9405134080476302e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.101246946223532e-05\n",
            "Total Loss: 1.218986724489208e-06\n",
            "----------------------------------------\n",
            "Epoch 724\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5796820410663894e-06\n",
            "E_s_wdiff_all_sq: 3.2000981450060025e-06\n",
            "E_IS_SCOPE: -5.702724495851415e-07\n",
            "E_IS_E_SCOPE: -1.911757474985053e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.981196801791192e-05\n",
            "Total Loss: 1.2189651609683682e-06\n",
            "----------------------------------------\n",
            "Epoch 725\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.597224564967863e-06\n",
            "E_s_wdiff_all_sq: 3.2175039622966134e-06\n",
            "E_IS_SCOPE: -5.633113186178125e-07\n",
            "E_IS_E_SCOPE: -1.8414700229003292e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.687761052160326e-05\n",
            "Total Loss: 1.2189666390969437e-06\n",
            "----------------------------------------\n",
            "Epoch 726\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.590771613346011e-06\n",
            "E_s_wdiff_all_sq: 3.2110512478827433e-06\n",
            "E_IS_SCOPE: -5.728740678295299e-07\n",
            "E_IS_E_SCOPE: -1.9370380538766605e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.086738052727692e-05\n",
            "Total Loss: 1.218954509660793e-06\n",
            "----------------------------------------\n",
            "Epoch 727\n",
            "Var loss:  tensor(1.2190e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5879320722133234e-06\n",
            "E_s_wdiff_all_sq: 3.208187947248991e-06\n",
            "E_IS_SCOPE: -5.780126440897612e-07\n",
            "E_IS_E_SCOPE: -1.9882923636153894e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.300714322373483e-05\n",
            "Total Loss: 1.2189519785891417e-06\n",
            "----------------------------------------\n",
            "Epoch 728\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.607380622086921e-06\n",
            "E_s_wdiff_all_sq: 3.227562326456274e-06\n",
            "E_IS_SCOPE: -5.643727317738806e-07\n",
            "E_IS_E_SCOPE: -1.8514019893840192e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.729224982691444e-05\n",
            "Total Loss: 1.2189278990409439e-06\n",
            "----------------------------------------\n",
            "Epoch 729\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6023912730479328e-06\n",
            "E_s_wdiff_all_sq: 3.2225939756015824e-06\n",
            "E_IS_SCOPE: -5.626021395070762e-07\n",
            "E_IS_E_SCOPE: -1.8336765441275732e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.655224870835112e-05\n",
            "Total Loss: 1.2189029963389662e-06\n",
            "----------------------------------------\n",
            "Epoch 730\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5974447247635795e-06\n",
            "E_s_wdiff_all_sq: 3.2177501067189395e-06\n",
            "E_IS_SCOPE: -5.599927787201358e-07\n",
            "E_IS_E_SCOPE: -1.808213512680868e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.548921917764174e-05\n",
            "Total Loss: 1.218926432221796e-06\n",
            "----------------------------------------\n",
            "Epoch 731\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5680423659748826e-06\n",
            "E_s_wdiff_all_sq: 3.188400379588243e-06\n",
            "E_IS_SCOPE: -5.787784677344142e-07\n",
            "E_IS_E_SCOPE: -1.996249305706866e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.333932929651598e-05\n",
            "Total Loss: 1.2189095811404374e-06\n",
            "----------------------------------------\n",
            "Epoch 732\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.583872344251166e-06\n",
            "E_s_wdiff_all_sq: 3.2041452225121787e-06\n",
            "E_IS_SCOPE: -5.733072321693006e-07\n",
            "E_IS_E_SCOPE: -1.9408909860397372e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.102823257184761e-05\n",
            "Total Loss: 1.2188655236895876e-06\n",
            "----------------------------------------\n",
            "Epoch 733\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6247312970277515e-06\n",
            "E_s_wdiff_all_sq: 3.244830370270977e-06\n",
            "E_IS_SCOPE: -5.516364175558359e-07\n",
            "E_IS_E_SCOPE: -1.7234731290587775e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.195148132335416e-05\n",
            "Total Loss: 1.218897386538111e-06\n",
            "----------------------------------------\n",
            "Epoch 734\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5994414107287243e-06\n",
            "E_s_wdiff_all_sq: 3.219724518256394e-06\n",
            "E_IS_SCOPE: -5.689385069681178e-07\n",
            "E_IS_E_SCOPE: -1.8971899461932996e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.920380345873502e-05\n",
            "Total Loss: 1.2188525368560078e-06\n",
            "----------------------------------------\n",
            "Epoch 735\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.568539224322157e-06\n",
            "E_s_wdiff_all_sq: 3.1888591444213698e-06\n",
            "E_IS_SCOPE: -5.872137505259875e-07\n",
            "E_IS_E_SCOPE: -2.0802239228215814e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.684509796391899e-05\n",
            "Total Loss: 1.2188720324943802e-06\n",
            "----------------------------------------\n",
            "Epoch 736\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5929935720057197e-06\n",
            "E_s_wdiff_all_sq: 3.213250720660454e-06\n",
            "E_IS_SCOPE: -5.684443430821416e-07\n",
            "E_IS_E_SCOPE: -1.8919159940859987e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.898362673526271e-05\n",
            "Total Loss: 1.2188120330794365e-06\n",
            "----------------------------------------\n",
            "Epoch 737\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6280631954181387e-06\n",
            "E_s_wdiff_all_sq: 3.2480610830540956e-06\n",
            "E_IS_SCOPE: -5.427127032715377e-07\n",
            "E_IS_E_SCOPE: -1.6338394576842195e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.820945870454358e-05\n",
            "Total Loss: 1.2189192664390643e-06\n",
            "----------------------------------------\n",
            "Epoch 738\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5633794903422432e-06\n",
            "E_s_wdiff_all_sq: 3.18364728042508e-06\n",
            "E_IS_SCOPE: -5.836282448565646e-07\n",
            "E_IS_E_SCOPE: -2.043921069478302e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.532952801955906e-05\n",
            "Total Loss: 1.2188346031809486e-06\n",
            "----------------------------------------\n",
            "Epoch 739\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.56368070809243e-06\n",
            "E_s_wdiff_all_sq: 3.1839147073851406e-06\n",
            "E_IS_SCOPE: -5.858416310364569e-07\n",
            "E_IS_E_SCOPE: -2.0658866165531918e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.624654472464648e-05\n",
            "Total Loss: 1.2188347310262669e-06\n",
            "----------------------------------------\n",
            "Epoch 740\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6322212244993395e-06\n",
            "E_s_wdiff_all_sq: 3.252203106255318e-06\n",
            "E_IS_SCOPE: -5.450645141864566e-07\n",
            "E_IS_E_SCOPE: -1.6568279391703387e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.91691808309942e-05\n",
            "Total Loss: 1.2188293467864295e-06\n",
            "----------------------------------------\n",
            "Epoch 741\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6313431536629346e-06\n",
            "E_s_wdiff_all_sq: 3.2514128696383227e-06\n",
            "E_IS_SCOPE: -5.466723704112531e-07\n",
            "E_IS_E_SCOPE: -1.6733967955479614e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.986089672728723e-05\n",
            "Total Loss: 1.2188395713929515e-06\n",
            "----------------------------------------\n",
            "Epoch 742\n",
            "Var loss:  tensor(1.2189e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.559303266891041e-06\n",
            "E_s_wdiff_all_sq: 3.179449584739566e-06\n",
            "E_IS_SCOPE: -5.934589581717091e-07\n",
            "E_IS_E_SCOPE: -2.1417648501189815e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.941430592336015e-05\n",
            "Total Loss: 1.2188634049131054e-06\n",
            "----------------------------------------\n",
            "Epoch 743\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6090996000558916e-06\n",
            "E_s_wdiff_all_sq: 3.2291302331229807e-06\n",
            "E_IS_SCOPE: -5.598505287436884e-07\n",
            "E_IS_E_SCOPE: -1.8046914455589967e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.534218007243832e-05\n",
            "Total Loss: 1.2187812676385875e-06\n",
            "----------------------------------------\n",
            "Epoch 744\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6295625802194164e-06\n",
            "E_s_wdiff_all_sq: 3.24943348593089e-06\n",
            "E_IS_SCOPE: -5.450574773708443e-07\n",
            "E_IS_E_SCOPE: -1.656265540194459e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.914570182298008e-05\n",
            "Total Loss: 1.2188419166669835e-06\n",
            "----------------------------------------\n",
            "Epoch 745\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5706815695029926e-06\n",
            "E_s_wdiff_all_sq: 3.1907539341140115e-06\n",
            "E_IS_SCOPE: -5.81379205593272e-07\n",
            "E_IS_E_SCOPE: -2.0203209380939267e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.434427075972645e-05\n",
            "Total Loss: 1.218808080902477e-06\n",
            "----------------------------------------\n",
            "Epoch 746\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5774627658450826e-06\n",
            "E_s_wdiff_all_sq: 3.197519814162171e-06\n",
            "E_IS_SCOPE: -5.758700333303767e-07\n",
            "E_IS_E_SCOPE: -1.9649834271659717e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.203404275739717e-05\n",
            "Total Loss: 1.2187742395366063e-06\n",
            "----------------------------------------\n",
            "Epoch 747\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6267957737587e-06\n",
            "E_s_wdiff_all_sq: 3.24665811771007e-06\n",
            "E_IS_SCOPE: -5.437413336178775e-07\n",
            "E_IS_E_SCOPE: -1.6427843874549388e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.858289124403905e-05\n",
            "Total Loss: 1.2187865353851167e-06\n",
            "----------------------------------------\n",
            "Epoch 748\n",
            "Var loss:  tensor(1.2187e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.598706534386557e-06\n",
            "E_s_wdiff_all_sq: 3.218745598162885e-06\n",
            "E_IS_SCOPE: -5.625717530664439e-07\n",
            "E_IS_E_SCOPE: -1.831536698958809e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.646291454520157e-05\n",
            "Total Loss: 1.2186994389637996e-06\n",
            "----------------------------------------\n",
            "Epoch 749\n",
            "Var loss:  tensor(1.2187e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5800343700718703e-06\n",
            "E_s_wdiff_all_sq: 3.200182919813294e-06\n",
            "E_IS_SCOPE: -5.769957192332867e-07\n",
            "E_IS_E_SCOPE: -1.9763454367615934e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.250838344042343e-05\n",
            "Total Loss: 1.2187037682255746e-06\n",
            "----------------------------------------\n",
            "Epoch 750\n",
            "Var loss:  tensor(1.2188e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.635778374102433e-06\n",
            "E_s_wdiff_all_sq: 3.2558454309197974e-06\n",
            "E_IS_SCOPE: -5.445285468209808e-07\n",
            "E_IS_E_SCOPE: -1.6516880331478252e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.895460025764656e-05\n",
            "Total Loss: 1.2187881252514927e-06\n",
            "----------------------------------------\n",
            "Epoch 751\n",
            "Var loss:  tensor(1.2187e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.592058205283133e-06\n",
            "E_s_wdiff_all_sq: 3.2121882084669874e-06\n",
            "E_IS_SCOPE: -5.773545218033774e-07\n",
            "E_IS_E_SCOPE: -1.9797350676017634e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.264989360149147e-05\n",
            "Total Loss: 1.2186826358109969e-06\n",
            "----------------------------------------\n",
            "Epoch 752\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.60073719804635e-06\n",
            "E_s_wdiff_all_sq: 3.2207866419208513e-06\n",
            "E_IS_SCOPE: -5.703505734127753e-07\n",
            "E_IS_E_SCOPE: -1.909114215540572e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.970161733744832e-05\n",
            "Total Loss: 1.2186469214893152e-06\n",
            "----------------------------------------\n",
            "Epoch 753\n",
            "Var loss:  tensor(1.2187e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.625502658033518e-06\n",
            "E_s_wdiff_all_sq: 3.245407986628733e-06\n",
            "E_IS_SCOPE: -5.465155352459435e-07\n",
            "E_IS_E_SCOPE: -1.670311271071719e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.973208238548989e-05\n",
            "Total Loss: 1.2187005242084947e-06\n",
            "----------------------------------------\n",
            "Epoch 754\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.572219218760804e-06\n",
            "E_s_wdiff_all_sq: 3.19236394885631e-06\n",
            "E_IS_SCOPE: -5.731529614936422e-07\n",
            "E_IS_E_SCOPE: -1.9375582512873888e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.088909770618236e-05\n",
            "Total Loss: 1.2186356662559412e-06\n",
            "----------------------------------------\n",
            "Epoch 755\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.556981835155085e-06\n",
            "E_s_wdiff_all_sq: 3.177156958683302e-06\n",
            "E_IS_SCOPE: -5.826821617592965e-07\n",
            "E_IS_E_SCOPE: -2.0330421954605025e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.487535725964806e-05\n",
            "Total Loss: 1.2186436611265446e-06\n",
            "----------------------------------------\n",
            "Epoch 756\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.614021568462927e-06\n",
            "E_s_wdiff_all_sq: 3.2340203780072496e-06\n",
            "E_IS_SCOPE: -5.534050716781716e-07\n",
            "E_IS_E_SCOPE: -1.739190496393448e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.260764929207116e-05\n",
            "Total Loss: 1.2186038154592778e-06\n",
            "----------------------------------------\n",
            "Epoch 757\n",
            "Var loss:  tensor(1.2187e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.643258999411536e-06\n",
            "E_s_wdiff_all_sq: 3.263186231266194e-06\n",
            "E_IS_SCOPE: -5.432403895444601e-07\n",
            "E_IS_E_SCOPE: -1.6375118256915208e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.836277256458278e-05\n",
            "Total Loss: 1.2186690232759788e-06\n",
            "----------------------------------------\n",
            "Epoch 758\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5861269695565703e-06\n",
            "E_s_wdiff_all_sq: 3.2061150652356204e-06\n",
            "E_IS_SCOPE: -5.845478187493744e-07\n",
            "E_IS_E_SCOPE: -2.0507119137239248e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.561303189012743e-05\n",
            "Total Loss: 1.218633318648239e-06\n",
            "----------------------------------------\n",
            "Epoch 759\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6171472470819268e-06\n",
            "E_s_wdiff_all_sq: 3.237032795370308e-06\n",
            "E_IS_SCOPE: -5.604239833680487e-07\n",
            "E_IS_E_SCOPE: -1.8087512659416827e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.551166927741394e-05\n",
            "Total Loss: 1.2185914072451118e-06\n",
            "----------------------------------------\n",
            "Epoch 760\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6265676359688458e-06\n",
            "E_s_wdiff_all_sq: 3.2463446095064784e-06\n",
            "E_IS_SCOPE: -5.456713765468732e-07\n",
            "E_IS_E_SCOPE: -1.660902049125384e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.933926659641592e-05\n",
            "Total Loss: 1.2186353522749511e-06\n",
            "----------------------------------------\n",
            "Epoch 761\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.574101173105788e-06\n",
            "E_s_wdiff_all_sq: 3.1940541063161553e-06\n",
            "E_IS_SCOPE: -5.727151973354967e-07\n",
            "E_IS_E_SCOPE: -1.9320753420370867e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.066019744898124e-05\n",
            "Total Loss: 1.2186064096073098e-06\n",
            "----------------------------------------\n",
            "Epoch 762\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5774758838195018e-06\n",
            "E_s_wdiff_all_sq: 3.197410540477908e-06\n",
            "E_IS_SCOPE: -5.704486947575556e-07\n",
            "E_IS_E_SCOPE: -1.9092232195870068e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.970616803364369e-05\n",
            "Total Loss: 1.2185872668251366e-06\n",
            "----------------------------------------\n",
            "Epoch 763\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6253984842594606e-06\n",
            "E_s_wdiff_all_sq: 3.245159768441664e-06\n",
            "E_IS_SCOPE: -5.452868093834516e-07\n",
            "E_IS_E_SCOPE: -1.6567079681844673e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.916417228748764e-05\n",
            "Total Loss: 1.2185813597690406e-06\n",
            "----------------------------------------\n",
            "Epoch 764\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6144118226612993e-06\n",
            "E_s_wdiff_all_sq: 3.234266429740424e-06\n",
            "E_IS_SCOPE: -5.589077132187343e-07\n",
            "E_IS_E_SCOPE: -1.7930766692826728e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.485728689700643e-05\n",
            "Total Loss: 1.2185199694211954e-06\n",
            "----------------------------------------\n",
            "Epoch 765\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5940335437279995e-06\n",
            "E_s_wdiff_all_sq: 3.213975091629738e-06\n",
            "E_IS_SCOPE: -5.752389058907274e-07\n",
            "E_IS_E_SCOPE: -1.9567780757577036e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.169148610324963e-05\n",
            "Total Loss: 1.2185109245496004e-06\n",
            "----------------------------------------\n",
            "Epoch 766\n",
            "Var loss:  tensor(1.2186e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6457478780820562e-06\n",
            "E_s_wdiff_all_sq: 3.2656058818177906e-06\n",
            "E_IS_SCOPE: -5.401824979998651e-07\n",
            "E_IS_E_SCOPE: -1.6061427327777934e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.70531770363106e-05\n",
            "Total Loss: 1.2185802159013472e-06\n",
            "----------------------------------------\n",
            "Epoch 767\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.601796340012048e-06\n",
            "E_s_wdiff_all_sq: 3.221764368225192e-06\n",
            "E_IS_SCOPE: -5.661496388486986e-07\n",
            "E_IS_E_SCOPE: -1.8657805656285478e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.7892526003358e-05\n",
            "Total Loss: 1.218463476296423e-06\n",
            "----------------------------------------\n",
            "Epoch 768\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5919585697217136e-06\n",
            "E_s_wdiff_all_sq: 3.2119275287048115e-06\n",
            "E_IS_SCOPE: -5.693792376654157e-07\n",
            "E_IS_E_SCOPE: -1.8981547664409994e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.924408273252367e-05\n",
            "Total Loss: 1.2184781880555234e-06\n",
            "----------------------------------------\n",
            "Epoch 769\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6018906216415973e-06\n",
            "E_s_wdiff_all_sq: 3.2217994615251836e-06\n",
            "E_IS_SCOPE: -5.610499994540617e-07\n",
            "E_IS_E_SCOPE: -1.8145689984083694e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.575454771970777e-05\n",
            "Total Loss: 1.2184796299712177e-06\n",
            "----------------------------------------\n",
            "Epoch 770\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.599022378771265e-06\n",
            "E_s_wdiff_all_sq: 3.218922646326622e-06\n",
            "E_IS_SCOPE: -5.621591869721575e-07\n",
            "E_IS_E_SCOPE: -1.8255607806361586e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.621343216666463e-05\n",
            "Total Loss: 1.218468183708813e-06\n",
            "----------------------------------------\n",
            "Epoch 771\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5915513448347312e-06\n",
            "E_s_wdiff_all_sq: 3.211466157941529e-06\n",
            "E_IS_SCOPE: -5.671373911967608e-07\n",
            "E_IS_E_SCOPE: -1.8753274116368076e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.829108731579075e-05\n",
            "Total Loss: 1.2184505559082956e-06\n",
            "----------------------------------------\n",
            "Epoch 772\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.603334419939917e-06\n",
            "E_s_wdiff_all_sq: 3.2232168176094595e-06\n",
            "E_IS_SCOPE: -5.60779464782352e-07\n",
            "E_IS_E_SCOPE: -1.8114348081883926e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.562370168255508e-05\n",
            "Total Loss: 1.218420303484686e-06\n",
            "----------------------------------------\n",
            "Epoch 773\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.613374362613841e-06\n",
            "E_s_wdiff_all_sq: 3.2332382730344785e-06\n",
            "E_IS_SCOPE: -5.56771615659353e-07\n",
            "E_IS_E_SCOPE: -1.7711088328522652e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.39401746160043e-05\n",
            "Total Loss: 1.218389293912363e-06\n",
            "----------------------------------------\n",
            "Epoch 774\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6380951195848734e-06\n",
            "E_s_wdiff_all_sq: 3.2579533248469276e-06\n",
            "E_IS_SCOPE: -5.43221111216968e-07\n",
            "E_IS_E_SCOPE: -1.6359653739195266e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.829821136318424e-05\n",
            "Total Loss: 1.2184673161691685e-06\n",
            "----------------------------------------\n",
            "Epoch 775\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5870316695449633e-06\n",
            "E_s_wdiff_all_sq: 3.206941689609189e-06\n",
            "E_IS_SCOPE: -5.80042412000125e-07\n",
            "E_IS_E_SCOPE: -2.0042936549361028e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.367516443868734e-05\n",
            "Total Loss: 1.2184385560039977e-06\n",
            "----------------------------------------\n",
            "Epoch 776\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6088805644178482e-06\n",
            "E_s_wdiff_all_sq: 3.2287300842209477e-06\n",
            "E_IS_SCOPE: -5.662967030279137e-07\n",
            "E_IS_E_SCOPE: -1.8661344834367471e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.790730134864032e-05\n",
            "Total Loss: 1.2183586399096762e-06\n",
            "----------------------------------------\n",
            "Epoch 777\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6504181718404026e-06\n",
            "E_s_wdiff_all_sq: 3.2700550050284696e-06\n",
            "E_IS_SCOPE: -5.339069553474114e-07\n",
            "E_IS_E_SCOPE: -1.541549014600763e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.43565212958415e-05\n",
            "Total Loss: 1.2184337281185169e-06\n",
            "----------------------------------------\n",
            "Epoch 778\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.60618999855291e-06\n",
            "E_s_wdiff_all_sq: 3.226184561138322e-06\n",
            "E_IS_SCOPE: -5.539978915125429e-07\n",
            "E_IS_E_SCOPE: -1.7439767440511826e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.280746535136912e-05\n",
            "Total Loss: 1.218379672280993e-06\n",
            "----------------------------------------\n",
            "Epoch 779\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5404173402604574e-06\n",
            "E_s_wdiff_all_sq: 3.160469098926468e-06\n",
            "E_IS_SCOPE: -5.959456016817416e-07\n",
            "E_IS_E_SCOPE: -2.1643222263252543e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.035603028531518e-05\n",
            "Total Loss: 1.2184961523168118e-06\n",
            "----------------------------------------\n",
            "Epoch 780\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.612235332641672e-06\n",
            "E_s_wdiff_all_sq: 3.2322606831255703e-06\n",
            "E_IS_SCOPE: -5.564250825274923e-07\n",
            "E_IS_E_SCOPE: -1.768398840443624e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.382703797065186e-05\n",
            "Total Loss: 1.2183789216310947e-06\n",
            "----------------------------------------\n",
            "Epoch 781\n",
            "Var loss:  tensor(1.2183e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6384867871150262e-06\n",
            "E_s_wdiff_all_sq: 3.2583057051856396e-06\n",
            "E_IS_SCOPE: -5.483629285850822e-07\n",
            "E_IS_E_SCOPE: -1.6865867609056944e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.041155082806274e-05\n",
            "Total Loss: 1.218347246021615e-06\n",
            "----------------------------------------\n",
            "Epoch 782\n",
            "Var loss:  tensor(1.2183e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6290769378282443e-06\n",
            "E_s_wdiff_all_sq: 3.2487997743007847e-06\n",
            "E_IS_SCOPE: -5.54125073886591e-07\n",
            "E_IS_E_SCOPE: -1.7436156667222424e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.279239111072591e-05\n",
            "Total Loss: 1.2183248181799804e-06\n",
            "----------------------------------------\n",
            "Epoch 783\n",
            "Var loss:  tensor(1.2183e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5959627464729757e-06\n",
            "E_s_wdiff_all_sq: 3.2157291752582185e-06\n",
            "E_IS_SCOPE: -5.67377007073567e-07\n",
            "E_IS_E_SCOPE: -1.8764745315411464e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.833897722772559e-05\n",
            "Total Loss: 1.2183491324571058e-06\n",
            "----------------------------------------\n",
            "Epoch 784\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.592295781575414e-06\n",
            "E_s_wdiff_all_sq: 3.2120087950639664e-06\n",
            "E_IS_SCOPE: -5.633985100866103e-07\n",
            "E_IS_E_SCOPE: -1.83647858999186e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.6669228397371e-05\n",
            "Total Loss: 1.2183603534178516e-06\n",
            "----------------------------------------\n",
            "Epoch 785\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6167762808102825e-06\n",
            "E_s_wdiff_all_sq: 3.2363299844217696e-06\n",
            "E_IS_SCOPE: -5.486574032143502e-07\n",
            "E_IS_E_SCOPE: -1.6883066600101002e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.048335310116014e-05\n",
            "Total Loss: 1.2183674910430864e-06\n",
            "----------------------------------------\n",
            "Epoch 786\n",
            "Var loss:  tensor(1.2184e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6195754243427322e-06\n",
            "E_s_wdiff_all_sq: 3.2390658002673465e-06\n",
            "E_IS_SCOPE: -5.52684012383067e-07\n",
            "E_IS_E_SCOPE: -1.7281771442833035e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.214786434660273e-05\n",
            "Total Loss: 1.2183516972471668e-06\n",
            "----------------------------------------\n",
            "Epoch 787\n",
            "Var loss:  tensor(1.2183e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6205858940116657e-06\n",
            "E_s_wdiff_all_sq: 3.2400366335560154e-06\n",
            "E_IS_SCOPE: -5.559603867096866e-07\n",
            "E_IS_E_SCOPE: -1.7606890509059082e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.350517001194867e-05\n",
            "Total Loss: 1.218340966298712e-06\n",
            "----------------------------------------\n",
            "Epoch 788\n",
            "Var loss:  tensor(1.2183e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.634632570699821e-06\n",
            "E_s_wdiff_all_sq: 3.2540537870241367e-06\n",
            "E_IS_SCOPE: -5.452769777006712e-07\n",
            "E_IS_E_SCOPE: -1.6535641529893935e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.90329244272927e-05\n",
            "Total Loss: 1.2183123279534743e-06\n",
            "----------------------------------------\n",
            "Epoch 789\n",
            "Var loss:  tensor(1.2183e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.624439375076003e-06\n",
            "E_s_wdiff_all_sq: 3.24394939902407e-06\n",
            "E_IS_SCOPE: -5.472365045382043e-07\n",
            "E_IS_E_SCOPE: -1.6734351684390937e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.986249871707927e-05\n",
            "Total Loss: 1.2182786697445973e-06\n",
            "----------------------------------------\n",
            "Epoch 790\n",
            "Var loss:  tensor(1.2182e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.60339195793286e-06\n",
            "E_s_wdiff_all_sq: 3.223048492777745e-06\n",
            "E_IS_SCOPE: -5.591207216889467e-07\n",
            "E_IS_E_SCOPE: -1.7928190811669548e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.48465331195412e-05\n",
            "Total Loss: 1.2182405070918664e-06\n",
            "----------------------------------------\n",
            "Epoch 791\n",
            "Var loss:  tensor(1.2182e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6129719289582613e-06\n",
            "E_s_wdiff_all_sq: 3.2326878263381865e-06\n",
            "E_IS_SCOPE: -5.567832007242458e-07\n",
            "E_IS_E_SCOPE: -1.7694875566668557e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.387248964824492e-05\n",
            "Total Loss: 1.2181898815862074e-06\n",
            "----------------------------------------\n",
            "Epoch 792\n",
            "Var loss:  tensor(1.2183e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6508239410572926e-06\n",
            "E_s_wdiff_all_sq: 3.270508834622843e-06\n",
            "E_IS_SCOPE: -5.376708754521219e-07\n",
            "E_IS_E_SCOPE: -1.5786372619582957e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.590487983539054e-05\n",
            "Total Loss: 1.218275477003119e-06\n",
            "----------------------------------------\n",
            "Epoch 793\n",
            "Var loss:  tensor(1.2182e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5956236306986572e-06\n",
            "E_s_wdiff_all_sq: 3.215452313639131e-06\n",
            "E_IS_SCOPE: -5.76496269236896e-07\n",
            "E_IS_E_SCOPE: -1.9671844970392063e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.212593292684932e-05\n",
            "Total Loss: 1.2181903470748293e-06\n",
            "----------------------------------------\n",
            "Epoch 794\n",
            "Var loss:  tensor(1.2182e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6062275885871167e-06\n",
            "E_s_wdiff_all_sq: 3.2260400627599537e-06\n",
            "E_IS_SCOPE: -5.657964826501658e-07\n",
            "E_IS_E_SCOPE: -1.859963851852092e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.764969008929967e-05\n",
            "Total Loss: 1.2181619999785021e-06\n",
            "----------------------------------------\n",
            "Epoch 795\n",
            "Var loss:  tensor(1.2182e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6186399447211054e-06\n",
            "E_s_wdiff_all_sq: 3.2383819755700406e-06\n",
            "E_IS_SCOPE: -5.498134302430588e-07\n",
            "E_IS_E_SCOPE: -1.69989287099976e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.096705373424527e-05\n",
            "Total Loss: 1.2181843519461525e-06\n",
            "----------------------------------------\n",
            "Epoch 796\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.578012223554538e-06\n",
            "E_s_wdiff_all_sq: 3.197915719623842e-06\n",
            "E_IS_SCOPE: -5.705876033317691e-07\n",
            "E_IS_E_SCOPE: -1.908212404865455e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.966396858455868e-05\n",
            "Total Loss: 1.2181384473215016e-06\n",
            "----------------------------------------\n",
            "Epoch 797\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5899544245104714e-06\n",
            "E_s_wdiff_all_sq: 3.209847467829322e-06\n",
            "E_IS_SCOPE: -5.647684680664548e-07\n",
            "E_IS_E_SCOPE: -1.8499048681195187e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.722974807339982e-05\n",
            "Total Loss: 1.2181256632533974e-06\n",
            "----------------------------------------\n",
            "Epoch 798\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6258026421361315e-06\n",
            "E_s_wdiff_all_sq: 3.2455241305149966e-06\n",
            "E_IS_SCOPE: -5.502542857235972e-07\n",
            "E_IS_E_SCOPE: -1.703858990106573e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.113263110242617e-05\n",
            "Total Loss: 1.2181164072765081e-06\n",
            "----------------------------------------\n",
            "Epoch 799\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.644713100293697e-06\n",
            "E_s_wdiff_all_sq: 3.2642542198267608e-06\n",
            "E_IS_SCOPE: -5.456911913640937e-07\n",
            "E_IS_E_SCOPE: -1.6573423903469303e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.91906581163665e-05\n",
            "Total Loss: 1.2181196448893875e-06\n",
            "----------------------------------------\n",
            "Epoch 800\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.618805293044866e-06\n",
            "E_s_wdiff_all_sq: 3.2383796325615007e-06\n",
            "E_IS_SCOPE: -5.630882101248853e-07\n",
            "E_IS_E_SCOPE: -1.8314860147420232e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.646079858272094e-05\n",
            "Total Loss: 1.2181211122632542e-06\n",
            "----------------------------------------\n",
            "Epoch 801\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.618218800704069e-06\n",
            "E_s_wdiff_all_sq: 3.2377690366535817e-06\n",
            "E_IS_SCOPE: -5.579164205993908e-07\n",
            "E_IS_E_SCOPE: -1.7795963605124048e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.429451155205708e-05\n",
            "Total Loss: 1.2181108640354393e-06\n",
            "----------------------------------------\n",
            "Epoch 802\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6314876285616962e-06\n",
            "E_s_wdiff_all_sq: 3.2509740933378923e-06\n",
            "E_IS_SCOPE: -5.420467727422103e-07\n",
            "E_IS_E_SCOPE: -1.620577756929467e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.765580979752953e-05\n",
            "Total Loss: 1.2181102102065302e-06\n",
            "----------------------------------------\n",
            "Epoch 803\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6060893879295964e-06\n",
            "E_s_wdiff_all_sq: 3.225693523181775e-06\n",
            "E_IS_SCOPE: -5.544362885875554e-07\n",
            "E_IS_E_SCOPE: -1.744879074091552e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.284513578669674e-05\n",
            "Total Loss: 1.2180737714722739e-06\n",
            "----------------------------------------\n",
            "Epoch 804\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5968475036179623e-06\n",
            "E_s_wdiff_all_sq: 3.216512059715004e-06\n",
            "E_IS_SCOPE: -5.624630833076801e-07\n",
            "E_IS_E_SCOPE: -1.8253515526585243e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.620469732614334e-05\n",
            "Total Loss: 1.2180542569005569e-06\n",
            "----------------------------------------\n",
            "Epoch 805\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.628498293524056e-06\n",
            "E_s_wdiff_all_sq: 3.2481206260673005e-06\n",
            "E_IS_SCOPE: -5.48149423501752e-07\n",
            "E_IS_E_SCOPE: -1.6818434402998756e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.021352688546339e-05\n",
            "Total Loss: 1.2180221775944802e-06\n",
            "----------------------------------------\n",
            "Epoch 806\n",
            "Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6483517594209784e-06\n",
            "E_s_wdiff_all_sq: 3.267874104810393e-06\n",
            "E_IS_SCOPE: -5.405739365791962e-07\n",
            "E_IS_E_SCOPE: -1.605738538557193e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.70363027535474e-05\n",
            "Total Loss: 1.218052158244885e-06\n",
            "----------------------------------------\n",
            "Epoch 807\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5966941322232284e-06\n",
            "E_s_wdiff_all_sq: 3.216416695255426e-06\n",
            "E_IS_SCOPE: -5.754151894398175e-07\n",
            "E_IS_E_SCOPE: -1.955052306108662e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.16194387469098e-05\n",
            "Total Loss: 1.218032188391153e-06\n",
            "----------------------------------------\n",
            "Epoch 808\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6166321548344628e-06\n",
            "E_s_wdiff_all_sq: 3.2363921250282174e-06\n",
            "E_IS_SCOPE: -5.60085603461913e-07\n",
            "E_IS_E_SCOPE: -1.8018364818109256e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.5222991169905e-05\n",
            "Total Loss: 1.2180107883258576e-06\n",
            "----------------------------------------\n",
            "Epoch 809\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6231731250602856e-06\n",
            "E_s_wdiff_all_sq: 3.2428501149301675e-06\n",
            "E_IS_SCOPE: -5.518264173872679e-07\n",
            "E_IS_E_SCOPE: -1.71870260023811e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.175232149338324e-05\n",
            "Total Loss: 1.217985364484457e-06\n",
            "----------------------------------------\n",
            "Epoch 810\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6260516194834125e-06\n",
            "E_s_wdiff_all_sq: 3.2456106164078793e-06\n",
            "E_IS_SCOPE: -5.443258165569254e-07\n",
            "E_IS_E_SCOPE: -1.6432103590950065e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.860067468956416e-05\n",
            "Total Loss: 1.2180061108619364e-06\n",
            "----------------------------------------\n",
            "Epoch 811\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.588475263117347e-06\n",
            "E_s_wdiff_all_sq: 3.208122812002582e-06\n",
            "E_IS_SCOPE: -5.656013524859085e-07\n",
            "E_IS_E_SCOPE: -1.8563859775372732e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.750032114782939e-05\n",
            "Total Loss: 1.2180016107316562e-06\n",
            "----------------------------------------\n",
            "Epoch 812\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.600430896872952e-06\n",
            "E_s_wdiff_all_sq: 3.220001531491798e-06\n",
            "E_IS_SCOPE: -5.611773448753182e-07\n",
            "E_IS_E_SCOPE: -1.8117146900039467e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.563538617643262e-05\n",
            "Total Loss: 1.217992282712559e-06\n",
            "----------------------------------------\n",
            "Epoch 813\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6443485779319322e-06\n",
            "E_s_wdiff_all_sq: 3.26372180384232e-06\n",
            "E_IS_SCOPE: -5.40275453016259e-07\n",
            "E_IS_E_SCOPE: -1.60171794037759e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.686845099540225e-05\n",
            "Total Loss: 1.2179941252138659e-06\n",
            "----------------------------------------\n",
            "Epoch 814\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6350429687113784e-06\n",
            "E_s_wdiff_all_sq: 3.254448011554028e-06\n",
            "E_IS_SCOPE: -5.514883489752671e-07\n",
            "E_IS_E_SCOPE: -1.713800915410364e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.15476861681263e-05\n",
            "Total Loss: 1.2179531113701427e-06\n",
            "----------------------------------------\n",
            "Epoch 815\n",
            "Var loss:  tensor(1.2179e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6217963656617975e-06\n",
            "E_s_wdiff_all_sq: 3.2412391095032035e-06\n",
            "E_IS_SCOPE: -5.590599902536422e-07\n",
            "E_IS_E_SCOPE: -1.789637600524561e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.471371280388776e-05\n",
            "Total Loss: 1.2179394648374757e-06\n",
            "----------------------------------------\n",
            "Epoch 816\n",
            "Var loss:  tensor(1.2179e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.639038199230538e-06\n",
            "E_s_wdiff_all_sq: 3.2584709215154683e-06\n",
            "E_IS_SCOPE: -5.419733603948775e-07\n",
            "E_IS_E_SCOPE: -1.618509865993583e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.756947957656852e-05\n",
            "Total Loss: 1.2178971992052851e-06\n",
            "----------------------------------------\n",
            "Epoch 817\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.654949008309944e-06\n",
            "E_s_wdiff_all_sq: 3.274399513442521e-06\n",
            "E_IS_SCOPE: -5.253024029300026e-07\n",
            "E_IS_E_SCOPE: -1.4525563194729258e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.064125812553468e-05\n",
            "Total Loss: 1.2180306219832562e-06\n",
            "----------------------------------------\n",
            "Epoch 818\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5663921830180066e-06\n",
            "E_s_wdiff_all_sq: 3.1859741912782564e-06\n",
            "E_IS_SCOPE: -5.842885316166293e-07\n",
            "E_IS_E_SCOPE: -2.042975843089404e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.529006674933649e-05\n",
            "Total Loss: 1.2180107662056256e-06\n",
            "----------------------------------------\n",
            "Epoch 819\n",
            "Var loss:  tensor(1.2179e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6404913837802227e-06\n",
            "E_s_wdiff_all_sq: 3.2598907742877567e-06\n",
            "E_IS_SCOPE: -5.420079077475711e-07\n",
            "E_IS_E_SCOPE: -1.61885649058843e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.758395044509664e-05\n",
            "Total Loss: 1.2179307611962638e-06\n",
            "----------------------------------------\n",
            "Epoch 820\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.654096845367373e-06\n",
            "E_s_wdiff_all_sq: 3.273390461352688e-06\n",
            "E_IS_SCOPE: -5.373274520244055e-07\n",
            "E_IS_E_SCOPE: -1.5717046377581938e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.561545694144157e-05\n",
            "Total Loss: 1.2179670765987668e-06\n",
            "----------------------------------------\n",
            "Epoch 821\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5859111649375995e-06\n",
            "E_s_wdiff_all_sq: 3.205372656194245e-06\n",
            "E_IS_SCOPE: -5.794232907799972e-07\n",
            "E_IS_E_SCOPE: -1.9936381590718388e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.323031926022648e-05\n",
            "Total Loss: 1.2179942280789827e-06\n",
            "----------------------------------------\n",
            "Epoch 822\n",
            "Var loss:  tensor(1.2179e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6125905734168308e-06\n",
            "E_s_wdiff_all_sq: 3.2320192647484944e-06\n",
            "E_IS_SCOPE: -5.561152260979163e-07\n",
            "E_IS_E_SCOPE: -1.7599137955697864e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.347280468585376e-05\n",
            "Total Loss: 1.2178982846677143e-06\n",
            "----------------------------------------\n",
            "Epoch 823\n",
            "Var loss:  tensor(1.2179e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.648729062389355e-06\n",
            "E_s_wdiff_all_sq: 3.267949104051717e-06\n",
            "E_IS_SCOPE: -5.275838092940746e-07\n",
            "E_IS_E_SCOPE: -1.4738071172219067e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.152843550681315e-05\n",
            "Total Loss: 1.2179484322751232e-06\n",
            "----------------------------------------\n",
            "Epoch 824\n",
            "Var loss:  tensor(1.2179e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5980056580993054e-06\n",
            "E_s_wdiff_all_sq: 3.2174520119481553e-06\n",
            "E_IS_SCOPE: -5.602444334587312e-07\n",
            "E_IS_E_SCOPE: -1.8011030384238817e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.519237140724386e-05\n",
            "Total Loss: 1.2178600559997181e-06\n",
            "----------------------------------------\n",
            "Epoch 825\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6067314729380627e-06\n",
            "E_s_wdiff_all_sq: 3.226153817152122e-06\n",
            "E_IS_SCOPE: -5.612237506346026e-07\n",
            "E_IS_E_SCOPE: -1.8106436856675215e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.559067393392054e-05\n",
            "Total Loss: 1.217833560731494e-06\n",
            "----------------------------------------\n",
            "Epoch 826\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.675153729791427e-06\n",
            "E_s_wdiff_all_sq: 3.2943592852452116e-06\n",
            "E_IS_SCOPE: -5.254769467126456e-07\n",
            "E_IS_E_SCOPE: -1.452129795200044e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.062345160871885e-05\n",
            "Total Loss: 1.2178411792421853e-06\n",
            "----------------------------------------\n",
            "Epoch 827\n",
            "Var loss:  tensor(1.2179e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.680312610573546e-06\n",
            "E_s_wdiff_all_sq: 3.2994442227029584e-06\n",
            "E_IS_SCOPE: -5.248768308846306e-07\n",
            "E_IS_E_SCOPE: -1.4458810270810797e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.0362578308738146e-05\n",
            "Total Loss: 1.217865600598796e-06\n",
            "----------------------------------------\n",
            "Epoch 828\n",
            "Var loss:  tensor(1.2179e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5850806330273098e-06\n",
            "E_s_wdiff_all_sq: 3.2044625840612813e-06\n",
            "E_IS_SCOPE: -5.830849251282806e-07\n",
            "E_IS_E_SCOPE: -2.0295493462790339e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.472953794375133e-05\n",
            "Total Loss: 1.2179327370465261e-06\n",
            "----------------------------------------\n",
            "Epoch 829\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.620066240112601e-06\n",
            "E_s_wdiff_all_sq: 3.2394678229233384e-06\n",
            "E_IS_SCOPE: -5.548922265551125e-07\n",
            "E_IS_E_SCOPE: -1.7470067583404717e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.293396225629292e-05\n",
            "Total Loss: 1.2177899848283843e-06\n",
            "----------------------------------------\n",
            "Epoch 830\n",
            "Var loss:  tensor(1.2179e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6615387120410043e-06\n",
            "E_s_wdiff_all_sq: 3.28067719677035e-06\n",
            "E_IS_SCOPE: -5.225404377126923e-07\n",
            "E_IS_E_SCOPE: -1.4227582095870922e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.939724792846667e-05\n",
            "Total Loss: 1.217906950843941e-06\n",
            "----------------------------------------\n",
            "Epoch 831\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5831759972460736e-06\n",
            "E_s_wdiff_all_sq: 3.202683548084999e-06\n",
            "E_IS_SCOPE: -5.690418251784888e-07\n",
            "E_IS_E_SCOPE: -1.8890534966648274e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.886412331727207e-05\n",
            "Total Loss: 1.217794167218316e-06\n",
            "----------------------------------------\n",
            "Epoch 832\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5830211507611604e-06\n",
            "E_s_wdiff_all_sq: 3.2025502636256433e-06\n",
            "E_IS_SCOPE: -5.703263322055457e-07\n",
            "E_IS_E_SCOPE: -1.901880854546632e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.939963929689437e-05\n",
            "Total Loss: 1.2177690627150062e-06\n",
            "----------------------------------------\n",
            "Epoch 833\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.658816842540205e-06\n",
            "E_s_wdiff_all_sq: 3.2780781566814634e-06\n",
            "E_IS_SCOPE: -5.27715359664244e-07\n",
            "E_IS_E_SCOPE: -1.4744781588442757e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.15564501233134e-05\n",
            "Total Loss: 1.2177782673803623e-06\n",
            "----------------------------------------\n",
            "Epoch 834\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.669405654896036e-06\n",
            "E_s_wdiff_all_sq: 3.2887701333391225e-06\n",
            "E_IS_SCOPE: -5.273071483830537e-07\n",
            "E_IS_E_SCOPE: -1.4712378617222282e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.14211743398224e-05\n",
            "Total Loss: 1.217843466216505e-06\n",
            "----------------------------------------\n",
            "Epoch 835\n",
            "Var loss:  tensor(1.2180e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.569728828559196e-06\n",
            "E_s_wdiff_all_sq: 3.189066817186462e-06\n",
            "E_IS_SCOPE: -5.984089953031007e-07\n",
            "E_IS_E_SCOPE: -2.1829563235561177e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -9.113396576703414e-05\n",
            "Total Loss: 1.2180099545590103e-06\n",
            "----------------------------------------\n",
            "Epoch 836\n",
            "Var loss:  tensor(1.2177e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6564621881976663e-06\n",
            "E_s_wdiff_all_sq: 3.2759111509078616e-06\n",
            "E_IS_SCOPE: -5.4194675676222e-07\n",
            "E_IS_E_SCOPE: -1.6175538533955643e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.752956800415613e-05\n",
            "Total Loss: 1.2177429635257312e-06\n",
            "----------------------------------------\n",
            "Epoch 837\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.674106565295929e-06\n",
            "E_s_wdiff_all_sq: 3.2933501790299798e-06\n",
            "E_IS_SCOPE: -5.22506970300067e-07\n",
            "E_IS_E_SCOPE: -1.4223517534544622e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.938027921549831e-05\n",
            "Total Loss: 1.2177874654379607e-06\n",
            "----------------------------------------\n",
            "Epoch 838\n",
            "Var loss:  tensor(1.2177e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6071296850753526e-06\n",
            "E_s_wdiff_all_sq: 3.2265092401162362e-06\n",
            "E_IS_SCOPE: -5.521387176720199e-07\n",
            "E_IS_E_SCOPE: -1.71880352347032e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.175653483209739e-05\n",
            "Total Loss: 1.217678383390393e-06\n",
            "----------------------------------------\n",
            "Epoch 839\n",
            "Var loss:  tensor(1.2177e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5932845037204e-06\n",
            "E_s_wdiff_all_sq: 3.2126452235429454e-06\n",
            "E_IS_SCOPE: -5.540934070133898e-07\n",
            "E_IS_E_SCOPE: -1.7384908567186661e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.257844076532109e-05\n",
            "Total Loss: 1.2177253065756609e-06\n",
            "----------------------------------------\n",
            "Epoch 840\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6179964478175357e-06\n",
            "E_s_wdiff_all_sq: 3.2371952853462707e-06\n",
            "E_IS_SCOPE: -5.469296458702752e-07\n",
            "E_IS_E_SCOPE: -1.6662134652823717e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.956100736740709e-05\n",
            "Total Loss: 1.217759232868442e-06\n",
            "----------------------------------------\n",
            "Epoch 841\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6424441022248823e-06\n",
            "E_s_wdiff_all_sq: 3.261469008633273e-06\n",
            "E_IS_SCOPE: -5.48711083578156e-07\n",
            "E_IS_E_SCOPE: -1.6832176269491795e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.027089637000313e-05\n",
            "Total Loss: 1.2177711209063857e-06\n",
            "----------------------------------------\n",
            "Epoch 842\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.659259343720739e-06\n",
            "E_s_wdiff_all_sq: 3.2781349818888283e-06\n",
            "E_IS_SCOPE: -5.473699597125141e-07\n",
            "E_IS_E_SCOPE: -1.669075282499052e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.968048238825019e-05\n",
            "Total Loss: 1.217774167987947e-06\n",
            "----------------------------------------\n",
            "Epoch 843\n",
            "Var loss:  tensor(1.2178e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6623937282582036e-06\n",
            "E_s_wdiff_all_sq: 3.2812039277090496e-06\n",
            "E_IS_SCOPE: -5.36606572731891e-07\n",
            "E_IS_E_SCOPE: -1.561060320059e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.517107842853046e-05\n",
            "Total Loss: 1.2177633881784247e-06\n",
            "----------------------------------------\n",
            "Epoch 844\n",
            "Var loss:  tensor(1.2177e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.633041858843403e-06\n",
            "E_s_wdiff_all_sq: 3.2519431802436796e-06\n",
            "E_IS_SCOPE: -5.356246947717068e-07\n",
            "E_IS_E_SCOPE: -1.5516005916426772e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.477615409754147e-05\n",
            "Total Loss: 1.2177440764660977e-06\n",
            "----------------------------------------\n",
            "Epoch 845\n",
            "Var loss:  tensor(1.2177e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6052921006257483e-06\n",
            "E_s_wdiff_all_sq: 3.224314837282033e-06\n",
            "E_IS_SCOPE: -5.411637508721587e-07\n",
            "E_IS_E_SCOPE: -1.6074722761438831e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.710868275500204e-05\n",
            "Total Loss: 1.2177188859094275e-06\n",
            "----------------------------------------\n",
            "Epoch 846\n",
            "Var loss:  tensor(1.2177e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.621229112572946e-06\n",
            "E_s_wdiff_all_sq: 3.2402494308610707e-06\n",
            "E_IS_SCOPE: -5.383295100474027e-07\n",
            "E_IS_E_SCOPE: -1.5789324678720988e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.591720407905608e-05\n",
            "Total Loss: 1.2176818242727433e-06\n",
            "----------------------------------------\n",
            "Epoch 847\n",
            "Var loss:  tensor(1.2176e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6545922222885914e-06\n",
            "E_s_wdiff_all_sq: 3.2735625870492086e-06\n",
            "E_IS_SCOPE: -5.381249102484699e-07\n",
            "E_IS_E_SCOPE: -1.5764222292513353e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.581240674616255e-05\n",
            "Total Loss: 1.2176389296739639e-06\n",
            "----------------------------------------\n",
            "Epoch 848\n",
            "Var loss:  tensor(1.2176e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6680416872251003e-06\n",
            "E_s_wdiff_all_sq: 3.287050423195766e-06\n",
            "E_IS_SCOPE: -5.458248772153837e-07\n",
            "E_IS_E_SCOPE: -1.6533624169689508e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.902450236067478e-05\n",
            "Total Loss: 1.2175886620736103e-06\n",
            "----------------------------------------\n",
            "Epoch 849\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6604628097542778e-06\n",
            "E_s_wdiff_all_sq: 3.2796092657200864e-06\n",
            "E_IS_SCOPE: -5.479608482010258e-07\n",
            "E_IS_E_SCOPE: -1.6751373866565416e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.993356284927603e-05\n",
            "Total Loss: 1.2175339940447014e-06\n",
            "----------------------------------------\n",
            "Epoch 850\n",
            "Var loss:  tensor(1.2176e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6517819224152877e-06\n",
            "E_s_wdiff_all_sq: 3.2711139140233033e-06\n",
            "E_IS_SCOPE: -5.343976369854086e-07\n",
            "E_IS_E_SCOPE: -1.540640075568577e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.431857494861059e-05\n",
            "Total Loss: 1.2175754186161351e-06\n",
            "----------------------------------------\n",
            "Epoch 851\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5864289307016425e-06\n",
            "E_s_wdiff_all_sq: 3.206034286533737e-06\n",
            "E_IS_SCOPE: -5.600170802600466e-07\n",
            "E_IS_E_SCOPE: -1.7978967726040722e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.505851636108036e-05\n",
            "Total Loss: 1.2175145072498806e-06\n",
            "----------------------------------------\n",
            "Epoch 852\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5736434220308665e-06\n",
            "E_s_wdiff_all_sq: 3.1932251588582025e-06\n",
            "E_IS_SCOPE: -5.683238740742418e-07\n",
            "E_IS_E_SCOPE: -1.8808280610587953e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.852072818890875e-05\n",
            "Total Loss: 1.2175107963171935e-06\n",
            "----------------------------------------\n",
            "Epoch 853\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6392070758688264e-06\n",
            "E_s_wdiff_all_sq: 3.258506227953941e-06\n",
            "E_IS_SCOPE: -5.396238997565e-07\n",
            "E_IS_E_SCOPE: -1.592568205758679e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.648646827200131e-05\n",
            "Total Loss: 1.2175413586348754e-06\n",
            "----------------------------------------\n",
            "Epoch 854\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.632056379537399e-06\n",
            "E_s_wdiff_all_sq: 3.251388786125692e-06\n",
            "E_IS_SCOPE: -5.57845512094723e-07\n",
            "E_IS_E_SCOPE: -1.7746464865058957e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.408786442705851e-05\n",
            "Total Loss: 1.2174805356046939e-06\n",
            "----------------------------------------\n",
            "Epoch 855\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6215288249180134e-06\n",
            "E_s_wdiff_all_sq: 3.240841495747904e-06\n",
            "E_IS_SCOPE: -5.668379903253031e-07\n",
            "E_IS_E_SCOPE: -1.864491770129472e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.783872142484854e-05\n",
            "Total Loss: 1.2174843716266506e-06\n",
            "----------------------------------------\n",
            "Epoch 856\n",
            "Var loss:  tensor(1.2174e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.653253759320877e-06\n",
            "E_s_wdiff_all_sq: 3.2724620413218093e-06\n",
            "E_IS_SCOPE: -5.372275874804676e-07\n",
            "E_IS_E_SCOPE: -1.567660243963803e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.544661176500395e-05\n",
            "Total Loss: 1.2174432609121463e-06\n",
            "----------------------------------------\n",
            "Epoch 857\n",
            "Var loss:  tensor(1.2176e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.662091600043045e-06\n",
            "E_s_wdiff_all_sq: 3.2812835800441698e-06\n",
            "E_IS_SCOPE: -5.201121099161288e-07\n",
            "E_IS_E_SCOPE: -1.3971122389246434e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.83265810593254e-05\n",
            "Total Loss: 1.2175809170327998e-06\n",
            "----------------------------------------\n",
            "Epoch 858\n",
            "Var loss:  tensor(1.2176e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5683590317086622e-06\n",
            "E_s_wdiff_all_sq: 3.187590338498906e-06\n",
            "E_IS_SCOPE: -5.810857893086801e-07\n",
            "E_IS_E_SCOPE: -2.0072025912794668e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.379660658678436e-05\n",
            "Total Loss: 1.2176123019295437e-06\n",
            "----------------------------------------\n",
            "Epoch 859\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.667407742582008e-06\n",
            "E_s_wdiff_all_sq: 3.286354373099362e-06\n",
            "E_IS_SCOPE: -5.258544821314525e-07\n",
            "E_IS_E_SCOPE: -1.4529370823925327e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.065715419936188e-05\n",
            "Total Loss: 1.217506490779501e-06\n",
            "----------------------------------------\n",
            "Epoch 860\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6829848334297228e-06\n",
            "E_s_wdiff_all_sq: 3.3018093736268614e-06\n",
            "E_IS_SCOPE: -5.233729267916362e-07\n",
            "E_IS_E_SCOPE: -1.4276428595555515e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.9601172083158115e-05\n",
            "Total Loss: 1.2175328472119522e-06\n",
            "----------------------------------------\n",
            "Epoch 861\n",
            "Var loss:  tensor(1.2176e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6027639688302674e-06\n",
            "E_s_wdiff_all_sq: 3.2217598382300597e-06\n",
            "E_IS_SCOPE: -5.734350778865661e-07\n",
            "E_IS_E_SCOPE: -1.9294813856473324e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.055190507030463e-05\n",
            "Total Loss: 1.2176049210377958e-06\n",
            "----------------------------------------\n",
            "Epoch 862\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.637140118315187e-06\n",
            "E_s_wdiff_all_sq: 3.2561425903772174e-06\n",
            "E_IS_SCOPE: -5.428154970107807e-07\n",
            "E_IS_E_SCOPE: -1.6226629163390268e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.774286094197939e-05\n",
            "Total Loss: 1.217473786265468e-06\n",
            "----------------------------------------\n",
            "Epoch 863\n",
            "Var loss:  tensor(1.2176e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.663143512973295e-06\n",
            "E_s_wdiff_all_sq: 3.281977563497815e-06\n",
            "E_IS_SCOPE: -5.183867779141784e-07\n",
            "E_IS_E_SCOPE: -1.377925807775865e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.7525586765195e-05\n",
            "Total Loss: 1.2175522242835497e-06\n",
            "----------------------------------------\n",
            "Epoch 864\n",
            "Var loss:  tensor(1.2175e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5941463789027905e-06\n",
            "E_s_wdiff_all_sq: 3.2132784209687976e-06\n",
            "E_IS_SCOPE: -5.624830397177476e-07\n",
            "E_IS_E_SCOPE: -1.8200032388166388e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.59814161522059e-05\n",
            "Total Loss: 1.217477195343079e-06\n",
            "----------------------------------------\n",
            "Epoch 865\n",
            "Var loss:  tensor(1.2174e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.617860687398479e-06\n",
            "E_s_wdiff_all_sq: 3.236962467945562e-06\n",
            "E_IS_SCOPE: -5.552602604129162e-07\n",
            "E_IS_E_SCOPE: -1.7473153354870562e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.294684472160377e-05\n",
            "Total Loss: 1.2174154348057493e-06\n",
            "----------------------------------------\n",
            "Epoch 866\n",
            "Var loss:  tensor(1.2174e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6877014943130727e-06\n",
            "E_s_wdiff_all_sq: 3.306542404948731e-06\n",
            "E_IS_SCOPE: -5.193681117395345e-07\n",
            "E_IS_E_SCOPE: -1.3871987421958274e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.791271282853838e-05\n",
            "Total Loss: 1.2174372834056917e-06\n",
            "----------------------------------------\n",
            "Epoch 867\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.643415543652252e-06\n",
            "E_s_wdiff_all_sq: 3.2625367267827327e-06\n",
            "E_IS_SCOPE: -5.490897434039181e-07\n",
            "E_IS_E_SCOPE: -1.6852060007583826e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.035390691341372e-05\n",
            "Total Loss: 1.2173151992946137e-06\n",
            "----------------------------------------\n",
            "Epoch 868\n",
            "Var loss:  tensor(1.2174e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.658009805161342e-06\n",
            "E_s_wdiff_all_sq: 3.277280454225267e-06\n",
            "E_IS_SCOPE: -5.330800463891559e-07\n",
            "E_IS_E_SCOPE: -1.5262832218570534e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.371920564353129e-05\n",
            "Total Loss: 1.2174005716104262e-06\n",
            "----------------------------------------\n",
            "Epoch 869\n",
            "Var loss:  tensor(1.2174e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6100270816251065e-06\n",
            "E_s_wdiff_all_sq: 3.2294596326354342e-06\n",
            "E_IS_SCOPE: -5.606252919461603e-07\n",
            "E_IS_E_SCOPE: -1.802456748521908e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.524888603761037e-05\n",
            "Total Loss: 1.2173828838829872e-06\n",
            "----------------------------------------\n",
            "Epoch 870\n",
            "Var loss:  tensor(1.2174e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6165999757563892e-06\n",
            "E_s_wdiff_all_sq: 3.2359864881374393e-06\n",
            "E_IS_SCOPE: -5.578609117731023e-07\n",
            "E_IS_E_SCOPE: -1.7744234821088974e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.407855444918005e-05\n",
            "Total Loss: 1.2173510295757784e-06\n",
            "----------------------------------------\n",
            "Epoch 871\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.653367393981732e-06\n",
            "E_s_wdiff_all_sq: 3.2725713310919053e-06\n",
            "E_IS_SCOPE: -5.350977089480997e-07\n",
            "E_IS_E_SCOPE: -1.5456962215939553e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.45296587132364e-05\n",
            "Total Loss: 1.2173145583936715e-06\n",
            "----------------------------------------\n",
            "Epoch 872\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6507008102037676e-06\n",
            "E_s_wdiff_all_sq: 3.2697835176966556e-06\n",
            "E_IS_SCOPE: -5.324802760228487e-07\n",
            "E_IS_E_SCOPE: -1.5188725398917975e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.340982481476975e-05\n",
            "Total Loss: 1.2173059175210273e-06\n",
            "----------------------------------------\n",
            "Epoch 873\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.604817719630763e-06\n",
            "E_s_wdiff_all_sq: 3.224051092404029e-06\n",
            "E_IS_SCOPE: -5.57394465209233e-07\n",
            "E_IS_E_SCOPE: -1.7687219617137697e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.384052762340135e-05\n",
            "Total Loss: 1.2172967582322756e-06\n",
            "----------------------------------------\n",
            "Epoch 874\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.610486756483796e-06\n",
            "E_s_wdiff_all_sq: 3.2296519170971853e-06\n",
            "E_IS_SCOPE: -5.579772736412178e-07\n",
            "E_IS_E_SCOPE: -1.774245531430173e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.407112537197494e-05\n",
            "Total Loss: 1.2173040674714621e-06\n",
            "----------------------------------------\n",
            "Epoch 875\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.667951695732284e-06\n",
            "E_s_wdiff_all_sq: 3.2868470675345546e-06\n",
            "E_IS_SCOPE: -5.318252175623035e-07\n",
            "E_IS_E_SCOPE: -1.511387223919879e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.309732816874022e-05\n",
            "Total Loss: 1.217306306938352e-06\n",
            "----------------------------------------\n",
            "Epoch 876\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6636117185475563e-06\n",
            "E_s_wdiff_all_sq: 3.282482605156746e-06\n",
            "E_IS_SCOPE: -5.401366595950036e-07\n",
            "E_IS_E_SCOPE: -1.5941739014933325e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.655350278777934e-05\n",
            "Total Loss: 1.2172652435807237e-06\n",
            "----------------------------------------\n",
            "Epoch 877\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6413396721921538e-06\n",
            "E_s_wdiff_all_sq: 3.2602429400107315e-06\n",
            "E_IS_SCOPE: -5.475187263261848e-07\n",
            "E_IS_E_SCOPE: -1.668126722420555e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.964088194329905e-05\n",
            "Total Loss: 1.2172592930944164e-06\n",
            "----------------------------------------\n",
            "Epoch 878\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6508714444235082e-06\n",
            "E_s_wdiff_all_sq: 3.2697816901136454e-06\n",
            "E_IS_SCOPE: -5.276375325714846e-07\n",
            "E_IS_E_SCOPE: -1.4691483620840253e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.133394199969569e-05\n",
            "Total Loss: 1.2172190306649528e-06\n",
            "----------------------------------------\n",
            "Epoch 879\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6312002117892955e-06\n",
            "E_s_wdiff_all_sq: 3.250252405695249e-06\n",
            "E_IS_SCOPE: -5.331288680132854e-07\n",
            "E_IS_E_SCOPE: -1.5245464117372349e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.364669737009706e-05\n",
            "Total Loss: 1.2171740214961763e-06\n",
            "----------------------------------------\n",
            "Epoch 880\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6581697127334126e-06\n",
            "E_s_wdiff_all_sq: 3.277297895829553e-06\n",
            "E_IS_SCOPE: -5.230001778814674e-07\n",
            "E_IS_E_SCOPE: -1.4242036841373805e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.945759353719993e-05\n",
            "Total Loss: 1.2172868670496549e-06\n",
            "----------------------------------------\n",
            "Epoch 881\n",
            "Var loss:  tensor(1.2173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6115272359366497e-06\n",
            "E_s_wdiff_all_sq: 3.23067042076586e-06\n",
            "E_IS_SCOPE: -5.734885170738494e-07\n",
            "E_IS_E_SCOPE: -1.9293147675000752e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.054494910313092e-05\n",
            "Total Loss: 1.2173174036043596e-06\n",
            "----------------------------------------\n",
            "Epoch 882\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.678540406339771e-06\n",
            "E_s_wdiff_all_sq: 3.2976246368939687e-06\n",
            "E_IS_SCOPE: -5.427677011536384e-07\n",
            "E_IS_E_SCOPE: -1.6211902116566434e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.768137853087432e-05\n",
            "Total Loss: 1.2171930785511085e-06\n",
            "----------------------------------------\n",
            "Epoch 883\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.685772982298121e-06\n",
            "E_s_wdiff_all_sq: 3.304730452226131e-06\n",
            "E_IS_SCOPE: -5.282845046013027e-07\n",
            "E_IS_E_SCOPE: -1.4756560927998743e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.160562645892165e-05\n",
            "Total Loss: 1.2171794085106137e-06\n",
            "----------------------------------------\n",
            "Epoch 884\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6375543148345873e-06\n",
            "E_s_wdiff_all_sq: 3.2565844841949763e-06\n",
            "E_IS_SCOPE: -5.319067515958486e-07\n",
            "E_IS_E_SCOPE: -1.5122969639006632e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.31353079539384e-05\n",
            "Total Loss: 1.2171903893092997e-06\n",
            "----------------------------------------\n",
            "Epoch 885\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.558139543353446e-06\n",
            "E_s_wdiff_all_sq: 3.1773826559819697e-06\n",
            "E_IS_SCOPE: -5.659012847849295e-07\n",
            "E_IS_E_SCOPE: -1.853507716831525e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.738015964491898e-05\n",
            "Total Loss: 1.217230530249175e-06\n",
            "----------------------------------------\n",
            "Epoch 886\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.601754477098671e-06\n",
            "E_s_wdiff_all_sq: 3.220806229108439e-06\n",
            "E_IS_SCOPE: -5.490244570075693e-07\n",
            "E_IS_E_SCOPE: -1.6836533510428766e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.028908696053871e-05\n",
            "Total Loss: 1.2172046732649226e-06\n",
            "----------------------------------------\n",
            "Epoch 887\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6858393137973186e-06\n",
            "E_s_wdiff_all_sq: 3.30445817351431e-06\n",
            "E_IS_SCOPE: -5.237880452747255e-07\n",
            "E_IS_E_SCOPE: -1.429303178719791e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.967048701550164e-05\n",
            "Total Loss: 1.2172403545587686e-06\n",
            "----------------------------------------\n",
            "Epoch 888\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6823338506352464e-06\n",
            "E_s_wdiff_all_sq: 3.3008885408148304e-06\n",
            "E_IS_SCOPE: -5.432772725951314e-07\n",
            "E_IS_E_SCOPE: -1.6236885950722846e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.77856809331794e-05\n",
            "Total Loss: 1.2172031527258632e-06\n",
            "----------------------------------------\n",
            "Epoch 889\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6747234768837664e-06\n",
            "E_s_wdiff_all_sq: 3.2932602061125446e-06\n",
            "E_IS_SCOPE: -5.378540532544742e-07\n",
            "E_IS_E_SCOPE: -1.5692698324388432e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.551380879473856e-05\n",
            "Total Loss: 1.2171837998312952e-06\n",
            "----------------------------------------\n",
            "Epoch 890\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.670182040862065e-06\n",
            "E_s_wdiff_all_sq: 3.288734539670387e-06\n",
            "E_IS_SCOPE: -5.140163723418358e-07\n",
            "E_IS_E_SCOPE: -1.3309474148197737e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.556433485683054e-05\n",
            "Total Loss: 1.2171789085532143e-06\n",
            "----------------------------------------\n",
            "Epoch 891\n",
            "Var loss:  tensor(1.2171e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.615178158285757e-06\n",
            "E_s_wdiff_all_sq: 3.2340036839662602e-06\n",
            "E_IS_SCOPE: -5.32656405352692e-07\n",
            "E_IS_E_SCOPE: -1.5184032971174248e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.33902348878094e-05\n",
            "Total Loss: 1.2171169921188501e-06\n",
            "----------------------------------------\n",
            "Epoch 892\n",
            "Var loss:  tensor(1.2171e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6128407281132257e-06\n",
            "E_s_wdiff_all_sq: 3.2317332379079364e-06\n",
            "E_IS_SCOPE: -5.44101301339582e-07\n",
            "E_IS_E_SCOPE: -1.6330509744418e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.817654114039118e-05\n",
            "Total Loss: 1.2170897514957391e-06\n",
            "----------------------------------------\n",
            "Epoch 893\n",
            "Var loss:  tensor(1.2170e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6829525207189953e-06\n",
            "E_s_wdiff_all_sq: 3.301700483307173e-06\n",
            "E_IS_SCOPE: -5.256349959843758e-07\n",
            "E_IS_E_SCOPE: -1.4473872117643718e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.042545844146676e-05\n",
            "Total Loss: 1.217034156877198e-06\n",
            "----------------------------------------\n",
            "Epoch 894\n",
            "Var loss:  tensor(1.2171e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.7257182958900776e-06\n",
            "E_s_wdiff_all_sq: 3.3444508369563246e-06\n",
            "E_IS_SCOPE: -5.149345429036771e-07\n",
            "E_IS_E_SCOPE: -1.3408584699400933e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.597810115545212e-05\n",
            "Total Loss: 1.2171447361956708e-06\n",
            "----------------------------------------\n",
            "Epoch 895\n",
            "Var loss:  tensor(1.2172e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.620853663978413e-06\n",
            "E_s_wdiff_all_sq: 3.239820449343242e-06\n",
            "E_IS_SCOPE: -5.766752433608481e-07\n",
            "E_IS_E_SCOPE: -1.959474329211764e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.180404917532305e-05\n",
            "Total Loss: 1.217152262837081e-06\n",
            "----------------------------------------\n",
            "Epoch 896\n",
            "Var loss:  tensor(1.2170e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6296974147286803e-06\n",
            "E_s_wdiff_all_sq: 3.248870040773268e-06\n",
            "E_IS_SCOPE: -5.482021392050872e-07\n",
            "E_IS_E_SCOPE: -1.6750412587620526e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.992954970611274e-05\n",
            "Total Loss: 1.2170060163789022e-06\n",
            "----------------------------------------\n",
            "Epoch 897\n",
            "Var loss:  tensor(1.2170e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.631887896008403e-06\n",
            "E_s_wdiff_all_sq: 3.2509520644121125e-06\n",
            "E_IS_SCOPE: -5.270690259219952e-07\n",
            "E_IS_E_SCOPE: -1.4632986474037329e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.108972836533755e-05\n",
            "Total Loss: 1.2170321783143009e-06\n",
            "----------------------------------------\n",
            "Epoch 898\n",
            "Var loss:  tensor(1.2170e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.60611742426638e-06\n",
            "E_s_wdiff_all_sq: 3.2254063065874884e-06\n",
            "E_IS_SCOPE: -5.408412246175534e-07\n",
            "E_IS_E_SCOPE: -1.6020172457306228e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.688094638227868e-05\n",
            "Total Loss: 1.2170067866711633e-06\n",
            "----------------------------------------\n",
            "Epoch 899\n",
            "Var loss:  tensor(1.2171e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.570688702984079e-06\n",
            "E_s_wdiff_all_sq: 3.189783054392053e-06\n",
            "E_IS_SCOPE: -5.830272149721369e-07\n",
            "E_IS_E_SCOPE: -2.0235750030986588e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -8.448012132418569e-05\n",
            "Total Loss: 1.2171408883487364e-06\n",
            "----------------------------------------\n",
            "Epoch 900\n",
            "Var loss:  tensor(1.2170e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6975488820826804e-06\n",
            "E_s_wdiff_all_sq: 3.316382449952761e-06\n",
            "E_IS_SCOPE: -5.234983013323518e-07\n",
            "E_IS_E_SCOPE: -1.4263579372701446e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.954752920340466e-05\n",
            "Total Loss: 1.2170160860004973e-06\n",
            "----------------------------------------\n",
            "Epoch 901\n",
            "Var loss:  tensor(1.2170e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.711848173826388e-06\n",
            "E_s_wdiff_all_sq: 3.3304702008644615e-06\n",
            "E_IS_SCOPE: -5.204540886357774e-07\n",
            "E_IS_E_SCOPE: -1.3946188598940012e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.8222487579867864e-05\n",
            "Total Loss: 1.2169682367504262e-06\n",
            "----------------------------------------\n",
            "Epoch 902\n",
            "Var loss:  tensor(1.2170e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6374684216546426e-06\n",
            "E_s_wdiff_all_sq: 3.256288366760245e-06\n",
            "E_IS_SCOPE: -5.528257014936772e-07\n",
            "E_IS_E_SCOPE: -1.7193159052415992e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.177792572402661e-05\n",
            "Total Loss: 1.2169665020366157e-06\n",
            "----------------------------------------\n",
            "Epoch 903\n",
            "Var loss:  tensor(1.2169e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6291808834084394e-06\n",
            "E_s_wdiff_all_sq: 3.2480350867092275e-06\n",
            "E_IS_SCOPE: -5.394883121109183e-07\n",
            "E_IS_E_SCOPE: -1.5859232415659996e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.620905459554612e-05\n",
            "Total Loss: 1.216928489871829e-06\n",
            "----------------------------------------\n",
            "Epoch 904\n",
            "Var loss:  tensor(1.2170e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6586970326473606e-06\n",
            "E_s_wdiff_all_sq: 3.277396854738442e-06\n",
            "E_IS_SCOPE: -5.155452944597527e-07\n",
            "E_IS_E_SCOPE: -1.3458707393690678e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.6187353161837295e-05\n",
            "Total Loss: 1.2169584059444796e-06\n",
            "----------------------------------------\n",
            "Epoch 905\n",
            "Var loss:  tensor(1.2169e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.633568895973755e-06\n",
            "E_s_wdiff_all_sq: 3.25239338155476e-06\n",
            "E_IS_SCOPE: -5.422130610257762e-07\n",
            "E_IS_E_SCOPE: -1.6128758733777182e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.733427189758504e-05\n",
            "Total Loss: 1.2168992361242398e-06\n",
            "----------------------------------------\n",
            "Epoch 906\n",
            "Var loss:  tensor(1.2169e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.659873905911099e-06\n",
            "E_s_wdiff_all_sq: 3.2786793278187405e-06\n",
            "E_IS_SCOPE: -5.396331337496893e-07\n",
            "E_IS_E_SCOPE: -1.5868691827533115e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.624854570714182e-05\n",
            "Total Loss: 1.216876816224896e-06\n",
            "----------------------------------------\n",
            "Epoch 907\n",
            "Var loss:  tensor(1.2169e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6950044700672113e-06\n",
            "E_s_wdiff_all_sq: 3.313723763641442e-06\n",
            "E_IS_SCOPE: -5.22345527153171e-07\n",
            "E_IS_E_SCOPE: -1.4136520174268713e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.9017083013739614e-05\n",
            "Total Loss: 1.2168947246860553e-06\n",
            "----------------------------------------\n",
            "Epoch 908\n",
            "Var loss:  tensor(1.2169e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.664793324361848e-06\n",
            "E_s_wdiff_all_sq: 3.2835875810211457e-06\n",
            "E_IS_SCOPE: -5.344121208595005e-07\n",
            "E_IS_E_SCOPE: -1.5345665370238323e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.406501712528234e-05\n",
            "Total Loss: 1.2168694781077216e-06\n",
            "----------------------------------------\n",
            "Epoch 909\n",
            "Var loss:  tensor(1.2169e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6148645274717686e-06\n",
            "E_s_wdiff_all_sq: 3.2337930256146176e-06\n",
            "E_IS_SCOPE: -5.556096619243956e-07\n",
            "E_IS_E_SCOPE: -1.7473773735143636e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.294943468247283e-05\n",
            "Total Loss: 1.2169023217924866e-06\n",
            "----------------------------------------\n",
            "Epoch 910\n",
            "Var loss:  tensor(1.2169e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6318017823839063e-06\n",
            "E_s_wdiff_all_sq: 3.2506545857324548e-06\n",
            "E_IS_SCOPE: -5.406754249119396e-07\n",
            "E_IS_E_SCOPE: -1.597584276335732e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.669587896855133e-05\n",
            "Total Loss: 1.2168878711759735e-06\n",
            "----------------------------------------\n",
            "Epoch 911\n",
            "Var loss:  tensor(1.2169e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6524526811953588e-06\n",
            "E_s_wdiff_all_sq: 3.2711788194978204e-06\n",
            "E_IS_SCOPE: -5.30782717246931e-07\n",
            "E_IS_E_SCOPE: -1.4980238392858646e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.253943416755195e-05\n",
            "Total Loss: 1.2168878641421044e-06\n",
            "----------------------------------------\n",
            "Epoch 912\n",
            "Var loss:  tensor(1.2169e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6368664566851295e-06\n",
            "E_s_wdiff_all_sq: 3.255612234634427e-06\n",
            "E_IS_SCOPE: -5.451397361040502e-07\n",
            "E_IS_E_SCOPE: -1.64157256391896e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.853230008770127e-05\n",
            "Total Loss: 1.2168639317076472e-06\n",
            "----------------------------------------\n",
            "Epoch 913\n",
            "Var loss:  tensor(1.2168e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.652528273052702e-06\n",
            "E_s_wdiff_all_sq: 3.2712265092091642e-06\n",
            "E_IS_SCOPE: -5.360828538527663e-07\n",
            "E_IS_E_SCOPE: -1.550564188080638e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.473288636665538e-05\n",
            "Total Loss: 1.2168235628353876e-06\n",
            "----------------------------------------\n",
            "Epoch 914\n",
            "Var loss:  tensor(1.2168e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6697748945401857e-06\n",
            "E_s_wdiff_all_sq: 3.2884251543082625e-06\n",
            "E_IS_SCOPE: -5.240396982341304e-07\n",
            "E_IS_E_SCOPE: -1.429775632579813e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.969021099872619e-05\n",
            "Total Loss: 1.216800139360879e-06\n",
            "----------------------------------------\n",
            "Epoch 915\n",
            "Var loss:  tensor(1.2168e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6649675425388856e-06\n",
            "E_s_wdiff_all_sq: 3.2837263252491387e-06\n",
            "E_IS_SCOPE: -5.27960433272957e-07\n",
            "E_IS_E_SCOPE: -1.4694716930252695e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.134744040578508e-05\n",
            "Total Loss: 1.21678935843014e-06\n",
            "----------------------------------------\n",
            "Epoch 916\n",
            "Var loss:  tensor(1.2168e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.65916089175516e-06\n",
            "E_s_wdiff_all_sq: 3.2779501787265837e-06\n",
            "E_IS_SCOPE: -5.369684585669126e-07\n",
            "E_IS_E_SCOPE: -1.5596825135243855e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.511355782117602e-05\n",
            "Total Loss: 1.2167849676808812e-06\n",
            "----------------------------------------\n",
            "Epoch 917\n",
            "Var loss:  tensor(1.2168e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6584164557286627e-06\n",
            "E_s_wdiff_all_sq: 3.2771270830390046e-06\n",
            "E_IS_SCOPE: -5.426394200329764e-07\n",
            "E_IS_E_SCOPE: -1.615852135402014e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.745852475528494e-05\n",
            "Total Loss: 1.2167556287853625e-06\n",
            "----------------------------------------\n",
            "Epoch 918\n",
            "Var loss:  tensor(1.2168e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6947839673628017e-06\n",
            "E_s_wdiff_all_sq: 3.3133309227671097e-06\n",
            "E_IS_SCOPE: -5.153539765674765e-07\n",
            "E_IS_E_SCOPE: -1.3423037503944732e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.603843866107783e-05\n",
            "Total Loss: 1.2167805106208868e-06\n",
            "----------------------------------------\n",
            "Epoch 919\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.636472470283163e-06\n",
            "E_s_wdiff_all_sq: 3.255306626322934e-06\n",
            "E_IS_SCOPE: -5.409861402798894e-07\n",
            "E_IS_E_SCOPE: -1.5997350542886875e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.678566955310037e-05\n",
            "Total Loss: 1.2167152433394417e-06\n",
            "----------------------------------------\n",
            "Epoch 920\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6185765169788303e-06\n",
            "E_s_wdiff_all_sq: 3.237578763942996e-06\n",
            "E_IS_SCOPE: -5.444683643181611e-07\n",
            "E_IS_E_SCOPE: -1.6354707193709687e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.827756054657911e-05\n",
            "Total Loss: 1.2167298373549587e-06\n",
            "----------------------------------------\n",
            "Epoch 921\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.634395098449024e-06\n",
            "E_s_wdiff_all_sq: 3.253354230130919e-06\n",
            "E_IS_SCOPE: -5.400233406918638e-07\n",
            "E_IS_E_SCOPE: -1.5907325306353952e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.640983258669716e-05\n",
            "Total Loss: 1.2167153621427104e-06\n",
            "----------------------------------------\n",
            "Epoch 922\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6595892052260297e-06\n",
            "E_s_wdiff_all_sq: 3.2783630784278676e-06\n",
            "E_IS_SCOPE: -5.375722565163428e-07\n",
            "E_IS_E_SCOPE: -1.5651643676472113e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.53424140289611e-05\n",
            "Total Loss: 1.2166891563761722e-06\n",
            "----------------------------------------\n",
            "Epoch 923\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6756350921417436e-06\n",
            "E_s_wdiff_all_sq: 3.294309280541357e-06\n",
            "E_IS_SCOPE: -5.343694353535169e-07\n",
            "E_IS_E_SCOPE: -1.5326261009264653e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.398400788338305e-05\n",
            "Total Loss: 1.2166868301598982e-06\n",
            "----------------------------------------\n",
            "Epoch 924\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.652024361479448e-06\n",
            "E_s_wdiff_all_sq: 3.270747286778036e-06\n",
            "E_IS_SCOPE: -5.439120458649205e-07\n",
            "E_IS_E_SCOPE: -1.6282339116403708e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.79754386118129e-05\n",
            "Total Loss: 1.216674434380898e-06\n",
            "----------------------------------------\n",
            "Epoch 925\n",
            "Var loss:  tensor(1.2166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6484888724824735e-06\n",
            "E_s_wdiff_all_sq: 3.2672240284236683e-06\n",
            "E_IS_SCOPE: -5.340297746271276e-07\n",
            "E_IS_E_SCOPE: -1.5293175795197358e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.384588387541883e-05\n",
            "Total Loss: 1.2166434797897508e-06\n",
            "----------------------------------------\n",
            "Epoch 926\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.664330863140033e-06\n",
            "E_s_wdiff_all_sq: 3.283031839094207e-06\n",
            "E_IS_SCOPE: -5.165041782352169e-07\n",
            "E_IS_E_SCOPE: -1.354159079383335e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.653337442070301e-05\n",
            "Total Loss: 1.2166971525333122e-06\n",
            "----------------------------------------\n",
            "Epoch 927\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6328419494486875e-06\n",
            "E_s_wdiff_all_sq: 3.251549083722947e-06\n",
            "E_IS_SCOPE: -5.42340265254598e-07\n",
            "E_IS_E_SCOPE: -1.6123257246015582e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.731130431037667e-05\n",
            "Total Loss: 1.2166521492181102e-06\n",
            "----------------------------------------\n",
            "Epoch 928\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.671580262959754e-06\n",
            "E_s_wdiff_all_sq: 3.290112687433871e-06\n",
            "E_IS_SCOPE: -5.297368265800612e-07\n",
            "E_IS_E_SCOPE: -1.485420721213408e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.201327974174919e-05\n",
            "Total Loss: 1.2166527356896952e-06\n",
            "----------------------------------------\n",
            "Epoch 929\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6913119483059905e-06\n",
            "E_s_wdiff_all_sq: 3.3097373488878576e-06\n",
            "E_IS_SCOPE: -5.244982644469552e-07\n",
            "E_IS_E_SCOPE: -1.4325370778291357e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.980549569503626e-05\n",
            "Total Loss: 1.2166601551713024e-06\n",
            "----------------------------------------\n",
            "Epoch 930\n",
            "Var loss:  tensor(1.2167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.661593092491871e-06\n",
            "E_s_wdiff_all_sq: 3.2801104419338066e-06\n",
            "E_IS_SCOPE: -5.388170831447133e-07\n",
            "E_IS_E_SCOPE: -1.5761395378687634e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.58006049586032e-05\n",
            "Total Loss: 1.2166510609236433e-06\n",
            "----------------------------------------\n",
            "Epoch 931\n",
            "Var loss:  tensor(1.2166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6525188477126982e-06\n",
            "E_s_wdiff_all_sq: 3.2710960153681984e-06\n",
            "E_IS_SCOPE: -5.325080108790141e-07\n",
            "E_IS_E_SCOPE: -1.5132081971798813e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.317335008129475e-05\n",
            "Total Loss: 1.216623119103701e-06\n",
            "----------------------------------------\n",
            "Epoch 932\n",
            "Var loss:  tensor(1.2166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6501988300393557e-06\n",
            "E_s_wdiff_all_sq: 3.2688154513944342e-06\n",
            "E_IS_SCOPE: -5.25552012941072e-07\n",
            "E_IS_E_SCOPE: -1.4437349152096123e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.027298252355637e-05\n",
            "Total Loss: 1.216601004885953e-06\n",
            "----------------------------------------\n",
            "Epoch 933\n",
            "Var loss:  tensor(1.2166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.634380631708041e-06\n",
            "E_s_wdiff_all_sq: 3.2530995865353704e-06\n",
            "E_IS_SCOPE: -5.384418255716885e-07\n",
            "E_IS_E_SCOPE: -1.5729401160869097e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.566703563703897e-05\n",
            "Total Loss: 1.2165600863279281e-06\n",
            "----------------------------------------\n",
            "Epoch 934\n",
            "Var loss:  tensor(1.2166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.684406295892814e-06\n",
            "E_s_wdiff_all_sq: 3.3030583863478466e-06\n",
            "E_IS_SCOPE: -5.171622619922535e-07\n",
            "E_IS_E_SCOPE: -1.3601780401681254e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.678465373407958e-05\n",
            "Total Loss: 1.2166336626753388e-06\n",
            "----------------------------------------\n",
            "Epoch 935\n",
            "Var loss:  tensor(1.2166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.646282180232173e-06\n",
            "E_s_wdiff_all_sq: 3.264937203854027e-06\n",
            "E_IS_SCOPE: -5.535331950792862e-07\n",
            "E_IS_E_SCOPE: -1.7236890305387327e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.196049476896044e-05\n",
            "Total Loss: 1.2165910614085723e-06\n",
            "----------------------------------------\n",
            "Epoch 936\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6803655879952156e-06\n",
            "E_s_wdiff_all_sq: 3.29892969614023e-06\n",
            "E_IS_SCOPE: -5.321015367822041e-07\n",
            "E_IS_E_SCOPE: -1.508577414927606e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.29800243849904e-05\n",
            "Total Loss: 1.216522970357352e-06\n",
            "----------------------------------------\n",
            "Epoch 937\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6845824720663034e-06\n",
            "E_s_wdiff_all_sq: 3.303107308175906e-06\n",
            "E_IS_SCOPE: -5.174214792820063e-07\n",
            "E_IS_E_SCOPE: -1.361700142740018e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.684819840613e-05\n",
            "Total Loss: 1.216546902955641e-06\n",
            "----------------------------------------\n",
            "Epoch 938\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6393489210491397e-06\n",
            "E_s_wdiff_all_sq: 3.2581896557182092e-06\n",
            "E_IS_SCOPE: -5.328386057491078e-07\n",
            "E_IS_E_SCOPE: -1.5174431801418894e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.335015196602274e-05\n",
            "Total Loss: 1.2165453589423467e-06\n",
            "----------------------------------------\n",
            "Epoch 939\n",
            "Var loss:  tensor(1.2166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.599844384787294e-06\n",
            "E_s_wdiff_all_sq: 3.2187160317029446e-06\n",
            "E_IS_SCOPE: -5.592764903874963e-07\n",
            "E_IS_E_SCOPE: -1.7823308699262793e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.440867173227897e-05\n",
            "Total Loss: 1.216616215375867e-06\n",
            "----------------------------------------\n",
            "Epoch 940\n",
            "Var loss:  tensor(1.2166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.679219554825931e-06\n",
            "E_s_wdiff_all_sq: 3.297917819567019e-06\n",
            "E_IS_SCOPE: -5.210642974249192e-07\n",
            "E_IS_E_SCOPE: -1.3991193864145763e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.8410375365543564e-05\n",
            "Total Loss: 1.2165716867732423e-06\n",
            "----------------------------------------\n",
            "Epoch 941\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6772665444692826e-06\n",
            "E_s_wdiff_all_sq: 3.2958192492835855e-06\n",
            "E_IS_SCOPE: -5.330949226844916e-07\n",
            "E_IS_E_SCOPE: -1.5182240710312678e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.33827525649502e-05\n",
            "Total Loss: 1.2164769331042208e-06\n",
            "----------------------------------------\n",
            "Epoch 942\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6920539220014676e-06\n",
            "E_s_wdiff_all_sq: 3.310452354644267e-06\n",
            "E_IS_SCOPE: -5.186163930016551e-07\n",
            "E_IS_E_SCOPE: -1.3728072470690247e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.7311897315158836e-05\n",
            "Total Loss: 1.2165048998489487e-06\n",
            "----------------------------------------\n",
            "Epoch 943\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6445410492815467e-06\n",
            "E_s_wdiff_all_sq: 3.2631008303754008e-06\n",
            "E_IS_SCOPE: -5.365934383486295e-07\n",
            "E_IS_E_SCOPE: -1.5533255844465608e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.484816902218339e-05\n",
            "Total Loss: 1.2164931281794513e-06\n",
            "----------------------------------------\n",
            "Epoch 944\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.629046273810743e-06\n",
            "E_s_wdiff_all_sq: 3.247616281901166e-06\n",
            "E_IS_SCOPE: -5.427336991836211e-07\n",
            "E_IS_E_SCOPE: -1.614840011816201e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.741627066379161e-05\n",
            "Total Loss: 1.2165052649868279e-06\n",
            "----------------------------------------\n",
            "Epoch 945\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.677958915352049e-06\n",
            "E_s_wdiff_all_sq: 3.296321822562457e-06\n",
            "E_IS_SCOPE: -5.19610906151859e-07\n",
            "E_IS_E_SCOPE: -1.382523250333265e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.771752059736599e-05\n",
            "Total Loss: 1.2164945996337802e-06\n",
            "----------------------------------------\n",
            "Epoch 946\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6808646052982064e-06\n",
            "E_s_wdiff_all_sq: 3.299203762110176e-06\n",
            "E_IS_SCOPE: -5.266300941071477e-07\n",
            "E_IS_E_SCOPE: -1.4524100575147581e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.0635151987658785e-05\n",
            "Total Loss: 1.2164573355579394e-06\n",
            "----------------------------------------\n",
            "Epoch 947\n",
            "Var loss:  tensor(1.2164e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6640038790131093e-06\n",
            "E_s_wdiff_all_sq: 3.2824000977258348e-06\n",
            "E_IS_SCOPE: -5.360364188131599e-07\n",
            "E_IS_E_SCOPE: -1.5466753181869147e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.45705339952668e-05\n",
            "Total Loss: 1.2164406763795911e-06\n",
            "----------------------------------------\n",
            "Epoch 948\n",
            "Var loss:  tensor(1.2164e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.673358145510048e-06\n",
            "E_s_wdiff_all_sq: 3.2917929041108475e-06\n",
            "E_IS_SCOPE: -5.202818527698799e-07\n",
            "E_IS_E_SCOPE: -1.3891001126475405e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.7992091159559945e-05\n",
            "Total Loss: 1.2163962274702035e-06\n",
            "----------------------------------------\n",
            "Epoch 949\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.679466880944409e-06\n",
            "E_s_wdiff_all_sq: 3.297991177710853e-06\n",
            "E_IS_SCOPE: -5.09438167703425e-07\n",
            "E_IS_E_SCOPE: -1.2815364089052535e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.35015263283516e-05\n",
            "Total Loss: 1.2164813186890108e-06\n",
            "----------------------------------------\n",
            "Epoch 950\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.608886719845125e-06\n",
            "E_s_wdiff_all_sq: 3.2274704523285005e-06\n",
            "E_IS_SCOPE: -5.625430527238847e-07\n",
            "E_IS_E_SCOPE: -1.8129419984215625e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.568662379493631e-05\n",
            "Total Loss: 1.2164932308344201e-06\n",
            "----------------------------------------\n",
            "Epoch 951\n",
            "Var loss:  tensor(1.2164e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.707492268978326e-06\n",
            "E_s_wdiff_all_sq: 3.3257675486164257e-06\n",
            "E_IS_SCOPE: -5.123108187087395e-07\n",
            "E_IS_E_SCOPE: -1.3088372133058017e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.4641279124504184e-05\n",
            "Total Loss: 1.2164451946868346e-06\n",
            "----------------------------------------\n",
            "Epoch 952\n",
            "Var loss:  tensor(1.2164e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6965879206196187e-06\n",
            "E_s_wdiff_all_sq: 3.3149140092487754e-06\n",
            "E_IS_SCOPE: -5.229283705676852e-07\n",
            "E_IS_E_SCOPE: -1.4150333040853145e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.907474890915248e-05\n",
            "Total Loss: 1.21639850013379e-06\n",
            "----------------------------------------\n",
            "Epoch 953\n",
            "Var loss:  tensor(1.2165e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6231854915272635e-06\n",
            "E_s_wdiff_all_sq: 3.241659862950315e-06\n",
            "E_IS_SCOPE: -5.590999570757446e-07\n",
            "E_IS_E_SCOPE: -1.7778771184735552e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.422273671010398e-05\n",
            "Total Loss: 1.2164758072014229e-06\n",
            "----------------------------------------\n",
            "Epoch 954\n",
            "Var loss:  tensor(1.2164e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6614666797569132e-06\n",
            "E_s_wdiff_all_sq: 3.2799104099721496e-06\n",
            "E_IS_SCOPE: -5.192130287904296e-07\n",
            "E_IS_E_SCOPE: -1.3783420530669635e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.7542964155525863e-05\n",
            "Total Loss: 1.2163732918985492e-06\n",
            "----------------------------------------\n",
            "Epoch 955\n",
            "Var loss:  tensor(1.2163e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6559921453691996e-06\n",
            "E_s_wdiff_all_sq: 3.274475122872748e-06\n",
            "E_IS_SCOPE: -5.175254150197085e-07\n",
            "E_IS_E_SCOPE: -1.3615283119898446e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.684102482343618e-05\n",
            "Total Loss: 1.2163465239362577e-06\n",
            "----------------------------------------\n",
            "Epoch 956\n",
            "Var loss:  tensor(1.2163e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.636510406248867e-06\n",
            "E_s_wdiff_all_sq: 3.255159938926614e-06\n",
            "E_IS_SCOPE: -5.405338344344619e-07\n",
            "E_IS_E_SCOPE: -1.592398574092855e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.647938649658537e-05\n",
            "Total Loss: 1.2163371823531535e-06\n",
            "----------------------------------------\n",
            "Epoch 957\n",
            "Var loss:  tensor(1.2164e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.693915148627431e-06\n",
            "E_s_wdiff_all_sq: 3.312486120480926e-06\n",
            "E_IS_SCOPE: -5.228860093129237e-07\n",
            "E_IS_E_SCOPE: -1.4157589492370577e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.910504311142504e-05\n",
            "Total Loss: 1.216383468449323e-06\n",
            "----------------------------------------\n",
            "Epoch 958\n",
            "Var loss:  tensor(1.2164e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.687299236842048e-06\n",
            "E_s_wdiff_all_sq: 3.305801474401288e-06\n",
            "E_IS_SCOPE: -5.39198280873882e-07\n",
            "E_IS_E_SCOPE: -1.5784298688852562e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.589622159838654e-05\n",
            "Total Loss: 1.2163618435513008e-06\n",
            "----------------------------------------\n",
            "Epoch 959\n",
            "Var loss:  tensor(1.2163e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6837392737822354e-06\n",
            "E_s_wdiff_all_sq: 3.3021895383972282e-06\n",
            "E_IS_SCOPE: -5.322242734104494e-07\n",
            "E_IS_E_SCOPE: -1.5081561919892215e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.296243918805688e-05\n",
            "Total Loss: 1.2163070960432063e-06\n",
            "----------------------------------------\n",
            "Epoch 960\n",
            "Var loss:  tensor(1.2163e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.668377347590472e-06\n",
            "E_s_wdiff_all_sq: 3.2867955544905246e-06\n",
            "E_IS_SCOPE: -5.175016049293664e-07\n",
            "E_IS_E_SCOPE: -1.3605269380126385e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.6799219506136e-05\n",
            "Total Loss: 1.2162586399249957e-06\n",
            "----------------------------------------\n",
            "Epoch 961\n",
            "Var loss:  tensor(1.2163e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6369850435552438e-06\n",
            "E_s_wdiff_all_sq: 3.2555517716798666e-06\n",
            "E_IS_SCOPE: -5.196208152034562e-07\n",
            "E_IS_E_SCOPE: -1.3824462305791068e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.771430518001516e-05\n",
            "Total Loss: 1.2162555566655403e-06\n",
            "----------------------------------------\n",
            "Epoch 962\n",
            "Var loss:  tensor(1.2163e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.612991988372931e-06\n",
            "E_s_wdiff_all_sq: 3.231732716062034e-06\n",
            "E_IS_SCOPE: -5.440899651098024e-07\n",
            "E_IS_E_SCOPE: -1.6280442084207182e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.796751889003964e-05\n",
            "Total Loss: 1.2162628528566879e-06\n",
            "----------------------------------------\n",
            "Epoch 963\n",
            "Var loss:  tensor(1.2163e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6707203739891947e-06\n",
            "E_s_wdiff_all_sq: 3.289299976573289e-06\n",
            "E_IS_SCOPE: -5.376191537128823e-07\n",
            "E_IS_E_SCOPE: -1.5625213756601408e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.523207451429785e-05\n",
            "Total Loss: 1.2162610342034234e-06\n",
            "----------------------------------------\n",
            "Epoch 964\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.721420384094444e-06\n",
            "E_s_wdiff_all_sq: 3.3397446832891016e-06\n",
            "E_IS_SCOPE: -5.274495481397457e-07\n",
            "E_IS_E_SCOPE: -1.459407370195412e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.092727549348373e-05\n",
            "Total Loss: 1.216232747646186e-06\n",
            "----------------------------------------\n",
            "Epoch 965\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.7102057067126366e-06\n",
            "E_s_wdiff_all_sq: 3.3284403236487222e-06\n",
            "E_IS_SCOPE: -5.233071331256375e-07\n",
            "E_IS_E_SCOPE: -1.4174008714599266e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.9173590009059395e-05\n",
            "Total Loss: 1.216205960185878e-06\n",
            "----------------------------------------\n",
            "Epoch 966\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6524860925252978e-06\n",
            "E_s_wdiff_all_sq: 3.2709116430607978e-06\n",
            "E_IS_SCOPE: -5.249981338827692e-07\n",
            "E_IS_E_SCOPE: -1.4352705318743676e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.99196118157739e-05\n",
            "Total Loss: 1.2162069571550892e-06\n",
            "----------------------------------------\n",
            "Epoch 967\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5959529938128357e-06\n",
            "E_s_wdiff_all_sq: 3.2145692789193275e-06\n",
            "E_IS_SCOPE: -5.389154172193007e-07\n",
            "E_IS_E_SCOPE: -1.5753967128825303e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.576959353334666e-05\n",
            "Total Loss: 1.2162068921126667e-06\n",
            "----------------------------------------\n",
            "Epoch 968\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.636042994066732e-06\n",
            "E_s_wdiff_all_sq: 3.254520436387546e-06\n",
            "E_IS_SCOPE: -5.259860748435116e-07\n",
            "E_IS_E_SCOPE: -1.4452667019145197e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.033693148837122e-05\n",
            "Total Loss: 1.2161784174563194e-06\n",
            "----------------------------------------\n",
            "Epoch 969\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.697382869795578e-06\n",
            "E_s_wdiff_all_sq: 3.315625806835418e-06\n",
            "E_IS_SCOPE: -5.211370020671035e-07\n",
            "E_IS_E_SCOPE: -1.3954746535179387e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.8258215214903885e-05\n",
            "Total Loss: 1.2161526586107937e-06\n",
            "----------------------------------------\n",
            "Epoch 970\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.7368191720156007e-06\n",
            "E_s_wdiff_all_sq: 3.3549946939291348e-06\n",
            "E_IS_SCOPE: -5.171794566308374e-07\n",
            "E_IS_E_SCOPE: -1.355679370585e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.659684347174787e-05\n",
            "Total Loss: 1.2161761080230453e-06\n",
            "----------------------------------------\n",
            "Epoch 971\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.687849857049869e-06\n",
            "E_s_wdiff_all_sq: 3.306127458143372e-06\n",
            "E_IS_SCOPE: -5.390551948380972e-07\n",
            "E_IS_E_SCOPE: -1.5749251322628517e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.574990600612202e-05\n",
            "Total Loss: 1.2161717047641272e-06\n",
            "----------------------------------------\n",
            "Epoch 972\n",
            "Var loss:  tensor(1.2161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6626955715882265e-06\n",
            "E_s_wdiff_all_sq: 3.2810878178518703e-06\n",
            "E_IS_SCOPE: -5.259996192190921e-07\n",
            "E_IS_E_SCOPE: -1.4446453310912176e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.0310990526232674e-05\n",
            "Total Loss: 1.2161122505976684e-06\n",
            "----------------------------------------\n",
            "Epoch 973\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6642954936289523e-06\n",
            "E_s_wdiff_all_sq: 3.282583597003828e-06\n",
            "E_IS_SCOPE: -5.030313421534562e-07\n",
            "E_IS_E_SCOPE: -1.21490959646992e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.071999305710555e-05\n",
            "Total Loss: 1.21620580069345e-06\n",
            "----------------------------------------\n",
            "Epoch 974\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.5988393961335296e-06\n",
            "E_s_wdiff_all_sq: 3.21738136290565e-06\n",
            "E_IS_SCOPE: -5.502321023246093e-07\n",
            "E_IS_E_SCOPE: -1.6879643853027576e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.04690638315466e-05\n",
            "Total Loss: 1.2161613747204652e-06\n",
            "----------------------------------------\n",
            "Epoch 975\n",
            "Var loss:  tensor(1.2161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.660971359038298e-06\n",
            "E_s_wdiff_all_sq: 3.279338642414807e-06\n",
            "E_IS_SCOPE: -5.362178774863808e-07\n",
            "E_IS_E_SCOPE: -1.546614585872684e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.456799854525053e-05\n",
            "Total Loss: 1.2160945479065196e-06\n",
            "----------------------------------------\n",
            "Epoch 976\n",
            "Var loss:  tensor(1.2161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.7422259798157455e-06\n",
            "E_s_wdiff_all_sq: 3.3602486860012115e-06\n",
            "E_IS_SCOPE: -5.046733212800397e-07\n",
            "E_IS_E_SCOPE: -1.2296785177452294e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.133656534093736e-05\n",
            "Total Loss: 1.2161410238847534e-06\n",
            "----------------------------------------\n",
            "Epoch 977\n",
            "Var loss:  tensor(1.2161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.70792858056595e-06\n",
            "E_s_wdiff_all_sq: 3.32626500190611e-06\n",
            "E_IS_SCOPE: -5.211203173252601e-07\n",
            "E_IS_E_SCOPE: -1.3955741567354888e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.826236927090769e-05\n",
            "Total Loss: 1.2161124444376716e-06\n",
            "----------------------------------------\n",
            "Epoch 978\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6177333136913882e-06\n",
            "E_s_wdiff_all_sq: 3.2362333782041864e-06\n",
            "E_IS_SCOPE: -5.597960105032835e-07\n",
            "E_IS_E_SCOPE: -1.7837420080945167e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -7.446758386722595e-05\n",
            "Total Loss: 1.2162309851807907e-06\n",
            "----------------------------------------\n",
            "Epoch 979\n",
            "Var loss:  tensor(1.2162e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6740293808071137e-06\n",
            "E_s_wdiff_all_sq: 3.292534990090493e-06\n",
            "E_IS_SCOPE: -5.099175135923693e-07\n",
            "E_IS_E_SCOPE: -1.284727114099173e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.363473175018142e-05\n",
            "Total Loss: 1.2161794554329694e-06\n",
            "----------------------------------------\n",
            "Epoch 980\n",
            "Var loss:  tensor(1.2161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.649302512867409e-06\n",
            "E_s_wdiff_all_sq: 3.267759627906856e-06\n",
            "E_IS_SCOPE: -5.287606369779853e-07\n",
            "E_IS_E_SCOPE: -1.472325825455152e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.146659460248278e-05\n",
            "Total Loss: 1.2160614451768663e-06\n",
            "----------------------------------------\n",
            "Epoch 981\n",
            "Var loss:  tensor(1.2160e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6671018309682223e-06\n",
            "E_s_wdiff_all_sq: 3.2853530684710523e-06\n",
            "E_IS_SCOPE: -5.271367692391901e-07\n",
            "E_IS_E_SCOPE: -1.454890704998791e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.073871395106154e-05\n",
            "Total Loss: 1.2160280340998014e-06\n",
            "----------------------------------------\n",
            "Epoch 982\n",
            "Var loss:  tensor(1.2161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.7112328737351e-06\n",
            "E_s_wdiff_all_sq: 3.329254161107991e-06\n",
            "E_IS_SCOPE: -5.049715719542703e-07\n",
            "E_IS_E_SCOPE: -1.2324594940723686e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.145266541983566e-05\n",
            "Total Loss: 1.2161021366142952e-06\n",
            "----------------------------------------\n",
            "Epoch 983\n",
            "Var loss:  tensor(1.2161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.654409826705639e-06\n",
            "E_s_wdiff_all_sq: 3.272640180042604e-06\n",
            "E_IS_SCOPE: -5.428829394802881e-07\n",
            "E_IS_E_SCOPE: -1.6124674128512791e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.731721950527101e-05\n",
            "Total Loss: 1.2160719193539683e-06\n",
            "----------------------------------------\n",
            "Epoch 984\n",
            "Var loss:  tensor(1.2160e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6719197813755185e-06\n",
            "E_s_wdiff_all_sq: 3.2901047162225937e-06\n",
            "E_IS_SCOPE: -5.32196151875193e-07\n",
            "E_IS_E_SCOPE: -1.505161487781414e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.283741640688088e-05\n",
            "Total Loss: 1.2160297280400754e-06\n",
            "----------------------------------------\n",
            "Epoch 985\n",
            "Var loss:  tensor(1.2161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.7131434158586357e-06\n",
            "E_s_wdiff_all_sq: 3.3311283483318557e-06\n",
            "E_IS_SCOPE: -5.044928038902993e-07\n",
            "E_IS_E_SCOPE: -1.2272390757099456e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.123472362081899e-05\n",
            "Total Loss: 1.216051943969424e-06\n",
            "----------------------------------------\n",
            "Epoch 986\n",
            "Var loss:  tensor(1.2160e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6604054784388e-06\n",
            "E_s_wdiff_all_sq: 3.2786045352487557e-06\n",
            "E_IS_SCOPE: -5.322868569997704e-07\n",
            "E_IS_E_SCOPE: -1.5059184570885797e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.286901832863329e-05\n",
            "Total Loss: 1.2159855896894717e-06\n",
            "----------------------------------------\n",
            "Epoch 987\n",
            "Var loss:  tensor(1.2160e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.665311289633397e-06\n",
            "E_s_wdiff_all_sq: 3.2835956513456434e-06\n",
            "E_IS_SCOPE: -5.218919723787402e-07\n",
            "E_IS_E_SCOPE: -1.4022502838325106e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.854108393493964e-05\n",
            "Total Loss: 1.2159564193780277e-06\n",
            "----------------------------------------\n",
            "Epoch 988\n",
            "Var loss:  tensor(1.2160e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.683138839870606e-06\n",
            "E_s_wdiff_all_sq: 3.3013793942012015e-06\n",
            "E_IS_SCOPE: -5.096227816847032e-07\n",
            "E_IS_E_SCOPE: -1.2794362116855053e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.341384738605524e-05\n",
            "Total Loss: 1.2159757937183513e-06\n",
            "----------------------------------------\n",
            "Epoch 989\n",
            "Var loss:  tensor(1.2159e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.668769682520901e-06\n",
            "E_s_wdiff_all_sq: 3.2870031358963905e-06\n",
            "E_IS_SCOPE: -5.270825891173549e-07\n",
            "E_IS_E_SCOPE: -1.4538352540774792e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.069465103184797e-05\n",
            "Total Loss: 1.2159430882865488e-06\n",
            "----------------------------------------\n",
            "Epoch 990\n",
            "Var loss:  tensor(1.2160e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.678161305996406e-06\n",
            "E_s_wdiff_all_sq: 3.2963136777988686e-06\n",
            "E_IS_SCOPE: -5.325081204563811e-07\n",
            "E_IS_E_SCOPE: -1.5078041882095543e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.294774374955457e-05\n",
            "Total Loss: 1.2159668940079404e-06\n",
            "----------------------------------------\n",
            "Epoch 991\n",
            "Var loss:  tensor(1.2160e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.699871329729348e-06\n",
            "E_s_wdiff_all_sq: 3.3179017561653832e-06\n",
            "E_IS_SCOPE: -5.22969808384739e-07\n",
            "E_IS_E_SCOPE: -1.4118409338302303e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.894147397442149e-05\n",
            "Total Loss: 1.2159728126417866e-06\n",
            "----------------------------------------\n",
            "Epoch 992\n",
            "Var loss:  tensor(1.2160e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.684093836701436e-06\n",
            "E_s_wdiff_all_sq: 3.302143941218306e-06\n",
            "E_IS_SCOPE: -5.23817464472069e-07\n",
            "E_IS_E_SCOPE: -1.4203678270842868e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.929745434357905e-05\n",
            "Total Loss: 1.2159632010371031e-06\n",
            "----------------------------------------\n",
            "Epoch 993\n",
            "Var loss:  tensor(1.2159e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6539404870684016e-06\n",
            "E_s_wdiff_all_sq: 3.2720843979228615e-06\n",
            "E_IS_SCOPE: -5.26838171072176e-07\n",
            "E_IS_E_SCOPE: -1.4509536901738848e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.057435162717738e-05\n",
            "Total Loss: 1.2159451541172181e-06\n",
            "----------------------------------------\n",
            "Epoch 994\n",
            "Var loss:  tensor(1.2159e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6523921389529976e-06\n",
            "E_s_wdiff_all_sq: 3.2705628933915796e-06\n",
            "E_IS_SCOPE: -5.193282327866928e-07\n",
            "E_IS_E_SCOPE: -1.375835020175885e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.743830065529596e-05\n",
            "Total Loss: 1.2159144531044632e-06\n",
            "----------------------------------------\n",
            "Epoch 995\n",
            "Var loss:  tensor(1.2159e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.662819945659009e-06\n",
            "E_s_wdiff_all_sq: 3.2809879528061225e-06\n",
            "E_IS_SCOPE: -5.209511533484687e-07\n",
            "E_IS_E_SCOPE: -1.3918632310631298e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.810744570714263e-05\n",
            "Total Loss: 1.2158770014498287e-06\n",
            "----------------------------------------\n",
            "Epoch 996\n",
            "Var loss:  tensor(1.2158e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6889836732233674e-06\n",
            "E_s_wdiff_all_sq: 3.3071139031427367e-06\n",
            "E_IS_SCOPE: -5.23275652137577e-07\n",
            "E_IS_E_SCOPE: -1.4147467903099345e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.9062787544504225e-05\n",
            "Total Loss: 1.2158424929487161e-06\n",
            "----------------------------------------\n",
            "Epoch 997\n",
            "Var loss:  tensor(1.2159e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.735881006197236e-06\n",
            "E_s_wdiff_all_sq: 3.3538786320945985e-06\n",
            "E_IS_SCOPE: -5.067595848066407e-07\n",
            "E_IS_E_SCOPE: -1.2491389434499352e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.214899834788614e-05\n",
            "Total Loss: 1.2158856622605964e-06\n",
            "----------------------------------------\n",
            "Epoch 998\n",
            "Var loss:  tensor(1.2158e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6941554411628478e-06\n",
            "E_s_wdiff_all_sq: 3.3122240552637444e-06\n",
            "E_IS_SCOPE: -5.304471309369699e-07\n",
            "E_IS_E_SCOPE: -1.486153977778993e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -6.204389170499618e-05\n",
            "Total Loss: 1.2158425886622152e-06\n",
            "----------------------------------------\n",
            "Epoch 999\n",
            "Var loss:  tensor(1.2159e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.6766216238448746e-06\n",
            "E_s_wdiff_all_sq: 3.294729430349551e-06\n",
            "E_IS_SCOPE: -5.245207616204289e-07\n",
            "E_IS_E_SCOPE: -1.427149442752055e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.958057293988004e-05\n",
            "Total Loss: 1.2158552278861307e-06\n",
            "----------------------------------------\n",
            "Epoch 1000\n",
            "Var loss:  tensor(1.2159e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.335165240584429e-06\n",
            "E_IS_all_sq: 5.737590571503175e-06\n",
            "E_s_wdiff_sq: 3.656004017010653e-06\n",
            "E_s_wdiff_all_sq: 3.274164378604106e-06\n",
            "E_IS_SCOPE: -5.211769573262327e-07\n",
            "E_IS_E_SCOPE: -1.3940216109436397e-07\n",
            "E_IS: 0.002395326819351208\n",
            "E_SCOPE: -5.819755365663298e-05\n",
            "Total Loss: 1.2158647150240635e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1033,  0.3019],\n",
            "        [ 0.5926, -0.5289],\n",
            "        [-0.0836, -0.5419],\n",
            "        [ 0.3137, -0.1360]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.3917, -0.2440, -0.6192, -0.3935], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.0047,  0.4741,  0.1776,  0.4629],\n",
            "        [-0.0177, -0.4446, -0.1491, -0.2068],\n",
            "        [-0.2918,  0.3167,  0.4459, -0.4529],\n",
            "        [-0.5238, -0.0424,  0.1372,  0.4130]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0192,  0.1064, -0.2219,  0.0005], dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1290, -0.0073,  0.2749,  0.6352]], dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0024], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_good.eval()\n",
        "# Loop through all combinations from [0,0] to [9,9]\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        # Prepare input data\n",
        "        input_data = torch.tensor([i, j], dtype=torch.float64)\n",
        "\n",
        "        # Pass input through the model_good\n",
        "        output = model_good(input_data)\n",
        "\n",
        "        print(f'Input: [{i}, {j}], Output: {output.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIZoe_PpgR5t",
        "outputId": "a69c9edc-1ae4-41fe-c049-6c065cd13217"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0, 0], Output: 0.0019660993297336716\n",
            "Input: [0, 1], Output: 0.0019660993297336716\n",
            "Input: [0, 2], Output: 0.0012663355224667334\n",
            "Input: [0, 3], Output: 0.0013732327753823586\n",
            "Input: [0, 4], Output: 0.001474233850085409\n",
            "Input: [0, 5], Output: 0.0015752349247884591\n",
            "Input: [0, 6], Output: 0.001676235999491509\n",
            "Input: [0, 7], Output: 0.0017772370741945592\n",
            "Input: [0, 8], Output: 0.0018782381488976095\n",
            "Input: [0, 9], Output: 0.0019792392236006595\n",
            "Input: [1, 0], Output: -0.01967680531202127\n",
            "Input: [1, 1], Output: 0.0019660993297336716\n",
            "Input: [1, 2], Output: 0.0012220106327563932\n",
            "Input: [1, 3], Output: 0.0013429294858047745\n",
            "Input: [1, 4], Output: 0.0014439305605078246\n",
            "Input: [1, 5], Output: 0.0015449316352108748\n",
            "Input: [1, 6], Output: 0.001645932709913925\n",
            "Input: [1, 7], Output: 0.0017469337846169751\n",
            "Input: [1, 8], Output: 0.0018479348593200252\n",
            "Input: [1, 9], Output: 0.0019489359340230752\n",
            "Input: [2, 0], Output: -0.034917623104704004\n",
            "Input: [2, 1], Output: -0.015269047045321876\n",
            "Input: [2, 2], Output: 0.0011776857430460528\n",
            "Input: [2, 3], Output: 0.0013126261962271904\n",
            "Input: [2, 4], Output: 0.0014136272709302405\n",
            "Input: [2, 5], Output: 0.0015146283456332905\n",
            "Input: [2, 6], Output: 0.0016156294203363405\n",
            "Input: [2, 7], Output: 0.0017166304950393908\n",
            "Input: [2, 8], Output: 0.0018176315697424408\n",
            "Input: [2, 9], Output: 0.0019186326444454909\n",
            "Input: [3, 0], Output: -0.017227589177864707\n",
            "Input: [3, 1], Output: -0.0055337673459431675\n",
            "Input: [3, 2], Output: 0.01411480871343895\n",
            "Input: [3, 3], Output: -0.007064419454956246\n",
            "Input: [3, 4], Output: 0.0007781430770980235\n",
            "Input: [3, 5], Output: 0.0014843250560557062\n",
            "Input: [3, 6], Output: 0.0015853261307587564\n",
            "Input: [3, 7], Output: 0.0016863272054618067\n",
            "Input: [3, 8], Output: 0.0017873282801648567\n",
            "Input: [3, 9], Output: 0.0018883293548679066\n",
            "Input: [4, 0], Output: 0.005787403517779709\n",
            "Input: [4, 1], Output: 0.004201512353435526\n",
            "Input: [4, 2], Output: 0.02385008841281765\n",
            "Input: [4, 3], Output: -0.01539694721734643\n",
            "Input: [4, 4], Output: -0.02081398082327444\n",
            "Input: [4, 5], Output: -0.009649432139426602\n",
            "Input: [4, 6], Output: -0.0018068696073723321\n",
            "Input: [4, 7], Output: 0.0016560239158842222\n",
            "Input: [4, 8], Output: 0.0017570249905872726\n",
            "Input: [4, 9], Output: 0.0018580260652903224\n",
            "Input: [5, 0], Output: 0.028802396213424123\n",
            "Input: [5, 1], Output: 0.018745973926204477\n",
            "Input: [5, 2], Output: 0.03358536811219632\n",
            "Input: [5, 3], Output: 0.025428385385048758\n",
            "Input: [5, 4], Output: -0.0585464008885531\n",
            "Input: [5, 5], Output: -0.03613414283594946\n",
            "Input: [5, 6], Output: -0.02007700735595123\n",
            "Input: [5, 7], Output: -0.012234444823896958\n",
            "Input: [5, 8], Output: -0.00439188229184268\n",
            "Input: [5, 9], Output: 0.0018277227757127383\n",
            "Input: [6, 0], Output: 0.051817388909068514\n",
            "Input: [6, 1], Output: 0.04176096662184892\n",
            "Input: [6, 2], Output: 0.043320647811575026\n",
            "Input: [6, 3], Output: 0.06296922387095719\n",
            "Input: [6, 4], Output: -0.017721068286157948\n",
            "Input: [6, 5], Output: -0.09296200652136077\n",
            "Input: [6, 6], Output: -0.05183244163563453\n",
            "Input: [6, 7], Output: -0.03064536190973961\n",
            "Input: [6, 8], Output: -0.02266202004042159\n",
            "Input: [6, 9], Output: -0.014819457508367315\n",
            "Input: [7, 0], Output: 0.0748323816047129\n",
            "Input: [7, 1], Output: 0.0647759593174933\n",
            "Input: [7, 2], Output: 0.05471953703027372\n",
            "Input: [7, 3], Output: 0.0727045035703359\n",
            "Input: [7, 4], Output: 0.023104264316237275\n",
            "Input: [7, 5], Output: -0.060870521957364566\n",
            "Input: [7, 6], Output: -0.10866030532104579\n",
            "Input: [7, 7], Output: -0.06753074043531956\n",
            "Input: [7, 8], Output: -0.04166075639865607\n",
            "Input: [7, 9], Output: -0.03360871961112673\n",
            "Input: [8, 0], Output: 0.09784737430035728\n",
            "Input: [8, 1], Output: 0.08779095201313769\n",
            "Input: [8, 2], Output: 0.07773452972591804\n",
            "Input: [8, 3], Output: 0.08243978326971457\n",
            "Input: [8, 4], Output: 0.06392959691863248\n",
            "Input: [8, 5], Output: -0.020045189354969375\n",
            "Input: [8, 6], Output: -0.10401997562857124\n",
            "Input: [8, 7], Output: -0.12435860412073083\n",
            "Input: [8, 8], Output: -0.08322903923500458\n",
            "Input: [8, 9], Output: -0.05267615088757251\n",
            "Input: [9, 0], Output: 0.12086236699600161\n",
            "Input: [9, 1], Output: 0.11080594470878202\n",
            "Input: [9, 2], Output: 0.10074952242156249\n",
            "Input: [9, 3], Output: 0.09217506296909311\n",
            "Input: [9, 4], Output: 0.10475492952102766\n",
            "Input: [9, 5], Output: 0.02078014324742578\n",
            "Input: [9, 6], Output: -0.063194643026176\n",
            "Input: [9, 7], Output: -0.147169429299778\n",
            "Input: [9, 8], Output: -0.14005690292041587\n",
            "Input: [9, 9], Output: -0.09892733803468959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.main_deaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glEeJzizrW4F",
        "outputId": "34f26042-3c3b-40dc-af35-ef2a82f0d3c6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 0],\n",
              " [9, 1],\n",
              " [9, 2],\n",
              " [9, 3],\n",
              " [9, 4],\n",
              " [9, 5],\n",
              " [9, 6],\n",
              " [9, 7],\n",
              " [9, 8],\n",
              " [9, 9],\n",
              " [8, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.dead_ends"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juL0M8E1rt4X",
        "outputId": "6f07d59b-2c7e-4ff3-f998-16e79f88a92e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 5],\n",
              " [5, 6],\n",
              " [5, 7],\n",
              " [5, 8],\n",
              " [5, 9],\n",
              " [6, 5],\n",
              " [6, 6],\n",
              " [6, 7],\n",
              " [6, 8],\n",
              " [6, 9],\n",
              " [7, 5],\n",
              " [7, 6],\n",
              " [7, 7],\n",
              " [7, 8],\n",
              " [7, 9],\n",
              " [8, 5],\n",
              " [8, 6],\n",
              " [8, 7],\n",
              " [8, 8],\n",
              " [8, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize an empty matrix to store the outputs\n",
        "outputs = np.zeros((10, 10))\n",
        "\n",
        "# Evaluate the model\n",
        "model_good.eval()\n",
        "\n",
        "# Loop through all combinations from [0,0] to [9,9]\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        # Prepare input data\n",
        "        input_data = torch.tensor([i, j], dtype=torch.float64)\n",
        "\n",
        "        # Pass input through the model\n",
        "        output = model_good(input_data)\n",
        "\n",
        "        # Store the output in the matrix\n",
        "        outputs[i, j] = output.item()\n",
        "\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(outputs, cmap='viridis', interpolation='nearest')\n",
        "plt.colorbar(label='Model Output')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('Heatmap of Model Output for Inputs (0,0) to (9,9)')\n",
        "plt.xticks(np.arange(0, 10), np.arange(0, 10))\n",
        "plt.yticks(np.arange(0, 10), np.arange(0, 10))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iAHSEtPkm3BV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK5WXqsJyp52",
        "outputId": "22e27ca3-a1ec-43fc-e3c9-f75465514edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doVlelxUzTZb",
        "outputId": "cd3fa2e2-2785-45e6-c629-d67ba91c4ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python310.zip',\n",
              " '/usr/lib/python3.10',\n",
              " '/usr/lib/python3.10/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.10/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.10/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/med-deadend/lifegate',\n",
              " '/content/Shaping/']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Viz"
      ],
      "metadata": {
        "id": "5ebPved71VIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create a dictionary with your data_output\n",
        "data_output = {\n",
        "    (0, 0): -0.07629156999575247, (0, 1): -0.0739922092557846, (0, 2): -0.06806199866049831, (0, 3): -0.06235090685494622, (0, 4): -0.05949649182707813, (0, 5): -0.05143036594780265, (0, 6): -0.039687894662760605, (0, 7): -0.0222229054842613, (0, 8): -0.011280308962696467, (0, 9): -0.0010591331534844928,\n",
        "    (1, 0): -0.07008427242278334, (1, 1): -0.06905842247901874, (1, 2): -0.0562396368370548, (1, 3): -0.04960020307044715, (1, 4): -0.049833296583263666, (1, 5): -0.04728215802309056, (1, 6): -0.042456905229073034, (1, 7): -0.03477634094197894, (1, 8): -0.02987845160003986, (1, 9): -0.022265104715127798,\n",
        "    (2, 0): -0.07764794928878793, (2, 1): -0.06202518684583705, (2, 2): -0.063303731579275, (2, 3): -0.05810317532715738, (2, 4): -0.04599925353341212, (2, 5): -0.0367768825058605, (2, 6): -0.033705717686027856, (2, 7): -0.031483801300259795, (2, 8): -0.03123791868675637, (2, 9): -0.029122144606675934,\n",
        "    (3, 0): -0.09361826254100514, (3, 1): -0.05135868230310183, (3, 2): -0.05485157285291843, (3, 3): -0.05702303838969039, (3, 4): -0.058456502152256146, (3, 5): -0.048305716653036235, (3, 6): -0.03648913058537322, (3, 7): -0.026657681083433846, (3, 8): -0.02115186714074907, (3, 9): -0.01652270780268504,\n",
        "    (4, 0): -0.11562832635499312, (4, 1): -0.05389101306363135, (4, 2): -0.044185068310183234, (4, 3): -0.047088697455768054, (4, 4): -0.048914111531389935, (4, 5): -0.050739525607011816, (4, 6): -0.04556883794383963, (4, 7): -0.03746410522021048, (4, 8): -0.026979007637334386, (4, 9): -0.01652593338976059,\n",
        "    (5, 0): -0.13596369941006214, (5, 1): -0.06702648233939557, (5, 2): -0.04712562963799444, (5, 3): -0.03701145431726459, (5, 4): -0.038979770597467635, (5, 5): -0.04080518467308947, (5, 6): -0.04263059874871137, (5, 7): -0.04135601287382022, (5, 8): -0.033251280150191076, (5, 9): -0.025146547426561923,\n",
        "    (6, 0): -0.156536015027422, (6, 1): -0.08703446648178848, (6, 2): -0.050615736199362785, (6, 3): -0.04036024621235747, (6, 4): -0.029312345564551534, (6, 5): -0.030870843739167153, (6, 6): -0.032696257814788965, (6, 7): -0.03452167189041089, (6, 8): -0.036543960778629515, (6, 9): -0.029038455080171707,\n",
        "    (7, 0): -0.17715162872726267, (7, 1): -0.10704245062418155, (7, 2): -0.05410584276073107, (7, 3): -0.04385035277372574, (7, 4): -0.03353461573473268, (7, 5): -0.021611649273532624, (7, 6): -0.02276191688086676, (7, 7): -0.024587330956488587, (7, 8): -0.026412745032110392, (7, 9): -0.028435775876834886,\n",
        "    (8, 0): -0.19776724242710345, (8, 1): -0.12705043476657463, (8, 2): -0.05811321769590784, (8, 3): -0.04734045933509399, (8, 4): -0.0370849693480888, (8, 5): -0.02583391944371382, (8, 6): -0.01391095298251381, (8, 7): -0.014652990022566204, (8, 8): -0.016478404098188085, (8, 9): -0.018303818173809855,\n",
        "    (9, 0): -0.21667245100237648, (9, 1): -0.14751551169818272, (9, 2): -0.07812120183830093, (9, 3): -0.050830565896462405, (9, 4): -0.04057507590945697, (9, 5): -0.03005618961389496, (9, 6): -0.01813322315269497, (9, 7): -0.006210256691494956, (9, 8): -0.006544063164265673, (9, 9): -0.008369477239887596\n",
        "}\n",
        "\n",
        "# Create a numpy array to hold the data_output values_output\n",
        "values_output = np.zeros((10, 10))\n",
        "for (x, y), value in data_output.items():\n",
        "    values_output[y, x] = value\n",
        "\n",
        "# Create the heatmap\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(values_output, cmap='hot')\n",
        "\n",
        "# Add colorbar\n",
        "cbar = ax.figure.colorbar(im, ax=ax)\n",
        "cbar.ax.set_ylabel('Values', rotation=-90, va=\"bottom\")\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xticks(np.arange(10))\n",
        "ax.set_yticks(np.arange(10))\n",
        "ax.set_xticklabels(range(10))\n",
        "ax.set_yticklabels(range(10))\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_title('Heatmap')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zusXKCNNuhk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnxf3zTo5yNp",
        "outputId": "e5631651-31b9-4ebe-961d-87c53a35f4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python310.zip',\n",
              " '/usr/lib/python3.10',\n",
              " '/usr/lib/python3.10/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.10/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.10/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/med-deadend/lifegate',\n",
              " '/content/Shaping/']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "LRcpZ6zAowqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "jqKcMhNSnRTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IS_tensor, samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor = test1.prepare()\n",
        "\n",
        "# Modified class with bootstrap_all_terms\n",
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor = test1.prepare()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "uftstgp1nRTP",
        "outputId": "37784d3c-0119-4de4-b402-83f755d3e636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 6)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-085bf38dcdb8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Modified class with bootstrap_all_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mIS_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_weight_diff_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_weights_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 6)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = test1.prep_policies()"
      ],
      "metadata": {
        "id": "IG7OqI1kuQ7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)\n",
        "\n",
        "\n",
        "# sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n"
      ],
      "metadata": {
        "id": "-AlHoAZwi9Dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "IS_SCOPE_1 = IS_tensor*sum_terms"
      ],
      "metadata": {
        "id": "Gspo0QLFDzTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdImElYSD_rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "E_IS_SCOPE_2 = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "E_IS_E_SCOPE_2 = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))"
      ],
      "metadata": {
        "id": "mZ_xYyhiCxe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_SCOPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGY9Jt3FDHKZ",
        "outputId": "4806bfd5-cc2a-40dc-9cf1-f9e471dfaf85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.1470e+24, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_SCOPE_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbttxO_jDJGy",
        "outputId": "a0767c9a-54f3-4b4a-878c-f97fde383d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.5943e+26, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS_SCOPE[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtJJjUv-Ctv9",
        "outputId": "30a2eb29-85cd-42f7-913a-422b80b5c82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -2.5405e-85,  -0.0000e+00,   7.9024e-62,  -2.9790e-61,  -3.1831e-75,\n",
              "         -1.5365e-64,  -0.0000e+00,  -8.3521e-71,   9.1314e-24,  -6.9648e-66,\n",
              "        -2.0605e-135,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.5136e-54,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "          0.0000e+00,   7.9024e-62,   0.0000e+00,  -0.0000e+00,  2.1164e-111,\n",
              "        -9.5684e-135,  -0.0000e+00, -1.4140e-116,  -3.3219e-82,  -0.0000e+00,\n",
              "         -1.5197e-87,  -2.5695e-67,   5.3077e-82,  -0.0000e+00,   2.3741e-47,\n",
              "         -0.0000e+00,  -1.8253e-71,  -3.4879e+11,  -0.0000e+00,  -0.0000e+00,\n",
              "         3.8146e-114,  -0.0000e+00,  -7.5975e-31,  1.2321e-124,  -0.0000e+00,\n",
              "         -0.0000e+00, -2.0958e-170,   0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.0845e-110,  -1.8398e-69,  -1.8253e-71,   0.0000e+00,\n",
              "         -1.0142e-82,  -3.8087e-71, -4.7846e-116,  -0.0000e+00,  -1.1575e+14,\n",
              "         -8.3983e-61,  -0.0000e+00,  -3.5652e-20,  -4.5806e-83,  -4.3459e-47,\n",
              "         -8.4544e-60,  -0.0000e+00,  -8.8170e-22,  -0.0000e+00,  -0.0000e+00,\n",
              "          1.2354e-36,  -1.5363e-35,  -0.0000e+00, -4.9603e-128,  -0.0000e+00,\n",
              "         -6.3533e-43,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -1.5943e-87,\n",
              "         -3.5388e-13,  -0.0000e+00,  -4.5280e-49,  -1.8006e-40,  -1.9589e-72,\n",
              "         -0.0000e+00,  -1.6958e-50,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -6.2039e-105,  -0.0000e+00, -2.1867e-103, -5.2111e-109,  -9.0234e-81,\n",
              "        -7.3637e-125,  -0.0000e+00, -4.3031e-114,  -0.0000e+00,  -0.0000e+00,\n",
              "         -9.0569e-20, -4.9603e-128,  -0.0000e+00,  -0.0000e+00,  -1.2844e-50,\n",
              "          6.8821e-47,  -0.0000e+00,  -0.0000e+00,  -3.6297e-43,  -1.2560e-81,\n",
              "         -0.0000e+00,  -9.6121e-75,  -0.0000e+00,  -0.0000e+00,  -4.7752e-22,\n",
              "         -0.0000e+00,  -8.8170e-22,  -0.0000e+00,  -0.0000e+00,  -3.1837e-84,\n",
              "         -1.1765e-76,  -0.0000e+00,  -1.2844e-50, -7.3798e-163,  -2.0995e-92,\n",
              "         -0.0000e+00, -2.1867e-103,  -0.0000e+00,  -5.9858e-99,  -0.0000e+00,\n",
              "        -3.8876e-136,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -5.4505e-63,\n",
              "         -1.7515e-70,  -0.0000e+00,  -4.5557e-54,  -0.0000e+00,   1.7970e-29,\n",
              "         -4.4059e-35,  -1.8068e-87,  -4.7919e-84,  -1.2284e-23,  -1.5365e-64,\n",
              "          7.8287e-64,  -0.0000e+00,   0.0000e+00,  -2.5680e-16,  1.0151e-134,\n",
              "          5.4627e-50,  -2.1715e-71,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,   2.3966e-44, -4.9603e-128,  -8.2095e-86,  -2.6167e-27,\n",
              "         -6.9755e-72,  -2.5695e-67,  -1.7051e-55, -3.8876e-136,  -1.0863e-21,\n",
              "         9.3247e-114,  -4.4059e-35, -5.3088e-177,  -1.7168e-40,  -0.0000e+00,\n",
              "         -9.1651e-07,  -0.0000e+00,  -0.0000e+00,  -5.1282e-98,  -2.1147e-36,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,   3.2571e-55,\n",
              "          0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -2.5695e-67,\n",
              "         -3.3292e-89,  -0.0000e+00,  -0.0000e+00,   0.0000e+00, -5.9574e-107,\n",
              "         -6.7180e-81,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00, -2.2899e-120,\n",
              "         -1.2131e-90,  -1.1847e-05,  -0.0000e+00,  -0.0000e+00,   5.6168e-64,\n",
              "         -0.0000e+00,  -0.0000e+00,  -7.5275e-79,  -3.9772e-98, -1.4124e-115,\n",
              "          6.7779e-24,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.4915e-62,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -4.7835e-21,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -7.4818e-121,  -1.4379e-56,  -5.9858e-99,   6.5353e-19,\n",
              "         -0.0000e+00, -1.0845e-110,  -1.6331e-73,  -0.0000e+00,  -3.3794e-44,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.4403e-82,  -0.0000e+00,  -8.2958e-38,\n",
              "         -0.0000e+00,  -2.1267e-31,  -2.0919e-39,  -6.2543e-89,  -7.2344e-89,\n",
              "         -0.0000e+00, -7.4410e-122,  -0.0000e+00,  -9.2244e-29,  -7.6267e-28,\n",
              "         -0.0000e+00,  -1.4441e-84,  -3.4686e-46,  -0.0000e+00,   1.5539e-32,\n",
              "         -0.0000e+00,   2.8584e-70,  -0.0000e+00, -6.7465e-145,   2.3744e-38,\n",
              "         -1.0969e-41,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.6507e-76,  -0.0000e+00, -6.5637e-111,  -0.0000e+00,  -1.0553e-59,\n",
              "         -6.3674e-30,  -0.0000e+00,  -1.1992e-76, -8.8087e-109,  -0.0000e+00,\n",
              "         -0.0000e+00,  -2.0183e-60,   2.3741e-47,  -0.0000e+00,   6.4848e-87,\n",
              "         -5.4107e-35,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -9.3262e-46,  -0.0000e+00,  -1.0841e-42,  -0.0000e+00,  -3.2018e-02,\n",
              "         -0.0000e+00,  -1.1614e-91,  -0.0000e+00,  -7.3072e-92,  -0.0000e+00,\n",
              "          1.7396e-15, -8.8087e-109,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.3292e-89,  -0.0000e+00,  -1.8096e-45,   1.6171e-12,   2.3741e-47,\n",
              "         -2.1147e-36, -7.3798e-163,  -0.0000e+00,   2.4396e-88,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.7320e-101,   3.5779e-27,  -0.0000e+00,  -3.9346e-91,\n",
              "         -1.4120e-71,  -0.0000e+00,  -0.0000e+00,  -1.1299e-90,  -0.0000e+00,\n",
              "         -0.0000e+00,  -5.2727e-61,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.0228e-11,  2.1164e-111,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.3794e-44, -2.3564e-152,  -0.0000e+00,  -2.5200e-98,  -1.4403e-82,\n",
              "         -0.0000e+00, -1.6503e-110,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5405e-85,  -0.0000e+00,  -0.0000e+00,  -1.7051e-55,  -1.1579e-96,\n",
              "        -1.6503e-110,  -0.0000e+00, -7.9975e-114,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -2.5266e-42,  -3.2963e-38,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.3348e-146,  -7.9739e-71,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.6331e-73,  -1.2096e-60,  -4.9155e-49,  -0.0000e+00,\n",
              "         -8.5756e-93,  -0.0000e+00, -2.3319e-135,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,   2.0816e+09,  -3.3419e-33,  -0.0000e+00,\n",
              "         -9.5822e-03,  -0.0000e+00, -3.0795e-106,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.1765e-76,  -0.0000e+00,  -0.0000e+00,  -1.0841e-42,  -0.0000e+00,\n",
              "         -4.1517e-59,  -1.0295e-65,  -0.0000e+00,  -1.8006e-40,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -8.4740e-76,   0.0000e+00,\n",
              "        -2.9514e-101,  -2.5200e-98, -2.0605e-135,   2.3977e-39,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.6331e-73, -5.5873e-109,  -0.0000e+00,  -1.1992e-76,\n",
              "         -3.1831e-75,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -1.8398e-69,\n",
              "        -1.0896e-137,  -0.0000e+00,  -1.1847e-05,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.8369e-95,  -6.2692e-86,  -0.0000e+00,  -0.0000e+00,   1.9911e-59,\n",
              "         -2.3919e-79, -5.9400e-117,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.3256e-29,  -0.0000e+00,  -0.0000e+00,  -2.9009e-36,\n",
              "        -5.9194e-108,  -1.7051e-55,  -4.4059e-35,  -0.0000e+00, -2.0605e-135,\n",
              "         -1.5469e-21,  -4.4059e-35,  -4.5557e-54,  -0.0000e+00,  -8.7108e-62,\n",
              "         -1.1976e-94,  -1.8848e-48,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -5.2070e-107,  -0.0000e+00,  -2.0882e-86,  -0.0000e+00,  -5.1132e-04,\n",
              "          0.0000e+00,   9.1906e-19,  -3.1091e-65,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -3.7267e-107,  -0.0000e+00,  -4.9777e-77,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -4.1925e-25, -3.0795e-106,  -0.0000e+00,\n",
              "         -0.0000e+00,   0.0000e+00,  -0.0000e+00,  -4.5806e-83,  2.1164e-111,\n",
              "         -2.5200e-98, -4.3088e-113,  -0.0000e+00,  -3.6404e-32,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -9.1264e-43,  -0.0000e+00,\n",
              "         -2.4591e-89,  -0.0000e+00,  -0.0000e+00,   1.9275e-45,  -1.1543e-33,\n",
              "         -1.2560e-81,  -0.0000e+00,  -0.0000e+00,   2.3977e-39, -3.3028e-112,\n",
              "          7.8287e-64,  -0.0000e+00,  -0.0000e+00, -7.7889e-104, -6.3394e-172,\n",
              "         -8.8170e-22, -5.5873e-109,  3.8146e-114,  -0.0000e+00,  3.4576e-143,\n",
              "        -1.3164e-160,  -0.0000e+00,  -1.1579e-96,  -0.0000e+00,  -1.1299e-90,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.1997e-38,  -2.4591e-89,   9.1690e-44,\n",
              "         -2.2622e-69,  -1.2560e-81,  -3.2067e-77,  -3.5388e-13,   2.4880e-25,\n",
              "         -3.5370e-23,   5.4627e-50,  -0.0000e+00, -2.4613e-126,  -0.0000e+00,\n",
              "        -7.9975e-114,  -4.0313e-39,  -0.0000e+00,  -5.2680e-78, -6.3760e-128,\n",
              "         -5.0730e-73,  -9.1651e-07,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -2.2899e-120,   6.4848e-87,  -0.0000e+00,  -0.0000e+00,   1.7396e-15,\n",
              "         -2.4878e-79,  -0.0000e+00, -6.7220e-124,  3.4576e-143,  -5.4505e-63,\n",
              "          0.0000e+00,  -0.0000e+00,  -9.2244e-29,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.8006e-40,  -0.0000e+00,  -0.0000e+00, -3.9715e-111, -7.8048e-109,\n",
              "         -0.0000e+00,  -0.0000e+00,  -6.0378e-78,  -6.9027e-64,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,   0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -4.6446e+26,  -2.8369e-95, -3.7267e-107,\n",
              "         -0.0000e+00,   5.9283e-29,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -5.2111e-109,  -4.9777e-77,  -2.5057e-97,  -0.0000e+00,  -0.0000e+00,\n",
              "         -4.3459e-47,  -0.0000e+00,  -9.6952e-11,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.0423e-88,  -0.0000e+00,  -9.7803e-64,  -0.0000e+00,  -2.6108e-10,\n",
              "         -1.1245e-32,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -1.1614e-91,\n",
              "          5.9283e-29,  -1.8006e-40,  -0.0000e+00,  -1.4581e-42,  -1.9457e-84,\n",
              "          0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.2597e-64,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -7.6267e-28,  -1.1340e-54,  -0.0000e+00,   5.6168e-64,\n",
              "         2.1164e-111,  -1.6117e-70, -1.6001e-142, -7.4188e-119,  -1.6297e-40,\n",
              "         -0.0000e+00, -9.6814e-148,   0.0000e+00,  -4.9886e-56,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -3.5652e-20, -5.6374e-108,  -0.0000e+00,\n",
              "          6.4848e-87,  -0.0000e+00, -1.2228e-108,   9.1690e-44,  -2.4591e-89,\n",
              "        -5.2111e-109, -1.0845e-110,  -0.0000e+00,  -0.0000e+00,  -1.2284e-23,\n",
              "        -1.3276e-126,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -2.5405e-85,  -1.1543e-33,  -6.5620e-73,\n",
              "          9.6998e-75,   2.3966e-44,  -0.0000e+00,  -1.5943e-87,   6.8821e-47,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5695e-67,  -3.9346e-91, -9.5684e-135,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.6503e-110,  -2.4878e-79,  -0.0000e+00,  -1.2096e-60,\n",
              "         -4.9154e-65,  -0.0000e+00,  -0.0000e+00,  -1.6205e-31, -5.9400e-117,\n",
              "         -3.6297e-43, -3.8447e-105,  -2.1245e-84,  -0.0000e+00,  -0.0000e+00,\n",
              "         -5.9911e-37,  -0.0000e+00,  -0.0000e+00,  -2.5057e-97, -2.6928e-118,\n",
              "         -0.0000e+00, -3.7267e-107,  -2.7470e-44, -2.1867e-103,  -5.0835e-67,\n",
              "        -7.4188e-119, -2.9514e-101,  -8.8828e-84, -3.9715e-111,  -5.5407e-09,\n",
              "         -8.3866e-92,  -0.0000e+00,  -3.7204e-20,   1.1578e-36,  -0.0000e+00,\n",
              "         -4.2977e-22,  -4.1575e-21,  -1.8068e-87,  -0.0000e+00,  -0.0000e+00,\n",
              "        -7.7889e-104,  -5.8622e-39,  -1.5944e+29,  -0.0000e+00,  -2.6167e-27,\n",
              "         -0.0000e+00,  -0.0000e+00,  -2.6167e-27,  -8.2095e-86,  -0.0000e+00,\n",
              "         -1.8470e-62,  -0.0000e+00,  -1.0278e-42,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.0553e-59,  -0.0000e+00, -6.5637e-111,  -0.0000e+00,\n",
              "         -4.6573e-78,  -1.3726e-66,  -1.7515e-70,  -2.3103e-40,  -0.0000e+00,\n",
              "         -4.9064e-04,   1.9275e-45,  -0.0000e+00,  -0.0000e+00,  -6.7637e-94,\n",
              "         -1.1299e-90,  -0.0000e+00, -1.2228e-108,  -0.0000e+00,  -1.5363e-35,\n",
              "        -2.6557e-114,  -7.6029e-46,  -2.7147e-61,  -1.9612e-45,  -1.2844e-50,\n",
              "         -1.6958e-50,  -2.7470e-44,  -0.0000e+00, -8.3040e-105,   0.0000e+00,\n",
              "        -7.4818e-121,  -0.0000e+00,   0.0000e+00,   6.8821e-47,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "          5.9283e-29,  -0.0000e+00, -8.8087e-109,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -8.2095e-86,  -0.0000e+00,  -0.0000e+00,  3.8146e-114,\n",
              "         -0.0000e+00,  -0.0000e+00, -5.7092e-133,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -3.1256e-52,  -0.0000e+00,\n",
              "          0.0000e+00,  -2.1977e-38,  -9.2244e-29,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -6.3676e+00,  -3.4200e-45,  -0.0000e+00,\n",
              "         -9.1264e-43, -9.5684e-135,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,   0.0000e+00,  -1.4581e-42,  -0.0000e+00,\n",
              "         -0.0000e+00,   2.0581e-29,   1.7970e-29,  -4.6949e-62, -4.3031e-114,\n",
              "         -0.0000e+00,  -0.0000e+00,  -4.1925e-25,  -0.0000e+00,  -0.0000e+00,\n",
              "        -1.6001e-142,  -0.0000e+00, -5.9574e-107, -1.6001e-142,  -3.7204e-20,\n",
              "        -8.0555e-127,  -0.0000e+00,  -0.0000e+00,  -1.4441e-84,  -0.0000e+00,\n",
              "         -5.1132e-04,   5.9283e-29,  -0.0000e+00,  -8.4817e-65,  -0.0000e+00,\n",
              "         -1.0142e-82,  -0.0000e+00,   0.0000e+00,  -0.0000e+00,  -1.6297e-40,\n",
              "         -1.1806e-76,  -0.0000e+00,   8.8334e-65,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.2844e-50,  -6.9755e-72,  -0.0000e+00,\n",
              "        -1.6001e-142,  -0.0000e+00,  -2.7082e-39, -2.3923e-123,  -1.2560e-81,\n",
              "         -5.5725e-99,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -6.2249e-32,\n",
              "         -0.0000e+00,  -3.4879e+11,  -1.2096e-60,  -1.2131e-90, -6.7220e-124,\n",
              "          7.6016e-81,  -5.5407e-09,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.0995e-92, -5.7092e-133,  -4.1575e-21,  -9.1264e-43, -1.8313e-144,\n",
              "         -0.0000e+00,  -1.5363e-35,  -0.0000e+00,  -3.4915e-62,  -0.0000e+00,\n",
              "         -0.0000e+00,  -3.2067e-77,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.5469e-21,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  9.3247e-114,  -0.0000e+00, -1.4124e-115,\n",
              "         -0.0000e+00,  -6.5620e-73, -1.6503e-110,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -3.0795e-106,  -1.1997e-38, -5.3088e-177,  -0.0000e+00,\n",
              "         -7.8034e-88,  -0.0000e+00,   2.0581e-29,  -2.5405e-85,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.9346e-91,  -4.1575e-21,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00, -7.4410e-122,  -0.0000e+00,  -0.0000e+00,\n",
              "          0.0000e+00,  -2.0389e-21,  -1.3726e-66, -7.3637e-125,  -0.0000e+00,\n",
              "         -7.5275e-79,  -0.0000e+00,  -7.9739e-71,  -0.0000e+00,  -0.0000e+00,\n",
              "        -4.7846e-116,  -0.0000e+00, -5.7104e-117,   0.0000e+00,  -0.0000e+00,\n",
              "        -7.4818e-121,  -1.5197e-87,  -0.0000e+00,  -0.0000e+00, -1.4183e-111,\n",
              "         -4.3459e-47,  -0.0000e+00, -3.6588e-102,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -4.7835e-21,\n",
              "         -4.7835e-21,  -0.0000e+00,  -1.0228e-11,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.9772e-98,  -0.0000e+00,  -4.2977e-22,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5680e-16, -1.4183e-111,  -0.0000e+00,  -4.2977e-22,  -1.2793e-97,\n",
              "         -6.8366e-36,  -0.0000e+00,   2.3977e-39,  -9.6952e-11,  -0.0000e+00,\n",
              "         -0.0000e+00,   1.9911e-59,  -1.4120e-71,  -0.0000e+00, -9.5684e-135,\n",
              "        -3.1407e-107,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5266e-42,  -2.6108e-10,  -0.0000e+00,  -0.0000e+00,  -5.3309e-32,\n",
              "         -0.0000e+00, -3.4482e-108,  -0.0000e+00, -3.3028e-112,  -1.8253e-71,\n",
              "         -1.5197e-87,  -0.0000e+00,  -1.2319e-33,  -0.0000e+00,   0.0000e+00],\n",
              "       dtype=torch.float64, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Orvqs0-IwoN4",
        "outputId": "82af141d-6b75-47cc-f39e-77dccf6c0612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.1683e-01,  5.2720e-01,  2.3982e+00,  5.2951e-01,  5.1357e-01,\n",
              "         5.1364e-01, -1.1535e+00,  5.1631e-01,  5.1753e-01,  5.1325e-01,\n",
              "         9.0952e-02,  3.6275e-01,  5.2720e-01,  7.6119e-02,  7.6752e-02,\n",
              "         5.3759e-01,  9.0952e-02,  7.6337e-02,  9.0952e-02,  9.0657e-02,\n",
              "         5.7605e+00,  2.3982e+00,  3.6205e+00,  9.0436e-02,  3.9866e+00,\n",
              "         7.6361e-02,  5.1632e-01,  7.7653e-02,  1.2674e-01,  9.0436e-02,\n",
              "         7.6119e-02,  5.1709e-01,  3.6920e+00,  5.1663e-01,  9.0973e-02,\n",
              "         5.3759e-01,  5.3762e-01, -2.9977e+06,  5.1357e-01,  5.3602e-01,\n",
              "         4.1946e+00,  5.2720e-01, -6.4696e+01,  5.2645e-01,  5.1683e-01,\n",
              "         5.2907e-01,  5.2645e-01,  3.6920e+00,  5.3771e-01,  4.8009e-01,\n",
              "         4.2201e-01,  9.0952e-02,  8.3283e-02,  5.3762e-01,  4.2676e+00,\n",
              "         5.1366e-01,  7.7653e-02,  5.3583e-01,  5.3728e-01, -5.6362e+07,\n",
              "         2.5242e-01, -1.5415e+10, -1.8276e-02,  8.9459e-02,  9.0952e-02,\n",
              "         5.1665e-01, -2.1687e+00, -4.6237e+01,  5.2644e-01,  5.3773e-01,\n",
              "         9.0433e-02, -3.7703e-01,  5.1365e-01,  7.7653e-02,  5.3583e-01,\n",
              "         5.1357e-01,  9.0955e-02,  9.0431e-02,  7.7654e-02,  5.1709e-01,\n",
              "         4.2142e-01,  5.3759e-01,  5.3759e-01,  5.1357e-01, -2.4942e+01,\n",
              "         8.9367e-02,  5.3773e-01,  5.2656e-01,  9.0952e-02,  5.3583e-01,\n",
              "         5.1364e-01,  5.2901e-01,  5.2644e-01,  7.7619e-02,  9.0952e-02,\n",
              "         9.0952e-02,  4.7722e-01,  5.2653e-01,  5.3771e-01,  5.3759e-01,\n",
              "        -2.7596e-01,  7.7653e-02,  9.0952e-02,  7.6361e-02,  9.0952e-02,\n",
              "         5.1728e-01,  9.0952e-02,  9.0431e-02,  4.7655e-01,  5.3759e-01,\n",
              "         5.2644e-01,  9.0657e-02,  7.6361e-02,  1.3149e-01,  5.1357e-01,\n",
              "         7.7556e-02, -4.6237e+01,  5.2653e-01,  9.0436e-02,  4.3616e-01,\n",
              "         7.7633e-02,  9.0433e-02,  9.0952e-02,  9.0952e-02,  5.1665e-01,\n",
              "         5.3547e-01,  5.2644e-01,  7.6105e-02,  9.0952e-02, -1.3443e+00,\n",
              "         5.0960e-01,  5.3761e-01,  9.0952e-02,  5.3591e-01,  5.1357e-01,\n",
              "         5.2714e-01,  4.7650e-01,  8.2442e-02,  5.2920e-01,  7.4989e-02,\n",
              "         5.1428e-01, -9.2283e-01,  5.3759e-01,  5.2900e-01,  5.1364e-01,\n",
              "         1.3196e+00,  5.3602e-01,  3.5049e+00, -1.3996e+03,  1.0444e+01,\n",
              "         7.6121e-02,  9.0949e-02,  7.7556e-02,  9.0952e-02,  5.1711e-01,\n",
              "         9.0955e-02,  4.2595e+00,  7.7653e-02,  5.1357e-01,  5.2900e-01,\n",
              "         5.1782e-01,  5.1709e-01, -2.5074e+01,  5.0960e-01, -1.8205e+00,\n",
              "         5.2652e-01,  5.1428e-01,  5.3773e-01,  5.3771e-01,  5.2720e-01,\n",
              "        -6.8967e+05,  5.3583e-01, -5.6433e-01,  5.3761e-01,  5.2720e-01,\n",
              "         7.7653e-02,  8.9262e-02, -4.4482e+00,  9.0956e-02,  9.0436e-02,\n",
              "         5.4839e+00,  5.2644e-01,  2.3645e-01,  5.1589e-01,  5.1709e-01,\n",
              "         5.3759e-01,  5.1916e-01,  9.0657e-02,  3.6926e+00,  5.2720e-01,\n",
              "         3.5348e-01,  7.6119e-02,  9.0433e-02,  5.2481e-01,  9.0952e-02,\n",
              "         3.9951e-01,  5.1318e-01,  9.0976e-02,  7.6361e-02,  7.4962e-02,\n",
              "         9.0436e-02,  9.0955e-02,  5.2644e-01,  5.1364e-01,  5.2656e-01,\n",
              "         7.6119e-02,  9.0954e-02,  5.3771e-01,  5.1724e-01,  4.3459e-01,\n",
              "         4.7453e-01,  5.2481e-01,  5.3093e-01,  5.2720e-01,  4.7947e-01,\n",
              "         5.1357e-01,  9.0654e-02,  4.0053e-01,  9.0954e-02,  5.3761e-01,\n",
              "         9.0974e-02,  2.5289e-01,  5.3583e-01,  5.1370e-01,  4.7938e-01,\n",
              "         8.3403e-02,  5.3602e-01,  2.3645e-01,  9.0973e-02,  5.2973e-01,\n",
              "         8.9367e-02,  7.7653e-02,  5.1366e-01,  9.0952e-02,  7.4973e-02,\n",
              "         4.7722e-01,  9.0952e-02,  9.0952e-02,  5.3583e-01,  4.8604e-02,\n",
              "         7.7653e-02,  5.1711e-01,  4.1136e-01,  4.7650e-01,  5.2264e-01,\n",
              "         5.3544e-01,  7.7653e-02,  5.2720e-01,  5.2720e-01,  5.1683e-01,\n",
              "         5.2643e-01,  9.0954e-02,  9.0952e-02,  5.1562e-01, -3.3918e-01,\n",
              "         7.7633e-02,  5.1665e-01,  5.3759e-01,  5.1364e-01,  2.8980e+00,\n",
              "        -1.2457e+01,  1.3655e+06,  5.1364e-01,  9.0952e-02,  7.7619e-02,\n",
              "         7.7653e-02,  5.2907e-01,  5.2481e-01,  8.4154e-02,  7.7633e-02,\n",
              "         5.3602e-01,  5.2644e-01,  5.3773e-01,  4.7939e-01,  7.7246e-02,\n",
              "        -4.3690e+00, -1.0027e+00, -8.2078e+00,  9.0973e-02,  5.2723e-01,\n",
              "         5.3330e-01,  5.1357e-01,  9.0973e-02,  4.2201e-01,  3.9321e+00,\n",
              "         4.7938e-01,  4.4394e-01,  5.1665e-01,  9.0436e-02, -7.3013e+01,\n",
              "         8.3361e-02,  5.1414e-01,  4.2142e-01,  5.1504e-01, -1.6895e+10,\n",
              "         9.0952e-02,  4.7722e-01,  7.7633e-02,  5.1357e-01,  9.0952e-02,\n",
              "         5.1815e+00,  9.0973e-02,  5.2644e-01,  4.8009e-01, -2.7487e+10,\n",
              "         5.3759e-01,  4.7722e-01,  7.5000e-02,  6.7563e-02,  9.0973e-02,\n",
              "         5.2720e-01,  9.0952e-02,  5.3058e-01,  5.1724e-01,  5.1364e-01,\n",
              "         9.0973e-02,  7.7627e-02,  5.3583e-01, -9.8881e+02,  5.2714e-01,\n",
              "         5.1683e-01,  5.3340e-01,  9.0952e-02,  5.2644e-01,  7.7653e-02,\n",
              "         5.1724e-01,  5.3759e-01,  5.3602e-01,  9.0418e-02,  5.3602e-01,\n",
              "         7.7556e-02, -4.9233e+04,  3.9866e+00, -4.4482e+00,  5.3602e-01,\n",
              "         4.8604e-02,  5.3761e-01,  5.3728e-01,  9.0952e-02,  4.1136e-01,\n",
              "         5.3759e-01,  9.0973e-02,  5.3591e-01,  4.7938e-01,  4.8097e-01,\n",
              "         5.1683e-01,  7.6119e-02,  5.2644e-01, -2.5074e+01,  5.3602e-01,\n",
              "         9.0973e-02,  9.0956e-02,  5.2652e-01,  5.2481e-01, -1.1318e+06,\n",
              "         5.1666e-01,  5.2720e-01,  5.1665e-01,  9.0952e-02,  7.6119e-02,\n",
              "         7.7653e-02,  7.6121e-02, -3.0503e+00,  4.7722e-01,  5.2901e-01,\n",
              "         5.2907e-01,  9.0952e-02,  5.1893e-01,  5.3058e-01,  5.2901e-01,\n",
              "         5.2900e-01, -1.1318e+06,  5.1728e-01,  5.1365e-01,  4.7708e-01,\n",
              "         7.7243e-02,  9.0976e-02, -2.0596e+05,  3.9834e-01, -1.1694e+00,\n",
              "        -7.6578e+01,  5.1632e-01,  5.3444e-01,  7.7627e-02,  5.2653e-01,\n",
              "         7.7633e-02, -1.2990e-01,  5.2481e-01,  4.2142e-01,  4.7708e-01,\n",
              "         5.1298e-01,  9.0948e-02,  3.3077e-01,  5.1357e-01,  7.6361e-02,\n",
              "         5.3771e-01,  5.3602e-01,  8.5267e-02,  5.1411e-01,  3.3376e+00,\n",
              "         5.3602e-01,  9.0952e-02,  9.0952e-02,  5.3761e-01,  5.3761e-01,\n",
              "         5.2720e-01,  9.0952e-02,  5.1364e-01,  5.1665e-01, -8.2078e+00,\n",
              "         5.1357e-01,  9.0656e-02,  5.1631e-01,  9.0433e-02,  8.3283e-02,\n",
              "         7.6361e-02,  5.3773e-01,  5.1318e-01,  9.0657e-02,  7.7619e-02,\n",
              "         5.1709e-01,  4.9870e-01,  8.1049e-02,  5.3602e-01,  5.3583e-01,\n",
              "         5.1414e-01,  5.1366e-01,  9.0436e-02,  4.3569e-01,  5.3408e-01,\n",
              "        -1.1694e+00,  5.1357e-01,  5.3005e-01, -1.1318e+06,  5.3771e-01,\n",
              "         5.3602e-01, -2.5074e+01,  5.1428e-01,  9.0952e-02,  9.0952e-02,\n",
              "         1.3058e+01,  5.1428e-01,  8.2442e-02,  5.1364e-01,  7.7574e-02,\n",
              "         4.7995e-01,  5.3602e-01,  6.9435e-02,  9.0657e-02,  9.0973e-02,\n",
              "         5.1709e-01,  5.3404e-01,  7.7653e-02,  5.1357e-01, -1.1658e+06,\n",
              "         3.5049e+00,  4.5514e-01,  5.1665e-01,  5.1047e-01, -7.2190e+10,\n",
              "         5.2653e-01, -2.0584e-01,  5.3602e-01,  5.3544e-01, -2.1687e+00,\n",
              "         5.3773e-01,  7.6361e-02,  5.2644e-01,  5.1770e-01,  4.3616e-01,\n",
              "        -3.4605e+02,  3.8834e-01, -5.7075e-01,  5.3444e-01,  4.3616e-01,\n",
              "         5.2724e-01,  5.4799e+00,  5.2993e-01,  8.9459e-02,  3.9866e+00,\n",
              "         9.0952e-02,  5.3761e-01, -2.2314e+00,  5.1792e-01,  4.7939e-01,\n",
              "         4.3616e-01,  8.9367e-02,  5.1683e-01, -5.4331e+00,  5.2973e-01,\n",
              "         5.1367e-01,  5.3602e-01,  9.0954e-02,  7.6118e-02,  5.1357e-01,\n",
              "         5.3759e-01,  4.3616e-01,  5.3408e-01,  5.3761e-01,  5.1414e-01,\n",
              "         1.3196e+00,  5.3591e-01, -7.5061e-02,  4.8096e-01,  7.6361e-02,\n",
              "        -4.6237e+01,  5.1364e-01,  4.1946e+00,  5.2481e-01,  5.1357e-01,\n",
              "         9.0976e-02,  5.1419e-01,  5.3602e-01,  5.2638e-01,  5.2644e-01,\n",
              "         5.2720e-01, -1.3566e+07, -2.2910e+00,  5.1367e-01,  4.2555e+00,\n",
              "         5.3759e-01,  5.3759e-01,  7.7653e-02,  4.2142e-01,  7.4973e-02,\n",
              "         2.5229e-01,  7.6121e-02,  4.3569e-01,  9.0657e-02,  5.3058e-01,\n",
              "         5.2652e-01,  4.7938e-01,  5.3762e-01,  5.2951e-01,  5.1709e-01,\n",
              "        -4.4662e-01, -6.8967e+05,  5.1605e-01,  5.2973e-01, -2.7469e+03,\n",
              "         9.0952e-02,  3.9321e+00,  5.2907e-01,  5.1297e-01,  5.1815e+00,\n",
              "         5.1411e-01, -2.0584e-01,  7.7633e-02,  5.1357e-01,  5.1357e-01,\n",
              "         4.4238e+00, -2.6895e+01,  5.1562e-01,  7.6361e-02,  5.3544e-01,\n",
              "         5.1357e-01,  5.2993e-01,  5.2653e-01,  5.1665e-01,  5.1711e-01,\n",
              "         5.3771e-01,  5.1364e-01,  5.1365e-01,  5.3583e-01,  9.0431e-02,\n",
              "         5.3759e-01,  9.0657e-02, -4.7566e-02,  3.6920e+00,  5.2652e-01,\n",
              "         5.2799e-01,  5.3728e-01, -5.2253e+15,  5.1709e-01,  5.3773e-01,\n",
              "         5.3544e-01,  7.6356e-02,  5.1631e-01,  5.1685e-01, -2.7487e+10,\n",
              "         7.7619e-02,  5.2644e-01,  5.1366e-01,  5.3759e-01,  5.2720e-01,\n",
              "         9.0952e-02,  8.6001e-02, -6.6563e+03, -3.5506e+00,  5.2973e-01,\n",
              "         5.3602e-01,  5.3759e-01,  5.3759e-01,  7.5080e-02,  3.0557e+00,\n",
              "        -2.5344e-01,  5.3762e-01,  9.0952e-02,  5.2901e-01,  4.7722e-01,\n",
              "         7.6356e-02,  5.1357e-01,  7.7653e-02,  5.1325e-01,  7.7556e-02,\n",
              "         1.3330e+00,  7.6104e-02,  5.2644e-01,  5.2901e-01,  7.6752e-02,\n",
              "         5.1711e-01,  9.0952e-02, -1.1708e+00,  5.2900e-01, -3.2846e+01,\n",
              "         5.2600e-01, -3.3918e-01,  5.1357e-01,  7.7653e-02,  7.4962e-02,\n",
              "         3.9866e+00,  9.0948e-02,  5.3773e-01,  5.3771e-01,  4.7939e-01,\n",
              "         5.1419e-01,  5.3761e-01,  5.7605e+00,  3.8131e-01,  5.2644e-01,\n",
              "         9.0973e-02,  9.0952e-02, -1.8276e-02,  7.6361e-02,  5.1297e-01,\n",
              "         3.9321e+00,  5.2653e-01,  9.0952e-02,  4.2555e+00,  5.1367e-01,\n",
              "         7.7619e-02,  9.0952e-02,  5.2481e-01,  5.1444e-01,  5.2900e-01,\n",
              "         4.3569e-01, -1.0532e+07,  5.1419e-01,  9.0955e-02,  7.7246e-02,\n",
              "         5.2920e-01, -1.1318e+06,  5.1683e-01,  5.1357e-01,  5.1357e-01,\n",
              "         7.4989e-02,  4.2595e+00,  7.6361e-02,  5.1709e-01,  5.1728e-01,\n",
              "         5.3761e-01,  9.0952e-02,  4.0053e-01,  8.1049e-02,  4.7650e-01,\n",
              "         4.2840e-01,  9.0952e-02,  5.2644e-01,  5.3588e-01,  5.1411e-01,\n",
              "         5.1709e-01,  5.2714e-01,  7.6361e-02,  5.3771e-01,  9.0431e-02,\n",
              "         5.1364e-01,  9.0973e-02,  5.1411e-01, -8.0030e+06,  5.1893e-01,\n",
              "         9.0952e-02,  5.1357e-01,  5.1711e-01,  5.3005e-01,  5.1366e-01,\n",
              "         4.7655e-01,  5.3759e-01,  8.4499e-02,  5.2720e-01,  9.0955e-02,\n",
              "         5.1357e-01, -1.8447e-01,  9.0433e-02,  5.1366e-01,  5.2721e-01,\n",
              "         9.0656e-02,  5.3773e-01,  5.1364e-01,  5.2644e-01,  5.3055e-01,\n",
              "         5.3771e-01,  5.3602e-01,  5.2631e-01,  5.1665e-01, -8.5441e+00,\n",
              "         4.7468e-01,  9.0973e-02, -6.4931e+01,  1.9185e+00,  9.0952e-02,\n",
              "         8.3283e-02,  5.1357e-01, -9.2283e-01,  5.2720e-01,  5.2720e-01,\n",
              "         4.8096e-01,  5.1357e-01, -9.3440e+14, -7.3013e+01,  5.2900e-01,\n",
              "         9.0952e-02,  7.7654e-02,  5.2900e-01,  5.1357e-01,  5.3547e-01,\n",
              "         5.0987e-01,  4.3616e-01,  9.0657e-02,  5.3583e-01,  5.1770e-01,\n",
              "         5.3591e-01,  7.7246e-02, -3.6693e+06,  5.3773e-01,  4.3569e-01,\n",
              "         4.8324e-01,  4.7938e-01,  5.2714e-01,  7.6345e-02,  7.7243e-02,\n",
              "        -2.4566e+05,  7.6118e-02,  5.3771e-01,  5.2907e-01,  9.0952e-02,\n",
              "         5.2644e-01,  9.0976e-02,  9.0952e-02,  9.0954e-02, -3.7703e-01,\n",
              "         5.1357e-01,  5.1411e-01,  7.7653e-02,  5.1665e-01,  9.0952e-02,\n",
              "         5.3773e-01,  5.1364e-01,  5.2644e-01,  5.1364e-01,  1.0034e+00,\n",
              "         7.7653e-02,  5.1297e-01,  5.4839e+00,  5.1728e-01,  5.3759e-01,\n",
              "        -2.6111e+01,  4.7939e-01,  5.2644e-01,  2.7664e-01,  5.1477e-01,\n",
              "         7.6356e-02,  5.3588e-01,  9.0973e-02,  9.0952e-02,  5.3583e-01,\n",
              "         5.3340e-01,  5.1357e-01,  5.3761e-01,  9.0957e-02,  4.1946e+00,\n",
              "         5.1365e-01,  5.3602e-01,  5.1683e-01,  4.3616e-01, -8.0030e+06,\n",
              "         4.3569e-01,  7.7556e-02,  9.0952e-02,  5.1665e-01,  5.1782e-01,\n",
              "         3.3888e+00,  5.1357e-01,  5.1562e-01,  5.1683e-01,  5.3602e-01,\n",
              "         5.1666e-01,  5.3759e-01, -1.5824e+02,  5.1357e-01,  5.2644e-01,\n",
              "        -5.4331e+00,  7.6361e-02,  5.3591e-01,  9.0433e-02,  5.2653e-01,\n",
              "         5.2720e-01,  7.7618e-02,  5.6180e+00,  5.1325e-01,  5.1711e-01,\n",
              "         3.6519e-01,  4.3561e-01,  7.4989e-02,  9.0952e-02,  5.2653e-01,\n",
              "         7.7637e-02,  5.3773e-01, -5.7075e-01,  9.0973e-02,  5.1365e-01,\n",
              "         5.3773e-01,  9.0431e-02,  5.2720e-01,  5.3773e-01, -6.4931e+01,\n",
              "         7.7633e-02,  5.3728e-01,  7.7653e-02,  5.1665e-01,  5.2481e-01,\n",
              "        -1.1658e+06,  7.6356e-02, -5.6433e-01,  4.3616e-01,  5.1444e-01,\n",
              "         5.1366e-01,  5.3759e-01,  5.4839e+00,  5.3602e-01,  4.7939e-01,\n",
              "         5.2644e-01,  5.2720e-01,  3.6919e+00,  9.0952e-02,  5.3762e-01,\n",
              "         5.1414e-01,  4.2835e-01,  9.0952e-02,  5.1782e-01,  7.7653e-02,\n",
              "         5.3773e-01,  5.3759e-01, -7.8570e-01,  9.0952e-02,  5.3759e-01,\n",
              "         7.5382e-02,  8.9367e-02, -4.4482e+00,  4.7938e-01,  5.1357e-01,\n",
              "         9.0656e-02, -2.9977e+06,  5.1893e-01,  3.9951e-01,  7.7633e-02,\n",
              "         7.7619e-02, -8.5441e+00,  5.3773e-01,  4.7453e-01,  5.1724e-01,\n",
              "         5.1665e-01,  5.1683e-01,  5.1357e-01, -5.4331e+00,  5.3420e-01,\n",
              "         5.3773e-01, -3.7703e-01,  5.2952e-01,  5.1357e-01,  1.9632e-01,\n",
              "         9.0952e-02,  7.7653e-02,  8.9262e-02,  5.2953e-01,  9.0973e-02,\n",
              "         5.3583e-01,  1.3058e+01,  5.2952e-01,  5.1370e-01,  5.3547e-01,\n",
              "         5.2644e-01,  9.0952e-02,  5.2652e-01,  5.1364e-01,  5.2656e-01,\n",
              "         5.2724e-01,  5.1357e-01,  9.0973e-02,  9.0952e-02,  7.6119e-02,\n",
              "         5.3602e-01,  5.3444e-01, -2.2910e+00,  5.3773e-01,  7.7654e-02,\n",
              "        -2.2579e-01,  4.6518e-01,  4.3561e-01,  5.1683e-01,  4.1597e-01,\n",
              "         9.0657e-02,  9.0436e-02,  7.7246e-02,  9.0436e-02,  7.7556e-02,\n",
              "         5.2714e-01,  5.1357e-01,  5.1367e-01,  5.2720e-01, -3.8281e+02,\n",
              "         5.2973e-01,  5.2644e-01,  9.0954e-02,  5.3537e-01,  4.7708e-01,\n",
              "         1.3330e+00,  5.1356e-01,  4.7938e-01,  9.0952e-02,  9.0657e-02,\n",
              "         5.2644e-01,  9.0952e-02, -3.0503e+00,  4.4394e-01,  9.0973e-02,\n",
              "         5.3583e-01,  5.1357e-01,  5.2951e-01,  3.3888e+00,  4.2835e-01,\n",
              "         7.7653e-02,  7.6119e-02,  9.0973e-02,  5.3761e-01,  5.2959e-01,\n",
              "         9.0952e-02,  5.3583e-01,  5.1724e-01,  5.3404e-01,  5.1357e-01,\n",
              "         7.7633e-02,  7.5080e-02,  5.3340e-01,  9.0955e-02,  9.0974e-02,\n",
              "         9.0974e-02,  5.1683e-01, -4.9233e+04,  5.3771e-01,  5.3110e-01,\n",
              "         5.1364e-01, -3.6693e+06,  8.3283e-02,  5.2481e-01, -3.4611e+00,\n",
              "        -1.3996e+03,  5.2959e-01,  5.2720e-01,  8.3283e-02,  7.7653e-02,\n",
              "         5.1355e-01,  5.1412e-01,  5.3761e-01, -6.6563e+03,  5.3759e-01,\n",
              "         4.7938e-01,  5.3583e-01,  5.1683e-01,  9.0957e-02,  7.6361e-02,\n",
              "         5.1357e-01,  9.0973e-02, -1.3134e+06,  4.2840e-01,  9.0436e-02,\n",
              "         5.2720e-01,  3.0557e+00,  5.2901e-01,  5.3602e-01,  5.1297e-01,\n",
              "         5.1504e-01,  5.1411e-01,  5.1419e-01,  5.1414e-01,  5.3762e-01,\n",
              "         7.6119e-02,  9.0955e-02, -3.0039e+04,  5.1365e-01,  3.5049e+00],\n",
              "       dtype=torch.float64, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sums_shaping = sums_states_weight_diff + gamma_weights_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "cQwdg78It-sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(sums_shaping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpNY7q-guFCA",
        "outputId": "21738905-c107-4f20-9480-a0e1cead242f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.7904e+39, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the min and max values of tensors\n",
        "print(\"padded_weight_diff_tensors - Min:\", padded_weight_diff_tensors.min().item(), \" Max:\", padded_weight_diff_tensors.max().item())\n",
        "print(\"sums_states_weight_diff - Min:\", sums_states_weight_diff.min().item(), \" Max:\", sums_states_weight_diff.max().item())\n",
        "print(\"gamma_weights_last_tensor - Min:\", gamma_weights_last_tensor.min().item(), \" Max:\", gamma_weights_last_tensor.max().item())\n",
        "print(\"samples_IS - Min:\", samples_IS.min().item(), \" Max:\", samples_IS.max().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RZCBfD9vwRx",
        "outputId": "ebaecd5c-ec6a-430d-f578-ee4fc5fe8ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded_weight_diff_tensors - Min: -6979572071212940.0  Max: 1.839130399958296e+16\n",
            "sums_states_weight_diff - Min: -5225342891061462.0  Max: 1365487.6953395614\n",
            "gamma_weights_last_tensor - Min: 1.846463839642936e-238  Max: 143894458319084.28\n",
            "samples_IS - Min: -10076.89890923087  Max: 159882731465649.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(sample_sums_states_weight_diff,dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj6mSyUmUqqp",
        "outputId": "21a53d42-836a-4dc8-d67f-ba381264b891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9.9641e+39, -2.6692e+27, -9.9641e+39,  ..., -1.9928e+40,\n",
              "        -2.9892e+40, -1.3346e+27], dtype=torch.float64,\n",
              "       grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(samples_gamma_weight_states_last_sub_states_first, dim =1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYJ0CkAeUxYJ",
        "outputId": "9c9fe1d0-8246-427a-e25a-4704db91823d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.7368e+38, 5.5852e+13, 1.7368e+38,  ..., 3.4735e+38, 5.2103e+38,\n",
              "        2.7925e+13], dtype=torch.float64, grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpf1bgqIRAzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calc Variance"
      ],
      "metadata": {
        "id": "wwmn8QMhO5QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE):\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(samples_IS, dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(samples_IS, dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  # E_IS_SCOPE = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "  # E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))\n",
        "\n",
        "  E_IS = torch.mean(torch.mean(samples_IS,dim = 1 ))\n",
        "  E_SCOPE = torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "\n",
        "  # SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_s_wdiff_all_sq\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, IS_variance, SCOPE_variance, E_IS, E_SCOPE\n"
      ],
      "metadata": {
        "id": "WlDazbYPvvrg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE = sample_sums_states_weight_diff-samples_gamma_weight_states_last_sub_states_first\n"
      ],
      "metadata": {
        "id": "ut3fyQ4s1l-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,_,_,_,_,_,IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)"
      ],
      "metadata": {
        "id": "yWcJ_iSFvvru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'IS Variance: {IS_variance.item()} SCOPE Variance: {SCOPE_variance.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ecraXkwWRcI",
        "outputId": "0b7a14e9-64a6-4c20-98a0-f958228fad62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IS Variance: 2.514807940970177e+22 SCOPE Variance: 5.892057226414652e+25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJtda6na7iFY",
        "outputId": "ce79b72f-e4fc-4ab7-c2b7-6e09fb2db4ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0262e+82, 1.7582e+80, 2.0262e+82,  ..., 4.0349e+82, 6.0435e+82,\n",
              "        1.7582e+80], dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing"
      ],
      "metadata": {
        "id": "InzaU1hEzXaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "wEeNxHjkz9Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_var(model, num_epochs, learning_rate, padded_state_tensors, states_first_tensor, states_last_tensor, test1):\n",
        "    model.train()\n",
        "\n",
        "    # Enable anomaly detection\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Forward pass\n",
        "        states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "        sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "        gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "        # sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "        samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "\n",
        "        E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss, E_IS, E_SCOPE = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"Var loss: \", variance_loss)\n",
        "\n",
        "        # Print each term\n",
        "        print(f\"E_IS_sq: {E_IS_sq}\")\n",
        "        print(f\"E_IS_all_sq: {E_IS_all_sq}\")\n",
        "        print(f\"E_s_wdiff_sq: {E_s_wdiff_sq}\")\n",
        "        print(f\"E_s_wdiff_all_sq: {E_s_wdiff_all_sq}\")\n",
        "        print(f\"E_IS_SCOPE: {E_IS_SCOPE}\")\n",
        "        print(f\"E_IS_E_SCOPE: {E_IS_E_SCOPE}\")\n",
        "        print(f\"E_IS: {E_IS}\")\n",
        "        print(f\"E_SCOPE: {E_SCOPE}\")\n",
        "\n",
        "        tot = variance_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Retain the graph to avoid clearing it before backward pass\n",
        "        tot.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Disable anomaly detection after running the code\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "lEfGUHfGNwiJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_var(model, 20, 0.0001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0zmGSWkVyC_",
        "outputId": "18597fc2-7ea7-4000-98c0-75ccad13417b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(-3.0838e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.210967549166126e+22\n",
            "E_s_wdiff_all_sq: 2.5172984363039316e+22\n",
            "E_IS_SCOPE: -1.5459488896936224e+25\n",
            "E_IS_E_SCOPE: -1.4417566494849713e+22\n",
            "Total Loss: -3.0838057890344423e+25\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(-3.3585e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.546944000346388e+22\n",
            "E_s_wdiff_all_sq: 3.517525168586692e+22\n",
            "E_IS_SCOPE: -1.6839284068856547e+25\n",
            "E_IS_E_SCOPE: -1.8983210591791954e+22\n",
            "Total Loss: -3.358515944880221e+25\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(-3.6329e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.127328468140865e+22\n",
            "E_s_wdiff_all_sq: 4.669789629828819e+22\n",
            "E_IS_SCOPE: -1.8217910544502339e+25\n",
            "E_IS_E_SCOPE: -2.3493888489215494e+22\n",
            "Total Loss: -3.632910984423342e+25\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(-3.9072e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 9.956227907220597e+22\n",
            "E_s_wdiff_all_sq: 5.9793486972912325e+22\n",
            "E_IS_SCOPE: -1.959656202176037e+25\n",
            "E_IS_E_SCOPE: -2.7986036228854552e+22\n",
            "Total Loss: -3.907223509955403e+25\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(-4.1814e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2030804144930232e+23\n",
            "E_s_wdiff_all_sq: 7.444645256087994e+22\n",
            "E_IS_SCOPE: -2.0974953048619344e+25\n",
            "E_IS_E_SCOPE: -3.2460902003401042e+22\n",
            "Total Loss: -4.1813974624933755e+25\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(-4.4554e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4346387559415976e+23\n",
            "E_s_wdiff_all_sq: 9.062655780558345e+22\n",
            "E_IS_SCOPE: -2.235296219189662e+25\n",
            "E_IS_E_SCOPE: -3.6915356807178387e+22\n",
            "Total Loss: -4.4554108272980605e+25\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(-4.7293e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.6896450448835388e+23\n",
            "E_s_wdiff_all_sq: 1.08290772380101e+23\n",
            "E_IS_SCOPE: -2.3730518621395594e+25\n",
            "E_IS_E_SCOPE: -4.134422009246762e+22\n",
            "Total Loss: -4.72925269910883e+25\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(-5.0029e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.9673881915757514e+23\n",
            "E_s_wdiff_all_sq: 1.2739332729182658e+23\n",
            "E_IS_SCOPE: -2.5107576940337e+25\n",
            "E_IS_E_SCOPE: -4.574329549359406e+22\n",
            "Total Loss: -5.0029173718411355e+25\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(-5.2764e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.267249722521212e+23\n",
            "E_s_wdiff_all_sq: 1.4789613654870718e+23\n",
            "E_IS_SCOPE: -2.6484105436396702e+25\n",
            "E_IS_E_SCOPE: -5.011115472982626e+22\n",
            "Total Loss: -5.276401164822063e+25\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(-5.5497e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.5887526111029046e+23\n",
            "E_s_wdiff_all_sq: 1.6977134979120384e+23\n",
            "E_IS_SCOPE: -2.786008235633142e+25\n",
            "E_IS_E_SCOPE: -5.444868998604533e+22\n",
            "Total Loss: -5.549701534196196e+25\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(-5.8228e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.93150580846501e+23\n",
            "E_s_wdiff_all_sq: 1.9299681728485064e+23\n",
            "E_IS_SCOPE: -2.9235491360209344e+25\n",
            "E_IS_E_SCOPE: -5.875756424517042e+22\n",
            "Total Loss: -5.822816574895699e+25\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(-6.0957e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 3.2951384287536245e+23\n",
            "E_s_wdiff_all_sq: 2.1755135214562837e+23\n",
            "E_IS_SCOPE: -3.061031877917925e+25\n",
            "E_IS_E_SCOPE: -6.303918086962085e+22\n",
            "Total Loss: -6.095744862647982e+25\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(-6.3685e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 3.67926590345648e+23\n",
            "E_s_wdiff_all_sq: 2.434124883277089e+23\n",
            "E_IS_SCOPE: -3.1984552495154813e+25\n",
            "E_IS_E_SCOPE: -6.729439799700456e+22\n",
            "Total Loss: -6.368485401288798e+25\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(-6.6411e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 4.083511343418876e+23\n",
            "E_s_wdiff_all_sq: 2.7055798170633747e+23\n",
            "E_IS_SCOPE: -3.3358493269605055e+25\n",
            "E_IS_E_SCOPE: -7.152390355712248e+22\n",
            "Total Loss: -6.641099750005061e+25\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(-6.9135e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 4.507797613123608e+23\n",
            "E_s_wdiff_all_sq: 2.9898588786408246e+23\n",
            "E_IS_SCOPE: -3.47318020008451e+25\n",
            "E_IS_E_SCOPE: -7.573118707256295e+22\n",
            "Total Loss: -6.91351996746871e+25\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(-7.1858e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 4.9525968530722806e+23\n",
            "E_s_wdiff_all_sq: 3.287304205334282e+23\n",
            "E_IS_SCOPE: -3.6104516466931023e+25\n",
            "E_IS_E_SCOPE: -7.992410040288414e+22\n",
            "Total Loss: -7.185750738887278e+25\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(-7.4578e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.422597581911685e+23\n",
            "E_s_wdiff_all_sq: 3.6010637596031907e+23\n",
            "E_IS_SCOPE: -3.7476645794703584e+25\n",
            "E_IS_E_SCOPE: -8.414638867962763e+22\n",
            "Total Loss: -7.457769735040736e+25\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(-7.7296e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.912088932901162e+23\n",
            "E_s_wdiff_all_sq: 3.9273065020191513e+23\n",
            "E_IS_SCOPE: -3.884814950188801e+25\n",
            "E_IS_E_SCOPE: -8.834554946761315e+22\n",
            "Total Loss: -7.7295981582342884e+25\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(-8.0012e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.420042041666823e+23\n",
            "E_s_wdiff_all_sq: 4.2653734809269504e+23\n",
            "E_IS_SCOPE: -4.021901783374139e+25\n",
            "E_IS_E_SCOPE: -9.251635569965136e+22\n",
            "Total Loss: -8.001238802059979e+25\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(-8.2727e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.945934268931316e+23\n",
            "E_s_wdiff_all_sq: 4.614945900147421e+23\n",
            "E_IS_SCOPE: -4.158924544997166e+25\n",
            "E_IS_E_SCOPE: -9.665836613397322e+22\n",
            "Total Loss: -8.272692725138728e+25\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.4510,  0.0021],\n",
            "        [ 0.3396,  0.6556],\n",
            "        [-0.0427,  0.1722],\n",
            "        [-0.1050, -0.3208],\n",
            "        [ 0.6667,  0.6256],\n",
            "        [ 0.0633, -0.0869],\n",
            "        [-0.5012,  0.5401],\n",
            "        [-0.2295, -0.6730],\n",
            "        [-0.2369, -0.6463],\n",
            "        [-0.3752, -0.3359],\n",
            "        [-0.6697,  0.5156],\n",
            "        [-0.2812,  0.2000],\n",
            "        [-0.1604,  0.5577],\n",
            "        [-0.5985, -0.1328],\n",
            "        [-0.4052, -0.3473],\n",
            "        [-0.2117,  0.0203]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.5800,  0.0521,  0.6555,  0.4989, -0.2725,  0.2633, -0.4585,  0.6680,\n",
            "         0.4422,  0.6497,  0.6227,  0.4099, -0.5805,  0.7856,  0.5691,  0.2211],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 1.7559e-01,  1.6233e-01,  2.3772e-01,  2.2629e-01,  1.8467e-01,\n",
            "          3.0120e-01, -2.3406e-01, -1.8666e-01,  7.2061e-02,  2.3042e-01,\n",
            "         -3.1664e-02, -1.7317e-01, -5.9300e-02,  2.1983e-01, -2.3025e-01,\n",
            "         -2.5168e-01],\n",
            "        [ 7.1529e-03,  2.4635e-01, -1.0106e-01, -1.2429e-01, -1.5923e-01,\n",
            "         -1.8235e-02,  1.4430e-02, -1.5267e-01,  1.9970e-01, -2.2146e-02,\n",
            "         -2.2856e-01, -1.7931e-01,  1.9001e-01,  2.4006e-02,  2.1272e-01,\n",
            "          9.1185e-02],\n",
            "        [-6.1545e-02, -1.6846e-01, -1.9149e-01,  9.8640e-02, -2.1220e-01,\n",
            "          1.1819e-01,  9.9572e-02, -1.0969e-01,  1.8555e-01,  2.3056e-01,\n",
            "         -7.3723e-02, -6.4354e-02,  1.8917e-01,  1.4870e-01, -1.2193e-01,\n",
            "          1.9635e-01],\n",
            "        [ 1.9140e-01,  5.9702e-02,  2.0254e-01, -5.3336e-02, -1.2643e-01,\n",
            "          1.1372e-01, -2.2702e-01, -1.5411e-01,  1.7170e-01, -1.0972e-01,\n",
            "         -6.0289e-02,  1.4019e-01, -1.7271e-01,  3.9220e-01, -8.3202e-02,\n",
            "         -1.3331e-01],\n",
            "        [-2.2063e-01, -2.3476e-01, -2.0329e-01,  1.1068e-02,  2.1729e-01,\n",
            "         -2.8234e-01,  8.6570e-02, -9.5660e-02, -1.9528e-01,  8.0604e-02,\n",
            "          7.2492e-02, -1.7119e-01, -1.3159e-01,  9.6841e-02,  1.2702e-01,\n",
            "         -2.1615e-01],\n",
            "        [-1.5366e-01,  1.9952e-01, -3.9314e-02, -1.4778e-01, -1.5110e-01,\n",
            "          8.4972e-02, -2.8361e-01,  6.8140e-02, -1.6945e-01,  2.4092e-02,\n",
            "         -1.8115e-01, -2.7334e-02, -3.8245e-02,  7.6595e-02, -6.4935e-02,\n",
            "          2.7648e-01],\n",
            "        [ 7.1929e-03, -8.6183e-02,  1.9110e-01,  1.1232e-01,  1.7308e-01,\n",
            "         -5.8804e-02, -2.2953e-01, -2.3573e-02, -2.7324e-02,  1.1141e-01,\n",
            "         -2.1644e-01,  2.0180e-01,  1.1418e-02, -1.7533e-01,  1.6569e-01,\n",
            "          1.9179e-01],\n",
            "        [ 3.6563e-02,  2.7998e-02,  2.6304e-01, -1.8567e-01,  1.8540e-01,\n",
            "         -1.3270e-01,  7.6032e-02, -2.9636e-02, -2.1079e-04, -1.0609e-01,\n",
            "          2.2287e-01, -2.2479e-01,  1.1056e-01, -2.3385e-01, -1.6760e-01,\n",
            "          9.9343e-02],\n",
            "        [ 1.7877e-01, -1.1848e-01,  2.7068e-02,  9.9388e-02,  2.4131e-01,\n",
            "         -1.5313e-01,  2.0315e-01, -1.8985e-01, -1.1247e-01, -1.1768e-02,\n",
            "         -2.8191e-02, -7.7164e-02,  1.1229e-01, -2.7218e-01, -9.0932e-02,\n",
            "         -1.9059e-01],\n",
            "        [ 1.5427e-01, -1.1397e-01,  2.4423e-01,  6.1690e-02, -2.4008e-03,\n",
            "          5.1089e-02,  1.0899e-01,  1.0263e-01, -1.7723e-02,  7.6825e-02,\n",
            "          4.6833e-02,  1.8567e-01,  6.8519e-03, -5.1221e-02,  7.3215e-02,\n",
            "          2.1663e-02],\n",
            "        [ 3.0704e-02,  1.6847e-01,  1.9887e-01, -1.9659e-01,  1.6256e-03,\n",
            "          2.7731e-01, -4.4841e-02, -1.0408e-01, -2.2601e-01, -1.8564e-01,\n",
            "          1.8752e-01, -1.7683e-01, -1.8726e-01,  1.9871e-01, -3.5240e-02,\n",
            "         -1.3091e-01],\n",
            "        [ 3.1929e-02,  3.2215e-02,  1.5373e-01, -2.2811e-01, -5.2812e-02,\n",
            "          1.1565e-01, -1.0283e-01,  1.9907e-01,  3.4308e-02, -1.2375e-01,\n",
            "          1.0030e-01,  7.0572e-02, -7.3479e-02, -5.4203e-02, -4.8761e-02,\n",
            "         -1.7009e-01],\n",
            "        [ 1.8268e-01, -3.1818e-02, -2.7465e-01,  2.0304e-01, -2.5103e-01,\n",
            "          1.3380e-01,  5.7078e-02, -1.6024e-01,  2.3616e-01,  1.3602e-01,\n",
            "          1.8643e-01, -1.7847e-01, -1.6410e-01,  2.1505e-01, -1.4369e-01,\n",
            "         -4.8390e-02],\n",
            "        [-1.3087e-01,  1.1866e-01,  3.6743e-02, -1.4394e-01, -1.1981e-01,\n",
            "         -7.0510e-02,  8.3873e-03,  1.4202e-01,  5.7004e-02,  2.4725e-01,\n",
            "          1.7666e-02, -2.3482e-01, -2.2211e-01,  2.0162e-01,  8.6532e-02,\n",
            "          7.8177e-02],\n",
            "        [-1.4544e-01, -3.7057e-01,  3.0520e-01, -7.4018e-02, -3.4248e-02,\n",
            "         -3.6749e-02, -5.1584e-02, -1.4300e-01,  7.9773e-02, -1.7701e-01,\n",
            "          2.3044e-01, -4.2904e-01, -1.0584e-01, -1.3126e-01,  1.9303e-02,\n",
            "          2.8921e-01],\n",
            "        [-2.4521e-01,  2.4946e-01, -3.0612e-01,  4.3380e-02, -1.0360e-02,\n",
            "          4.2349e-02,  7.6393e-02, -1.4996e-01,  2.6837e-02, -1.2947e-01,\n",
            "         -6.0119e-02, -1.2891e-01, -2.9666e-01,  7.5903e-03,  1.1003e-01,\n",
            "         -1.3607e-01],\n",
            "        [-2.3086e-01,  1.2024e-01, -1.7377e-01,  1.9102e-01, -1.4026e-01,\n",
            "         -2.1704e-01,  2.3345e-01,  1.8437e-01, -3.6461e-02, -2.4583e-01,\n",
            "         -4.0944e-01, -3.2514e-01, -3.4505e-01,  2.2425e-01,  2.4350e-03,\n",
            "          2.9624e-01],\n",
            "        [ 1.7996e-01,  6.2290e-03,  4.7523e-02,  1.1118e-02,  1.6657e-01,\n",
            "         -9.6748e-03,  1.1051e-01, -2.2243e-01,  7.2220e-02, -1.1556e-01,\n",
            "          3.8988e-02, -2.0665e-01,  5.8580e-02,  1.9515e-01, -1.9692e-01,\n",
            "         -1.6146e-01],\n",
            "        [-2.4386e-01, -1.9133e-01,  3.3801e-02, -2.1412e-01,  1.1644e-01,\n",
            "         -3.6942e-01, -1.6242e-01, -1.4523e-01,  1.8902e-01,  8.2447e-02,\n",
            "         -4.7722e-01,  5.2936e-02, -9.7944e-02,  9.3941e-02,  5.6936e-02,\n",
            "         -2.5046e-01],\n",
            "        [-2.1121e-02, -3.0001e-01, -4.9378e-02,  1.1902e-01,  7.8042e-02,\n",
            "          3.1770e-01,  3.9925e-02,  2.2312e-01,  5.2246e-02,  9.3138e-02,\n",
            "          1.1217e-01,  5.3098e-02,  2.2271e-01,  3.9138e-01,  5.3523e-02,\n",
            "         -1.2653e-01],\n",
            "        [ 1.9650e-01, -1.4172e-01,  2.8714e-02, -2.9400e-02,  2.3476e-01,\n",
            "          2.9832e-01,  1.4017e-01,  2.4546e-01,  9.2309e-03,  1.0585e-01,\n",
            "         -1.4108e-01, -1.6467e-01, -2.5441e-01,  1.3023e-01,  5.3941e-02,\n",
            "          3.4543e-02],\n",
            "        [ 6.2436e-02, -8.1427e-02,  6.8004e-03, -2.4202e-01, -6.0287e-02,\n",
            "         -1.4947e-01,  1.9532e-01, -2.4530e-01, -2.7072e-02,  1.3022e-01,\n",
            "          3.4743e-01,  1.9774e-01,  5.8964e-02, -4.1659e-02,  1.8627e-01,\n",
            "         -1.6851e-01],\n",
            "        [-2.3660e-01,  1.4217e-01, -2.7298e-01, -2.3568e-01,  1.8135e-01,\n",
            "         -9.9376e-02, -2.1404e-01, -7.8582e-02, -7.0298e-02, -1.0721e-02,\n",
            "          1.1153e-01,  1.2434e-01,  1.4717e-01,  1.4747e-01,  1.7566e-01,\n",
            "          1.6961e-01],\n",
            "        [-2.1504e-01, -5.6804e-02,  1.2303e-01, -1.2970e-01, -9.0758e-04,\n",
            "          9.0054e-02, -1.4854e-01, -5.5772e-03, -3.3620e-02, -1.3572e-01,\n",
            "         -1.2283e-01, -3.5842e-02,  2.0300e-01,  1.7445e-01,  1.9926e-01,\n",
            "          1.4480e-02],\n",
            "        [-1.8815e-02, -8.8772e-02,  1.6216e-01,  3.7306e-02,  1.0765e-01,\n",
            "         -2.1936e-02,  1.8456e-01,  1.4760e-01, -7.9331e-02,  1.5561e-01,\n",
            "          2.0303e-01, -1.4509e-01, -8.1366e-02, -3.1612e-01,  5.6964e-02,\n",
            "         -1.7146e-01],\n",
            "        [ 2.7233e-04,  2.0508e-01,  2.3661e-01,  3.0674e-02,  1.2631e-01,\n",
            "          7.2449e-02, -2.0767e-01,  6.0481e-02,  5.9943e-02,  1.2595e-01,\n",
            "         -1.5610e-01, -1.2661e-01,  2.0987e-01, -2.9389e-01, -2.3863e-01,\n",
            "          1.8265e-01],\n",
            "        [-2.3910e-01,  2.7046e-01,  1.7394e-01,  1.4304e-01,  2.2724e-01,\n",
            "          1.5284e-01,  6.0089e-02, -2.4203e-02,  1.4016e-01,  1.2150e-01,\n",
            "          1.1739e-01,  4.5788e-02, -2.4074e-01,  7.2400e-02, -1.8276e-01,\n",
            "         -1.9739e-01],\n",
            "        [ 3.0014e-02,  8.0140e-03, -3.5501e-02,  1.3929e-01, -2.8273e-01,\n",
            "         -8.2736e-02, -2.0914e-01, -1.9566e-01,  1.4068e-01, -2.0598e-01,\n",
            "          1.6162e-01,  1.1231e-01,  1.1277e-01, -6.3876e-02, -5.7794e-02,\n",
            "         -4.4601e-02],\n",
            "        [-6.8022e-02,  1.2553e-01, -7.4896e-02,  5.8154e-02,  1.5711e-01,\n",
            "         -2.2227e-01,  1.3049e-01, -1.2746e-01, -2.7043e-02, -7.6503e-03,\n",
            "          2.5763e-02,  7.0767e-02, -5.9477e-03, -4.2300e-01, -9.2563e-02,\n",
            "          1.0574e-01],\n",
            "        [ 2.4462e-01, -4.4803e-02,  6.5335e-02,  2.1805e-01,  2.5980e-01,\n",
            "          1.4863e-02,  1.3684e-01,  1.9241e-01, -1.3083e-01,  1.8042e-01,\n",
            "         -9.6065e-02,  1.9216e-01,  1.2768e-01, -3.9125e-02,  8.0967e-02,\n",
            "          6.9863e-02],\n",
            "        [-2.0339e-01, -1.3332e-01,  1.2844e-02, -2.4017e-01,  1.1610e-01,\n",
            "         -1.6190e-01, -5.8829e-02,  1.3671e-01, -6.2188e-02,  1.3888e-01,\n",
            "          1.7607e-01,  1.4970e-01,  6.7824e-02,  7.6705e-02,  7.5816e-02,\n",
            "         -1.3883e-01],\n",
            "        [-8.8667e-02, -9.7587e-02,  7.9214e-02, -1.6263e-01, -3.5249e-02,\n",
            "          5.5645e-02, -2.3595e-02,  7.8961e-02, -1.2570e-01,  2.1665e-01,\n",
            "          2.7871e-02,  1.2805e-01,  4.8840e-02,  7.5699e-02, -1.5474e-01,\n",
            "         -1.3606e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0152, -0.0980,  0.0864,  0.0689,  0.2498, -0.0135,  0.1991,  0.1723,\n",
            "         0.1992, -0.0625,  0.1075, -0.0684,  0.2318, -0.0104, -0.2247, -0.0120,\n",
            "        -0.1201,  0.2344,  0.0327,  0.0824,  0.2338,  0.0025, -0.0555, -0.2357,\n",
            "         0.0321, -0.2639,  0.1652,  0.0119,  0.0660,  0.0135, -0.1878, -0.2406],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0168,  0.1780,  0.1248,  0.0681, -0.1202, -0.0241,  0.1450, -0.0256,\n",
            "         -0.0325, -0.1131,  0.1277, -0.0804,  0.0521,  0.0330,  0.1509,  0.0562,\n",
            "         -0.1326,  0.0699, -0.1098,  0.1518,  0.1084, -0.3186,  0.1366, -0.1010,\n",
            "         -0.0525, -0.0417,  0.0804, -0.0123, -0.1114, -0.0858, -0.1678,  0.1389]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0005], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = train_var(model4, 500, 0.0001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K7RunrrFPEy7",
        "outputId": "fa9e6784-1b9a-4a4f-be7b-e7e99b2b6a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(1.6838e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2080531216272573e+22\n",
            "E_s_wdiff_all_sq: 7.854446300022197e+18\n",
            "E_IS_SCOPE: -3.2924307594909997e+22\n",
            "E_IS_E_SCOPE: -1.0101281026055919e+22\n",
            "Total Loss: 1.683838514322106e+21\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(2.4018e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.5681370975049804e+22\n",
            "E_s_wdiff_all_sq: 5.3651102132735515e+20\n",
            "E_IS_SCOPE: -2.958920317364135e+22\n",
            "E_IS_E_SCOPE: -6.916923741107582e+21\n",
            "Total Loss: 2.401815260791626e+21\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(2.3126e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.060980670643068e+22\n",
            "E_s_wdiff_all_sq: 2.9444178650483524e+20\n",
            "E_IS_SCOPE: -3.670629845441955e+22\n",
            "E_IS_E_SCOPE: -1.3322424158069409e+22\n",
            "Total Loss: 2.3125616815015744e+21\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(2.2341e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0633852358230838e+22\n",
            "E_s_wdiff_all_sq: 2.5690002961311597e+20\n",
            "E_IS_SCOPE: -3.649677342924772e+22\n",
            "E_IS_E_SCOPE: -1.3148560016495734e+22\n",
            "Total Loss: 2.2340649589243705e+21\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(1.6178e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2198354392569919e+22\n",
            "E_s_wdiff_all_sq: 3.652535509560464e+18\n",
            "E_IS_SCOPE: -3.332237717470749e+22\n",
            "E_IS_E_SCOPE: -1.0305375073970072e+22\n",
            "Total Loss: 1.6178046747669262e+21\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(2.0155e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4497548452943698e+22\n",
            "E_s_wdiff_all_sq: 3.101753381008754e+20\n",
            "E_IS_SCOPE: -3.054246607770964e+22\n",
            "E_IS_E_SCOPE: -7.818279936741865e+21\n",
            "Total Loss: 2.0155355174517866e+21\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(2.0581e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4616360950367095e+22\n",
            "E_s_wdiff_all_sq: 3.4398198073409634e+20\n",
            "E_IS_SCOPE: -3.036719256598841e+22\n",
            "E_IS_E_SCOPE: -7.676013074519667e+21\n",
            "Total Loss: 2.0580944516510541e+21\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(1.6603e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2939949932413746e+22\n",
            "E_s_wdiff_all_sq: 7.213751316865191e+19\n",
            "E_IS_SCOPE: -3.213132082516763e+22\n",
            "E_IS_E_SCOPE: -9.278309953212547e+21\n",
            "Total Loss: 1.6603175514178983e+21\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(1.6789e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1369778160525388e+22\n",
            "E_s_wdiff_all_sq: 1.6735233495303238e+19\n",
            "E_IS_SCOPE: -3.4343132217582195e+22\n",
            "E_IS_E_SCOPE: -1.1282428200323708e+22\n",
            "Total Loss: 1.6788777360338956e+21\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(1.9160e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0759040073523123e+22\n",
            "E_s_wdiff_all_sq: 1.146480960753118e+20\n",
            "E_IS_SCOPE: -3.550444204464186e+22\n",
            "E_IS_E_SCOPE: -1.2339266693254665e+22\n",
            "Total Loss: 1.9160354737051664e+21\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(1.7996e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0934688991814363e+22\n",
            "E_s_wdiff_all_sq: 6.6358570149114085e+19\n",
            "E_IS_SCOPE: -3.5050020881405305e+22\n",
            "E_IS_E_SCOPE: -1.1938953376668441e+22\n",
            "Total Loss: 1.7995867687108477e+21\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(1.5873e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.177134347775273e+22\n",
            "E_s_wdiff_all_sq: 2.4829363686499043e+17\n",
            "E_IS_SCOPE: -3.352526279960078e+22\n",
            "E_IS_E_SCOPE: -1.057280545146834e+22\n",
            "Total Loss: 1.5873136426579615e+21\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(1.6518e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2952111814378758e+22\n",
            "E_s_wdiff_all_sq: 9.31244535538539e+19\n",
            "E_IS_SCOPE: -3.191352877889636e+22\n",
            "E_IS_E_SCOPE: -9.126238020662737e+21\n",
            "Total Loss: 1.6518477282760217e+21\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(1.7801e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.359938149685174e+22\n",
            "E_s_wdiff_all_sq: 1.9379745607524398e+20\n",
            "E_IS_SCOPE: -3.1165569678760726e+22\n",
            "E_IS_E_SCOPE: -8.454597465652572e+21\n",
            "Total Loss: 1.780113945989774e+21\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(1.6882e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3203151331044018e+22\n",
            "E_s_wdiff_all_sq: 1.319710181949291e+20\n",
            "E_IS_SCOPE: -3.1602686497240834e+22\n",
            "E_IS_E_SCOPE: -8.847446901451736e+21\n",
            "Total Loss: 1.688198450619331e+21\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(1.5562e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2215919712213322e+22\n",
            "E_s_wdiff_all_sq: 2.0899687616620753e+19\n",
            "E_IS_SCOPE: -3.283190220996491e+22\n",
            "E_IS_E_SCOPE: -9.951990093450058e+21\n",
            "Total Loss: 1.5561649823354454e+21\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(1.6003e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1377950739780977e+22\n",
            "E_s_wdiff_all_sq: 6.728656834605102e+18\n",
            "E_IS_SCOPE: -3.4107211151752986e+22\n",
            "E_IS_E_SCOPE: -1.1096232306045503e+22\n",
            "Total Loss: 1.6003047641132869e+21\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(1.6798e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1052807949431192e+22\n",
            "E_s_wdiff_all_sq: 3.5202491836908536e+19\n",
            "E_IS_SCOPE: -3.471015741715299e+22\n",
            "E_IS_E_SCOPE: -1.163307656577775e+22\n",
            "Total Loss: 1.6798022221602352e+21\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(1.6168e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1245231656492002e+22\n",
            "E_s_wdiff_all_sq: 1.5721640040077249e+19\n",
            "E_IS_SCOPE: -3.43792134152922e+22\n",
            "E_IS_E_SCOPE: -1.1327314441601773e+22\n",
            "Total Loss: 1.6168275604146917e+21\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(1.5268e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.186523423103466e+22\n",
            "E_s_wdiff_all_sq: 2.7415667138166825e+18\n",
            "E_IS_SCOPE: -3.3405647924408474e+22\n",
            "E_IS_E_SCOPE: -1.0441599899703955e+22\n",
            "Total Loss: 1.5268174910313474e+21\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(1.5536e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.263193783444266e+22\n",
            "E_s_wdiff_all_sq: 5.60570436459224e+19\n",
            "E_IS_SCOPE: -3.2396879704542404e+22\n",
            "E_IS_E_SCOPE: -9.522452985415874e+21\n",
            "Total Loss: 1.5536167913072424e+21\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(1.6038e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3038238778747116e+22\n",
            "E_s_wdiff_all_sq: 1.038464977379727e+20\n",
            "E_IS_SCOPE: -3.1941390037369942e+22\n",
            "E_IS_E_SCOPE: -9.100087115917017e+21\n",
            "Total Loss: 1.603799461460053e+21\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(1.5579e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.280744616265086e+22\n",
            "E_s_wdiff_all_sq: 7.232327063685525e+19\n",
            "E_IS_SCOPE: -3.226097241733373e+22\n",
            "E_IS_E_SCOPE: -9.374780287438828e+21\n",
            "Total Loss: 1.5579216000016533e+21\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(1.4955e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2186054363945735e+22\n",
            "E_s_wdiff_all_sq: 1.4320783436180496e+19\n",
            "E_IS_SCOPE: -3.311621804425452e+22\n",
            "E_IS_E_SCOPE: -1.0131275611539864e+22\n",
            "Total Loss: 1.4955245197580546e+21\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(1.5135e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1632689759298687e+22\n",
            "E_s_wdiff_all_sq: 1.084200194891547e+18\n",
            "E_IS_SCOPE: -3.399041051449923e+22\n",
            "E_IS_E_SCOPE: -1.0904521428491936e+22\n",
            "Total Loss: 1.5135124254778102e+21\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(1.5428e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1424102425190768e+22\n",
            "E_s_wdiff_all_sq: 9.995917013511735e+18\n",
            "E_IS_SCOPE: -3.438730299143147e+22\n",
            "E_IS_E_SCOPE: -1.1248423262188292e+22\n",
            "Total Loss: 1.5428456385944727e+21\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(1.5052e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1604771700615028e+22\n",
            "E_s_wdiff_all_sq: 2.497813187449078e+18\n",
            "E_IS_SCOPE: -3.41309817677249e+22\n",
            "E_IS_E_SCOPE: -1.10047754887802e+22\n",
            "Total Loss: 1.5052140412075927e+21\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(1.4629e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2080736777878213e+22\n",
            "E_s_wdiff_all_sq: 5.962303699342489e+18\n",
            "E_IS_SCOPE: -3.344352078594305e+22\n",
            "E_IS_E_SCOPE: -1.0373720528271083e+22\n",
            "Total Loss: 1.4629362005071322e+21\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(1.4770e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2592625258055936e+22\n",
            "E_s_wdiff_all_sq: 3.991967222209619e+19\n",
            "E_IS_SCOPE: -3.2780876560970264e+22\n",
            "E_IS_E_SCOPE: -9.766007546533942e+21\n",
            "Total Loss: 1.4769741854190055e+21\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(1.4901e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2793876705606977e+22\n",
            "E_s_wdiff_all_sq: 5.9502027677624975e+19\n",
            "E_IS_SCOPE: -3.2554403762262136e+22\n",
            "E_IS_E_SCOPE: -9.552317118832756e+21\n",
            "Total Loss: 1.490099947282744e+21\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(1.4566e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.255984103315449e+22\n",
            "E_s_wdiff_all_sq: 3.5746662274154856e+19\n",
            "E_IS_SCOPE: -3.2879345052357864e+22\n",
            "E_IS_E_SCOPE: -9.83578305695054e+21\n",
            "Total Loss: 1.4565795089921522e+21\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(1.4298e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21067556028737e+22\n",
            "E_s_wdiff_all_sq: 5.902081057804411e+18\n",
            "E_IS_SCOPE: -3.3523765883237877e+22\n",
            "E_IS_E_SCOPE: -1.0407510391118763e+22\n",
            "Total Loss: 1.4298344194560062e+21\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(1.4413e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.175482671195341e+22\n",
            "E_s_wdiff_all_sq: 3.608061351989825e+17\n",
            "E_IS_SCOPE: -3.4076115135540777e+22\n",
            "E_IS_E_SCOPE: -1.0896870497663756e+22\n",
            "Total Loss: 1.4412873435648958e+21\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(1.4412e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1683486231838048e+22\n",
            "E_s_wdiff_all_sq: 1.556677069839308e+18\n",
            "E_IS_SCOPE: -3.420723472477327e+22\n",
            "E_IS_E_SCOPE: -1.100803445272771e+22\n",
            "Total Loss: 1.4411995501764154e+21\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(1.4114e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1899953007459526e+22\n",
            "E_s_wdiff_all_sq: 5.0133590337038566e+17\n",
            "E_IS_SCOPE: -3.3877475235530344e+22\n",
            "E_IS_E_SCOPE: -1.0706104847560193e+22\n",
            "Total Loss: 1.411396488781185e+21\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(1.3971e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2270487781157556e+22\n",
            "E_s_wdiff_all_sq: 1.452261542540968e+19\n",
            "E_IS_SCOPE: -3.334386714471336e+22\n",
            "E_IS_E_SCOPE: -1.0222092984288681e+22\n",
            "Total Loss: 1.3971118542986527e+21\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(1.4043e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.25455514272645e+22\n",
            "E_s_wdiff_all_sq: 3.5443729775789773e+19\n",
            "E_IS_SCOPE: -3.2980659698734673e+22\n",
            "E_IS_E_SCOPE: -9.890679039300559e+21\n",
            "Total Loss: 1.4043485573986008e+21\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(1.3937e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2523128111479212e+22\n",
            "E_s_wdiff_all_sq: 3.3737923484991574e+19\n",
            "E_IS_SCOPE: -3.302263786840805e+22\n",
            "E_IS_E_SCOPE: -9.92258909122313e+21\n",
            "Total Loss: 1.393699058034271e+21\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(1.3697e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2241589554837774e+22\n",
            "E_s_wdiff_all_sq: 1.3463824661238282e+19\n",
            "E_IS_SCOPE: -3.341677226186248e+22\n",
            "E_IS_E_SCOPE: -1.0271178566861467e+22\n",
            "Total Loss: 1.3696601413989884e+21\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(1.3640e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1928459720067207e+22\n",
            "E_s_wdiff_all_sq: 1.2785224077778248e+18\n",
            "E_IS_SCOPE: -3.3881247263236477e+22\n",
            "E_IS_E_SCOPE: -1.0683328741037868e+22\n",
            "Total Loss: 1.3640308264096256e+21\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(1.3643e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1786838981563338e+22\n",
            "E_s_wdiff_all_sq: 2550734243817073.0\n",
            "E_IS_SCOPE: -3.410544001229776e+22\n",
            "E_IS_E_SCOPE: -1.0880103563929582e+22\n",
            "Total Loss: 1.3643490584583356e+21\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(1.3475e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1880218899585343e+22\n",
            "E_s_wdiff_all_sq: 6.887443066764826e+17\n",
            "E_IS_SCOPE: -3.3964912908349544e+22\n",
            "E_IS_E_SCOPE: -1.0749667745270736e+22\n",
            "Total Loss: 1.347475728400235e+21\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(1.3311e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2132323808601113e+22\n",
            "E_s_wdiff_all_sq: 9.0125476743935e+18\n",
            "E_IS_SCOPE: -3.3596038639327665e+22\n",
            "E_IS_E_SCOPE: -1.04142431226007e+22\n",
            "Total Loss: 1.3310553074496543e+21\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(1.3288e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2359518219820369e+22\n",
            "E_s_wdiff_all_sq: 2.355155912170939e+19\n",
            "E_IS_SCOPE: -3.3284183456581075e+22\n",
            "E_IS_E_SCOPE: -1.0129853799297874e+22\n",
            "Total Loss: 1.3287921142536088e+21\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(1.3210e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.238773829114204e+22\n",
            "E_s_wdiff_all_sq: 2.6027424365793227e+19\n",
            "E_IS_SCOPE: -3.325724543577118e+22\n",
            "E_IS_E_SCOPE: -1.0099905093363302e+22\n",
            "Total Loss: 1.3210421093913623e+21\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(1.3036e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2205940343263744e+22\n",
            "E_s_wdiff_all_sq: 1.3827445038710628e+19\n",
            "E_IS_SCOPE: -3.351893605020439e+22\n",
            "E_IS_E_SCOPE: -1.0329141024401517e+22\n",
            "Total Loss: 1.3035707257612906e+21\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(1.2943e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1971769088341126e+22\n",
            "E_s_wdiff_all_sq: 3.3808223308120694e+18\n",
            "E_IS_SCOPE: -3.3868683983787127e+22\n",
            "E_IS_E_SCOPE: -1.0637275207129033e+22\n",
            "Total Loss: 1.2943061518557412e+21\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(1.2897e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1854936498453332e+22\n",
            "E_s_wdiff_all_sq: 7.516945630442011e+17\n",
            "E_IS_SCOPE: -3.405854906542557e+22\n",
            "E_IS_E_SCOPE: -1.080127225483636e+22\n",
            "Total Loss: 1.289734541813041e+21\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(1.2763e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1921079734718163e+22\n",
            "E_s_wdiff_all_sq: 2.076841512173565e+18\n",
            "E_IS_SCOPE: -3.397632371078965e+22\n",
            "E_IS_E_SCOPE: -1.071993393085295e+22\n",
            "Total Loss: 1.2763135153994832e+21\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(1.2627e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2110884012131495e+22\n",
            "E_s_wdiff_all_sq: 9.069685530858882e+18\n",
            "E_IS_SCOPE: -3.3718835790941866e+22\n",
            "E_IS_E_SCOPE: -1.0480477852306265e+22\n",
            "Total Loss: 1.2627253968683265e+21\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(1.2564e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2278191404034225e+22\n",
            "E_s_wdiff_all_sq: 1.8685241388524634e+19\n",
            "E_IS_SCOPE: -3.350828240418175e+22\n",
            "E_IS_E_SCOPE: -1.0282236121184601e+22\n",
            "Total Loss: 1.256414368926305e+21\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(1.2467e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2292507139117263e+22\n",
            "E_s_wdiff_all_sq: 1.943348264484393e+19\n",
            "E_IS_SCOPE: -3.351490470015154e+22\n",
            "E_IS_E_SCOPE: -1.0278635985077858e+22\n",
            "Total Loss: 1.246685103749526e+21\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(1.2325e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2156577494832555e+22\n",
            "E_s_wdiff_all_sq: 1.0911978081941123e+19\n",
            "E_IS_SCOPE: -3.3732205758776047e+22\n",
            "E_IS_E_SCOPE: -1.0464088822638019e+22\n",
            "Total Loss: 1.2325118548962894e+21\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(1.2232e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.199476757834252e+22\n",
            "E_s_wdiff_all_sq: 3.8209152072431867e+18\n",
            "E_IS_SCOPE: -3.399230348502566e+22\n",
            "E_IS_E_SCOPE: -1.0688333226491356e+22\n",
            "Total Loss: 1.2232396974670364e+21\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(1.2150e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1934386231559609e+22\n",
            "E_s_wdiff_all_sq: 2.0219336569202732e+18\n",
            "E_IS_SCOPE: -3.4108479363212556e+22\n",
            "E_IS_E_SCOPE: -1.0783161025489789e+22\n",
            "Total Loss: 1.2149899913056339e+21\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(1.2020e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2012212744656058e+22\n",
            "E_s_wdiff_all_sq: 4.200909866380894e+18\n",
            "E_IS_SCOPE: -3.4019954462078697e+22\n",
            "E_IS_E_SCOPE: -1.0693855981469404e+22\n",
            "Total Loss: 1.2019511746086463e+21\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(1.1903e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.214390478637759e+22\n",
            "E_s_wdiff_all_sq: 9.84692014117684e+18\n",
            "E_IS_SCOPE: -3.3848198683308272e+22\n",
            "E_IS_E_SCOPE: -1.0531587344468344e+22\n",
            "Total Loss: 1.1903488628678501e+21\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(1.1801e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.216407197502897e+22\n",
            "E_s_wdiff_all_sq: 1.1790627644726143e+19\n",
            "E_IS_SCOPE: -3.3809238666236645e+22\n",
            "E_IS_E_SCOPE: -1.049547874794727e+22\n",
            "Total Loss: 1.1801102960992631e+21\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(1.1689e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2084167305902185e+22\n",
            "E_s_wdiff_all_sq: 8.847664656674314e+18\n",
            "E_IS_SCOPE: -3.3900875979975534e+22\n",
            "E_IS_E_SCOPE: -1.0579472643091774e+22\n",
            "Total Loss: 1.1689126849282069e+21\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(1.1585e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2001962823171067e+22\n",
            "E_s_wdiff_all_sq: 6.025374071502084e+18\n",
            "E_IS_SCOPE: -3.4005369668284935e+22\n",
            "E_IS_E_SCOPE: -1.0673082323603003e+22\n",
            "Total Loss: 1.1585498671119744e+21\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(1.1473e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2064932943767403e+22\n",
            "E_s_wdiff_all_sq: 8.533814493309938e+18\n",
            "E_IS_SCOPE: -3.3947366417133333e+22\n",
            "E_IS_E_SCOPE: -1.0609657567980491e+22\n",
            "Total Loss: 1.1472522231439824e+21\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(1.1367e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212830196089783e+22\n",
            "E_s_wdiff_all_sq: 1.1377345801781285e+19\n",
            "E_IS_SCOPE: -3.3892766133473864e+22\n",
            "E_IS_E_SCOPE: -1.0548613427595294e+22\n",
            "Total Loss: 1.1366893864377574e+21\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(1.1254e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2092257992794534e+22\n",
            "E_s_wdiff_all_sq: 9.581448977066113e+18\n",
            "E_IS_SCOPE: -3.3962956285604794e+22\n",
            "E_IS_E_SCOPE: -1.0603645791052633e+22\n",
            "Total Loss: 1.1253622044446163e+21\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(1.1144e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2028444769477068e+22\n",
            "E_s_wdiff_all_sq: 6.633882610849539e+18\n",
            "E_IS_SCOPE: -3.407678218877208e+22\n",
            "E_IS_E_SCOPE: -1.0697158144042446e+22\n",
            "Total Loss: 1.1144342337620206e+21\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(1.1031e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2051917330869666e+22\n",
            "E_s_wdiff_all_sq: 7.10035377010985e+18\n",
            "E_IS_SCOPE: -3.4089221360463743e+22\n",
            "E_IS_E_SCOPE: -1.0693856547036306e+22\n",
            "Total Loss: 1.1031236607528665e+21\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(1.0918e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127351467841742e+22\n",
            "E_s_wdiff_all_sq: 9.71706088519e+18\n",
            "E_IS_SCOPE: -3.404097726408538e+22\n",
            "E_IS_E_SCOPE: -1.0632784592245564e+22\n",
            "Total Loss: 1.0918301261094464e+21\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(1.0806e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2146223448982945e+22\n",
            "E_s_wdiff_all_sq: 1.0052183228978827e+19\n",
            "E_IS_SCOPE: -3.4059757960315407e+22\n",
            "E_IS_E_SCOPE: -1.0635270460826664e+22\n",
            "Total Loss: 1.0805983205338907e+21\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(1.0691e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101062659164732e+22\n",
            "E_s_wdiff_all_sq: 7.609704325882423e+18\n",
            "E_IS_SCOPE: -3.4157812232006274e+22\n",
            "E_IS_E_SCOPE: -1.0711846053681341e+22\n",
            "Total Loss: 1.0690557658979799e+21\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(1.0577e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2082168099871543e+22\n",
            "E_s_wdiff_all_sq: 6.393003270357774e+18\n",
            "E_IS_SCOPE: -3.422562451272381e+22\n",
            "E_IS_E_SCOPE: -1.075957872307528e+22\n",
            "Total Loss: 1.0577346533515382e+21\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(1.0460e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213020326599022e+22\n",
            "E_s_wdiff_all_sq: 7.831166897434421e+18\n",
            "E_IS_SCOPE: -3.4207913238684225e+22\n",
            "E_IS_E_SCOPE: -1.0727856352283935e+22\n",
            "Total Loss: 1.0460252551753446e+21\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(1.0346e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2177250193971446e+22\n",
            "E_s_wdiff_all_sq: 9.487218270428697e+18\n",
            "E_IS_SCOPE: -3.418695069608659e+22\n",
            "E_IS_E_SCOPE: -1.0694381326064123e+22\n",
            "Total Loss: 1.0345721896924076e+21\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(1.0228e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2161087009954743e+22\n",
            "E_s_wdiff_all_sq: 8.49785090682553e+18\n",
            "E_IS_SCOPE: -3.4241322838926444e+22\n",
            "E_IS_E_SCOPE: -1.0732085248959202e+22\n",
            "Total Loss: 1.0227764886812314e+21\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(1.0111e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2121070845041656e+22\n",
            "E_s_wdiff_all_sq: 6.68449501634125e+18\n",
            "E_IS_SCOPE: -3.432317794684397e+22\n",
            "E_IS_E_SCOPE: -1.0796089635684118e+22\n",
            "Total Loss: 1.0110632681078386e+21\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(9.9918e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127058158385526e+22\n",
            "E_s_wdiff_all_sq: 6.826442545100489e+18\n",
            "E_IS_SCOPE: -3.434318336583652e+22\n",
            "E_IS_E_SCOPE: -1.0803469958265608e+22\n",
            "Total Loss: 9.991807112110827e+20\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(9.8722e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2168073481343449e+22\n",
            "E_s_wdiff_all_sq: 8.508589829581772e+18\n",
            "E_IS_SCOPE: -3.4314882434000207e+22\n",
            "E_IS_E_SCOPE: -1.0766942331751084e+22\n",
            "Total Loss: 9.872150182980559e+20\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(9.7525e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2176684387901119e+22\n",
            "E_s_wdiff_all_sq: 8.980974322210485e+18\n",
            "E_IS_SCOPE: -3.43240522518299e+22\n",
            "E_IS_E_SCOPE: -1.0766197186037736e+22\n",
            "Total Loss: 9.752508520563013e+20\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(9.6309e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2139674910767213e+22\n",
            "E_s_wdiff_all_sq: 7.545514491885366e+18\n",
            "E_IS_SCOPE: -3.438931357036018e+22\n",
            "E_IS_E_SCOPE: -1.0817988395033115e+22\n",
            "Total Loss: 9.630923648479758e+20\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(9.5101e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115370444249251e+22\n",
            "E_s_wdiff_all_sq: 6.778270906114173e+18\n",
            "E_IS_SCOPE: -3.4435642213529958e+22\n",
            "E_IS_E_SCOPE: -1.0852947379384148e+22\n",
            "Total Loss: 9.510075650435543e+20\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(9.3868e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21355216942951e+22\n",
            "E_s_wdiff_all_sq: 7.81528263127965e+18\n",
            "E_IS_SCOPE: -3.442446713968044e+22\n",
            "E_IS_E_SCOPE: -1.0834671522602918e+22\n",
            "Total Loss: 9.38681392444746e+20\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(9.2643e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2156487501320747e+22\n",
            "E_s_wdiff_all_sq: 9.02246369271829e+18\n",
            "E_IS_SCOPE: -3.440994847517194e+22\n",
            "E_IS_E_SCOPE: -1.081392153187406e+22\n",
            "Total Loss: 9.26434556300822e+20\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(9.1402e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2136907593662983e+22\n",
            "E_s_wdiff_all_sq: 8.473657060423804e+18\n",
            "E_IS_SCOPE: -3.444711980633373e+22\n",
            "E_IS_E_SCOPE: -1.0841089739270146e+22\n",
            "Total Loss: 9.140166085077337e+20\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(9.0160e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2104044271443062e+22\n",
            "E_s_wdiff_all_sq: 7.335639167722385e+18\n",
            "E_IS_SCOPE: -3.450389617466081e+22\n",
            "E_IS_E_SCOPE: -1.088575519237585e+22\n",
            "Total Loss: 9.015969089507662e+20\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(8.8908e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.210462980474097e+22\n",
            "E_s_wdiff_all_sq: 7.573405599137854e+18\n",
            "E_IS_SCOPE: -3.451885488122717e+22\n",
            "E_IS_E_SCOPE: -1.0891360132994127e+22\n",
            "Total Loss: 8.890798509707808e+20\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(8.7648e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128173657756937e+22\n",
            "E_s_wdiff_all_sq: 8.77376816568012e+18\n",
            "E_IS_SCOPE: -3.450570525847417e+22\n",
            "E_IS_E_SCOPE: -1.0870547232488094e+22\n",
            "Total Loss: 8.764842479746516e+20\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(8.6383e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212906469517107e+22\n",
            "E_s_wdiff_all_sq: 8.930388870312846e+18\n",
            "E_IS_SCOPE: -3.4525139627025638e+22\n",
            "E_IS_E_SCOPE: -1.0878989833763344e+22\n",
            "Total Loss: 8.638343521115979e+20\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(8.5112e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2104141925470454e+22\n",
            "E_s_wdiff_all_sq: 7.879041544775077e+18\n",
            "E_IS_SCOPE: -3.458123738420071e+22\n",
            "E_IS_E_SCOPE: -1.0920456986651288e+22\n",
            "Total Loss: 8.511175267246743e+20\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(8.3837e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2095989539369612e+22\n",
            "E_s_wdiff_all_sq: 7.551307781983021e+18\n",
            "E_IS_SCOPE: -3.4616653838467564e+22\n",
            "E_IS_E_SCOPE: -1.0942534790485513e+22\n",
            "Total Loss: 8.383656435927986e+20\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(8.2549e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116214096607895e+22\n",
            "E_s_wdiff_all_sq: 8.415079779994917e+18\n",
            "E_IS_SCOPE: -3.4615901098296012e+22\n",
            "E_IS_E_SCOPE: -1.0930998201774231e+22\n",
            "Total Loss: 8.254859150403358e+20\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(8.1257e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127881795100419e+22\n",
            "E_s_wdiff_all_sq: 8.926240639637699e+18\n",
            "E_IS_SCOPE: -3.4626769304095033e+22\n",
            "E_IS_E_SCOPE: -1.0930050732786012e+22\n",
            "Total Loss: 8.125747949701599e+20\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(7.9961e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2112026495103854e+22\n",
            "E_s_wdiff_all_sq: 8.237318787873422e+18\n",
            "E_IS_SCOPE: -3.4672668280155697e+22\n",
            "E_IS_E_SCOPE: -1.0961612287202992e+22\n",
            "Total Loss: 7.996062061032081e+20\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(7.8658e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2099940651323695e+22\n",
            "E_s_wdiff_all_sq: 7.605545050523092e+18\n",
            "E_IS_SCOPE: -3.4719271398748027e+22\n",
            "E_IS_E_SCOPE: -1.0992368307587204e+22\n",
            "Total Loss: 7.865821862910241e+20\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(7.7343e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116220275722086e+22\n",
            "E_s_wdiff_all_sq: 8.067148890868569e+18\n",
            "E_IS_SCOPE: -3.473374738855318e+22\n",
            "E_IS_E_SCOPE: -1.099220797935788e+22\n",
            "Total Loss: 7.734288463911348e+20\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(7.6028e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2137587735952986e+22\n",
            "E_s_wdiff_all_sq: 8.68580370972083e+18\n",
            "E_IS_SCOPE: -3.474494150470191e+22\n",
            "E_IS_E_SCOPE: -1.0988164678149632e+22\n",
            "Total Loss: 7.602781706998356e+20\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(7.4706e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2134175266144829e+22\n",
            "E_s_wdiff_all_sq: 8.33367465602258e+18\n",
            "E_IS_SCOPE: -3.4783819423621598e+22\n",
            "E_IS_E_SCOPE: -1.1010813608694362e+22\n",
            "Total Loss: 7.470566546864897e+20\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(7.3375e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120698413984216e+22\n",
            "E_s_wdiff_all_sq: 7.654825889031122e+18\n",
            "E_IS_SCOPE: -3.4832144012901597e+22\n",
            "E_IS_E_SCOPE: -1.1043087591814073e+22\n",
            "Total Loss: 7.337525733250145e+20\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(7.2035e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125549607379469e+22\n",
            "E_s_wdiff_all_sq: 7.800669340819894e+18\n",
            "E_IS_SCOPE: -3.4854958292456954e+22\n",
            "E_IS_E_SCOPE: -1.1052213694925352e+22\n",
            "Total Loss: 7.203535169433905e+20\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(7.0694e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.214051485679126e+22\n",
            "E_s_wdiff_all_sq: 8.436832673704211e+18\n",
            "E_IS_SCOPE: -3.4862528911040294e+22\n",
            "E_IS_E_SCOPE: -1.1047802340738316e+22\n",
            "Total Loss: 7.069434666273871e+20\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(6.9349e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2138996324570675e+22\n",
            "E_s_wdiff_all_sq: 8.40636883391521e+18\n",
            "E_IS_SCOPE: -3.488983493688199e+22\n",
            "E_IS_E_SCOPE: -1.1062028830543643e+22\n",
            "Total Loss: 6.93492352139393e+20\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(6.7992e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212507933697997e+22\n",
            "E_s_wdiff_all_sq: 7.759711596577149e+18\n",
            "E_IS_SCOPE: -3.493699909694722e+22\n",
            "E_IS_E_SCOPE: -1.1093587469670529e+22\n",
            "Total Loss: 6.799229617988908e+20\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(6.6627e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2126933425903955e+22\n",
            "E_s_wdiff_all_sq: 7.675937753143454e+18\n",
            "E_IS_SCOPE: -3.4968613877174485e+22\n",
            "E_IS_E_SCOPE: -1.110949578580027e+22\n",
            "Total Loss: 6.662724386575708e+20\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(6.5265e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2118295601655837e+22\n",
            "E_s_wdiff_all_sq: 7.393457080459871e+18\n",
            "E_IS_SCOPE: -3.5003825086458283e+22\n",
            "E_IS_E_SCOPE: -1.1131307214810055e+22\n",
            "Total Loss: 6.526464828712073e+20\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(6.3911e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2185973985349649e+22\n",
            "E_s_wdiff_all_sq: 1.01791643920203e+19\n",
            "E_IS_SCOPE: -3.495239374762885e+22\n",
            "E_IS_E_SCOPE: -1.106994767943105e+22\n",
            "Total Loss: 6.391089380868657e+20\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(6.2507e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2136319738575835e+22\n",
            "E_s_wdiff_all_sq: 8.142100704686345e+18\n",
            "E_IS_SCOPE: -3.503571868745321e+22\n",
            "E_IS_E_SCOPE: -1.113736891045439e+22\n",
            "Total Loss: 6.250685047343541e+20\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(6.1144e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2087617619006325e+22\n",
            "E_s_wdiff_all_sq: 6.422063779349371e+18\n",
            "E_IS_SCOPE: -3.511513274938363e+22\n",
            "E_IS_E_SCOPE: -1.120200239658005e+22\n",
            "Total Loss: 6.11438719680987e+20\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(5.9739e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120737570239967e+22\n",
            "E_s_wdiff_all_sq: 7.808324648228662e+18\n",
            "E_IS_SCOPE: -3.509748065004141e+22\n",
            "E_IS_E_SCOPE: -1.1174510754122558e+22\n",
            "Total Loss: 5.973879422265946e+20\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(5.8353e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2162968083986043e+22\n",
            "E_s_wdiff_all_sq: 9.638060411956275e+18\n",
            "E_IS_SCOPE: -3.5072453658775975e+22\n",
            "E_IS_E_SCOPE: -1.1139129005088728e+22\n",
            "Total Loss: 5.835271914020489e+20\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(5.6940e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2137580062259297e+22\n",
            "E_s_wdiff_all_sq: 8.512270176500157e+18\n",
            "E_IS_SCOPE: -3.513236770320805e+22\n",
            "E_IS_E_SCOPE: -1.1182825869870771e+22\n",
            "Total Loss: 5.6940167515728354e+20\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(5.5543e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2095684426043654e+22\n",
            "E_s_wdiff_all_sq: 6.873550518731116e+18\n",
            "E_IS_SCOPE: -3.521004777742553e+22\n",
            "E_IS_E_SCOPE: -1.1243921260508644e+22\n",
            "Total Loss: 5.5543206242029666e+20\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(5.4122e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.211184758891624e+22\n",
            "E_s_wdiff_all_sq: 7.617602314669122e+18\n",
            "E_IS_SCOPE: -3.5213492215301592e+22\n",
            "E_IS_E_SCOPE: -1.1236091168822407e+22\n",
            "Total Loss: 5.412160744820467e+20\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(5.2705e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.214812585238545e+22\n",
            "E_s_wdiff_all_sq: 9.313738670386946e+18\n",
            "E_IS_SCOPE: -3.5190487640541667e+22\n",
            "E_IS_E_SCOPE: -1.120393945465897e+22\n",
            "Total Loss: 5.2704834498079595e+20\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(5.1279e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2131420756020654e+22\n",
            "E_s_wdiff_all_sq: 8.851903681805893e+18\n",
            "E_IS_SCOPE: -3.522899041069885e+22\n",
            "E_IS_E_SCOPE: -1.1230423947615305e+22\n",
            "Total Loss: 5.1279118717063633e+20\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(4.9853e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2091093760979184e+22\n",
            "E_s_wdiff_all_sq: 7.273800898953008e+18\n",
            "E_IS_SCOPE: -3.530378582897494e+22\n",
            "E_IS_E_SCOPE: -1.128897779932501e+22\n",
            "Total Loss: 4.9853491070610964e+20\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(4.8414e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2098322663072957e+22\n",
            "E_s_wdiff_all_sq: 7.567748981419239e+18\n",
            "E_IS_SCOPE: -3.532324057333828e+22\n",
            "E_IS_E_SCOPE: -1.1294739428627817e+22\n",
            "Total Loss: 4.841392119816158e+20\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(4.6980e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135996318699995e+22\n",
            "E_s_wdiff_all_sq: 9.036747450801875e+18\n",
            "E_IS_SCOPE: -3.530978938996114e+22\n",
            "E_IS_E_SCOPE: -1.126843288614729e+22\n",
            "Total Loss: 4.697956069213607e+20\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(4.5539e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2134749561741143e+22\n",
            "E_s_wdiff_all_sq: 8.947076666151327e+18\n",
            "E_IS_SCOPE: -3.534148910052979e+22\n",
            "E_IS_E_SCOPE: -1.128517897897711e+22\n",
            "Total Loss: 4.553877073146602e+20\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(4.4090e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2102280523613894e+22\n",
            "E_s_wdiff_all_sq: 7.58825348756846e+18\n",
            "E_IS_SCOPE: -3.541062934509949e+22\n",
            "E_IS_E_SCOPE: -1.1337265590590505e+22\n",
            "Total Loss: 4.408980148882034e+20\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(4.2635e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101040142819569e+22\n",
            "E_s_wdiff_all_sq: 7.573095252815326e+18\n",
            "E_IS_SCOPE: -3.543980535359371e+22\n",
            "E_IS_E_SCOPE: -1.135227882976325e+22\n",
            "Total Loss: 4.263453346236759e+20\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(4.1168e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2129312227831413e+22\n",
            "E_s_wdiff_all_sq: 8.815906185424067e+18\n",
            "E_IS_SCOPE: -3.543145657752981e+22\n",
            "E_IS_E_SCOPE: -1.1332399964825884e+22\n",
            "Total Loss: 4.116783769512145e+20\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(3.9707e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2129276424265883e+22\n",
            "E_s_wdiff_all_sq: 8.973023490845377e+18\n",
            "E_IS_SCOPE: -3.5454495983748543e+22\n",
            "E_IS_E_SCOPE: -1.134290140752373e+22\n",
            "Total Loss: 3.970680890417595e+20\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(3.8237e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101396448771196e+22\n",
            "E_s_wdiff_all_sq: 7.757830553102307e+18\n",
            "E_IS_SCOPE: -3.5520072943078486e+22\n",
            "E_IS_E_SCOPE: -1.1391013150754131e+22\n",
            "Total Loss: 3.823694245783887e+20\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(3.6757e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101589800352104e+22\n",
            "E_s_wdiff_all_sq: 7.568626379815266e+18\n",
            "E_IS_SCOPE: -3.555780874143794e+22\n",
            "E_IS_E_SCOPE: -1.141117389001589e+22\n",
            "Total Loss: 3.675733972256639e+20\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(3.5272e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2133500199739933e+22\n",
            "E_s_wdiff_all_sq: 8.599337443984928e+18\n",
            "E_IS_SCOPE: -3.5560002140252473e+22\n",
            "E_IS_E_SCOPE: -1.1397047848270029e+22\n",
            "Total Loss: 3.5271887374684206e+20\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(3.3789e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2142785055565522e+22\n",
            "E_s_wdiff_all_sq: 8.817136149464127e+18\n",
            "E_IS_SCOPE: -3.5585433688957807e+22\n",
            "E_IS_E_SCOPE: -1.1405964049542711e+22\n",
            "Total Loss: 3.3788923597981064e+20\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(3.2294e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120776852312835e+22\n",
            "E_s_wdiff_all_sq: 7.797444480348061e+18\n",
            "E_IS_SCOPE: -3.5646489801883994e+22\n",
            "E_IS_E_SCOPE: -1.1449021931728665e+22\n",
            "Total Loss: 3.2294245343261046e+20\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(3.0794e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115403123188319e+22\n",
            "E_s_wdiff_all_sq: 7.568939925811033e+18\n",
            "E_IS_SCOPE: -3.5683686433781696e+22\n",
            "E_IS_E_SCOPE: -1.1470610342222066e+22\n",
            "Total Loss: 3.079406919928932e+20\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(2.9286e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135820367177324e+22\n",
            "E_s_wdiff_all_sq: 8.478356919777422e+18\n",
            "E_IS_SCOPE: -3.5685792951848042e+22\n",
            "E_IS_E_SCOPE: -1.1460183369630207e+22\n",
            "Total Loss: 2.928639820736307e+20\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(2.7779e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2140165405517856e+22\n",
            "E_s_wdiff_all_sq: 8.69040690733726e+18\n",
            "E_IS_SCOPE: -3.5709542682080307e+22\n",
            "E_IS_E_SCOPE: -1.1469543959836764e+22\n",
            "Total Loss: 2.777913305693044e+20\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(2.6258e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2121119769083255e+22\n",
            "E_s_wdiff_all_sq: 7.798521990456603e+18\n",
            "E_IS_SCOPE: -3.5767462779568483e+22\n",
            "E_IS_E_SCOPE: -1.150943692666e+22\n",
            "Total Loss: 2.6258439962805823e+20\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(2.4743e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120516103250008e+22\n",
            "E_s_wdiff_all_sq: 7.614902570840139e+18\n",
            "E_IS_SCOPE: -3.5805307264536462e+22\n",
            "E_IS_E_SCOPE: -1.15298148631276e+22\n",
            "Total Loss: 2.4742557326165148e+20\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(2.3217e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2142033045783449e+22\n",
            "E_s_wdiff_all_sq: 8.463252554697501e+18\n",
            "E_IS_SCOPE: -3.58108669594462e+22\n",
            "E_IS_E_SCOPE: -1.152126423133578e+22\n",
            "Total Loss: 2.321712306001606e+20\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(2.1685e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2143886463254502e+22\n",
            "E_s_wdiff_all_sq: 8.594348642653532e+18\n",
            "E_IS_SCOPE: -3.5837171162239233e+22\n",
            "E_IS_E_SCOPE: -1.1533074111513965e+22\n",
            "Total Loss: 2.1684588301970204e+20\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(2.0145e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2122656214780607e+22\n",
            "E_s_wdiff_all_sq: 7.835351096493454e+18\n",
            "E_IS_SCOPE: -3.588909749357273e+22\n",
            "E_IS_E_SCOPE: -1.156963725164919e+22\n",
            "Total Loss: 2.0145239228449345e+20\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(1.8598e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116587504463832e+22\n",
            "E_s_wdiff_all_sq: 7.842054687835633e+18\n",
            "E_IS_SCOPE: -3.591691991489834e+22\n",
            "E_IS_E_SCOPE: -1.1585051820466264e+22\n",
            "Total Loss: 1.859825457677174e+20\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(1.7054e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127241736386242e+22\n",
            "E_s_wdiff_all_sq: 8.555112100219276e+18\n",
            "E_IS_SCOPE: -3.5923674091904486e+22\n",
            "E_IS_E_SCOPE: -1.15808567177009e+22\n",
            "Total Loss: 1.7054311538174093e+20\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(1.5501e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125134238247589e+22\n",
            "E_s_wdiff_all_sq: 8.533636510262068e+18\n",
            "E_IS_SCOPE: -3.5954667843890572e+22\n",
            "E_IS_E_SCOPE: -1.159704359178439e+22\n",
            "Total Loss: 1.5500873552138705e+20\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(1.3934e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2113305957379978e+22\n",
            "E_s_wdiff_all_sq: 7.918880979269823e+18\n",
            "E_IS_SCOPE: -3.6005627774352402e+22\n",
            "E_IS_E_SCOPE: -1.1629738387696611e+22\n",
            "Total Loss: 1.3934498146678106e+20\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(1.2372e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2119076915685639e+22\n",
            "E_s_wdiff_all_sq: 8.005162939135414e+18\n",
            "E_IS_SCOPE: -3.6036068511186265e+22\n",
            "E_IS_E_SCOPE: -1.1642901561206362e+22\n",
            "Total Loss: 1.2372398663396858e+20\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(1.0809e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213297720219529e+22\n",
            "E_s_wdiff_all_sq: 8.55781666713699e+18\n",
            "E_IS_SCOPE: -3.6051434308650897e+22\n",
            "E_IS_E_SCOPE: -1.164329958974709e+22\n",
            "Total Loss: 1.0808676383653993e+20\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(9.2405e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128708857438969e+22\n",
            "E_s_wdiff_all_sq: 8.48763461236741e+18\n",
            "E_IS_SCOPE: -3.608367032371898e+22\n",
            "E_IS_E_SCOPE: -1.1660985745921e+22\n",
            "Total Loss: 9.240485746577926e+19\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(7.6648e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117665998150513e+22\n",
            "E_s_wdiff_all_sq: 8.14955694662722e+18\n",
            "E_IS_SCOPE: -3.6123798920388103e+22\n",
            "E_IS_E_SCOPE: -1.1686166742476337e+22\n",
            "Total Loss: 7.664779450509165e+19\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(6.0822e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2111003667703475e+22\n",
            "E_s_wdiff_all_sq: 8.045203847492336e+18\n",
            "E_IS_SCOPE: -3.6156687509448928e+22\n",
            "E_IS_E_SCOPE: -1.1705037969994805e+22\n",
            "Total Loss: 6.0821968491808555e+19\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(4.5004e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2112585362610982e+22\n",
            "E_s_wdiff_all_sq: 8.33121977073828e+18\n",
            "E_IS_SCOPE: -3.617740301194891e+22\n",
            "E_IS_E_SCOPE: -1.171304828703877e+22\n",
            "Total Loss: 4.500360953124094e+19\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(2.9147e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117110253448205e+22\n",
            "E_s_wdiff_all_sq: 8.591672382237137e+18\n",
            "E_IS_SCOPE: -3.6200836211480593e+22\n",
            "E_IS_E_SCOPE: -1.172187660925064e+22\n",
            "Total Loss: 2.9147067940710908e+19\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(1.3173e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117068352872522e+22\n",
            "E_s_wdiff_all_sq: 8.493027115927862e+18\n",
            "E_IS_SCOPE: -3.6236785327513887e+22\n",
            "E_IS_E_SCOPE: -1.1740531847299932e+22\n",
            "Total Loss: 1.3172649446315393e+19\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(-2.8655e+18, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115045973815909e+22\n",
            "E_s_wdiff_all_sq: 8.204898352980747e+18\n",
            "E_IS_SCOPE: -3.6279690314680703e+22\n",
            "E_IS_E_SCOPE: -1.1764463259738832e+22\n",
            "Total Loss: -2.865466627227386e+18\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(-1.8837e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21182928109298e+22\n",
            "E_s_wdiff_all_sq: 8.016914411021243e+18\n",
            "E_IS_SCOPE: -3.63209903236539e+22\n",
            "E_IS_E_SCOPE: -1.1785590517616624e+22\n",
            "Total Loss: -1.8836873826359312e+19\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(-3.4878e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127278674333649e+22\n",
            "E_s_wdiff_all_sq: 8.165706400204357e+18\n",
            "E_IS_SCOPE: -3.635125478450819e+22\n",
            "E_IS_E_SCOPE: -1.1797424419202824e+22\n",
            "Total Loss: -3.487822737248669e+19\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(-5.0993e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135913387610308e+22\n",
            "E_s_wdiff_all_sq: 8.430319069066772e+18\n",
            "E_IS_SCOPE: -3.637685334953238e+22\n",
            "E_IS_E_SCOPE: -1.180624032837817e+22\n",
            "Total Loss: -5.09929166181761e+19\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(-6.7169e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135347018513852e+22\n",
            "E_s_wdiff_all_sq: 8.367625721076847e+18\n",
            "E_IS_SCOPE: -3.641155817954212e+22\n",
            "E_IS_E_SCOPE: -1.182417368615821e+22\n",
            "Total Loss: -6.71688723939889e+19\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(-8.3421e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128855530491697e+22\n",
            "E_s_wdiff_all_sq: 8.131162501062754e+18\n",
            "E_IS_SCOPE: -3.6450744394082956e+22\n",
            "E_IS_E_SCOPE: -1.1847044150901915e+22\n",
            "Total Loss: -8.342139526669612e+19\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(-9.9733e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2123977943652638e+22\n",
            "E_s_wdiff_all_sq: 8.085648236205699e+18\n",
            "E_IS_SCOPE: -3.648302565185138e+22\n",
            "E_IS_E_SCOPE: -1.1864753728287364e+22\n",
            "Total Loss: -9.973276548626016e+19\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(-1.1610e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2122836464148526e+22\n",
            "E_s_wdiff_all_sq: 8.255304982092833e+18\n",
            "E_IS_SCOPE: -3.6508355153682198e+22\n",
            "E_IS_E_SCOPE: -1.1876563661881833e+22\n",
            "Total Loss: -1.1610344786860232e+20\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(-1.3250e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21218220693654e+22\n",
            "E_s_wdiff_all_sq: 8.437896556983168e+18\n",
            "E_IS_SCOPE: -3.653336550031556e+22\n",
            "E_IS_E_SCOPE: -1.1888109242496026e+22\n",
            "Total Loss: -1.3250179407587102e+20\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(-1.4892e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2119185830499483e+22\n",
            "E_s_wdiff_all_sq: 8.382579473740544e+18\n",
            "E_IS_SCOPE: -3.656727125519529e+22\n",
            "E_IS_E_SCOPE: -1.1906118321752961e+22\n",
            "Total Loss: -1.489223049304395e+20\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(-1.6541e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117650689385132e+22\n",
            "E_s_wdiff_all_sq: 8.26333388347596e+18\n",
            "E_IS_SCOPE: -3.6604477559866455e+22\n",
            "E_IS_E_SCOPE: -1.1925937647230688e+22\n",
            "Total Loss: -1.6541207895394065e+20\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(-1.8192e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120739593354765e+22\n",
            "E_s_wdiff_all_sq: 8.229488802725618e+18\n",
            "E_IS_SCOPE: -3.664043847529751e+22\n",
            "E_IS_E_SCOPE: -1.194337817449285e+22\n",
            "Total Loss: -1.819234240599341e+20\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(-1.9848e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125690287053961e+22\n",
            "E_s_wdiff_all_sq: 8.348566220547242e+18\n",
            "E_IS_SCOPE: -3.6671138775860448e+22\n",
            "E_IS_E_SCOPE: -1.1956674411768094e+22\n",
            "Total Loss: -1.9848461966088182e+20\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(-2.1512e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128147442954976e+22\n",
            "E_s_wdiff_all_sq: 8.420738146647486e+18\n",
            "E_IS_SCOPE: -3.670274869727986e+22\n",
            "E_IS_E_SCOPE: -1.1971382361353921e+22\n",
            "Total Loss: -2.151234578412051e+20\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(-2.3184e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2126009066524512e+22\n",
            "E_s_wdiff_all_sq: 8.344881417173497e+18\n",
            "E_IS_SCOPE: -3.673834145068559e+22\n",
            "E_IS_E_SCOPE: -1.199025233810653e+22\n",
            "Total Loss: -2.3183741082530533e+20\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(-2.4857e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212222862724474e+22\n",
            "E_s_wdiff_all_sq: 8.248367842994133e+18\n",
            "E_IS_SCOPE: -3.677405529269655e+22\n",
            "E_IS_E_SCOPE: -1.2009744608298323e+22\n",
            "Total Loss: -2.485687235516249e+20\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(-2.6531e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2121951517397496e+22\n",
            "E_s_wdiff_all_sq: 8.258280085326128e+18\n",
            "E_IS_SCOPE: -3.6807117129377695e+22\n",
            "E_IS_E_SCOPE: -1.202629835048986e+22\n",
            "Total Loss: -2.653082801865375e+20\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(-2.8219e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125247681776715e+22\n",
            "E_s_wdiff_all_sq: 8.264314752660881e+18\n",
            "E_IS_SCOPE: -3.6842280926602175e+22\n",
            "E_IS_E_SCOPE: -1.204301443460597e+22\n",
            "Total Loss: -2.8219145790795284e+20\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(-2.9902e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2130926858498822e+22\n",
            "E_s_wdiff_all_sq: 8.219817826283616e+18\n",
            "E_IS_SCOPE: -3.688056087900254e+22\n",
            "E_IS_E_SCOPE: -1.2061030600384847e+22\n",
            "Total Loss: -2.990236886499391e+20\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(-3.1591e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213479631084819e+22\n",
            "E_s_wdiff_all_sq: 8.23389938709003e+18\n",
            "E_IS_SCOPE: -3.6915697644503143e+22\n",
            "E_IS_E_SCOPE: -1.207753652447686e+22\n",
            "Total Loss: -3.1590999502574374e+20\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(-3.3286e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2136468634913175e+22\n",
            "E_s_wdiff_all_sq: 8.289467987627777e+18\n",
            "E_IS_SCOPE: -3.694824043785155e+22\n",
            "E_IS_E_SCOPE: -1.2093024621805932e+22\n",
            "Total Loss: -3.328589656703579e+20\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(-3.4989e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2134705751119041e+22\n",
            "E_s_wdiff_all_sq: 8.291764886023741e+18\n",
            "E_IS_SCOPE: -3.698149670076634e+22\n",
            "E_IS_E_SCOPE: -1.2110106369742548e+22\n",
            "Total Loss: -3.4988913148421997e+20\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(-3.6700e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213039316564978e+22\n",
            "E_s_wdiff_all_sq: 8.264366484504631e+18\n",
            "E_IS_SCOPE: -3.701491381174132e+22\n",
            "E_IS_E_SCOPE: -1.2128119695772934e+22\n",
            "Total Loss: -3.6699596081228415e+20\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(-3.8416e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2123261165467863e+22\n",
            "E_s_wdiff_all_sq: 8.239663391580307e+18\n",
            "E_IS_SCOPE: -3.704699648541147e+22\n",
            "E_IS_E_SCOPE: -1.214616576249274e+22\n",
            "Total Loss: -3.8415510817507954e+20\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(-4.0132e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116852350069638e+22\n",
            "E_s_wdiff_all_sq: 8.291866007374452e+18\n",
            "E_IS_SCOPE: -3.7076294944289123e+22\n",
            "E_IS_E_SCOPE: -1.2162111886370726e+22\n",
            "Total Loss: -4.013224696946591e+20\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(-4.1853e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.210642780049374e+22\n",
            "E_s_wdiff_all_sq: 8.01366323478059e+18\n",
            "E_IS_SCOPE: -3.711735197027742e+22\n",
            "E_IS_E_SCOPE: -1.2187223125450188e+22\n",
            "Total Loss: -4.1852735400876546e+20\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(-4.3586e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2109008702331886e+22\n",
            "E_s_wdiff_all_sq: 8.16398986667352e+18\n",
            "E_IS_SCOPE: -3.714713199838404e+22\n",
            "E_IS_E_SCOPE: -1.2200439302998408e+22\n",
            "Total Loss: -4.3585797573920267e+20\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(-4.5314e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212087637752977e+22\n",
            "E_s_wdiff_all_sq: 8.638088036883652e+18\n",
            "E_IS_SCOPE: -3.71681940797954e+22\n",
            "E_IS_E_SCOPE: -1.2204764859696138e+22\n",
            "Total Loss: -4.531377932708474e+20\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(-4.7048e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2123902708499142e+22\n",
            "E_s_wdiff_all_sq: 8.733292606359138e+18\n",
            "E_IS_SCOPE: -3.7200627660297574e+22\n",
            "E_IS_E_SCOPE: -1.2219597293820418e+22\n",
            "Total Loss: -4.704813209329766e+20\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(-4.8790e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115666260143678e+22\n",
            "E_s_wdiff_all_sq: 8.331541217390411e+18\n",
            "E_IS_SCOPE: -3.724784002286469e+22\n",
            "E_IS_E_SCOPE: -1.2248011196940373e+22\n",
            "Total Loss: -4.8790078506281625e+20\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(-5.0527e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2106786529175245e+22\n",
            "E_s_wdiff_all_sq: 8.213216407732219e+18\n",
            "E_IS_SCOPE: -3.728333488111103e+22\n",
            "E_IS_E_SCOPE: -1.2268844606422237e+22\n",
            "Total Loss: -5.0527000407833156e+20\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(-5.2267e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2104740401032292e+22\n",
            "E_s_wdiff_all_sq: 8.510874854617543e+18\n",
            "E_IS_SCOPE: -3.7305213053481672e+22\n",
            "E_IS_E_SCOPE: -1.2278310889669188e+22\n",
            "Total Loss: -5.226736272217169e+20\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(-5.4007e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2100940052908405e+22\n",
            "E_s_wdiff_all_sq: 8.792421467982654e+18\n",
            "E_IS_SCOPE: -3.7327119683469124e+22\n",
            "E_IS_E_SCOPE: -1.2288382970208966e+22\n",
            "Total Loss: -5.400709937011706e+20\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(-5.5752e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2093763765539095e+22\n",
            "E_s_wdiff_all_sq: 8.614067751322986e+18\n",
            "E_IS_SCOPE: -3.7365843230369256e+22\n",
            "E_IS_E_SCOPE: -1.2310774985500672e+22\n",
            "Total Loss: -5.5751832899562766e+20\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(-5.7494e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.208933879273105e+22\n",
            "E_s_wdiff_all_sq: 8.377411254038716e+18\n",
            "E_IS_SCOPE: -3.7408247779311686e+22\n",
            "E_IS_E_SCOPE: -1.2334712859416265e+22\n",
            "Total Loss: -5.7493877794175504e+20\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(-5.9243e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2093801035991972e+22\n",
            "E_s_wdiff_all_sq: 8.56574149282789e+18\n",
            "E_IS_SCOPE: -3.7437849953760174e+22\n",
            "E_IS_E_SCOPE: -1.2347130385251166e+22\n",
            "Total Loss: -5.924283060731039e+20\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(-6.0998e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2100305099436887e+22\n",
            "E_s_wdiff_all_sq: 8.85042078515889e+18\n",
            "E_IS_SCOPE: -3.746482005382111e+22\n",
            "E_IS_E_SCOPE: -1.2357091174867993e+22\n",
            "Total Loss: -6.099820738995814e+20\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(-6.2760e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2099466959183845e+22\n",
            "E_s_wdiff_all_sq: 8.780537904300356e+18\n",
            "E_IS_SCOPE: -3.7502545657424113e+22\n",
            "E_IS_E_SCOPE: -1.2376647901713424e+22\n",
            "Total Loss: -6.276012408223386e+20\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(-6.4528e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2093927200575749e+22\n",
            "E_s_wdiff_all_sq: 8.502721682101603e+18\n",
            "E_IS_SCOPE: -3.7546498660110006e+22\n",
            "E_IS_E_SCOPE: -1.2401904736392521e+22\n",
            "Total Loss: -6.452765007649303e+20\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(-6.6288e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2091641687126665e+22\n",
            "E_s_wdiff_all_sq: 8.421209012866424e+18\n",
            "E_IS_SCOPE: -3.758405071735987e+22\n",
            "E_IS_E_SCOPE: -1.2421832478324517e+22\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-01d57a9c684f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_all_shaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS_SCOPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-5d294114b799>\u001b[0m in \u001b[0;36mtrain_var\u001b[0;34m(model, num_epochs, learning_rate, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Retain the graph to avoid clearing it before backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_var(model, 200, 0.0001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V5HankiakEiu",
        "outputId": "6616ce3c-94b2-4fdf-9833-cd1af30ac8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(-5.0872e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2091641687126665e+22\n",
            "E_s_wdiff_all_sq: 8.421209012866424e+18\n",
            "E_IS_SCOPE: -2.547315218031649e+25\n",
            "E_IS_E_SCOPE: -1.2421832478324517e+22\n",
            "Total Loss: -5.087179914210118e+25\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(-5.3797e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1588018418409055e+22\n",
            "E_s_wdiff_all_sq: 8.04536804186359e+20\n",
            "E_IS_SCOPE: -2.694291367756086e+25\n",
            "E_IS_E_SCOPE: -1.7349946687008094e+22\n",
            "Total Loss: -5.379704141723259e+25\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(-5.6711e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4111873352395464e+22\n",
            "E_s_wdiff_all_sq: 3.463374565893483e+21\n",
            "E_IS_SCOPE: -2.8408122806833696e+25\n",
            "E_IS_E_SCOPE: -2.215367046350286e+22\n",
            "Total Loss: -5.671052464951478e+25\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(-5.9621e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.9427952560721845e+22\n",
            "E_s_wdiff_all_sq: 7.837952653226776e+21\n",
            "E_IS_SCOPE: -2.987325832672755e+25\n",
            "E_IS_E_SCOPE: -2.682911211818654e+22\n",
            "Total Loss: -5.962145328513011e+25\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(-6.2530e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.7263608969798527e+22\n",
            "E_s_wdiff_all_sq: 1.375398874050293e+22\n",
            "E_IS_SCOPE: -3.1338148723437466e+25\n",
            "E_IS_E_SCOPE: -3.1355187507019592e+22\n",
            "Total Loss: -6.252982019597437e+25\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(-6.5435e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 3.748339183415563e+22\n",
            "E_s_wdiff_all_sq: 2.116529777547345e+22\n",
            "E_IS_SCOPE: -3.280275788491791e+25\n",
            "E_IS_E_SCOPE: -3.5795217994547766e+22\n",
            "Total Loss: -6.543549864460832e+25\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(-6.8338e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.004461314920678e+22\n",
            "E_s_wdiff_all_sq: 3.0068462342649105e+22\n",
            "E_IS_SCOPE: -3.4266963700336215e+25\n",
            "E_IS_E_SCOPE: -4.018966356332541e+22\n",
            "Total Loss: -6.833816571742354e+25\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(-7.1238e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.481053799005235e+22\n",
            "E_s_wdiff_all_sq: 4.037113835105185e+22\n",
            "E_IS_SCOPE: -3.57308221505971e+25\n",
            "E_IS_E_SCOPE: -4.452089429979757e+22\n",
            "Total Loss: -7.1238123000895045e+25\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(-7.4135e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.170428479059414e+22\n",
            "E_s_wdiff_all_sq: 5.203125263787489e+22\n",
            "E_IS_SCOPE: -3.7194150366745127e+25\n",
            "E_IS_E_SCOPE: -4.879709737567206e+22\n",
            "Total Loss: -7.413505707716294e+25\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(-7.7029e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.006562379984491e+23\n",
            "E_s_wdiff_all_sq: 6.5009257231549674e+22\n",
            "E_IS_SCOPE: -3.8656945868055057e+25\n",
            "E_IS_E_SCOPE: -5.302351238455299e+22\n",
            "Total Loss: -7.702901688154831e+25\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(-7.9920e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.215950259010862e+23\n",
            "E_s_wdiff_all_sq: 7.926284934170995e+22\n",
            "E_IS_SCOPE: -4.0119165595627445e+25\n",
            "E_IS_E_SCOPE: -5.720242133076124e+22\n",
            "Total Loss: -7.991998082195182e+25\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(-8.2808e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4444713311004935e+23\n",
            "E_s_wdiff_all_sq: 9.47475141144426e+22\n",
            "E_IS_SCOPE: -4.158076958043214e+25\n",
            "E_IS_E_SCOPE: -6.133460319520498e+22\n",
            "Total Loss: -8.280794013875891e+25\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(-8.5693e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.691368025139844e+23\n",
            "E_s_wdiff_all_sq: 1.1141678394072568e+23\n",
            "E_IS_SCOPE: -4.3041720954261145e+25\n",
            "E_IS_E_SCOPE: -6.5420000998008646e+22\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-5d2902af0be1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_all_shaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS_SCOPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-5d294114b799>\u001b[0m in \u001b[0;36mtrain_var\u001b[0;34m(model, num_epochs, learning_rate, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Retain the graph to avoid clearing it before backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = train_var(model, 20, 0.001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHLpALXBN40b",
        "outputId": "8cffe722-37df-4139-8ebf-3479a805cb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(-1.3998e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.7000520983736854e+26\n",
            "E_s_wdiff_all_sq: 1.1991158006418987e+26\n",
            "E_IS_SCOPE: -2.0238984353616566e+26\n",
            "E_IS_E_SCOPE: 1.7432066784634587e+24\n",
            "Total Loss: -1.3997894919094345e+26\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(-1.8930e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.4851380256092592e+26\n",
            "E_s_wdiff_all_sq: 1.0868796875981285e+26\n",
            "E_IS_SCOPE: -2.1642866384407017e+26\n",
            "E_IS_E_SCOPE: 1.6592145943890643e+24\n",
            "Total Loss: -1.892960208309719e+26\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(-2.3750e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.2864222596610805e+26\n",
            "E_s_wdiff_all_sq: 9.831123864853387e+25\n",
            "E_IS_SCOPE: -2.3071556879644427e+26\n",
            "E_IS_E_SCOPE: 1.5775847477927258e+24\n",
            "Total Loss: -2.3749651779074894e+26\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(-2.8423e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.1107685666169942e+26\n",
            "E_s_wdiff_all_sq: 8.908178298603343e+25\n",
            "E_IS_SCOPE: -2.454130057488368e+26\n",
            "E_IS_E_SCOPE: 1.5012467817496386e+24\n",
            "Total Loss: -2.842277471018134e+26\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(-3.2993e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.95377408787041e+26\n",
            "E_s_wdiff_all_sq: 8.078126017319421e+25\n",
            "E_IS_SCOPE: -2.6052506542281885e+26\n",
            "E_IS_E_SCOPE: 1.4291329785199847e+24\n",
            "Total Loss: -3.299349729147468e+26\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(-3.7487e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.8132467079007727e+26\n",
            "E_s_wdiff_all_sq: 7.329651482777037e+25\n",
            "E_IS_SCOPE: -2.7606843344170066e+26\n",
            "E_IS_E_SCOPE: 1.360869471486018e+24\n",
            "Total Loss: -3.748696564283724e+26\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(-4.1896e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.688620283159106e+26\n",
            "E_s_wdiff_all_sq: 6.659493094301345e+25\n",
            "E_IS_SCOPE: -2.9198032751618074e+26\n",
            "E_IS_E_SCOPE: 1.2967482268817199e+24\n",
            "Total Loss: -4.189637233176863e+26\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(-4.6262e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.576707664912865e+26\n",
            "E_s_wdiff_all_sq: 6.052083489607422e+25\n",
            "E_IS_SCOPE: -3.08305451841946e+26\n",
            "E_IS_E_SCOPE: 1.2357861039386222e+24\n",
            "Total Loss: -4.626223474250116e+26\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(-5.0587e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4763612808585628e+26\n",
            "E_s_wdiff_all_sq: 5.50174234409973e+25\n",
            "E_IS_SCOPE: -3.2499784261118546e+26\n",
            "E_IS_E_SCOPE: 1.1778527193751983e+24\n",
            "Total Loss: -5.058679672152305e+26\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(-5.4889e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3848700547605917e+26\n",
            "E_s_wdiff_all_sq: 4.995988928518009e+25\n",
            "E_IS_SCOPE: -3.420172749344094e+26\n",
            "E_IS_E_SCOPE: 1.1220005061754078e+24\n",
            "Total Loss: -5.488883978318761e+26\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(-5.9179e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3006442730443957e+26\n",
            "E_s_wdiff_all_sq: 4.527488207429612e+25\n",
            "E_IS_SCOPE: -3.593391101377815e+26\n",
            "E_IS_E_SCOPE: 1.067680399123898e+24\n",
            "Total Loss: -5.917916860890854e+26\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(-6.3462e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2229417912969604e+26\n",
            "E_s_wdiff_all_sq: 4.092707164503446e+25\n",
            "E_IS_SCOPE: -3.769466846843736e+26\n",
            "E_IS_E_SCOPE: 1.0146928561134615e+24\n",
            "Total Loss: -6.346181207279818e+26\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(-6.7612e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1518335335596193e+26\n",
            "E_s_wdiff_all_sq: 3.6950381982478167e+25\n",
            "E_IS_SCOPE: -3.9421864533730626e+26\n",
            "E_IS_E_SCOPE: 9.636992190084379e+23\n",
            "Total Loss: -6.761198868962662e+26\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(-7.1583e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0875381753628806e+26\n",
            "E_s_wdiff_all_sq: 3.3357822679325225e+25\n",
            "E_IS_SCOPE: -4.10933498575679e+26\n",
            "E_IS_E_SCOPE: 9.152111976069571e+23\n",
            "Total Loss: -7.158336651284811e+26\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(-7.5579e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0300003666921198e+26\n",
            "E_s_wdiff_all_sq: 3.008197928388507e+25\n",
            "E_IS_SCOPE: -4.281029201156582e+26\n",
            "E_IS_E_SCOPE: 8.686640466504931e+23\n",
            "Total Loss: -7.557866476226461e+26\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(-7.9625e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 9.780866290057678e+25\n",
            "E_s_wdiff_all_sq: 2.706676561722053e+25\n",
            "E_IS_SCOPE: -4.458086666377223e+26\n",
            "E_IS_E_SCOPE: 8.235217772818606e+23\n",
            "Total Loss: -7.962540876273037e+26\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(-8.3770e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 9.25864062540654e+25\n",
            "E_s_wdiff_all_sq: 2.408043092938196e+25\n",
            "E_IS_SCOPE: -4.639890551795465e+26\n",
            "E_IS_E_SCOPE: 7.762667967592406e+23\n",
            "Total Loss: -8.376953564158955e+26\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(-8.7964e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.772145597482964e+25\n",
            "E_s_wdiff_all_sq: 2.128158973430442e+25\n",
            "E_IS_SCOPE: -4.826000005768793e+26\n",
            "E_IS_E_SCOPE: 7.292373507211456e+23\n",
            "Total Loss: -8.796411091516826e+26\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(-9.2201e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.332681175269682e+25\n",
            "E_s_wdiff_all_sq: 1.8710506668717508e+25\n",
            "E_IS_SCOPE: -5.016565446564469e+26\n",
            "E_IS_E_SCOPE: 6.832218590962401e+23\n",
            "Total Loss: -9.220107950580761e+26\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(-9.6468e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 7.938632829251062e+25\n",
            "E_s_wdiff_all_sq: 1.636020374096819e+25\n",
            "E_IS_SCOPE: -5.210907454597642e+26\n",
            "E_IS_E_SCOPE: 6.382979689732807e+23\n",
            "Total Loss: -9.64684908454528e+26\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.6824,  0.3805],\n",
            "        [ 0.6172,  0.3862],\n",
            "        [-0.0410, -0.2904],\n",
            "        [ 0.3265, -0.6162],\n",
            "        [-0.4672,  0.3825],\n",
            "        [-0.4019,  0.5381],\n",
            "        [-0.0941, -0.5162],\n",
            "        [-0.5809,  0.0319],\n",
            "        [-0.1979,  0.2670],\n",
            "        [-0.4053, -0.3357],\n",
            "        [ 0.0179,  0.6101],\n",
            "        [ 0.3949,  0.0047],\n",
            "        [ 0.7054,  0.4417],\n",
            "        [-0.3734, -0.1384],\n",
            "        [ 0.1148,  0.4802],\n",
            "        [ 0.3828, -0.3846]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.2569,  0.1246,  0.6364, -0.6841, -0.2801, -0.0636, -0.0846, -0.5966,\n",
            "         0.2269, -0.0934,  0.5676, -0.6006,  0.3885, -0.4913, -0.3735,  0.0440],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 4.8119e-02, -4.0558e-02,  2.2185e-01,  1.7136e-01,  2.0620e-01,\n",
            "         -7.6490e-02, -4.9387e-03,  1.0780e-01, -9.7940e-02, -5.2611e-02,\n",
            "          8.6816e-02,  2.0431e-01, -1.1189e-01, -2.3857e-01,  4.5704e-02,\n",
            "         -2.4755e-02],\n",
            "        [-1.1661e-01,  1.6673e-01, -1.2172e-01, -1.7377e-02, -1.9116e-01,\n",
            "          2.1572e-01,  1.8230e-01, -3.6067e-02, -4.8273e-02,  2.0668e-01,\n",
            "          1.8825e-01, -2.2010e-01,  3.0955e-02, -2.3602e-01,  1.6450e-01,\n",
            "         -1.9474e-01],\n",
            "        [-2.3669e-01, -8.8660e-02,  1.5782e-01,  5.4865e-02, -3.7314e-02,\n",
            "         -2.2701e-01, -1.7717e-01,  1.0917e-01, -1.3188e-01, -2.3322e-01,\n",
            "         -2.0656e-01, -6.6348e-02,  2.9485e-03, -1.5408e-01,  4.4631e-02,\n",
            "          5.9431e-03],\n",
            "        [-3.1699e-02,  2.1269e-01,  6.5254e-02,  1.6674e-01,  1.0271e-01,\n",
            "         -1.5640e-01, -1.1433e-01,  9.1803e-02,  4.8161e-02,  6.3060e-02,\n",
            "         -1.2206e-01,  1.8972e-01, -1.1215e-01, -6.9293e-02, -1.9905e-01,\n",
            "         -8.7023e-05],\n",
            "        [-5.5292e-02, -2.1445e-01,  1.0447e-01,  1.9652e-01, -2.0886e-01,\n",
            "          8.6149e-02, -6.7564e-02,  1.6284e-01,  1.8813e-01,  1.2977e-01,\n",
            "         -1.8909e-03,  1.5335e-01,  2.2191e-01, -2.0367e-01, -1.9575e-01,\n",
            "         -1.1563e-02],\n",
            "        [-1.5999e-01,  3.4475e-02,  1.4412e-01, -2.0440e-01, -2.4086e-01,\n",
            "          4.3020e-03,  7.6393e-02,  2.0897e-01,  6.2470e-02, -1.5482e-01,\n",
            "          1.8559e-01,  1.2675e-01, -3.5940e-02,  1.3949e-01, -2.4669e-01,\n",
            "         -1.6998e-01],\n",
            "        [-1.4121e-03,  9.2029e-02,  1.6774e-02,  2.4159e-01, -1.8972e-01,\n",
            "          2.2045e-01,  2.4686e-01, -1.0914e-02, -1.4103e-01,  9.1213e-02,\n",
            "         -4.3784e-02, -1.6879e-01,  4.5783e-02,  1.8536e-01,  6.9759e-02,\n",
            "          2.2215e-01],\n",
            "        [-1.2859e-01, -9.0884e-02,  5.4626e-02, -3.8355e-02,  1.1648e-01,\n",
            "          7.5265e-02,  2.2921e-01,  2.3633e-01,  1.0943e-01,  9.5796e-02,\n",
            "          9.7141e-02,  1.2300e-01, -2.5879e-01, -1.2350e-01, -1.5009e-02,\n",
            "          1.3043e-02],\n",
            "        [-1.6694e-02,  1.5965e-01, -4.7113e-02, -2.1283e-01,  7.2415e-02,\n",
            "         -1.0634e-01,  7.0834e-02,  1.0853e-01, -1.9885e-01, -2.0899e-01,\n",
            "         -8.6902e-02,  6.2196e-02,  4.3863e-02,  2.2491e-01,  6.7579e-02,\n",
            "         -2.4318e-01],\n",
            "        [ 1.6246e-02, -1.8128e-01, -1.9994e-01,  7.6150e-02, -2.1505e-01,\n",
            "         -2.4253e-01, -7.8125e-02, -2.0187e-01,  7.0338e-03,  5.8107e-02,\n",
            "         -2.5847e-03, -1.5630e-01, -6.0726e-02, -1.1809e-01, -1.6551e-01,\n",
            "         -5.4297e-02],\n",
            "        [ 2.4383e-01,  4.2616e-02,  5.6662e-02,  1.3916e-01,  2.2539e-01,\n",
            "          1.9607e-01, -1.7537e-01, -1.8012e-01, -1.2684e-01, -1.7179e-01,\n",
            "         -3.5418e-02,  1.2716e-01,  1.2756e-01, -5.8339e-02,  9.8414e-02,\n",
            "          2.5362e-02],\n",
            "        [ 1.6507e-01,  1.7497e-01,  6.1446e-02, -9.7664e-02,  1.8058e-01,\n",
            "         -2.5965e-01, -3.1194e-02, -1.4002e-01,  1.0309e-01,  4.9587e-02,\n",
            "          1.3151e-01,  6.2520e-02, -1.0080e-01,  1.8290e-01, -2.2798e-03,\n",
            "          2.0217e-03],\n",
            "        [-1.5221e-01,  1.4097e-01, -7.1615e-04, -6.8548e-02,  2.2222e-01,\n",
            "          1.2362e-01,  1.8278e-01, -2.1061e-01, -7.6397e-02,  1.7362e-01,\n",
            "          4.3270e-02, -2.1091e-01,  4.2701e-02,  1.2101e-01, -4.7703e-02,\n",
            "         -2.0536e-01],\n",
            "        [-6.6673e-02, -4.6614e-02, -2.1227e-01,  2.9418e-02, -2.1981e-01,\n",
            "          1.3636e-01,  1.7628e-01, -1.8667e-02, -1.4600e-01,  1.7796e-01,\n",
            "         -8.2919e-02, -2.2852e-01, -1.9402e-02, -1.0765e-01,  1.1574e-01,\n",
            "         -1.5714e-01],\n",
            "        [-1.0918e-01, -1.9517e-01,  9.8679e-02,  1.5596e-01, -4.4319e-02,\n",
            "         -1.7486e-01, -1.5448e-01,  2.9712e-02, -3.3289e-03,  1.5767e-01,\n",
            "          1.1929e-01, -2.6514e-01, -1.0920e-03,  8.7649e-02,  7.2158e-02,\n",
            "          6.2090e-02],\n",
            "        [-8.3881e-03,  6.5977e-02,  2.1695e-01,  1.9215e-01, -2.9525e-02,\n",
            "          1.7588e-01, -5.8884e-02,  8.2231e-03,  5.6097e-02, -1.6881e-01,\n",
            "         -1.4676e-01, -1.2744e-01, -1.5995e-01, -1.6587e-02, -2.8196e-02,\n",
            "          2.3959e-01],\n",
            "        [ 9.9272e-02, -8.2990e-02, -1.1069e-01,  1.9435e-01,  2.0021e-01,\n",
            "          1.6971e-01,  5.8639e-02, -1.3337e-01, -1.8521e-02,  2.2435e-01,\n",
            "          6.4262e-02,  5.9340e-02, -5.0475e-02, -5.0460e-03,  1.2239e-01,\n",
            "          1.1172e-01],\n",
            "        [ 8.1245e-02,  1.7842e-01, -1.4347e-01, -1.9353e-01, -9.7532e-02,\n",
            "          3.3191e-02,  9.2401e-02,  3.2447e-02, -7.3296e-02,  4.2897e-02,\n",
            "         -5.4902e-03, -1.7552e-01,  2.3623e-01,  1.8997e-01,  1.3470e-01,\n",
            "         -2.2129e-01],\n",
            "        [-1.9724e-01, -8.5698e-02,  4.3844e-02,  1.9982e-01,  2.4789e-01,\n",
            "         -2.3965e-01, -1.8726e-01,  2.2428e-01, -1.4151e-01,  1.6169e-02,\n",
            "          1.3268e-01,  1.4430e-01, -5.2540e-02, -2.0882e-01, -1.0297e-01,\n",
            "          7.5755e-02],\n",
            "        [-1.3038e-01, -2.1669e-01, -5.8820e-02, -9.0053e-02,  2.5145e-01,\n",
            "         -2.2259e-01,  2.0062e-01, -6.5883e-02,  2.1339e-01,  6.7655e-02,\n",
            "         -1.5339e-01,  1.2299e-01, -6.6090e-02, -9.7631e-02,  2.4591e-01,\n",
            "          1.6375e-02],\n",
            "        [ 2.0833e-01,  2.2925e-01, -8.1671e-02, -7.4458e-02,  2.4689e-01,\n",
            "         -1.7912e-01, -3.0479e-02,  2.2088e-01,  4.1135e-02, -1.4143e-01,\n",
            "          1.4276e-02, -4.4181e-02,  2.1406e-02, -8.7408e-02, -2.6004e-02,\n",
            "         -3.1061e-02],\n",
            "        [ 2.7277e-02, -9.2468e-02, -1.8294e-01, -2.0342e-01,  1.7406e-01,\n",
            "          6.5903e-02,  8.9643e-02, -5.2062e-02,  2.6414e-01, -1.2718e-01,\n",
            "         -2.3894e-01,  1.6539e-01,  1.8297e-02,  6.2260e-02, -9.3196e-02,\n",
            "          4.3673e-03],\n",
            "        [-5.9226e-02, -1.7806e-01, -1.5932e-01,  2.5755e-02,  1.8840e-01,\n",
            "         -2.3118e-01,  4.6522e-02, -1.5184e-01,  5.4040e-03, -6.1534e-03,\n",
            "         -7.5576e-02,  1.5076e-01,  1.9803e-01, -5.7331e-02,  1.2015e-03,\n",
            "         -2.8805e-02],\n",
            "        [ 9.5230e-02, -5.9195e-02,  5.9797e-02, -1.4853e-01,  2.2916e-01,\n",
            "          6.8206e-03, -1.0452e-02, -6.4086e-02,  1.3535e-01,  2.1016e-01,\n",
            "         -1.2791e-01,  1.3874e-01,  2.4114e-01,  1.8081e-01,  1.3184e-01,\n",
            "         -2.1979e-01],\n",
            "        [ 1.9239e-01,  3.5063e-02, -1.7934e-01,  1.7502e-01,  8.2594e-02,\n",
            "          1.0295e-01,  2.3758e-01,  1.2021e-01, -5.1508e-02,  1.5860e-01,\n",
            "          1.1935e-01, -7.2050e-02, -1.4643e-01,  2.2494e-01, -1.6159e-01,\n",
            "         -1.2161e-02],\n",
            "        [-1.1569e-01,  2.4863e-01,  8.7303e-02, -4.0421e-02,  1.6243e-01,\n",
            "          1.6153e-02,  2.2084e-01, -1.5133e-01, -3.1824e-02,  1.2209e-01,\n",
            "          2.3849e-01,  3.1212e-02, -4.0532e-02,  1.5685e-01, -1.0802e-02,\n",
            "         -7.3412e-02],\n",
            "        [ 2.5694e-01, -3.9981e-02, -5.8586e-03,  2.5751e-01, -9.3908e-02,\n",
            "         -2.6468e-01, -6.8448e-02,  5.6993e-02, -8.4784e-02,  1.0977e-01,\n",
            "         -9.5266e-03, -4.4528e-02,  5.6235e-02, -3.2194e-02, -1.3303e-01,\n",
            "          7.7084e-02],\n",
            "        [-1.2107e-01, -4.9455e-02, -1.0928e-01, -1.4182e-01, -2.1752e-01,\n",
            "         -1.3493e-01, -2.4229e-01,  6.4488e-02, -6.0827e-02, -9.6155e-02,\n",
            "          4.3416e-02, -1.0943e-01, -8.7071e-02,  1.0680e-01, -1.9074e-01,\n",
            "          1.8180e-01],\n",
            "        [ 1.1885e-01, -1.3959e-01,  1.3637e-01, -1.7812e-01,  1.7236e-01,\n",
            "          1.7322e-01,  1.5212e-01, -4.9635e-02,  1.2627e-02, -1.7094e-01,\n",
            "          5.6883e-02,  1.1782e-01,  2.6690e-01,  1.5117e-01, -1.3883e-01,\n",
            "         -7.5040e-02],\n",
            "        [ 1.7444e-02, -3.5884e-02, -1.8073e-01, -4.8182e-02,  5.1672e-02,\n",
            "         -2.1597e-01,  1.5905e-02, -2.4473e-01,  2.2163e-01,  6.5373e-02,\n",
            "          1.5828e-01,  4.6021e-02,  2.7998e-02,  1.6024e-01,  2.1393e-01,\n",
            "          1.7622e-02],\n",
            "        [-2.4343e-02,  1.6148e-02,  1.8917e-02,  4.6976e-02,  8.1570e-02,\n",
            "         -7.2976e-02, -8.2241e-02,  9.8812e-02,  1.2289e-01,  1.7245e-01,\n",
            "         -1.7320e-01, -2.4167e-01,  1.7690e-01, -7.3494e-02,  1.4066e-01,\n",
            "         -2.3803e-01],\n",
            "        [-1.9888e-01, -1.8503e-01,  8.4259e-02,  2.4136e-01,  5.5319e-02,\n",
            "         -1.5181e-01,  8.2156e-02, -1.8184e-01, -7.5127e-02, -2.1625e-01,\n",
            "          1.1747e-01, -4.3509e-02, -2.2899e-01,  9.2018e-02,  1.9127e-01,\n",
            "         -1.1790e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0860, -0.2362, -0.2142,  0.1716,  0.1689,  0.2149, -0.0474, -0.1591,\n",
            "        -0.1497, -0.0224, -0.1051, -0.1015,  0.1446,  0.1406,  0.2544, -0.1735,\n",
            "        -0.1481, -0.1807,  0.0241, -0.2079,  0.2115,  0.0250,  0.1389,  0.2335,\n",
            "         0.2197,  0.1802,  0.2623, -0.1372,  0.0478,  0.2256,  0.0486, -0.0534],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1721,  0.0623, -0.0768,  0.1644,  0.0325, -0.0332, -0.0931,  0.0436,\n",
            "          0.0268, -0.0838, -0.1538, -0.0204,  0.0539, -0.0472,  0.1059, -0.0720,\n",
            "          0.1543, -0.0265,  0.0777,  0.1012,  0.1266,  0.0518, -0.1264, -0.1316,\n",
            "         -0.0902, -0.0639, -0.1390,  0.0065,  0.1957, -0.0794,  0.0822,  0.1624]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.1091], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working on prep"
      ],
      "metadata": {
        "id": "O36PGywGna2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Working on padding trajectories to allow for easier optimization\n",
        "\n",
        "# def pad_trajectories(pi_b):\n",
        "#     # Find the maximum length among all trajectories\n",
        "#     max_length = max(len(traj) for traj in pi_b)\n",
        "\n",
        "#     # Define the padding value\n",
        "#     padding_value = np.array([np.array([0, 0]), 0, 0, np.array([0, 0]), 0, 0], dtype=object)\n",
        "\n",
        "#     # Pad each trajectory to match the maximum length\n",
        "#     padded_pi_b = [traj + [padding_value] * (max_length - len(traj)) for traj in pi_b]\n",
        "\n",
        "#     return padded_pi_b"
      ],
      "metadata": {
        "id": "ErjhWCq3czmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pi_b_padded = pad_trajectories(pi_b)"
      ],
      "metadata": {
        "id": "31TWTP7Eb1sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variance_terms_tens(eval_policy, behav_policy, behavior_policies):\n",
        "  # Initialize lists to store axis data for each policy\n",
        "  timesteps = []\n",
        "  states = []\n",
        "  state_first = []\n",
        "  state_last = []\n",
        "  actions = []\n",
        "  rewards = []\n",
        "  gamma_last = []\n",
        "  weight_last = []\n",
        "  weights = calculate_importance_weights(eval_policy, behav_policy, behavior_policies)\n",
        "  psi = []\n",
        "\n",
        "  for index, policy in enumerate(behavior_policies):\n",
        "      policy_array = np.array(policy)\n",
        "      timesteps.append(policy_array[:, 4].astype(int))\n",
        "      # s.append(policy_array[:, 0])\n",
        "\n",
        "      # last timestep for gamma\n",
        "      gamma_last.append(len(policy))\n",
        "      # last importance weight\n",
        "      weight_last.append(weights[index][-1])\n",
        "\n",
        "\n",
        "      states.append(policy_array[:, 0][1:])\n",
        "      psi.append(policy_array[:,5][1:])\n",
        "      state_first.append(policy_array[:,0][0])\n",
        "      state_last.append(policy_array[:,0][-1])\n",
        "      actions.append(policy_array[:, 1])\n",
        "      rewards.append(policy_array[:, 2].astype(float))\n",
        "\n",
        "  weights_difference = []\n",
        "  for index, weight in enumerate(weights):\n",
        "    # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "    diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "    weights_difference.append(diff)\n",
        "\n",
        "  return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference"
      ],
      "metadata": {
        "id": "Kcx483JVfDWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t, s, s_f, s_l, a, r, g_l, w_l, w, w_diff = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "q8d3KfusfsZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "BAqNV3alEAjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def padding_IS_terms(timesteps, actions, rewards, weights):\n",
        "    # Find the maximum length among all lists\n",
        "    max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "    # Define the padding values\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each list to match the maximum length\n",
        "    padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "    padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "    padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "    padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "    return padded_timesteps, padded_rewards, padded_actions, padded_weights"
      ],
      "metadata": {
        "id": "AuuBKl0joAEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timesteps, padded_rewards, padded_actions, padded_weights = padding_IS_terms(timesteps, actions, rewards, weights)"
      ],
      "metadata": {
        "id": "xD675spBnrP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_states_weights_difference(states, weights_difference):\n",
        "    # Find the maximum length of trajectories\n",
        "    max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states\n",
        "    ]\n",
        "\n",
        "    padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "    return padded_states, padded_weights_difference"
      ],
      "metadata": {
        "id": "4DekSrOTzLAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_states, padded_weights_difference = padding_states_weights_difference(states, weights_difference)"
      ],
      "metadata": {
        "id": "aX6DIhEQTCVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_padded_terms(padded_states, padded_weights_difference):\n",
        "  padded_state_tensors = torch.tensor(padded_states, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "  return padded_state_tensors, padded_weight_diff_tensors\n"
      ],
      "metadata": {
        "id": "hHZhHnuUzHFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_state_tensors, padded_weight_diff_tensors = tensorize_padded_terms(padded_states, padded_weights_difference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5kb1vOxTZSu",
        "outputId": "6b5b983d-35ca-4d5f-9ff4-1cba9d74450b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-3c22136e8020>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last):\n",
        "  states_first_tensor = torch.tensor(states_first, dtype = torch.float64)\n",
        "  states_last_tensor = torch.tensor(states_last, dtype = torch.float64)\n",
        "  gamma_last_tensor = torch.tensor(gamma_last, dtype = torch.float64)\n",
        "  weights_last_tensor = torch.tensor(weights_last, dtype = torch.float64)\n",
        "\n",
        "  return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor"
      ],
      "metadata": {
        "id": "AqtoK6MEmPWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "gvE-AddhDTkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_IS_terms(gamma, timesteps, rewards, weights):\n",
        "  gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
        "  IS_tensor = torch.sum(torch.tensor(gtrw, dtype = torch.float32), dim = 1, keepdim = True)\n",
        "\n",
        "  return IS_tensor\n"
      ],
      "metadata": {
        "id": "YVpa0bTwd3HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor = calc_IS_terms(0.9, padded_timesteps, padded_rewards, padded_weights)"
      ],
      "metadata": {
        "id": "xjRU7xlj89PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.finfo(torch.float64).max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGtcFc-YY9SK",
        "outputId": "ce82a7a6-848c-4034-f260-6a3bf7702324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7976931348623157e+308"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS[0]"
      ],
      "metadata": {
        "id": "s_JAi7apXuJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_gamma_weight_last(gamma, gamma_last, weights_last):\n",
        "  gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
        "  gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = torch.float64).unsqueeze(-1)\n",
        "\n",
        "  return gamma_weight_last_tensor"
      ],
      "metadata": {
        "id": "8I3qisEpsYzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_last_tensor = calc_gamma_weight_last(0.9, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "XHDztxg4C3So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_IS_terms(IS_tensor, num_samples):\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "  new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "  IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "  # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "  return IS_bootstraps"
      ],
      "metadata": {
        "id": "rdqtMRAT35lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS = bootstrap_IS_terms(IS_tensor, 10000)"
      ],
      "metadata": {
        "id": "MHOyNeJ-UdcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "  max_float64 = torch.finfo(torch.float64).max\n",
        "  return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "ng9lLOfsGvdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-1e50, dtype=torch.float64)\n",
        "    return torch.clamp(input_term, min=min_value, max=max_float64)\n",
        "\n",
        "    # return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "C1Su5BQ0cfUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomizableFeatureNet_d(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_prob=0.2, dtype=torch.float32):\n",
        "        super(CustomizableFeatureNet_d, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        # Create the hidden layers based on the provided sizes\n",
        "        for in_dim, out_dim in zip([input_dim] + hidden_dims, hidden_dims):\n",
        "            self.hidden_layers.append(nn.Linear(in_dim, out_dim).to(dtype))\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim).to(dtype)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YFqvRa0LS7OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet_d(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "udif1c2cTBzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "ct8DQIU6rUvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "  # Get model outputs for states\n",
        "  states_output = model(padded_state_tensors)\n",
        "  states_first_output = model(states_first_tensor)\n",
        "  states_last_output = model(states_last_tensor)\n",
        "  return states_output, states_first_output, states_last_output"
      ],
      "metadata": {
        "id": "0JNHRYkBmZ5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)"
      ],
      "metadata": {
        "id": "duNRe00YE34A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def states_weight_diff_sums(states_output, padded_weight_diff_tensors):\n",
        "  states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "  sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "  return sums_states_weight_diff"
      ],
      "metadata": {
        "id": "8nZkrdWPW5AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sums_states_weight_diff = states_weight_diff_sums(states_output, padded_weight_diff_tensors)"
      ],
      "metadata": {
        "id": "nlxvS4QpYW0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output):\n",
        "  gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output -  states_first_output\n",
        "\n",
        "  return gamma_weights_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "fDDD0NcUaxpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_states_last_sub_states_first = last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)"
      ],
      "metadata": {
        "id": "ScpV8dhaCqHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gamma_weights_states_last_sub_states_first.shape"
      ],
      "metadata": {
        "id": "oC-P2rDqFIwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, num_samples):\n",
        "\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # sizes\n",
        "  # size_states_weights_diff = (num_samples, states_output.shape[0], states_output.shape[1])\n",
        "  reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories x length_padded_trajectories\n",
        "  # samples_states_output = states_output[sampled_indices].view(size_states_weights_diff)\n",
        "  # samples_weight_diff = padded_weight_diff_tensors[sampled_indices].view(size_states_weights_diff)\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories\n",
        "  sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_first_output = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_last_output = states_last_output[sampled_indices].view(reshaped_size)\n",
        "  samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "  return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first\n"
      ],
      "metadata": {
        "id": "d3UM9eUGeQdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first = bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, 10000)"
      ],
      "metadata": {
        "id": "whCU0iyDCi8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def gtrw_plus_states_weight_diff_min_last_firsts_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   sum_IS_and_shaping = gtrw_tensor + sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "#   return sum_IS_and_shaping"
      ],
      "metadata": {
        "id": "sIw1SreEnUpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def bootstrap_IS_shaping_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   seed = 42\n",
        "#   torch.manual_seed(seed)\n",
        "\n",
        "#   num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "#   # Sample indices with replacement\n",
        "#   sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n"
      ],
      "metadata": {
        "id": "OZHZzE6d58xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTVuyCVBB4-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "tdFIzbNUgx94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1)**2)))"
      ],
      "metadata": {
        "id": "4dLA0DBLh-pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1))**2) - torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "7pfgg5rZlakd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "MWwuJS4En1ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mean(SCOPE,dim =1).shape"
      ],
      "metadata": {
        "id": "ECEj-Lhooh8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(clamp_large_terms(samples_IS), dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6YXvZmXYUKd",
        "outputId": "d5a030e2-5c73-48bd-b58f-8e4970fbe046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([      -inf, 2.0056e+14,       -inf,  ...,       -inf,       -inf,\n",
              "        1.0028e+14])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first):\n",
        "\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = clamp_large_terms(sample_sums_states_weight_diff)+clamp_large_terms(samples_gamma_weight_states_last_sub_states_first)\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS),dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "LLuzewmQ3DR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)"
      ],
      "metadata": {
        "id": "Nz9ApTk-qnx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN1zDrJWo4wZ",
        "outputId": "548dc965-3831-4791-9077-d8d8de7062d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(inf)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBjjOVEggKhd",
        "outputId": "fdeba7f8-0ed2-498d-f842-25fe37e45dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan, dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyMAdyWjgb4b",
        "outputId": "fcadf31c-726b-4846-b87e-576e2d0c1d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    # min_value = torch.tensor(-1e38, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-9e-38, dtype=torch.float64)\n",
        "\n",
        "    # min_value = torch.tensor(-1.7e+308, dtype = torch.float64)\n",
        "    # min_value = torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)\n",
        "\n",
        "\n",
        "    # Using torch.where to explicitly set values outside the desired range\n",
        "    clamped_result = torch.where(input_term < min_value, min_value, input_term)\n",
        "    clamped_result = torch.where(clamped_result > max_float64, max_float64, clamped_result)\n",
        "\n",
        "    return clamped_result\n",
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDs0epOwdjjK",
        "outputId": "70d2de61-11b2-465f-a114-7527e815ead9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGlLqnsIhLAr",
        "outputId": "dbacfd91-4d5b-48ae-8d2b-c36b24042d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000e+00, -9.5567e-34, -1.1020e-12, -5.7703e-20,  0.0000e+00,\n",
              "        -6.6609e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.4562e-17,\n",
              "        -1.3518e-33, -6.3068e-29, -1.1566e-08,  0.0000e+00, -3.2522e-24,\n",
              "         0.0000e+00,  0.0000e+00, -4.0924e-02,  0.0000e+00,  0.0000e+00,\n",
              "        -6.0833e-21, -1.1020e-12,  0.0000e+00, -3.5032e-43, -3.4013e-37,\n",
              "        -7.9832e-23,  0.0000e+00, -2.2156e-12,  0.0000e+00, -7.3671e-27,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.0953e-12,  0.0000e+00, -7.1745e-11,  0.0000e+00,\n",
              "        -1.2184e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -4.8370e-19,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.7865e-25, -3.0953e-12, -3.1972e-14,\n",
              "         0.0000e+00, -3.9939e-21,  0.0000e+00, -4.2383e-17,  0.0000e+00,\n",
              "         0.0000e+00, -9.5567e-34,  0.0000e+00,  0.0000e+00, -5.4262e-07,\n",
              "        -3.7487e-37, -2.6165e-41,  0.0000e+00, -1.0701e-07,  0.0000e+00,\n",
              "         0.0000e+00, -6.6945e-22,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34, -1.7190e-19,  0.0000e+00,\n",
              "         9.6867e-18, -4.6108e-20,  1.3313e-32, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00, -1.9068e-20, -3.2430e-22, -8.2104e-17,  0.0000e+00,\n",
              "        -1.0108e-29,  0.0000e+00, -8.4772e-20,  0.0000e+00, -2.0319e-39,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -6.3362e-38,  0.0000e+00,\n",
              "         4.7220e-16,  0.0000e+00, -1.5748e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34,  3.4275e-23,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2642e-11,\n",
              "        -2.0774e-08,  0.0000e+00, -2.4060e-40, -3.5032e-43,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.3884e-01, -8.4772e-20, -2.5036e-39,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3247e-35,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.8730e-15, -1.0150e-03, -2.0038e-36,  0.0000e+00,\n",
              "         0.0000e+00, -8.4655e-19,  0.0000e+00, -7.3035e-20, -6.6609e-06,\n",
              "         0.0000e+00,  0.0000e+00, -1.6692e-14, -2.6013e-38,  0.0000e+00,\n",
              "         0.0000e+00, -5.6024e-35, -4.5634e-22,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8727e-10, -2.2156e-12,\n",
              "         0.0000e+00,  0.0000e+00,  5.1149e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -1.3400e-08,  0.0000e+00, -2.6687e-08,  0.0000e+00, -4.5020e-30,\n",
              "        -1.0701e-07, -1.0052e-13,  0.0000e+00,  0.0000e+00, -4.5720e-36,\n",
              "        -2.7511e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -9.6992e-23,  0.0000e+00,  0.0000e+00,  1.1169e-32,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2418e-12,  3.4265e-14,\n",
              "         0.0000e+00,  0.0000e+00, -1.6255e-43, -1.1568e-11,  0.0000e+00,\n",
              "        -2.5918e-04, -4.2958e-02, -1.4635e-26,  0.0000e+00, -8.7134e-11,\n",
              "         3.6282e-29,  0.0000e+00,  0.0000e+00, -1.2983e-17,  0.0000e+00,\n",
              "         0.0000e+00, -1.2418e-12, -1.6759e-21,  0.0000e+00,  0.0000e+00,\n",
              "        -1.9035e-38, -2.1801e-26,  0.0000e+00, -1.2909e-23, -4.1059e-16,\n",
              "        -2.4789e-27, -1.0616e-20,  0.0000e+00, -2.5688e-29, -5.9457e-04,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4309e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -3.0097e+06,  0.0000e+00, -3.9645e-25, -8.8058e-20,  1.9898e-43,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00, -3.8730e-15,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.4202e-34,  0.0000e+00,  0.0000e+00, -3.2028e-23,\n",
              "         0.0000e+00,  0.0000e+00, -3.9735e-34,  0.0000e+00, -3.8966e-08,\n",
              "         0.0000e+00, -2.2030e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -7.4222e-38,  0.0000e+00,  0.0000e+00, -9.4159e-16,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.1972e-42, -8.4772e-20,  0.0000e+00,\n",
              "         0.0000e+00, -2.0903e-15,  0.0000e+00,  0.0000e+00, -2.5223e-44,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4013e-45,  0.0000e+00,\n",
              "        -1.7457e-24,  0.0000e+00, -1.0543e-37, -1.6182e-33, -3.5188e-28,\n",
              "        -8.2104e-17,  0.0000e+00, -3.8662e-06,  0.0000e+00,  0.0000e+00,\n",
              "        -2.4441e-09, -8.4772e-20,  0.0000e+00,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -3.0097e+06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5720e-36,  0.0000e+00, -3.6430e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -1.6816e-44,  1.9004e-41, -4.8050e-26, -2.8832e-06, -1.4013e-45,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.4110e-04,\n",
              "         0.0000e+00,  0.0000e+00, -5.9390e-13,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5634e-22,  0.0000e+00, -3.4013e-37,  0.0000e+00,  0.0000e+00,\n",
              "         1.9898e-43,  0.0000e+00, -4.2383e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2412e-14, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  5.1149e-40,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5719e-17,\n",
              "         0.0000e+00,  0.0000e+00, -6.4470e-14, -1.3247e-35,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.8613e-27, -3.9645e-25, -1.5112e-30, -1.1566e-08,  0.0000e+00,\n",
              "         0.0000e+00, -1.5719e-17,  0.0000e+00, -1.3828e-31,  0.0000e+00,\n",
              "        -4.5551e-22, -1.6255e-43, -1.9179e-27,  4.6289e-17, -6.6137e-04,\n",
              "        -8.4772e-20,  0.0000e+00,  0.0000e+00, -8.2205e-14, -1.2163e-08,\n",
              "         0.0000e+00,  0.0000e+00, -1.2418e-12, -1.0543e-37,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  2.8294e-34, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.7118e-30,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3518e-33,  0.0000e+00,  0.0000e+00,\n",
              "        -1.8627e-28, -3.9645e-25,  0.0000e+00,  0.0000e+00, -2.1972e-42,\n",
              "         0.0000e+00, -2.4485e-09, -1.0150e-03,  0.0000e+00, -1.7865e-25,\n",
              "         0.0000e+00,        -inf,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.7035e-32,  0.0000e+00,  0.0000e+00, -6.3710e-32,\n",
              "        -6.6137e-04, -6.5706e-01,  0.0000e+00, -1.5719e-17,  0.0000e+00,\n",
              "         0.0000e+00,  5.1149e-40,  0.0000e+00, -7.1308e-38, -1.3518e-33,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -5.4345e-13,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.3034e-30,\n",
              "        -8.1634e-13,  0.0000e+00,  1.7343e-39,  0.0000e+00, -3.7737e+01,\n",
              "        -1.6692e-14,  0.0000e+00,  0.0000e+00, -1.1301e-18,  0.0000e+00,\n",
              "        -1.0095e-10, -8.0009e-07,  0.0000e+00, -2.4070e-08, -2.6165e-41,\n",
              "        -3.0533e-07,  0.0000e+00, -2.6325e-14,  0.0000e+00,  0.0000e+00,\n",
              "        -6.7686e-14,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3188e+01,  0.0000e+00, -3.4013e-37,\n",
              "         0.0000e+00,  7.1993e-41, -2.2864e-35, -6.5861e-44, -4.9438e-23,\n",
              "        -2.0903e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.6133e-21,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.8006e-24,\n",
              "         0.0000e+00,  0.0000e+00, -6.3710e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.0236e-15,  0.0000e+00, -2.5559e-05, -3.8831e-13,\n",
              "         0.0000e+00,  0.0000e+00, -1.2184e+02,  0.0000e+00, -1.0090e+01,\n",
              "        -5.2582e-35, -1.3873e-42,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         1.6419e-27, -8.8237e-12, -1.2808e-33, -4.6133e-21,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.6867e-18,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4571e-31,  0.0000e+00,  1.3201e-38,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.1568e-11,  0.0000e+00,\n",
              "        -1.4013e-45, -1.0701e-07,  3.2638e-35,  0.0000e+00,  0.0000e+00,\n",
              "         3.4265e-14, -2.5223e-44,  0.0000e+00, -1.7958e-41, -2.4441e-09,\n",
              "         0.0000e+00, -8.0009e-07, -1.4125e-01, -1.0090e+01,  0.0000e+00,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4070e-08,\n",
              "        -4.5634e-22, -1.3188e+01,  0.0000e+00,  0.0000e+00, -5.0588e-29,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3046e-34,\n",
              "        -2.3189e-15,  0.0000e+00, -2.9159e+00, -4.8370e-19, -1.0197e-32,\n",
              "         0.0000e+00, -4.2383e-17,  1.0241e-28,  0.0000e+00, -3.0533e-07,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -2.6325e-14, -1.4617e-36, -3.8065e-38,  0.0000e+00,\n",
              "        -5.4262e-07, -1.0095e-10,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -6.6729e-06,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.5634e-22,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "        -1.8556e-23,  0.0000e+00, -5.4529e-33,  0.0000e+00, -3.2522e-24,\n",
              "         1.1032e-38, -1.5748e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -7.9976e-23, -3.2028e-23, -9.3884e-01,  0.0000e+00,  0.0000e+00,\n",
              "        -3.4013e-37,  2.8026e-45,  0.0000e+00, -6.8054e-14,  0.0000e+00,\n",
              "        -1.0145e-30, -4.4114e-29, -6.0833e-21,  0.0000e+00, -1.2272e+09,\n",
              "         0.0000e+00, -8.2104e-17,  0.0000e+00, -6.1665e+15, -1.7958e-41,\n",
              "        -2.5223e-44, -6.8813e-12, -3.8615e-09,  0.0000e+00, -4.6133e-21,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40, -5.1789e+02, -7.3035e-20,\n",
              "         0.0000e+00, -2.3485e-09, -1.0284e-27, -4.5693e-33,  0.0000e+00,\n",
              "        -2.0038e-36, -1.5719e-17,  0.0000e+00, -5.8006e-24, -1.7944e-15,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8730e-15,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4013e-45, -7.9832e-23,  0.0000e+00, -1.3046e-34,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5112e-30,\n",
              "        -5.8855e-44,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.7035e-32,\n",
              "         3.4275e-23,  0.0000e+00, -3.5486e-18,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4617e-36,  0.0000e+00,\n",
              "         0.0000e+00, -3.0533e-07, -1.4830e-20, -8.4772e-20,  0.0000e+00,\n",
              "        -6.8054e-14,  0.0000e+00, -2.0976e-10,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.0095e-10, -8.4655e-19, -9.5567e-34,  0.0000e+00,\n",
              "        -2.5559e-05, -1.4857e-20,  0.0000e+00,  0.0000e+00, -2.2156e-12,\n",
              "        -1.5748e-17,  0.0000e+00, -2.2156e-12, -2.8727e-10,  0.0000e+00,\n",
              "        -6.2816e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6129e-11,\n",
              "        -1.2412e-14,  0.0000e+00, -4.7570e-17,  0.0000e+00, -2.4571e-31,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.5551e-22,\n",
              "        -1.0701e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -5.6052e-45, -3.8615e-09,  0.0000e+00, -6.6945e-22,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4857e-20,  0.0000e+00,\n",
              "        -1.9068e-20, -1.4830e-20,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -1.4309e-17, -1.7958e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.9438e-23, -5.4529e-33,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -8.4772e-20,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.8727e-10,  0.0000e+00, -9.0216e-24, -1.2184e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.2036e-30, -2.2960e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.3133e-27,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -7.9832e-23,  0.0000e+00, -1.3400e-08, -2.4060e-40,\n",
              "        -9.5567e-34, -2.6038e-21,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -9.8091e-45,  0.0000e+00,\n",
              "         0.0000e+00, -1.3046e-34,  1.1169e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.2383e-17, -2.2156e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -3.7737e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1789e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.2141e-04, -7.1308e-38,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.7511e-36,\n",
              "         0.0000e+00, -2.3189e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.5112e-30,  0.0000e+00, -1.4125e-01,\n",
              "        -3.2425e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0095e-10,  0.0000e+00, -7.4033e-39,\n",
              "        -1.7015e-18, -6.6945e-22,  0.0000e+00, -1.9035e-38, -4.2974e-25,\n",
              "        -1.1244e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6816e-44,\n",
              "        -1.0052e-13,  0.0000e+00,  0.0000e+00, -2.5688e-29,  0.0000e+00,\n",
              "         0.0000e+00, -7.1308e-38, -1.3400e-08,  0.0000e+00, -8.7134e-11,\n",
              "         0.0000e+00, -1.7944e-15,  0.0000e+00, -2.5462e-42,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2808e-33, -2.6687e-08,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5322e-01, -2.0774e-08,\n",
              "        -1.4013e-45, -1.0095e-10,  0.0000e+00, -9.5567e-34,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4202e-34, -3.3704e-28,  0.0000e+00,\n",
              "        -1.8556e-23, -3.0591e-21,  0.0000e+00,  0.0000e+00,  2.1787e-40,\n",
              "        -1.4635e-26,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4565e-24,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.2036e-30,  0.0000e+00,\n",
              "        -1.4309e-17,  0.0000e+00, -2.4565e-24,  0.0000e+00,  0.0000e+00,\n",
              "        -5.4262e-07,  0.0000e+00, -2.8903e-30,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4789e-27,\n",
              "        -2.4789e-27,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4645e-07,\n",
              "         0.0000e+00, -4.7570e-17,  0.0000e+00, -1.2418e-12,  0.0000e+00,\n",
              "        -2.6013e-38,  0.0000e+00, -4.5020e-30,  0.0000e+00,  0.0000e+00,\n",
              "        -1.1129e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6108e-20,\n",
              "        -1.6266e-28,  0.0000e+00,  0.0000e+00, -9.0216e-24, -7.9832e-23,\n",
              "         0.0000e+00, -1.6816e-44,  0.0000e+00,  0.0000e+00, -3.5032e-43,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8558e-42, -4.0543e-28,\n",
              "        -1.6182e-33,  0.0000e+00, -1.3873e-42,  0.0000e+00, -3.0953e-12,\n",
              "         0.0000e+00,  0.0000e+00,  1.8187e-35, -1.3828e-31, -1.6692e-14])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg4Fy5iQcqnl",
        "outputId": "534b197d-a951-470c-d848-9b9d74a2121f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(tensor):\n",
        "    max_float64 = torch.finfo(torch.float64).max\n",
        "    min_float64 = torch.finfo(torch.float64).min\n",
        "\n",
        "    tensor[tensor == float('inf')] = 1e38  # Choose a large finite value\n",
        "    tensor[tensor == float('-inf')] = -1e38  # Choose a small finite value\n",
        "\n",
        "    return tensor\n",
        "\n",
        "# Example usage:\n",
        "# samples_IS_clamped = clamp_tensor(samples_IS)"
      ],
      "metadata": {
        "id": "5I1eVRAvlZK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS_clamped[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "fMWanHX9l-kL",
        "outputId": "d8453853-77ac-49e1-fca3-d1760b015b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'samples_IS_clamped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-5babce667c95>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples_IS_clamped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'samples_IS_clamped' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZvLUFyNeJBo",
        "outputId": "c35697a7-262f-427d-d331-dfc87a2c111b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.7977e+308, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MHWCgv3e3fSs",
        "outputId": "f1041452-2c44-40ad-fd87-8a903fee57eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet_d(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=32, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(state_tensors)"
      ],
      "metadata": {
        "id": "HkIlYqmg25KD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "651d0a8b-af25-4e2f-a721-0b694511e29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Float and Double",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-602b7502521b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-0c890199681a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Float and Double"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "Tukv3iQZ3ekc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FltSKPtH8TAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "pG06s2t_0gZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3PZWZk4GqndI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scope_set, phi_set = subset_policies(pi_b, 0.3)"
      ],
      "metadata": {
        "id": "OFF9HKErgm34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS, state_tensors, w_diff, f, st_og, psi_res, sample_last_tensors = variance_terms_tens(P_pi_e, P_pi_b, phi_set)"
      ],
      "metadata": {
        "id": "inVdxVMRjT4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "qq1dLzLCjUp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_mse_var(model, 40, 0.001, 1, 1, IS, state_tensors, w_diff, f, sample_last_tensors, phi_set, st_og, psi_res)"
      ],
      "metadata": {
        "id": "TYKlf1urD34t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test class"
      ],
      "metadata": {
        "id": "72Fy4L1cuitK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from IS import calculate_importance_weights\n",
        "\n",
        "# import torch\n",
        "\n",
        "class SCOPE_variance_play(object):\n",
        "    def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, dtype):\n",
        "        self.model = model\n",
        "        self.gamma = gamma\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.pi_b = pi_b\n",
        "        self.P_pi_b = P_pi_b\n",
        "        self.P_pi_e = P_pi_e\n",
        "        self.dtype = dtype\n",
        "\n",
        "\n",
        "    def prep_policies(self):\n",
        "        # Initialize lists to store axis data for each policy\n",
        "        timesteps = []\n",
        "        states = []\n",
        "        state_first = []\n",
        "        state_last = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        gamma_last = []\n",
        "        weight_last = []\n",
        "        weight_first = []\n",
        "        # all_weights_temp, weights = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        weights, all_weights_temp = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        psi = []\n",
        "\n",
        "        for index, policy in enumerate(self.pi_b):\n",
        "            policy_array = np.array(policy)\n",
        "            timesteps.append(policy_array['timestep'].astype(int))\n",
        "            # s.append(policy_array[:, 0])\n",
        "\n",
        "            # last timestep for gamma\n",
        "            gamma_last.append(len(policy))\n",
        "            # last importance weight\n",
        "            weight_last.append(weights[index][-1])\n",
        "            weight_first.append(weights[index][0])\n",
        "\n",
        "\n",
        "            states.append(policy_array['state'][:])\n",
        "            psi.append(policy_array['psi'][:])\n",
        "            state_first.append(policy_array['state'][0])\n",
        "            state_last.append(policy_array['state_next'][-1])\n",
        "            actions.append(policy_array['action'])\n",
        "            rewards.append(policy_array['reward'].astype(float))\n",
        "\n",
        "        weights_difference = []\n",
        "        for index, weight in enumerate(weights):\n",
        "            # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "            diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "            weights_difference.append(diff)\n",
        "\n",
        "        return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference, weight_first\n",
        "\n",
        "    def padding_IS_terms(self,timesteps, actions, rewards, weights):\n",
        "        # Find the maximum length among all lists\n",
        "        max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "        # Define the padding values\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each list to match the maximum length\n",
        "        padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "        padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "        padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "        padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "        return padded_timesteps, padded_rewards, padded_actions, padded_weights\n",
        "\n",
        "    def padding_states_weights_difference(self, states, weights_difference):\n",
        "        # Find the maximum length of trajectories\n",
        "        max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each trajectory to make them all the same length\n",
        "        padded_states = [\n",
        "            [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "            for trajectory in states\n",
        "        ]\n",
        "\n",
        "        padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "        return padded_states, padded_weights_difference\n",
        "\n",
        "    def tensorize_padded_terms(self, padded_states, padded_weights_difference):\n",
        "        padded_state_tensors = torch.tensor(padded_states, dtype = self.dtype)\n",
        "        padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n",
        "        padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "        return padded_state_tensors, padded_weight_diff_tensors\n",
        "\n",
        "    def tensorize_last_and_first_terms(self, states_first, states_last, gamma_last, weights_last):\n",
        "        states_first_tensor = torch.tensor(states_first, dtype = self.dtype)\n",
        "        states_last_tensor = torch.tensor(states_last, dtype = self.dtype)\n",
        "        gamma_last_tensor = torch.tensor(gamma_last, dtype = self.dtype)\n",
        "        weights_last_tensor = torch.tensor(weights_last, dtype = self.dtype)\n",
        "\n",
        "        return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor\n",
        "\n",
        "    def calc_IS_terms(self, gamma, timesteps, rewards, weights):\n",
        "        gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
        "        IS_tensor = torch.sum(torch.tensor(gtrw, dtype = self.dtype), dim = 1, keepdim = True)\n",
        "\n",
        "        return IS_tensor\n",
        "\n",
        "    def calc_gamma_weight_last(self, gamma, gamma_last, weights_last):\n",
        "        gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
        "        gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = self.dtype).unsqueeze(-1)\n",
        "\n",
        "        return gamma_weight_last_tensor\n",
        "\n",
        "    def tensorize_weight_first(self, weights_first):\n",
        "\n",
        "      weight_first_tensor = torch.tensor(weights_first, dtype = torch.float64).unsqueeze(-1)\n",
        "\n",
        "      return weight_first_tensor\n",
        "    def bootstrap_IS_terms(self, IS_tensor, num_samples):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "        new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "        IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "        # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "        return IS_bootstraps\n",
        "\n",
        "    def states_weight_diff_sums(self, states_output, padded_weight_diff_tensors):\n",
        "        states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "        sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "        return sums_states_weight_diff\n",
        "\n",
        "    def last_first_terms_operations(self, gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor):\n",
        "        gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output -  weight_first_tensor*states_first_output\n",
        "\n",
        "        return gamma_weights_states_last_sub_states_first\n",
        "\n",
        "\n",
        "    def bootstrap_shaping_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor):\n",
        "\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        num_samples = self.num_bootstraps\n",
        "\n",
        "        num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "        reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "        # Resize samples to shape num_samples x num_trajectories\n",
        "        sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "        samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "        sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "        # sample IS terms\n",
        "\n",
        "        IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "        samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "        sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, sample_all_shaping, samples_IS_SCOPE\n",
        "\n",
        "    def bootstrap_all_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        # sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "        # new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "        # IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "        num_samples = self.num_bootstraps\n",
        "        num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "        reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "        IS_bootstraps = IS_tensor[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Resize samples to shape num_samples x num_trajectories\n",
        "        sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "        samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "        sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "        # sample IS terms\n",
        "\n",
        "        IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "        samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        return IS_bootstraps, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, sample_all_shaping, samples_IS_SCOPE\n",
        "\n",
        "\n",
        "\n",
        "    def pass_states(self,model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "        # Get model outputs for states\n",
        "        states_output = model(padded_state_tensors)\n",
        "        states_first_output = model(states_first_tensor)\n",
        "        states_last_output = model(states_last_tensor)\n",
        "        return states_output, states_first_output, states_last_output\n",
        "\n",
        "\n",
        "    # def prepare(self):\n",
        "    #     timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = self.prep_policies()\n",
        "    #     padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "    #     padded_states, padded_weights_difference = self.padding_states_weights_difference(states, weights_difference)\n",
        "    #     padded_state_tensors, padded_weight_diff_tensors = self.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "    #     states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = self.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "    #     IS_tensor = self.calc_IS_terms(self.gamma, padded_timesteps, padded_rewards, padded_weights)\n",
        "    #     gamma_weights_last_tensor = self.calc_gamma_weight_last(self.gamma, gamma_last, weights_last)\n",
        "    #     samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "    #     return IS_tensor, samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor\n",
        "\n",
        "\n",
        "    def prepare(self):\n",
        "        timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference, weight_first = self.prep_policies()\n",
        "        padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "        padded_states, padded_weights_difference = self.padding_states_weights_difference(states, weights_difference)\n",
        "        padded_state_tensors, padded_weight_diff_tensors = self.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "        states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = self.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "        IS_tensor = self.calc_IS_terms(self.gamma, padded_timesteps, padded_rewards, padded_weights)\n",
        "        gamma_weights_last_tensor = self.calc_gamma_weight_last(self.gamma, gamma_last, weights_last)\n",
        "        weight_first_tensor = self.tensorize_weight_first(weight_first)\n",
        "        # samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "        return IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor"
      ],
      "metadata": {
        "id": "1vZCWSiPum0K"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from IS import calculate_importance_weights\n",
        "\n",
        "import torch\n",
        "\n",
        "class SCOPE_variance(object):\n",
        "    def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, dtype):\n",
        "        self.model = model\n",
        "        self.gamma = gamma\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.pi_b = pi_b\n",
        "        self.P_pi_b = P_pi_b\n",
        "        self.P_pi_e = P_pi_e\n",
        "        self.dtype = dtype\n",
        "\n",
        "\n",
        "    def prep_policies(self):\n",
        "        # Initialize lists to store axis data for each policy\n",
        "        timesteps = []\n",
        "        states = []\n",
        "        state_first = []\n",
        "        state_last = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        gamma_last = []\n",
        "        weight_last = []\n",
        "        weight_first = []\n",
        "        # all_weights_temp, weights = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        weights = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        psi = []\n",
        "\n",
        "        for index, policy in enumerate(self.pi_b):\n",
        "            policy_array = np.array(policy)\n",
        "            timesteps.append(policy_array['timestep'].astype(int))\n",
        "            # s.append(policy_array[:, 0])\n",
        "\n",
        "            # last timestep for gamma\n",
        "            gamma_last.append(len(policy))\n",
        "            # last importance weight\n",
        "            weight_last.append(weights[index][-1])\n",
        "            weight_first.append(weights[index][0])\n",
        "\n",
        "\n",
        "            states.append(policy_array['state'][1:])\n",
        "            psi.append(policy_array['psi'][1:])\n",
        "            state_first.append(policy_array['state'][0])\n",
        "            state_last.append(policy_array['state'][-1])\n",
        "            actions.append(policy_array['action'])\n",
        "            rewards.append(policy_array['reward'].astype(float))\n",
        "\n",
        "        weights_difference = []\n",
        "        for index, weight in enumerate(weights):\n",
        "            # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "            diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "            weights_difference.append(diff)\n",
        "\n",
        "        return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference, weight_first, psi\n",
        "\n",
        "    def padding_IS_terms(self,timesteps, actions, rewards, weights):\n",
        "        # Find the maximum length among all lists\n",
        "        max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "        # Define the padding values\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each list to match the maximum length\n",
        "        padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "        padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "        padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "        padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "        return padded_timesteps, padded_rewards, padded_actions, padded_weights\n",
        "\n",
        "    def padding_states_weights_difference(self, states, weights_difference, psi):\n",
        "        # Find the maximum length of trajectories\n",
        "        max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each trajectory to make them all the same length\n",
        "        padded_states = [\n",
        "            [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "            for trajectory in states\n",
        "        ]\n",
        "\n",
        "        padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "        padded_psi = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in psi]\n",
        "        return padded_states, padded_weights_difference, padded_psi\n",
        "\n",
        "    def tensorize_padded_terms(self, padded_states, padded_weights_difference, padded_psi):\n",
        "        padded_state_tensors = torch.tensor(padded_states, dtype = self.dtype)\n",
        "        padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n",
        "        padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "        padded_psi_tensors = torch.tensor(padded_psi, dtype = self.dtype)\n",
        "        padded_psi_tensors = padded_psi_tensors.unsqueeze(-1)\n",
        "\n",
        "        return padded_state_tensors, padded_weight_diff_tensors, padded_psi_tensors\n",
        "\n",
        "    def tensorize_last_and_first_terms(self, states_first, states_last, gamma_last, weights_last):\n",
        "        states_first_tensor = torch.tensor(states_first, dtype = self.dtype)\n",
        "        states_last_tensor = torch.tensor(states_last, dtype = self.dtype)\n",
        "        gamma_last_tensor = torch.tensor(gamma_last, dtype = self.dtype)\n",
        "        weights_last_tensor = torch.tensor(weights_last, dtype = self.dtype)\n",
        "\n",
        "        return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor\n",
        "\n",
        "    def calc_IS_terms(self, gamma, timesteps, rewards, weights):\n",
        "        gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
        "        IS_tensor = torch.sum(torch.tensor(gtrw, dtype = self.dtype), dim = 1, keepdim = True)\n",
        "\n",
        "        return IS_tensor\n",
        "\n",
        "    def calc_gamma_weight_last(self, gamma, gamma_last, weights_last):\n",
        "        gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
        "        gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = self.dtype).unsqueeze(-1)\n",
        "\n",
        "        return gamma_weight_last_tensor\n",
        "\n",
        "    def tensorize_weight_first(self, weights_first):\n",
        "\n",
        "      weight_first_tensor = torch.tensor(weights_first, dtype = torch.float64).unsqueeze(-1)\n",
        "\n",
        "      return weight_first_tensor\n",
        "    def bootstrap_IS_terms(self, IS_tensor, num_samples):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "        new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "        IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "        # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "        return IS_bootstraps\n",
        "\n",
        "    def states_weight_diff_sums(self, states_output, padded_weight_diff_tensors):\n",
        "        states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "        sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "        return sums_states_weight_diff\n",
        "\n",
        "    def last_first_terms_operations(self, gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor):\n",
        "        gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output -  weight_first_tensor*states_first_output\n",
        "\n",
        "        return gamma_weights_states_last_sub_states_first\n",
        "\n",
        "\n",
        "    def bootstrap_shaping_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor):\n",
        "\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        num_samples = self.num_bootstraps\n",
        "\n",
        "        num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "        reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "        # Resize samples to shape num_samples x num_trajectories\n",
        "        sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "        samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "        sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "        # sample IS terms\n",
        "\n",
        "        IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "        samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "        sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, sample_all_shaping, samples_IS_SCOPE\n",
        "\n",
        "    def bootstrap_all_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor, padded_psi_tensors):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        # sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "        # new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "        # IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "        num_samples = self.num_bootstraps\n",
        "        num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "        reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "        IS_bootstraps = IS_tensor[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Resize samples to shape num_samples x num_trajectories\n",
        "        sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "        samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "        sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "        # sample IS terms\n",
        "\n",
        "        IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "        samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # sample_psi = padded_psi_tensors[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        return IS_bootstraps, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, sample_all_shaping, samples_IS_SCOPE\n",
        "\n",
        "\n",
        "\n",
        "    def pass_states(self,model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "        # Get model outputs for states\n",
        "        states_output = model(padded_state_tensors)\n",
        "        states_first_output = model(states_first_tensor)\n",
        "        states_last_output = model(states_last_tensor)\n",
        "        return states_output, states_first_output, states_last_output\n",
        "\n",
        "\n",
        "    # def prepare(self):\n",
        "    #     timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = self.prep_policies()\n",
        "    #     padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "    #     padded_states, padded_weights_difference = self.padding_states_weights_difference(states, weights_difference)\n",
        "    #     padded_state_tensors, padded_weight_diff_tensors = self.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "    #     states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = self.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "    #     IS_tensor = self.calc_IS_terms(self.gamma, padded_timesteps, padded_rewards, padded_weights)\n",
        "    #     gamma_weights_last_tensor = self.calc_gamma_weight_last(self.gamma, gamma_last, weights_last)\n",
        "    #     samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "    #     return IS_tensor, samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor\n",
        "\n",
        "\n",
        "    def prepare(self):\n",
        "        timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference, weight_first, psi = self.prep_policies()\n",
        "        padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "        padded_states, padded_weights_difference, padded_psi = self.padding_states_weights_difference(states, weights_difference, psi)\n",
        "        padded_state_tensors, padded_weight_diff_tensors, padded_psi_tensors = self.tensorize_padded_terms(padded_states, padded_weights_difference, padded_psi)\n",
        "        states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = self.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "        IS_tensor = self.calc_IS_terms(self.gamma, padded_timesteps, padded_rewards, padded_weights)\n",
        "        gamma_weights_last_tensor = self.calc_gamma_weight_last(self.gamma, gamma_last, weights_last)\n",
        "        weight_first_tensor = self.tensorize_weight_first(weight_first)\n",
        "        # samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "        return IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor, padded_psi_tensors\n"
      ],
      "metadata": {
        "id": "BFb6kj8bJTee"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_importance_weights(eval_policy, behav_policy, behavior_policies):\n",
        "    \"\"\"\n",
        "    Calculate importance weights for behavior policies.\n",
        "\n",
        "    Parameters:\n",
        "    - eval_policy: Evaluation policy\n",
        "    - behav_policy: Behavior policy\n",
        "    - behavior_policies: List of behavior policies\n",
        "\n",
        "    Returns:\n",
        "    - all_weights: List of importance weights\n",
        "    \"\"\"\n",
        "    all_weights_temp = []\n",
        "    for trajectory in behavior_policies:\n",
        "        cum_ratio = 1\n",
        "        cumul_weights = []\n",
        "        for step in trajectory:\n",
        "            # eval_action_probs = get_quadrant_policy(step[0], eval_policy)\n",
        "            # behav_action_probs = get_quadrant_policy(step[0], behav_policy)\n",
        "\n",
        "            P_pi_b = behav_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "            P_pi_e = eval_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "\n",
        "            # ratio = (0.8*eval_action_probs[step[1]] +0.2*0.25)/ (0.8*behav_action_probs[step[1]]+0.2*0.25)\n",
        "            ratio = P_pi_e/P_pi_b\n",
        "            cum_ratio *= ratio\n",
        "            cumul_weights.append(cum_ratio)\n",
        "        all_weights_temp.append(cumul_weights)\n",
        "\n",
        "        all_weights = [list(np.cumprod(i)) for i in all_weights_temp]\n",
        "\n",
        "    return all_weights_temp, all_weights"
      ],
      "metadata": {
        "id": "qRsjTJiS5cYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test variance"
      ],
      "metadata": {
        "id": "x6L6-NZfHdt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance_play(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE):\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(samples_IS, dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(samples_IS, dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  E_IS = torch.mean(torch.mean(samples_IS,dim = 1 ))\n",
        "  E_SCOPE = torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  # samples_IS_SCOPE seems to be wrong, get means and then multiply\n",
        "  # E_IS_SCOPE = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "  # E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))\n",
        "\n",
        "\n",
        "\n",
        "  # SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_s_wdiff_all_sq\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, IS_variance, SCOPE_variance, E_IS, E_SCOPE\n"
      ],
      "metadata": {
        "id": "2c4zRUmqHfz2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing play"
      ],
      "metadata": {
        "id": "ScU_mVSALakh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def train_var_play(model, num_epochs, learning_rate, padded_state_tensors, states_first_tensor, states_last_tensor, test1, padded_psi_tensors):\n",
        "    model.train()\n",
        "\n",
        "    # Enable anomaly detection\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Forward pass\n",
        "        states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "        sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "        gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "        # sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "        samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor, padded_psi_tensors)\n",
        "\n",
        "        # Calculate MSE loss between states_output and padded_state_tensors\n",
        "        # mse_loss = F.mse_loss(states_output, padded_state_tensors)\n",
        "\n",
        "        E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss, E_IS, E_SCOPE = calculate_shaped_variance_play(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"Var loss: \", variance_loss)\n",
        "        # print(\"MSE loss: \", mse_loss.item())\n",
        "\n",
        "        # Print each term\n",
        "        print(f\"E_IS_sq: {E_IS_sq}\")\n",
        "        print(f\"E_IS_all_sq: {E_IS_all_sq}\")\n",
        "        print(f\"E_s_wdiff_sq: {E_s_wdiff_sq}\")\n",
        "        print(f\"E_s_wdiff_all_sq: {E_s_wdiff_all_sq}\")\n",
        "        print(f\"E_IS_SCOPE: {E_IS_SCOPE}\")\n",
        "        print(f\"E_IS_E_SCOPE: {E_IS_E_SCOPE}\")\n",
        "        print(f\"E_IS: {E_IS}\")\n",
        "        print(f\"E_SCOPE: {E_SCOPE}\")\n",
        "\n",
        "        tot = variance_loss\n",
        "        # tot = variance_loss + mse_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Retain the graph to avoid clearing it before backward pass\n",
        "        tot.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Disable anomaly detection after running the code\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "6Dk99vwwLcPN"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = testing.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "sums_states_weight_diff = testing.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "gamma_weights_states_last_sub_states_first = testing.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "\n",
        "\n",
        "# sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = testing.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = testing.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n"
      ],
      "metadata": {
        "id": "fHvR4UmfMh6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5EdwiZbW0cPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_SCOPE = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "# Sample indices with replacement\n",
        "# sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "# new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "# new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "# IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "num_samples = 10000\n",
        "num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "\n",
        "# Sample indices with replacement\n",
        "sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "# IS_bootstraps = IS_tensor[sampled_indices].view(reshaped_size)\n",
        "\n",
        "# # Resize samples to shape num_samples x num_trajectories\n",
        "# sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "# samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "# Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "\n",
        "samples_sum_terms = sum_terms[sampled_indices].view(reshaped_size)\n",
        "# sample IS terms\n",
        "\n",
        "IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "3n0LFWhfzw1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff + samples_gamma_weight_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "ze7OQ2Gmz_Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "# I believe this is wrong, need to get means for full samples first then expected value\n",
        "E_IS_SCOPE_2 = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "E_IS_E_SCOPE_2 = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))"
      ],
      "metadata": {
        "id": "KS9W2QBbxaAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ--fCnzfqiP",
        "outputId": "0c3fb638-e79c-4c09-f64a-61df13f7de45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70T4d5TUfw53",
        "outputId": "4817d316-ffff-4e75-845e-708f5e560f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_IS*SCOPE, dim = 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4bIivIL6a_w",
        "outputId": "4677859b-b2a7-42af-cce5-6c8634c9419a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1475, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(IS_tensor*sum_terms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D6NmpCN2qn6",
        "outputId": "d282953a-f0f4-4b6a-eff6-ba44cef40cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1482, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_IS, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsy6Ei4R2lSg",
        "outputId": "7b90369b-c186-4cc3-a982-ea06d3ff8e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0044, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_IS_SCOPE, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl2FQXTo2c86",
        "outputId": "92046c51-06bd-4601-e019-e264738757a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1475, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_sum_terms, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEXHNRtU1MQ_",
        "outputId": "a8e20f5f-e8e7-4c25-ccb5-5cc3ab5b216e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3184, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean"
      ],
      "metadata": {
        "id": "xBrxbL2j1mrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(SCOPE, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEHEGqddyEtn",
        "outputId": "806ed392-ccee-4d4c-a247-114bc0be26d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3184, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_all_shaping, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78G2yHu6yFgy",
        "outputId": "9e85a406-22ba-4615-b7e0-293403c4f153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3184, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_SCOPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pgIK7pqxH7n",
        "outputId": "cb4f2b75-dcec-4313-e318-a429e84d0890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0015, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_SCOPE_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVdR3bVMxlXq",
        "outputId": "88b13c07-d8be-4702-bf86-a51aa531f524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1475, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_E_SCOPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFU4WYuJxhOg",
        "outputId": "b8704738-fdce-47ad-8f1f-5d3367ef75e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0014, dtype=torch.float64, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_E_SCOPE_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vzjRzVfxoXV",
        "outputId": "8efcebb9-0d64-4e28-cb99-6fcb9b8c13a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0014, dtype=torch.float64, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class play"
      ],
      "metadata": {
        "id": "GKFk2XRHQeQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env, P_pi_e)"
      ],
      "metadata": {
        "id": "TnCDINz7AoG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "gEgO1QxNLnCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = SCOPE_variance_play(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "I2S6fvyWQgjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz6hDK3ZJjM6",
        "outputId": "fb83e747-3ec6-46b7-f7c2-2732a5628ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-41662d94a8d9>:92: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1000 = train_var_play(model, 100, 0.001, padded_state_tensors, states_first_tensor, states_last_tensor, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B7y3q-Xjtpy",
        "outputId": "878d6336-c857-4a97-b446-dbe5fdde90d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(0.4364, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.91612813590345\n",
            "E_s_wdiff_all_sq: 0.47977377573226215\n",
            "E_IS_SCOPE: 0.0018630194424027102\n",
            "E_IS_E_SCOPE: 0.0018434664174459066\n",
            "Total Loss: 0.43639459134416786\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(0.0953, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.10377027388910455\n",
            "E_s_wdiff_all_sq: 0.00848972906796978\n",
            "E_IS_SCOPE: -0.0002716328863720476\n",
            "E_IS_E_SCOPE: -0.00026625847027983576\n",
            "Total Loss: 0.09527092111201678\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(0.0876, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.09273451330953343\n",
            "E_s_wdiff_all_sq: 0.005075734755404952\n",
            "E_IS_SCOPE: -0.00023341896140770455\n",
            "E_IS_E_SCOPE: -0.00022784492566733285\n",
            "Total Loss: 0.08764875560571417\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(0.0791, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08132886587014147\n",
            "E_s_wdiff_all_sq: 0.0021883635850759526\n",
            "E_IS_SCOPE: -0.00018601687001004106\n",
            "E_IS_E_SCOPE: -0.00018030005141584092\n",
            "Total Loss: 0.07913019377094355\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(0.0706, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.071032391331592\n",
            "E_s_wdiff_all_sq: 0.0004147307649607041\n",
            "E_IS_SCOPE: -0.00013300607224001144\n",
            "E_IS_E_SCOPE: -0.00012726564015150342\n",
            "Total Loss: 0.07060730482552072\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(0.0624, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0624413959860953\n",
            "E_s_wdiff_all_sq: 4.973075033803511e-05\n",
            "E_IS_SCOPE: -7.732244445190367e-05\n",
            "E_IS_E_SCOPE: -7.162573197204863e-05\n",
            "Total Loss: 0.06238139693386399\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(0.0537, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0551337285828942\n",
            "E_s_wdiff_all_sq: 0.001390025889742699\n",
            "E_IS_SCOPE: -1.4220526037030317e-05\n",
            "E_IS_E_SCOPE: -8.594540055994792e-06\n",
            "Total Loss: 0.05373357584425586\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(0.0458, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0504123122634963\n",
            "E_s_wdiff_all_sq: 0.004594387678063869\n",
            "E_IS_SCOPE: 4.994035759673149e-05\n",
            "E_IS_E_SCOPE: 5.543781151084006e-05\n",
            "Total Loss: 0.045808054800670656\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(0.0389, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.048515872656841715\n",
            "E_s_wdiff_all_sq: 0.009582613863139158\n",
            "E_IS_SCOPE: 0.00011337560882700084\n",
            "E_IS_E_SCOPE: 0.00011870225494622833\n",
            "Total Loss: 0.03892373062453054\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(0.0341, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.04950488927357401\n",
            "E_s_wdiff_all_sq: 0.015386559139357287\n",
            "E_IS_SCOPE: 0.00016646643441788316\n",
            "E_IS_E_SCOPE: 0.00017161545398003815\n",
            "Total Loss: 0.03410915721815885\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.05234703835465415\n",
            "E_s_wdiff_all_sq: 0.022390642577197396\n",
            "E_IS_SCOPE: 0.00021817072671318174\n",
            "E_IS_E_SCOPE: 0.00022315749374691508\n",
            "Total Loss: 0.029947547366455725\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(0.0263, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0569632752586208\n",
            "E_s_wdiff_all_sq: 0.030634205779846418\n",
            "E_IS_SCOPE: 0.0002695396784779753\n",
            "E_IS_E_SCOPE: 0.00027434676599848715\n",
            "Total Loss: 0.02632058042679979\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06321574139382483\n",
            "E_s_wdiff_all_sq: 0.03993184424256603\n",
            "E_IS_SCOPE: 0.0003197964958500142\n",
            "E_IS_E_SCOPE: 0.0003243912983452474\n",
            "Total Loss: 0.023275832669334764\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(0.0208, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.07077811203035576\n",
            "E_s_wdiff_all_sq: 0.04995584483465661\n",
            "E_IS_SCOPE: 0.00036798485978724164\n",
            "E_IS_E_SCOPE: 0.0003723377888989095\n",
            "Total Loss: 0.020814686460542256\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0793085919755429\n",
            "E_s_wdiff_all_sq: 0.06039850122952358\n",
            "E_IS_SCOPE: 0.0004134152678751711\n",
            "E_IS_E_SCOPE: 0.00041750881420025374\n",
            "Total Loss: 0.01890302877643559\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(0.0175, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08846424225442905\n",
            "E_s_wdiff_all_sq: 0.07097461945883708\n",
            "E_IS_SCOPE: 0.00045580352366264944\n",
            "E_IS_E_SCOPE: 0.0004596221890870441\n",
            "Total Loss: 0.017483110587809603\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(0.0165, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.09769536624212337\n",
            "E_s_wdiff_all_sq: 0.08123409527225472\n",
            "E_IS_SCOPE: 0.0004942089200272758\n",
            "E_IS_E_SCOPE: 0.0004977367640809867\n",
            "Total Loss: 0.016455340404827656\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.10672146615707488\n",
            "E_s_wdiff_all_sq: 0.09095097090991745\n",
            "E_IS_SCOPE: 0.0005290266073228855\n",
            "E_IS_E_SCOPE: 0.0005321991348745425\n",
            "Total Loss: 0.015765275315120564\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(0.0154, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.11523150839064138\n",
            "E_s_wdiff_all_sq: 0.0998746482486804\n",
            "E_IS_SCOPE: 0.0005602125165639581\n",
            "E_IS_E_SCOPE: 0.0005630182791410967\n",
            "Total Loss: 0.015352373739873124\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1228997639045931\n",
            "E_s_wdiff_all_sq: 0.10774675470546063\n",
            "E_IS_SCOPE: 0.000587511790980629\n",
            "E_IS_E_SCOPE: 0.0005899504260743376\n",
            "Total Loss: 0.015149257052011492\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.12939065808812644\n",
            "E_s_wdiff_all_sq: 0.11431017292684988\n",
            "E_IS_SCOPE: 0.0006105297884030049\n",
            "E_IS_E_SCOPE: 0.0006126166866516021\n",
            "Total Loss: 0.015077436487845805\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.13452292513357333\n",
            "E_s_wdiff_all_sq: 0.11944390807755928\n",
            "E_IS_SCOPE: 0.0006293534481527638\n",
            "E_IS_E_SCOPE: 0.0006311046671788489\n",
            "Total Loss: 0.015076639741028325\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1381697901437851\n",
            "E_s_wdiff_all_sq: 0.12307553131082917\n",
            "E_IS_SCOPE: 0.0006440631700123626\n",
            "E_IS_E_SCOPE: 0.0006454929486758053\n",
            "Total Loss: 0.015092524398695503\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.14025435623748944\n",
            "E_s_wdiff_all_sq: 0.12517200301504958\n",
            "E_IS_SCOPE: 0.0006547388476835425\n",
            "E_IS_E_SCOPE: 0.0006558683594635652\n",
            "Total Loss: 0.015081219321946254\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.14075832825977388\n",
            "E_s_wdiff_all_sq: 0.12574657946510517\n",
            "E_IS_SCOPE: 0.0006617166283364141\n",
            "E_IS_E_SCOPE: 0.0006625689841587855\n",
            "Total Loss: 0.015011169206090413\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(0.0149, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.13970832461982804\n",
            "E_s_wdiff_all_sq: 0.12484510919561963\n",
            "E_IS_SCOPE: 0.0006647198466471599\n",
            "E_IS_E_SCOPE: 0.0006653208451685685\n",
            "Total Loss: 0.014863138550232038\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(0.0146, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.13726218722544753\n",
            "E_s_wdiff_all_sq: 0.1226334607225394\n",
            "E_IS_SCOPE: 0.0006642705965718272\n",
            "E_IS_E_SCOPE: 0.0006646482952402545\n",
            "Total Loss: 0.014629096228637714\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.13353579432308188\n",
            "E_s_wdiff_all_sq: 0.11922872111858607\n",
            "E_IS_SCOPE: 0.0006606111745987252\n",
            "E_IS_E_SCOPE: 0.0006607982551451171\n",
            "Total Loss: 0.014307824166469474\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.12869547597066078\n",
            "E_s_wdiff_all_sq: 0.11479169752388439\n",
            "E_IS_SCOPE: 0.0006541425804998462\n",
            "E_IS_E_SCOPE: 0.0006541707997583372\n",
            "Total Loss: 0.013904847131325823\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.12296005484405509\n",
            "E_s_wdiff_all_sq: 0.10952465785483498\n",
            "E_IS_SCOPE: 0.0006451689497578333\n",
            "E_IS_E_SCOPE: 0.0006450707242915479\n",
            "Total Loss: 0.01343671856321911\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.11656705223068252\n",
            "E_s_wdiff_all_sq: 0.1036447805234519\n",
            "E_IS_SCOPE: 0.0006340489980968916\n",
            "E_IS_E_SCOPE: 0.0006338501625595316\n",
            "Total Loss: 0.012923794501371766\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1096972935346874\n",
            "E_s_wdiff_all_sq: 0.09732649816710795\n",
            "E_IS_SCOPE: 0.0006212014605605339\n",
            "E_IS_E_SCOPE: 0.0006209148108541839\n",
            "Total Loss: 0.0123724937900586\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(0.0118, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.10252623230531457\n",
            "E_s_wdiff_all_sq: 0.09072406962516637\n",
            "E_IS_SCOPE: 0.0006067578276412343\n",
            "E_IS_E_SCOPE: 0.0006063956278411918\n",
            "Total Loss: 0.011804012202814726\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.09518493309471086\n",
            "E_s_wdiff_all_sq: 0.08395227224210194\n",
            "E_IS_SCOPE: 0.0005908899110144122\n",
            "E_IS_E_SCOPE: 0.000590480234134969\n",
            "Total Loss: 0.011234605329434252\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08782738884762503\n",
            "E_s_wdiff_all_sq: 0.07714970917994547\n",
            "E_IS_SCOPE: 0.0005739173614441375\n",
            "E_IS_E_SCOPE: 0.0005734855168339148\n",
            "Total Loss: 0.010679668479966445\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08060641426730712\n",
            "E_s_wdiff_all_sq: 0.07045594499066074\n",
            "E_IS_SCOPE: 0.0005562252990201838\n",
            "E_IS_E_SCOPE: 0.0005557820754269913\n",
            "Total Loss: 0.010152480846899209\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.07364903217570176\n",
            "E_s_wdiff_all_sq: 0.06398550181581818\n",
            "E_IS_SCOPE: 0.0005381594140114158\n",
            "E_IS_E_SCOPE: 0.0005377216179733293\n",
            "Total Loss: 0.009665531075026199\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06704607140190602\n",
            "E_s_wdiff_all_sq: 0.05782829374240399\n",
            "E_IS_SCOPE: 0.0005199532597512808\n",
            "E_IS_E_SCOPE: 0.0005195431840519399\n",
            "Total Loss: 0.009219722933967153\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.060851631021386174\n",
            "E_s_wdiff_all_sq: 0.05203656550846089\n",
            "E_IS_SCOPE: 0.000502085730377354\n",
            "E_IS_E_SCOPE: 0.0005017274120744586\n",
            "Total Loss: 0.008816907272597513\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.05510726665927724\n",
            "E_s_wdiff_all_sq: 0.04664912441505664\n",
            "E_IS_SCOPE: 0.00048455651652294857\n",
            "E_IS_E_SCOPE: 0.0004842669450594438\n",
            "Total Loss: 0.008459846510214038\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.049831324978314114\n",
            "E_s_wdiff_all_sq: 0.04168616634026927\n",
            "E_IS_SCOPE: 0.00046755531116912365\n",
            "E_IS_E_SCOPE: 0.00046734959222684416\n",
            "Total Loss: 0.008146695198995843\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.04503345527054377\n",
            "E_s_wdiff_all_sq: 0.03716105902878415\n",
            "E_IS_SCOPE: 0.00045124032058162873\n",
            "E_IS_E_SCOPE: 0.0004511306204056378\n",
            "Total Loss: 0.007873740765178036\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.04071917518708896\n",
            "E_s_wdiff_all_sq: 0.03308456189465976\n",
            "E_IS_SCOPE: 0.00043581185807951286\n",
            "E_IS_E_SCOPE: 0.0004358086535694071\n",
            "Total Loss: 0.007635744824515844\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.03687006603934186\n",
            "E_s_wdiff_all_sq: 0.029443166531977115\n",
            "E_IS_SCOPE: 0.0004214204415014725\n",
            "E_IS_E_SCOPE: 0.00042152940818290015\n",
            "Total Loss: 0.007427806697068329\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.033460296592982684\n",
            "E_s_wdiff_all_sq: 0.02621689535377135\n",
            "E_IS_SCOPE: 0.0004082326325838883\n",
            "E_IS_E_SCOPE: 0.0004084567745120869\n",
            "Total Loss: 0.007244078078421368\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.030459607790362223\n",
            "E_s_wdiff_all_sq: 0.023381532383757595\n",
            "E_IS_SCOPE: 0.00039621202771657524\n",
            "E_IS_E_SCOPE: 0.0003965527631215214\n",
            "Total Loss: 0.007078519058861168\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.027835388209585983\n",
            "E_s_wdiff_all_sq: 0.02090933692266301\n",
            "E_IS_SCOPE: 0.00038540490218007115\n",
            "E_IS_E_SCOPE: 0.00038586771904216925\n",
            "Total Loss: 0.00692625077626521\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.025545132524872154\n",
            "E_s_wdiff_all_sq: 0.018763323201636768\n",
            "E_IS_SCOPE: 0.00037579562476641916\n",
            "E_IS_E_SCOPE: 0.0003763782920297131\n",
            "Total Loss: 0.006781769111775231\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.02355787177510137\n",
            "E_s_wdiff_all_sq: 0.01691637330059643\n",
            "E_IS_SCOPE: 0.0003674201354001065\n",
            "E_IS_E_SCOPE: 0.000368117680158597\n",
            "Total Loss: 0.006641228508054389\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.021846839033319552\n",
            "E_s_wdiff_all_sq: 0.015344033075692128\n",
            "E_IS_SCOPE: 0.00036034068433630633\n",
            "E_IS_E_SCOPE: 0.0003611462890959928\n",
            "Total Loss: 0.006502319871174481\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.020369553692523922\n",
            "E_s_wdiff_all_sq: 0.014006469277111222\n",
            "E_IS_SCOPE: 0.0003544335485147866\n",
            "E_IS_E_SCOPE: 0.00035534056112929396\n",
            "Total Loss: 0.006362395513250121\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.019092600218665632\n",
            "E_s_wdiff_all_sq: 0.012871232531858904\n",
            "E_IS_SCOPE: 0.00034959583577815856\n",
            "E_IS_E_SCOPE: 0.0003505972058056035\n",
            "Total Loss: 0.006220490069818271\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.018002808908375863\n",
            "E_s_wdiff_all_sq: 0.011924113588473402\n",
            "E_IS_SCOPE: 0.00034592659780299356\n",
            "E_IS_E_SCOPE: 0.00034701325275206024\n",
            "Total Loss: 0.006077647133070758\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.01707463186836262\n",
            "E_s_wdiff_all_sq: 0.011139150281763922\n",
            "E_IS_SCOPE: 0.0003433335062096914\n",
            "E_IS_E_SCOPE: 0.0003444944901438544\n",
            "Total Loss: 0.005934284741796806\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.016282250721570263\n",
            "E_s_wdiff_all_sq: 0.010490793715210762\n",
            "E_IS_SCOPE: 0.00034170493809580033\n",
            "E_IS_E_SCOPE: 0.0003429311883867716\n",
            "Total Loss: 0.0057901296288439905\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.01558309286996791\n",
            "E_s_wdiff_all_sq: 0.009938476752041252\n",
            "E_IS_SCOPE: 0.00034075441941519346\n",
            "E_IS_E_SCOPE: 0.0003420406410002784\n",
            "Total Loss: 0.005643168797822919\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.015090695900328887\n",
            "E_s_wdiff_all_sq: 0.009615755479097293\n",
            "E_IS_SCOPE: 0.0003429535444466902\n",
            "E_IS_E_SCOPE: 0.00034429713652351485\n",
            "Total Loss: 0.005473378360144377\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.014697834342306877\n",
            "E_s_wdiff_all_sq: 0.009381531354162219\n",
            "E_IS_SCOPE: 0.00034606412319170953\n",
            "E_IS_E_SCOPE: 0.00034746095853127335\n",
            "Total Loss: 0.005314634440531964\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.014373973727138906\n",
            "E_s_wdiff_all_sq: 0.009201950018571837\n",
            "E_IS_SCOPE: 0.00034971756923699395\n",
            "E_IS_E_SCOPE: 0.00035116255284229513\n",
            "Total Loss: 0.005170258864422902\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.01409473514687836\n",
            "E_s_wdiff_all_sq: 0.009048892901178116\n",
            "E_IS_SCOPE: 0.0003536149744808655\n",
            "E_IS_E_SCOPE: 0.0003551019443809888\n",
            "Total Loss: 0.005043993428966434\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.013844683245555796\n",
            "E_s_wdiff_all_sq: 0.008905398021757603\n",
            "E_IS_SCOPE: 0.0003574008598681113\n",
            "E_IS_E_SCOPE: 0.0003589207347105837\n",
            "Total Loss: 0.004937370597179682\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0136024923157964\n",
            "E_s_wdiff_all_sq: 0.008751282402029412\n",
            "E_IS_SCOPE: 0.0003608091371339045\n",
            "E_IS_E_SCOPE: 0.000362352782027908\n",
            "Total Loss: 0.004849247747045414\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.013331931607751812\n",
            "E_s_wdiff_all_sq: 0.008554041833265148\n",
            "E_IS_SCOPE: 0.0003636140482961245\n",
            "E_IS_E_SCOPE: 0.00036517285300706064\n",
            "Total Loss: 0.004775897288131227\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.01292204805659021\n",
            "E_s_wdiff_all_sq: 0.008209413258973466\n",
            "E_IS_SCOPE: 0.00036435521875047814\n",
            "E_IS_E_SCOPE: 0.00036592023246146793\n",
            "Total Loss: 0.0047106298932611985\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.012327187384937299\n",
            "E_s_wdiff_all_sq: 0.007679449670478537\n",
            "E_IS_SCOPE: 0.0003624026869585557\n",
            "E_IS_E_SCOPE: 0.00036397083698921413\n",
            "Total Loss: 0.00464572653746388\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.011641767619024567\n",
            "E_s_wdiff_all_sq: 0.00705998507561085\n",
            "E_IS_SCOPE: 0.00035888770717816104\n",
            "E_IS_E_SCOPE: 0.00036045640906800776\n",
            "Total Loss: 0.004579770262700456\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.010916261344749137\n",
            "E_s_wdiff_all_sq: 0.006399280207747667\n",
            "E_IS_SCOPE: 0.0003543615660858103\n",
            "E_IS_E_SCOPE: 0.0003559322248064307\n",
            "Total Loss: 0.004514964942626661\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.010219151949191846\n",
            "E_s_wdiff_all_sq: 0.005762754166968863\n",
            "E_IS_SCOPE: 0.0003494868092154718\n",
            "E_IS_E_SCOPE: 0.00035105574482906086\n",
            "Total Loss: 0.004454385034062238\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.009585241391823618\n",
            "E_s_wdiff_all_sq: 0.0051866963524843475\n",
            "E_IS_SCOPE: 0.0003446939023859514\n",
            "E_IS_E_SCOPE: 0.0003462545518829453\n",
            "Total Loss: 0.004396548863411716\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.009027924701307628\n",
            "E_s_wdiff_all_sq: 0.004685912756500788\n",
            "E_IS_SCOPE: 0.0003402441280326053\n",
            "E_IS_E_SCOPE: 0.00034179103438031357\n",
            "Total Loss: 0.004340043255177856\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.008563846343288727\n",
            "E_s_wdiff_all_sq: 0.004277002180948894\n",
            "E_IS_SCOPE: 0.00033652777190890657\n",
            "E_IS_E_SCOPE: 0.0003380564628114167\n",
            "Total Loss: 0.004284911903601247\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.008208273690172383\n",
            "E_s_wdiff_all_sq: 0.00397884934966099\n",
            "E_IS_SCOPE: 0.0003340195999925944\n",
            "E_IS_E_SCOPE: 0.0003355286676491658\n",
            "Total Loss: 0.004227531328264683\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.00793515347682762\n",
            "E_s_wdiff_all_sq: 0.003763588789927591\n",
            "E_IS_SCOPE: 0.0003324583675959316\n",
            "E_IS_E_SCOPE: 0.0003339468754733705\n",
            "Total Loss: 0.004169712794211584\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0077082143960846596\n",
            "E_s_wdiff_all_sq: 0.0035916048577938455\n",
            "E_IS_SCOPE: 0.00033128913762055944\n",
            "E_IS_E_SCOPE: 0.0003327560192033841\n",
            "Total Loss: 0.004114800898191599\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.007484704253024982\n",
            "E_s_wdiff_all_sq: 0.0034185809933272968\n",
            "E_IS_SCOPE: 0.0003297735813530524\n",
            "E_IS_E_SCOPE: 0.00033122212415713\n",
            "Total Loss: 0.0040643512971559655\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.007240860558559237\n",
            "E_s_wdiff_all_sq: 0.0032240777326951408\n",
            "E_IS_SCOPE: 0.00032757962855704006\n",
            "E_IS_E_SCOPE: 0.00032900978012682155\n",
            "Total Loss: 0.004015047645790967\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.006979422630294758\n",
            "E_s_wdiff_all_sq: 0.003011557741644556\n",
            "E_IS_SCOPE: 0.00032470660126135225\n",
            "E_IS_E_SCOPE: 0.0003261184027025264\n",
            "Total Loss: 0.003966166408834288\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0067113177758735135\n",
            "E_s_wdiff_all_sq: 0.002791524054462898\n",
            "E_IS_SCOPE: 0.0003213424476694919\n",
            "E_IS_E_SCOPE: 0.0003227340950860501\n",
            "Total Loss: 0.003918135549643933\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.006447835233454535\n",
            "E_s_wdiff_all_sq: 0.002574821444572861\n",
            "E_IS_SCOPE: 0.0003176922755539199\n",
            "E_IS_E_SCOPE: 0.00031906497919659195\n",
            "Total Loss: 0.0038713935046627637\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.006201877607733952\n",
            "E_s_wdiff_all_sq: 0.002373963574160789\n",
            "E_IS_SCOPE: 0.00031401918317040806\n",
            "E_IS_E_SCOPE: 0.00031537497107917215\n",
            "Total Loss: 0.0038263275808220693\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005987797994605537\n",
            "E_s_wdiff_all_sq: 0.002203578956221644\n",
            "E_IS_SCOPE: 0.0003107420342818258\n",
            "E_IS_E_SCOPE: 0.00031206575049514535\n",
            "Total Loss: 0.003782696729023688\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005810721025780044\n",
            "E_s_wdiff_all_sq: 0.0020691189464985722\n",
            "E_IS_SCOPE: 0.0003080571836583361\n",
            "E_IS_E_SCOPE: 0.00030933903392561714\n",
            "Total Loss: 0.003740163501813344\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005664955034010021\n",
            "E_s_wdiff_all_sq: 0.0019647691901534506\n",
            "E_IS_SCOPE: 0.00030591240445649844\n",
            "E_IS_E_SCOPE: 0.00030715569746104024\n",
            "Total Loss: 0.0036988243809139205\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005546839543450366\n",
            "E_s_wdiff_all_sq: 0.0018863713403155912\n",
            "E_IS_SCOPE: 0.0003042651210074962\n",
            "E_IS_E_SCOPE: 0.00030547451648233094\n",
            "Total Loss: 0.0036591745352515387\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.00544364099782422\n",
            "E_s_wdiff_all_sq: 0.0018219545909874935\n",
            "E_IS_SCOPE: 0.00030293586066468085\n",
            "E_IS_E_SCOPE: 0.0003041171705437067\n",
            "Total Loss: 0.003620448910145109\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005331150909892116\n",
            "E_s_wdiff_all_sq: 0.0017471589767959744\n",
            "E_IS_SCOPE: 0.0003012430029190858\n",
            "E_IS_E_SCOPE: 0.00030239329117806097\n",
            "Total Loss: 0.003582816479644625\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005154437889830231\n",
            "E_s_wdiff_all_sq: 0.0016051010872319726\n",
            "E_IS_SCOPE: 0.0002974528424718552\n",
            "E_IS_E_SCOPE: 0.0002985652004955169\n",
            "Total Loss: 0.003548237209617368\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0049899532274222955\n",
            "E_s_wdiff_all_sq: 0.0014736694193556\n",
            "E_IS_SCOPE: 0.0002938946021185957\n",
            "E_IS_E_SCOPE: 0.00029496819040062034\n",
            "Total Loss: 0.0035152617545690804\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004837414959578078\n",
            "E_s_wdiff_all_sq: 0.0013528547022474363\n",
            "E_IS_SCOPE: 0.0002905792268313363\n",
            "E_IS_E_SCOPE: 0.0002916200009191387\n",
            "Total Loss: 0.0034836038322214715\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004697623319309264\n",
            "E_s_wdiff_all_sq: 0.001243785452595476\n",
            "E_IS_SCOPE: 0.0002875304751435228\n",
            "E_IS_E_SCOPE: 0.0002885454813812173\n",
            "Total Loss: 0.003452932977304833\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004570785512760991\n",
            "E_s_wdiff_all_sq: 0.0011470071604600682\n",
            "E_IS_SCOPE: 0.0002848759470677444\n",
            "E_IS_E_SCOPE: 0.0002858716066256076\n",
            "Total Loss: 0.0034229121562516307\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004456341276362587\n",
            "E_s_wdiff_all_sq: 0.0010622647678557515\n",
            "E_IS_SCOPE: 0.00028254493938619223\n",
            "E_IS_E_SCOPE: 0.0002835272934322516\n",
            "Total Loss: 0.003393236923481151\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004353356020422386\n",
            "E_s_wdiff_all_sq: 0.0009888186723630997\n",
            "E_IS_SCOPE: 0.0002805295590759807\n",
            "E_IS_E_SCOPE: 0.00028150463152687866\n",
            "Total Loss: 0.003363712326223924\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004261752359474844\n",
            "E_s_wdiff_all_sq: 0.0009263055687244455\n",
            "E_IS_SCOPE: 0.0002788551115124601\n",
            "E_IS_E_SCOPE: 0.0002798291567532099\n",
            "Total Loss: 0.0033346238233353323\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004181557094295289\n",
            "E_s_wdiff_all_sq: 0.0008745929968227259\n",
            "E_IS_SCOPE: 0.0002775429446410165\n",
            "E_IS_E_SCOPE: 0.0002785195681194593\n",
            "Total Loss: 0.003306135973582112\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004109885719853463\n",
            "E_s_wdiff_all_sq: 0.0008312354798769383\n",
            "E_IS_SCOPE: 0.0002765063688131618\n",
            "E_IS_E_SCOPE: 0.0002774887063359298\n",
            "Total Loss: 0.003277810687997423\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004045104316372374\n",
            "E_s_wdiff_all_sq: 0.0007944505461247694\n",
            "E_IS_SCOPE: 0.0002757004696401811\n",
            "E_IS_E_SCOPE: 0.00027669159817488964\n",
            "Total Loss: 0.0032497966362446218\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.003985727607939652\n",
            "E_s_wdiff_all_sq: 0.0007626242429272893\n",
            "E_IS_SCOPE: 0.00027503963035422984\n",
            "E_IS_E_SCOPE: 0.00027604184943446855\n",
            "Total Loss: 0.0032222240499183196\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.003929667385998214\n",
            "E_s_wdiff_all_sq: 0.0007332116937730933\n",
            "E_IS_SCOPE: 0.000274446027611878\n",
            "E_IS_E_SCOPE: 0.00027546078784154384\n",
            "Total Loss: 0.003195551294832223\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0038766636658137585\n",
            "E_s_wdiff_all_sq: 0.0007062275085991669\n",
            "E_IS_SCOPE: 0.0002739092519125207\n",
            "E_IS_E_SCOPE: 0.0002749363678194191\n",
            "Total Loss: 0.0031695070484672287\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.2165,  0.1824],\n",
            "        [ 0.1057, -0.4369],\n",
            "        [-0.5297, -0.2837],\n",
            "        [ 0.2928,  0.3621],\n",
            "        [ 0.1498,  0.2231],\n",
            "        [ 0.5104, -0.4407],\n",
            "        [-0.3571,  0.2021],\n",
            "        [ 0.3101, -0.2008],\n",
            "        [-0.4288, -0.6201],\n",
            "        [-0.2209,  0.4062],\n",
            "        [-0.0940, -0.2111],\n",
            "        [-0.6620,  0.0024],\n",
            "        [ 0.1370, -0.5095],\n",
            "        [ 0.0414, -0.1268],\n",
            "        [-0.3401,  0.3611],\n",
            "        [ 0.4502,  0.4955]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.2590, -0.6539,  0.5999,  0.3264, -0.5191, -0.5932,  0.4432,  0.5988,\n",
            "        -0.1064, -0.0684,  0.0274, -0.4292, -0.7034,  0.1701, -0.1496, -0.2422],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1202,  0.1017, -0.0671, -0.1920,  0.1667,  0.3111,  0.0579, -0.1307,\n",
            "         -0.0131,  0.1041,  0.0329,  0.0436,  0.1578, -0.0170,  0.1095, -0.0599],\n",
            "        [-0.1380, -0.1483, -0.0294,  0.1491,  0.0353,  0.2037, -0.2511, -0.0186,\n",
            "          0.2349, -0.1940, -0.1982, -0.0407,  0.0064,  0.1178, -0.1044,  0.0981],\n",
            "        [ 0.2382,  0.1787, -0.0535, -0.1045,  0.0170,  0.2594,  0.1312, -0.1223,\n",
            "          0.0542, -0.1201, -0.0913, -0.0708,  0.0291, -0.0487,  0.0570, -0.1241],\n",
            "        [-0.0135,  0.0455, -0.1060, -0.1504,  0.0138,  0.0873,  0.1123,  0.1736,\n",
            "          0.1834,  0.0853,  0.1525,  0.1261,  0.1738,  0.1884,  0.1928, -0.1363],\n",
            "        [-0.1803, -0.1873,  0.0862,  0.0773, -0.1843,  0.2415, -0.1996,  0.1837,\n",
            "         -0.2287,  0.1907, -0.1608,  0.2066,  0.0172, -0.1272,  0.0143, -0.1417],\n",
            "        [-0.0671, -0.0873,  0.0118, -0.1958,  0.2151,  0.0347,  0.0332, -0.0912,\n",
            "         -0.2390, -0.2059,  0.2041, -0.2481, -0.0043, -0.2861,  0.1089,  0.2244],\n",
            "        [ 0.2249,  0.0813,  0.0149, -0.0385, -0.1740,  0.0409, -0.0838, -0.0093,\n",
            "         -0.2258, -0.0588,  0.2057,  0.0686,  0.1960, -0.0102, -0.0433,  0.0287],\n",
            "        [-0.1031, -0.1352,  0.0706,  0.2149,  0.0172, -0.1802, -0.2364,  0.0867,\n",
            "         -0.0941, -0.1533, -0.1061,  0.0900, -0.2077,  0.1008,  0.0029,  0.2143],\n",
            "        [ 0.1085, -0.0489, -0.1435, -0.0561,  0.0481,  0.1679,  0.1764, -0.1277,\n",
            "         -0.0971,  0.1566, -0.0940, -0.1636, -0.0375,  0.2488,  0.0376,  0.2310],\n",
            "        [-0.0662,  0.1713,  0.0006,  0.1844,  0.1895,  0.1986, -0.1038, -0.0559,\n",
            "          0.0507,  0.1294,  0.0306,  0.0647,  0.0835,  0.1939, -0.0121,  0.1681],\n",
            "        [ 0.1259, -0.0591, -0.2146, -0.1027, -0.0133, -0.0636,  0.1477,  0.1800,\n",
            "          0.0874,  0.1531,  0.0031, -0.2016,  0.0920, -0.2103,  0.0736, -0.0006],\n",
            "        [-0.2557, -0.1778,  0.0629,  0.0686, -0.2381,  0.1940, -0.1716, -0.1980,\n",
            "         -0.1985, -0.2137,  0.2257, -0.1361,  0.1222,  0.0494, -0.1675, -0.2158],\n",
            "        [-0.0831,  0.0709, -0.2017,  0.1086,  0.2124,  0.2201,  0.1749,  0.0725,\n",
            "         -0.0886,  0.2134,  0.0917,  0.1350,  0.1253, -0.0431,  0.0416,  0.2141],\n",
            "        [ 0.1291,  0.1348, -0.0498, -0.0741, -0.0627, -0.1251,  0.0767,  0.0613,\n",
            "         -0.1886,  0.0893, -0.2180, -0.0019, -0.1196, -0.0314, -0.0155,  0.1899],\n",
            "        [ 0.0418, -0.1517,  0.1819,  0.2133, -0.1023,  0.1967, -0.0569, -0.0994,\n",
            "         -0.0923, -0.0759,  0.1433,  0.0491,  0.1204, -0.1128,  0.0287, -0.2167],\n",
            "        [ 0.1818,  0.0141,  0.0982, -0.2132, -0.1249, -0.2748,  0.1027,  0.1993,\n",
            "          0.2049,  0.1003, -0.0117, -0.1837, -0.1601, -0.1306,  0.0420,  0.0473],\n",
            "        [-0.1893,  0.1670, -0.0325,  0.0084,  0.0246, -0.2045, -0.1985, -0.2100,\n",
            "          0.1194, -0.0222,  0.1009, -0.1538,  0.0808, -0.2470, -0.2145, -0.1102],\n",
            "        [ 0.2265,  0.2467,  0.1579,  0.1236, -0.1438, -0.0263,  0.0643, -0.0210,\n",
            "          0.2029, -0.1669,  0.0602, -0.1794,  0.1844,  0.0737,  0.0269, -0.1034],\n",
            "        [ 0.0244,  0.1083, -0.1823, -0.1257,  0.1370,  0.0381, -0.2375, -0.1633,\n",
            "         -0.2342,  0.1744,  0.1361, -0.0678,  0.2080, -0.0369, -0.0717,  0.0696],\n",
            "        [ 0.0070, -0.0064,  0.1709, -0.1914, -0.0066, -0.0036,  0.2500,  0.0034,\n",
            "         -0.1030, -0.1479, -0.0270, -0.2493,  0.0753, -0.0549, -0.1489, -0.1326],\n",
            "        [ 0.1943,  0.0679, -0.1120, -0.0876, -0.0412, -0.0796,  0.1821, -0.1811,\n",
            "         -0.2178, -0.1067,  0.0504,  0.2030,  0.1255, -0.0341,  0.1828, -0.0382],\n",
            "        [-0.2438, -0.2035, -0.0571,  0.0196,  0.1096, -0.1511,  0.0509, -0.1182,\n",
            "          0.0824, -0.1235,  0.1599,  0.1151, -0.2014, -0.0329, -0.1739, -0.0421],\n",
            "        [ 0.1567, -0.0499,  0.0880,  0.1795, -0.1368,  0.1184, -0.0163,  0.1732,\n",
            "         -0.1810, -0.0677, -0.0673, -0.0921, -0.1717, -0.2367,  0.1916, -0.0703],\n",
            "        [-0.0100, -0.1186,  0.0913,  0.2278, -0.0373,  0.1041, -0.2132, -0.1803,\n",
            "          0.0094, -0.0009,  0.0199,  0.2156,  0.0105, -0.0507,  0.2145,  0.2152],\n",
            "        [-0.1629, -0.2352, -0.2190,  0.1469,  0.1291, -0.1240, -0.0518, -0.1249,\n",
            "          0.0364, -0.0430,  0.2295, -0.0597, -0.1776,  0.0244,  0.2391, -0.2482],\n",
            "        [ 0.2557,  0.2339, -0.1477, -0.1718,  0.0093,  0.2345,  0.1637,  0.0214,\n",
            "          0.2231,  0.1529, -0.1756, -0.0229,  0.1534, -0.0598, -0.1096,  0.0333],\n",
            "        [ 0.1075, -0.0298,  0.1039,  0.0664,  0.0033, -0.2526,  0.1169,  0.1375,\n",
            "          0.1352,  0.1272,  0.0224,  0.0716,  0.0222,  0.1534,  0.1167,  0.0998],\n",
            "        [-0.0343,  0.2046, -0.1392,  0.1667,  0.0116, -0.1618, -0.2364,  0.1483,\n",
            "         -0.1424,  0.0375, -0.0719,  0.2118,  0.1254, -0.0958,  0.1509, -0.0903],\n",
            "        [-0.0219,  0.1919, -0.0056, -0.2381,  0.1627, -0.1609,  0.1913,  0.0217,\n",
            "          0.0185,  0.1205,  0.1241, -0.0141,  0.0497, -0.1412,  0.1221, -0.1867],\n",
            "        [ 0.2151,  0.1289,  0.0829,  0.0079,  0.2351,  0.0492,  0.1064,  0.1604,\n",
            "         -0.1835, -0.0360, -0.0151,  0.2104, -0.0305,  0.0426, -0.2075,  0.1820],\n",
            "        [ 0.1390, -0.1827, -0.1759,  0.0495, -0.0013,  0.2123, -0.2250,  0.0587,\n",
            "         -0.0550,  0.0887, -0.1730, -0.1354, -0.0049,  0.2302,  0.0661,  0.1076],\n",
            "        [ 0.2383,  0.2018, -0.1136, -0.0514,  0.0956,  0.1789, -0.1448,  0.1936,\n",
            "         -0.0237, -0.1457, -0.1746,  0.2433,  0.0124, -0.1484, -0.1188, -0.1749]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.2075,  0.1655, -0.1337,  0.0393, -0.2189,  0.1552,  0.1827,  0.1205,\n",
            "         0.1333,  0.0004,  0.2323, -0.0712, -0.1063,  0.2275, -0.1184,  0.0257,\n",
            "        -0.0581, -0.2027, -0.2404, -0.1763, -0.1866,  0.0307,  0.1148, -0.2608,\n",
            "        -0.1526,  0.1085,  0.1814, -0.0485,  0.0756,  0.1581,  0.0018, -0.0322],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.0186, -0.0070, -0.1887, -0.0950,  0.0555,  0.0622, -0.0112,  0.0093,\n",
            "          0.0879, -0.1263,  0.0234,  0.1382,  0.0836, -0.0946, -0.0569, -0.0216,\n",
            "          0.1726, -0.1004,  0.1597, -0.2557, -0.1109,  0.0019,  0.1491, -0.0992,\n",
            "         -0.2216,  0.1503, -0.0702,  0.0411,  0.0430, -0.1156,  0.0589, -0.1216]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0430], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P_pi_b[tuple(np.append(pi_b[0]['state'][0].astype(int) , (pi_b[0]['action'][0],)))]"
      ],
      "metadata": {
        "id": "5WwYv6SGDudT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padded_timesteps, padded_rewards, padded_actions, padded_weights = testing.padding_IS_terms(timesteps, actions, rewards, weights)"
      ],
      "metadata": {
        "id": "dmpbvgzDRSlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padded_states, padded_weights_difference = testing.padding_states_weights_difference(states, weights_difference)\n",
        "# padded_state_tensors, padded_weight_diff_tensors = testing.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "# states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = testing.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "# IS_tensor = testing.calc_IS_terms(testing.gamma, padded_timesteps, padded_rewards, padded_weights)"
      ],
      "metadata": {
        "id": "x68IJ4fcRYjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# states_output, states_first_output, states_last_output = testing.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "# sums_states_weight_diff = testing.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "\n",
        "# gamma_weights_last_tensor = testing.calc_gamma_weight_last(testing.gamma, gamma_last, weights_last)\n",
        "\n",
        "# gamma_weights_states_last_sub_states_first = testing.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n"
      ],
      "metadata": {
        "id": "JTJBak1Gco7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "XBOko5a3I0y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 200 trajectories"
      ],
      "metadata": {
        "id": "mP1Eorc7oaMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "200 Trajectories:"
      ],
      "metadata": {
        "id": "QWksRYNyI5dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(200, env, P_pi_e)"
      ],
      "metadata": {
        "id": "v4PMaoImI8LA"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "gdGaF6NLJKVS"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "vjYDF_4AJ2_j"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor, padded_psi_tensors = testing.prepare()"
      ],
      "metadata": {
        "id": "pCRa5GCXJrrs"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teSV103bOKaS",
        "outputId": "1133c192-5639-4d21-b6a2-3aa3382d5dbd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_state_tensors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE22rR57LvzK",
        "outputId": "026da6cc-301e-42ed-ff6c-ce437f5486d4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 57, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_psi_tensors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnuRjTX6Lyb_",
        "outputId": "2d96d539-6f5f-4600-d791-1269352e326c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 57, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single cumprod\n",
        "# 200 trajectories\n",
        "model_200_1 = train_var_play(model_200_1, 500, 0.0001, padded_state_tensors, states_first_tensor, states_last_tensor, testing, padded_psi_tensors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W1dMNu9G2LG",
        "outputId": "b07c235c-6e11-4758-b854-5f40431b7cfd"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 98\n",
            "Var loss:  tensor(6.2778e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009383571082722341\n",
            "E_s_wdiff_all_sq: 0.009289674042755717\n",
            "E_IS_SCOPE: 0.001785029969612453\n",
            "E_IS_E_SCOPE: 0.0018375627848776293\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34424533069732405\n",
            "Total Loss: 6.277805687392515e-06\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(6.2362e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009368495620192527\n",
            "E_s_wdiff_all_sq: 0.009274645718051349\n",
            "E_IS_SCOPE: 0.0017848133331227394\n",
            "E_IS_E_SCOPE: 0.00183734337090667\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34420422612358426\n",
            "Total Loss: 6.236222824437462e-06\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(6.1969e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009360945036109458\n",
            "E_s_wdiff_all_sq: 0.009267120823810825\n",
            "E_IS_SCOPE: 0.0017847700082442935\n",
            "E_IS_E_SCOPE: 0.001837306864448513\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3441973870768511\n",
            "Total Loss: 6.196896141313912e-06\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(6.1539e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009363025257094228\n",
            "E_s_wdiff_all_sq: 0.009269213990982012\n",
            "E_IS_SCOPE: 0.001784935297604006\n",
            "E_IS_E_SCOPE: 0.0018374871543841743\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34423116223220035\n",
            "Total Loss: 6.15394880299977e-06\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(6.1127e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009366010409938962\n",
            "E_s_wdiff_all_sq: 0.009272202868480904\n",
            "E_IS_SCOPE: 0.0017850731197965569\n",
            "E_IS_E_SCOPE: 0.0018376437549996027\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3442604994777569\n",
            "Total Loss: 6.112667303086877e-06\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(6.0698e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009359604466942608\n",
            "E_s_wdiff_all_sq: 0.009265807912080594\n",
            "E_IS_SCOPE: 0.0017849230975220034\n",
            "E_IS_E_SCOPE: 0.0018375096944568696\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3442353848442617\n",
            "Total Loss: 6.069757243402571e-06\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(6.0251e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00934259672424159\n",
            "E_s_wdiff_all_sq: 0.009248820104601397\n",
            "E_IS_SCOPE: 0.0017845140690121951\n",
            "E_IS_E_SCOPE: 0.0018371130074394714\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3441610702931555\n",
            "Total Loss: 6.025139036762786e-06\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(5.9831e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00932395079617028\n",
            "E_s_wdiff_all_sq: 0.009230238574507443\n",
            "E_IS_SCOPE: 0.0017841605418835104\n",
            "E_IS_E_SCOPE: 0.0018367482766935702\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34409274236592957\n",
            "Total Loss: 5.98314829383835e-06\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(5.9404e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009312712350103005\n",
            "E_s_wdiff_all_sq: 0.00921905736318536\n",
            "E_IS_SCOPE: 0.0017840457111673348\n",
            "E_IS_E_SCOPE: 0.0018366261864944265\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440698702326207\n",
            "Total Loss: 5.940432514582594e-06\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(5.8971e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009308850114894138\n",
            "E_s_wdiff_all_sq: 0.009215243867744936\n",
            "E_IS_SCOPE: 0.0017841280206620344\n",
            "E_IS_E_SCOPE: 0.0018367057920543046\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440847833787244\n",
            "Total Loss: 5.8971006157808314e-06\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(5.8546e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009305936223940022\n",
            "E_s_wdiff_all_sq: 0.009212368467695256\n",
            "E_IS_SCOPE: 0.0017842126868294016\n",
            "E_IS_E_SCOPE: 0.0018367924637922813\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3441010202884765\n",
            "Total Loss: 5.854598570127073e-06\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(5.8099e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009299282400303102\n",
            "E_s_wdiff_all_sq: 0.009205748129247477\n",
            "E_IS_SCOPE: 0.0017841569283820462\n",
            "E_IS_E_SCOPE: 0.0018367423111898852\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34409162480042066\n",
            "Total Loss: 5.8099016910680146e-06\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(5.7615e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009291508123617058\n",
            "E_s_wdiff_all_sq: 0.009198004183006616\n",
            "E_IS_SCOPE: 0.0017840203562163432\n",
            "E_IS_E_SCOPE: 0.0018366147704037944\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.344067731565073\n",
            "Total Loss: 5.761508486658989e-06\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(5.7131e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009287930929968621\n",
            "E_s_wdiff_all_sq: 0.009194449661672028\n",
            "E_IS_SCOPE: 0.0017840007019051705\n",
            "E_IS_E_SCOPE: 0.0018366079661623434\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34406645687211135\n",
            "Total Loss: 5.713136033367802e-06\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(5.6625e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009288432339012987\n",
            "E_s_wdiff_all_sq: 0.009194970992523846\n",
            "E_IS_SCOPE: 0.0017840945391720596\n",
            "E_IS_E_SCOPE: 0.0018367171433042063\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440869098991396\n",
            "Total Loss: 5.66253447596872e-06\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(5.6114e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009287985250700456\n",
            "E_s_wdiff_all_sq: 0.009194551245769384\n",
            "E_IS_SCOPE: 0.0017841306714669613\n",
            "E_IS_E_SCOPE: 0.0018367651941352057\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440959116455527\n",
            "Total Loss: 5.611355845702715e-06\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(5.5592e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00928120905458305\n",
            "E_s_wdiff_all_sq: 0.00918781601807634\n",
            "E_IS_SCOPE: 0.001783978817048467\n",
            "E_IS_E_SCOPE: 0.0018366189327294336\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440685113268193\n",
            "Total Loss: 5.559201395896954e-06\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(5.5067e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009269204270580369\n",
            "E_s_wdiff_all_sq: 0.009175864426165938\n",
            "E_IS_SCOPE: 0.001783682449376732\n",
            "E_IS_E_SCOPE: 0.0018363222153383967\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440129248852339\n",
            "Total Loss: 5.506708742221769e-06\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(5.4543e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009258170348751059\n",
            "E_s_wdiff_all_sq: 0.009164931381326045\n",
            "E_IS_SCOPE: 0.0017835178569946296\n",
            "E_IS_E_SCOPE: 0.0018361333827855934\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3439775493731038\n",
            "Total Loss: 5.454312094208338e-06\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(5.4016e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009253599267570791\n",
            "E_s_wdiff_all_sq: 0.009160448867502117\n",
            "E_IS_SCOPE: 0.0017835628154402386\n",
            "E_IS_E_SCOPE: 0.0018361604173257663\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3439826139696981\n",
            "Total Loss: 5.401592548741341e-06\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(5.3486e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009253815606906274\n",
            "E_s_wdiff_all_sq: 0.009160731818456539\n",
            "E_IS_SCOPE: 0.0017837472267697159\n",
            "E_IS_E_SCOPE: 0.0018363380279739947\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34401588719270737\n",
            "Total Loss: 5.348582292298218e-06\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(5.2955e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009253692797357806\n",
            "E_s_wdiff_all_sq: 0.009160659708851085\n",
            "E_IS_SCOPE: 0.0017838875423185734\n",
            "E_IS_E_SCOPE: 0.0018364795254136475\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34404239503957224\n",
            "Total Loss: 5.295518567692906e-06\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(5.2417e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009249331384516305\n",
            "E_s_wdiff_all_sq: 0.009156336686816735\n",
            "E_IS_SCOPE: 0.0017838697022224774\n",
            "E_IS_E_SCOPE: 0.0018364693797825028\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440404943773596\n",
            "Total Loss: 5.241738830642079e-06\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(5.1881e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009242880116004633\n",
            "E_s_wdiff_all_sq: 0.009149913167458392\n",
            "E_IS_SCOPE: 0.0017837686027390852\n",
            "E_IS_E_SCOPE: 0.0018363812152176631\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34402397780441374\n",
            "Total Loss: 5.188119840206923e-06\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(5.1344e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0092386744020426\n",
            "E_s_wdiff_all_sq: 0.009145728370371592\n",
            "E_IS_SCOPE: 0.0017837037906995143\n",
            "E_IS_E_SCOPE: 0.001836332823521221\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440149122009515\n",
            "Total Loss: 5.1343622787143606e-06\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(5.0832e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009237058951724192\n",
            "E_s_wdiff_all_sq: 0.00914413229329442\n",
            "E_IS_SCOPE: 0.0017836939353323238\n",
            "E_IS_E_SCOPE: 0.0018363388740574383\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34401604569628463\n",
            "Total Loss: 5.083177230663649e-06\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(5.0286e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009236511882257806\n",
            "E_s_wdiff_all_sq: 0.009143652314139165\n",
            "E_IS_SCOPE: 0.0017835244985301372\n",
            "E_IS_E_SCOPE: 0.00183616318100436\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343983131711709\n",
            "Total Loss: 5.028599421317073e-06\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(4.9774e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009231132653658335\n",
            "E_s_wdiff_all_sq: 0.009138379788002807\n",
            "E_IS_SCOPE: 0.0017833964182485573\n",
            "E_IS_E_SCOPE: 0.001836007372796983\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34395394291428927\n",
            "Total Loss: 4.977352809796762e-06\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(4.9252e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009223537220911996\n",
            "E_s_wdiff_all_sq: 0.009130876538771248\n",
            "E_IS_SCOPE: 0.0017833243349957293\n",
            "E_IS_E_SCOPE: 0.0018359152528746516\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3439366853525952\n",
            "Total Loss: 4.925242634025093e-06\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(4.8715e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009219039156152511\n",
            "E_s_wdiff_all_sq: 0.009126450622153027\n",
            "E_IS_SCOPE: 0.0017833853589984256\n",
            "E_IS_E_SCOPE: 0.0018359670677773213\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343946392252654\n",
            "Total Loss: 4.871512692815327e-06\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(4.8173e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009219207534459373\n",
            "E_s_wdiff_all_sq: 0.009126665840484119\n",
            "E_IS_SCOPE: 0.0017835865147942122\n",
            "E_IS_E_SCOPE: 0.0018361719183555968\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3439847685495851\n",
            "Total Loss: 4.817283103605505e-06\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(4.7643e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009220461286251452\n",
            "E_s_wdiff_all_sq: 0.009127943003358716\n",
            "E_IS_SCOPE: 0.0017837930434871894\n",
            "E_IS_E_SCOPE: 0.0018363932309722831\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440262288118116\n",
            "Total Loss: 4.764304173669742e-06\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(4.7119e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009218331706576289\n",
            "E_s_wdiff_all_sq: 0.009125822962976185\n",
            "E_IS_SCOPE: 0.0017838521870812618\n",
            "E_IS_E_SCOPE: 0.001836473815304763\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440413253192136\n",
            "Total Loss: 4.7118834042222946e-06\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(4.6590e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00921209000924848\n",
            "E_s_wdiff_all_sq: 0.009119588044753943\n",
            "E_IS_SCOPE: 0.0017837340647686392\n",
            "E_IS_E_SCOPE: 0.0018363787341115368\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3440235129989628\n",
            "Total Loss: 4.6590220598614895e-06\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(4.6058e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009203620783599086\n",
            "E_s_wdiff_all_sq: 0.009111129508525604\n",
            "E_IS_SCOPE: 0.0017835510243128325\n",
            "E_IS_E_SCOPE: 0.001836216952872947\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34399320522584215\n",
            "Total Loss: 4.605814204373601e-06\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(4.5527e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009195162472196648\n",
            "E_s_wdiff_all_sq: 0.009102696115874689\n",
            "E_IS_SCOPE: 0.0017833960374146777\n",
            "E_IS_E_SCOPE: 0.001836076044846409\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34396680779844935\n",
            "Total Loss: 4.552737709617033e-06\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(4.5000e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009185938929843636\n",
            "E_s_wdiff_all_sq: 0.009093553656396322\n",
            "E_IS_SCOPE: 0.0017833340685332747\n",
            "E_IS_E_SCOPE: 0.001835999919762175\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34395254667767994\n",
            "Total Loss: 4.499967240634631e-06\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(4.4483e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009175596377581113\n",
            "E_s_wdiff_all_sq: 0.009083299939972212\n",
            "E_IS_SCOPE: 0.0017832554076497797\n",
            "E_IS_E_SCOPE: 0.0018359026841117565\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34393433074573504\n",
            "Total Loss: 4.448280936068458e-06\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(4.3966e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009166173492317225\n",
            "E_s_wdiff_all_sq: 0.00907396484473834\n",
            "E_IS_SCOPE: 0.001783210531577409\n",
            "E_IS_E_SCOPE: 0.001835839736585513\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3439225382822793\n",
            "Total Loss: 4.396633813798581e-06\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(4.3446e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009158726816115122\n",
            "E_s_wdiff_all_sq: 0.00906659379311913\n",
            "E_IS_SCOPE: 0.0017832070853927157\n",
            "E_IS_E_SCOPE: 0.0018358244947961073\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34391968291598785\n",
            "Total Loss: 4.344600440329277e-06\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(4.2928e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009155512328339228\n",
            "E_s_wdiff_all_sq: 0.009063435420048836\n",
            "E_IS_SCOPE: 0.0017832692304776772\n",
            "E_IS_E_SCOPE: 0.0018358844924824269\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343930922762342\n",
            "Total Loss: 4.292780532015247e-06\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(4.2409e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009154638402985688\n",
            "E_s_wdiff_all_sq: 0.009062596026792465\n",
            "E_IS_SCOPE: 0.001783366867273774\n",
            "E_IS_E_SCOPE: 0.0018359908024894126\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34395083866606646\n",
            "Total Loss: 4.24090201306751e-06\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(4.1892e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009152730209009904\n",
            "E_s_wdiff_all_sq: 0.009060705494532539\n",
            "E_IS_SCOPE: 0.0017833916104616602\n",
            "E_IS_E_SCOPE: 0.001836032579305208\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3439586650510408\n",
            "Total Loss: 4.189173041391908e-06\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(4.1374e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009148676210074268\n",
            "E_s_wdiff_all_sq: 0.009056662038052691\n",
            "E_IS_SCOPE: 0.0017832901328218064\n",
            "E_IS_E_SCOPE: 0.0018359516944442468\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34394351224323516\n",
            "Total Loss: 4.13744502781796e-06\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(4.0865e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009143456690960866\n",
            "E_s_wdiff_all_sq: 0.009051453387535725\n",
            "E_IS_SCOPE: 0.001783118589725615\n",
            "E_IS_E_SCOPE: 0.0018358001811068446\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34391512803815205\n",
            "Total Loss: 4.08651691380206e-06\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(4.0356e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009140132750923308\n",
            "E_s_wdiff_all_sq: 0.009048187848556636\n",
            "E_IS_SCOPE: 0.0017827513155011137\n",
            "E_IS_E_SCOPE: 0.0018354291683505563\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3438456232516857\n",
            "Total Loss: 4.035592918909606e-06\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(3.9874e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009136400662390909\n",
            "E_s_wdiff_all_sq: 0.009044551860044731\n",
            "E_IS_SCOPE: 0.0017825687198246307\n",
            "E_IS_E_SCOPE: 0.0018352226309650637\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34380693095167\n",
            "Total Loss: 3.987376316433311e-06\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(3.9372e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009131875014197937\n",
            "E_s_wdiff_all_sq: 0.009040112212887832\n",
            "E_IS_SCOPE: 0.0017825276577735692\n",
            "E_IS_E_SCOPE: 0.001835163674339452\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3437958861355431\n",
            "Total Loss: 3.937164429460363e-06\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(3.8844e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009128253982905591\n",
            "E_s_wdiff_all_sq: 0.009036563788222112\n",
            "E_IS_SCOPE: 0.0017826042318345287\n",
            "E_IS_E_SCOPE: 0.0018352303027313022\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3438083681649873\n",
            "Total Loss: 3.884449141053348e-06\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(3.8319e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009126050757177219\n",
            "E_s_wdiff_all_sq: 0.009034414375637756\n",
            "E_IS_SCOPE: 0.0017827649711865405\n",
            "E_IS_E_SCOPE: 0.0018353904199803143\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3438383642096341\n",
            "Total Loss: 3.831880203034738e-06\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(3.7814e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009124761347077582\n",
            "E_s_wdiff_all_sq: 0.009033152067831111\n",
            "E_IS_SCOPE: 0.0017829353594028866\n",
            "E_IS_E_SCOPE: 0.0018355725066000407\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3438724759521765\n",
            "Total Loss: 3.7813811032821887e-06\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(3.7314e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009122344592087044\n",
            "E_s_wdiff_all_sq: 0.009030742555870556\n",
            "E_IS_SCOPE: 0.0017830148983309037\n",
            "E_IS_E_SCOPE: 0.001835673426202136\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34389138202824804\n",
            "Total Loss: 3.731376725144009e-06\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(3.6798e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00911435086559857\n",
            "E_s_wdiff_all_sq: 0.009022749322966482\n",
            "E_IS_SCOPE: 0.0017829421056326457\n",
            "E_IS_E_SCOPE: 0.0018356261838376408\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3438825317383301\n",
            "Total Loss: 3.6797824732193868e-06\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(3.6276e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009101465215508924\n",
            "E_s_wdiff_all_sq: 0.009009865856618034\n",
            "E_IS_SCOPE: 0.0017827388579029434\n",
            "E_IS_E_SCOPE: 0.0018354479557256256\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3438491428408921\n",
            "Total Loss: 3.6275594966460323e-06\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(3.5765e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00908677520800212\n",
            "E_s_wdiff_all_sq: 0.008995192281922016\n",
            "E_IS_SCOPE: 0.0017824838257432542\n",
            "E_IS_E_SCOPE: 0.0018352102147720021\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34380460492693676\n",
            "Total Loss: 3.5765442737284436e-06\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(3.5265e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00907178050964831\n",
            "E_s_wdiff_all_sq: 0.008980273882510915\n",
            "E_IS_SCOPE: 0.0017823097268065552\n",
            "E_IS_E_SCOPE: 0.001835022996868604\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3437695318999914\n",
            "Total Loss: 3.5264832644182897e-06\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(3.4765e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009058340405152914\n",
            "E_s_wdiff_all_sq: 0.008966920049878393\n",
            "E_IS_SCOPE: 0.0017822081613907842\n",
            "E_IS_E_SCOPE: 0.001834903272084837\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3437471028988603\n",
            "Total Loss: 3.4765301375368207e-06\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(3.4259e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009045858944950014\n",
            "E_s_wdiff_all_sq: 0.008954523798593756\n",
            "E_IS_SCOPE: 0.0017822003033714836\n",
            "E_IS_E_SCOPE: 0.0018348781065443132\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34374238843691585\n",
            "Total Loss: 3.4259362617205386e-06\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(3.3752e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009035636661129477\n",
            "E_s_wdiff_all_sq: 0.008944378001582563\n",
            "E_IS_SCOPE: 0.0017822303154204932\n",
            "E_IS_E_SCOPE: 0.0018348952497786197\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3437456000160856\n",
            "Total Loss: 3.3751870817805285e-06\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(3.3250e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009027462265004161\n",
            "E_s_wdiff_all_sq: 0.00893626003327846\n",
            "E_IS_SCOPE: 0.0017823038764468357\n",
            "E_IS_E_SCOPE: 0.001834965715160263\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3437588008595105\n",
            "Total Loss: 3.324950549969327e-06\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(3.2753e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.009021160374995011\n",
            "E_s_wdiff_all_sq: 0.008929996136415156\n",
            "E_IS_SCOPE: 0.0017823360820017151\n",
            "E_IS_E_SCOPE: 0.0018350037648961687\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3437659290208052\n",
            "Total Loss: 3.2752690420686376e-06\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(3.2250e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00901459389544659\n",
            "E_s_wdiff_all_sq: 0.00892345619857794\n",
            "E_IS_SCOPE: 0.0017822720917779306\n",
            "E_IS_E_SCOPE: 0.001834951661213483\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3437561680212768\n",
            "Total Loss: 3.2249542486657845e-06\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(3.1742e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00900683435563299\n",
            "E_s_wdiff_all_sq: 0.008915717440592604\n",
            "E_IS_SCOPE: 0.0017821006513087866\n",
            "E_IS_E_SCOPE: 0.0018347952144678677\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3437268596013827\n",
            "Total Loss: 3.1741849733438188e-06\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(3.1241e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008999422699715879\n",
            "E_s_wdiff_all_sq: 0.008908320479732891\n",
            "E_IS_SCOPE: 0.0017819233438053602\n",
            "E_IS_E_SCOPE: 0.0018346356240908906\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3436969622598874\n",
            "Total Loss: 3.124055663049005e-06\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(3.0739e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008992259876669285\n",
            "E_s_wdiff_all_sq: 0.008901214020571651\n",
            "E_IS_SCOPE: 0.0017818235205366115\n",
            "E_IS_E_SCOPE: 0.0018345326898516305\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3436776787657256\n",
            "Total Loss: 3.0739137187162785e-06\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(3.0248e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008986245735143134\n",
            "E_s_wdiff_all_sq: 0.008895253653795985\n",
            "E_IS_SCOPE: 0.0017817431562261016\n",
            "E_IS_E_SCOPE: 0.0018344500029070787\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34366218835919043\n",
            "Total Loss: 3.024784236315553e-06\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(2.9754e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008980695029732555\n",
            "E_s_wdiff_all_sq: 0.00888975295523448\n",
            "E_IS_SCOPE: 0.001781695854206232\n",
            "E_IS_E_SCOPE: 0.0018344023684296641\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34365326461162377\n",
            "Total Loss: 2.9754423023307247e-06\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(2.9259e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008975416249447784\n",
            "E_s_wdiff_all_sq: 0.00888451850773491\n",
            "E_IS_SCOPE: 0.0017816792903663245\n",
            "E_IS_E_SCOPE: 0.0018343884342337886\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3436506542072846\n",
            "Total Loss: 2.92585022906508e-06\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(2.8777e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008970092742691118\n",
            "E_s_wdiff_all_sq: 0.008879230960626542\n",
            "E_IS_SCOPE: 0.0017816667995737025\n",
            "E_IS_E_SCOPE: 0.001834382033965227\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3436494551937947\n",
            "Total Loss: 2.8777095326480012e-06\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(2.8289e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008966378718163682\n",
            "E_s_wdiff_all_sq: 0.008875543343875159\n",
            "E_IS_SCOPE: 0.0017814117632335312\n",
            "E_IS_E_SCOPE: 0.0018341381947522535\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34360377484415017\n",
            "Total Loss: 2.8289075021999815e-06\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(2.7812e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008961063674176895\n",
            "E_s_wdiff_all_sq: 0.008870291188828372\n",
            "E_IS_SCOPE: 0.0017812895236631562\n",
            "E_IS_E_SCOPE: 0.0018340083407862656\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34357944826231485\n",
            "Total Loss: 2.7812473534245125e-06\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(2.7328e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008953937614957516\n",
            "E_s_wdiff_all_sq: 0.008863226104856991\n",
            "E_IS_SCOPE: 0.0017812094873510527\n",
            "E_IS_E_SCOPE: 0.0018339220576266406\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34356328414805265\n",
            "Total Loss: 2.732765800469994e-06\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(2.6818e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008948550241780021\n",
            "E_s_wdiff_all_sq: 0.008857890444313338\n",
            "E_IS_SCOPE: 0.0017812337858427888\n",
            "E_IS_E_SCOPE: 0.0018339460003022235\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34356776952092893\n",
            "Total Loss: 2.6817647989351573e-06\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(2.6292e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008944987674978904\n",
            "E_s_wdiff_all_sq: 0.008854370117359133\n",
            "E_IS_SCOPE: 0.0017813341677753306\n",
            "E_IS_E_SCOPE: 0.001834051566583235\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34358754609651937\n",
            "Total Loss: 2.6291562550840447e-06\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(2.5765e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00894064797374307\n",
            "E_s_wdiff_all_sq: 0.008850062313934986\n",
            "E_IS_SCOPE: 0.0017813885088042915\n",
            "E_IS_E_SCOPE: 0.0018341162643822418\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34359966645256806\n",
            "Total Loss: 2.5765449033036958e-06\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(2.5236e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008933330137578582\n",
            "E_s_wdiff_all_sq: 0.008842771579405386\n",
            "E_IS_SCOPE: 0.0017813926737810174\n",
            "E_IS_E_SCOPE: 0.0018341333736037588\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34360287165985\n",
            "Total Loss: 2.5235547788347856e-06\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(2.4689e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008923828242950169\n",
            "E_s_wdiff_all_sq: 0.008833334305646643\n",
            "E_IS_SCOPE: 0.0017814021936153985\n",
            "E_IS_E_SCOPE: 0.0018341379196772744\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34360372331215466\n",
            "Total Loss: 2.468881430893813e-06\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(2.4144e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008912921238166852\n",
            "E_s_wdiff_all_sq: 0.008822489483405341\n",
            "E_IS_SCOPE: 0.0017813421784978135\n",
            "E_IS_E_SCOPE: 0.001834074043767096\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3435917569271125\n",
            "Total Loss: 2.4144204740662173e-06\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(2.3603e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0089023997063973\n",
            "E_s_wdiff_all_sq: 0.008812022171301642\n",
            "E_IS_SCOPE: 0.0017812597931446796\n",
            "E_IS_E_SCOPE: 0.0018339915880948945\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34357630984667614\n",
            "Total Loss: 2.3603414463502226e-06\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(2.3064e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008891800995042491\n",
            "E_s_wdiff_all_sq: 0.008801512153287451\n",
            "E_IS_SCOPE: 0.0017812170386853413\n",
            "E_IS_E_SCOPE: 0.0018339314473130818\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343565043193099\n",
            "Total Loss: 2.306420750679619e-06\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(2.2517e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00888225483037711\n",
            "E_s_wdiff_all_sq: 0.008792041291801727\n",
            "E_IS_SCOPE: 0.0017811830492913607\n",
            "E_IS_E_SCOPE: 0.00183388718123157\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3435567504740724\n",
            "Total Loss: 2.251670946085138e-06\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(2.1962e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008874037736083676\n",
            "E_s_wdiff_all_sq: 0.008783879395000381\n",
            "E_IS_SCOPE: 0.001781198122002323\n",
            "E_IS_E_SCOPE: 0.0018339023980149707\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343559601155789\n",
            "Total Loss: 2.1961853091199274e-06\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(2.1407e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008867541263993486\n",
            "E_s_wdiff_all_sq: 0.008777426184520215\n",
            "E_IS_SCOPE: 0.0017812232864775246\n",
            "E_IS_E_SCOPE: 0.0018339336703306766\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34356545964876156\n",
            "Total Loss: 2.140708018088036e-06\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(2.0860e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008862805970923354\n",
            "E_s_wdiff_all_sq: 0.008772726332992255\n",
            "E_IS_SCOPE: 0.0017812376967726272\n",
            "E_IS_E_SCOPE: 0.0018339576969095097\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34356996073990465\n",
            "Total Loss: 2.086033908454271e-06\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(2.0299e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008858532644522545\n",
            "E_s_wdiff_all_sq: 0.008768520630942161\n",
            "E_IS_SCOPE: 0.0017812944927169546\n",
            "E_IS_E_SCOPE: 0.0018340087523112515\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34357952535658126\n",
            "Total Loss: 2.029890642910731e-06\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(1.9743e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00885349945665462\n",
            "E_s_wdiff_all_sq: 0.008763583152156019\n",
            "E_IS_SCOPE: 0.0017813127792395069\n",
            "E_IS_E_SCOPE: 0.001834006957589131\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3435791891369348\n",
            "Total Loss: 1.9743440504722126e-06\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(1.9200e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00884891271441582\n",
            "E_s_wdiff_all_sq: 0.008759068585332836\n",
            "E_IS_SCOPE: 0.001780955208787198\n",
            "E_IS_E_SCOPE: 0.0018336404950160352\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3435105367726718\n",
            "Total Loss: 1.91995287643007e-06\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "Var loss:  tensor(1.8671e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008842987938650237\n",
            "E_s_wdiff_all_sq: 0.00875319159179001\n",
            "E_IS_SCOPE: 0.0017806715961905984\n",
            "E_IS_E_SCOPE: 0.0018333593931426871\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34345787571088565\n",
            "Total Loss: 1.8671492071700713e-06\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "Var loss:  tensor(1.8112e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008838032782225854\n",
            "E_s_wdiff_all_sq: 0.008748271278738054\n",
            "E_IS_SCOPE: 0.0017805247363672436\n",
            "E_IS_E_SCOPE: 0.0018332230766612782\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434323384543585\n",
            "Total Loss: 1.811219150852847e-06\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "Var loss:  tensor(1.7532e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008834519219593478\n",
            "E_s_wdiff_all_sq: 0.008744782225894723\n",
            "E_IS_SCOPE: 0.001780533735087257\n",
            "E_IS_E_SCOPE: 0.0018332488402137092\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34343716494665555\n",
            "Total Loss: 1.7531796969710162e-06\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "Var loss:  tensor(1.6972e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008832085657785095\n",
            "E_s_wdiff_all_sq: 0.008742364383982694\n",
            "E_IS_SCOPE: 0.0017806466151478273\n",
            "E_IS_E_SCOPE: 0.0018333818356853664\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434620800518692\n",
            "Total Loss: 1.6972289784440014e-06\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "Var loss:  tensor(1.6419e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008828922510034854\n",
            "E_s_wdiff_all_sq: 0.008739258056938882\n",
            "E_IS_SCOPE: 0.001780822944662604\n",
            "E_IS_E_SCOPE: 0.0018335574260374826\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434949747966523\n",
            "Total Loss: 1.6418865973356206e-06\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "Var loss:  tensor(1.5861e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008821569499889218\n",
            "E_s_wdiff_all_sq: 0.008731991738178298\n",
            "E_IS_SCOPE: 0.0017809437433636318\n",
            "E_IS_E_SCOPE: 0.0018336627525692886\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3435147064581069\n",
            "Total Loss: 1.5861395507264786e-06\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "Var loss:  tensor(1.5285e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008809864027215494\n",
            "E_s_wdiff_all_sq: 0.008720353001437708\n",
            "E_IS_SCOPE: 0.0017809009518398636\n",
            "E_IS_E_SCOPE: 0.0018336154063518756\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3435058367125914\n",
            "Total Loss: 1.5285130048822704e-06\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "Var loss:  tensor(1.4703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008794655851988081\n",
            "E_s_wdiff_all_sq: 0.008705186805555555\n",
            "E_IS_SCOPE: 0.0017806862637734003\n",
            "E_IS_E_SCOPE: 0.0018334088143323892\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434671341775527\n",
            "Total Loss: 1.4703415656697888e-06\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "Var loss:  tensor(1.4136e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008778650685637508\n",
            "E_s_wdiff_all_sq: 0.008689202049954372\n",
            "E_IS_SCOPE: 0.001780416489643882\n",
            "E_IS_E_SCOPE: 0.0018331572170587724\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34342000044836996\n",
            "Total Loss: 1.4135771044757744e-06\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "Var loss:  tensor(1.3575e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008764426292087247\n",
            "E_s_wdiff_all_sq: 0.008674983336060342\n",
            "E_IS_SCOPE: 0.001780204024568821\n",
            "E_IS_E_SCOPE: 0.0018329699586905359\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34338491984082287\n",
            "Total Loss: 1.3574840345958322e-06\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "Var loss:  tensor(1.3005e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008754450736180797\n",
            "E_s_wdiff_all_sq: 0.008665010926406091\n",
            "E_IS_SCOPE: 0.001780143856152955\n",
            "E_IS_E_SCOPE: 0.00183293669869575\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433786889800336\n",
            "Total Loss: 1.3005209402363466e-06\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "Var loss:  tensor(1.2426e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008747332761643214\n",
            "E_s_wdiff_all_sq: 0.008657937805769823\n",
            "E_IS_SCOPE: 0.0017802922933305143\n",
            "E_IS_E_SCOPE: 0.0018330916913162772\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434077249870469\n",
            "Total Loss: 1.2425561529850332e-06\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "Var loss:  tensor(1.1859e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00874090124662579\n",
            "E_s_wdiff_all_sq: 0.008651594048874113\n",
            "E_IS_SCOPE: 0.0017805129540726789\n",
            "E_IS_E_SCOPE: 0.0018332968152083655\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434461524860401\n",
            "Total Loss: 1.1858717314256612e-06\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "Var loss:  tensor(1.1301e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008733143387648409\n",
            "E_s_wdiff_all_sq: 0.008643912274337213\n",
            "E_IS_SCOPE: 0.0017806654654883352\n",
            "E_IS_E_SCOPE: 0.001833439159991717\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434728190725759\n",
            "Total Loss: 1.1301205555536153e-06\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "Var loss:  tensor(1.0736e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00872430492253159\n",
            "E_s_wdiff_all_sq: 0.008635135304819642\n",
            "E_IS_SCOPE: 0.0017806715705164962\n",
            "E_IS_E_SCOPE: 0.001833442794286212\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34347349991402554\n",
            "Total Loss: 1.0735664236379006e-06\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "Var loss:  tensor(1.0157e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008715797280377972\n",
            "E_s_wdiff_all_sq: 0.008626669336308285\n",
            "E_IS_SCOPE: 0.0017805498145225264\n",
            "E_IS_E_SCOPE: 0.00183332912867937\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434522060269604\n",
            "Total Loss: 1.0157120071199732e-06\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "Var loss:  tensor(9.5786e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008707626065778825\n",
            "E_s_wdiff_all_sq: 0.008618523793705946\n",
            "E_IS_SCOPE: 0.0017803277647283771\n",
            "E_IS_E_SCOPE: 0.0018331231679614684\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434136217586959\n",
            "Total Loss: 9.578618578170994e-07\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "Var loss:  tensor(9.0128e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008699971151975136\n",
            "E_s_wdiff_all_sq: 0.00861088392358996\n",
            "E_IS_SCOPE: 0.0017801296137917588\n",
            "E_IS_E_SCOPE: 0.0018329457867218785\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433803915126413\n",
            "Total Loss: 9.012787760588614e-07\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "Var loss:  tensor(8.4444e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008692711240466798\n",
            "E_s_wdiff_all_sq: 0.008603677911462618\n",
            "E_IS_SCOPE: 0.0017800626862235997\n",
            "E_IS_E_SCOPE: 0.0018328803269830399\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433681284163111\n",
            "Total Loss: 8.444437364207164e-07\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "Var loss:  tensor(7.8745e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008686187713978435\n",
            "E_s_wdiff_all_sq: 0.008597245554152476\n",
            "E_IS_SCOPE: 0.0017801024527997547\n",
            "E_IS_E_SCOPE: 0.0018329030051156714\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433723768922443\n",
            "Total Loss: 7.874514452478609e-07\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "Var loss:  tensor(7.3440e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008680401272840001\n",
            "E_s_wdiff_all_sq: 0.008591535875663405\n",
            "E_IS_SCOPE: 0.0017801781120305872\n",
            "E_IS_E_SCOPE: 0.0018329668090345235\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433843297905756\n",
            "Total Loss: 7.343994198431847e-07\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "Var loss:  tensor(6.7618e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008676147174881013\n",
            "E_s_wdiff_all_sq: 0.008587342232848927\n",
            "E_IS_SCOPE: 0.0017799507365310096\n",
            "E_IS_E_SCOPE: 0.0018327383134272653\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34334152388128597\n",
            "Total Loss: 6.76184490695092e-07\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "Var loss:  tensor(6.2088e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008671142777287219\n",
            "E_s_wdiff_all_sq: 0.008582386144609041\n",
            "E_IS_SCOPE: 0.0017798003568462366\n",
            "E_IS_E_SCOPE: 0.0018325914323729666\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343314007478839\n",
            "Total Loss: 6.208778758377831e-07\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "Var loss:  tensor(5.6385e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00866749076044314\n",
            "E_s_wdiff_all_sq: 0.00857876638113222\n",
            "E_IS_SCOPE: 0.0017798239565330577\n",
            "E_IS_E_SCOPE: 0.001832627421221103\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433207495575479\n",
            "Total Loss: 5.638461859514693e-07\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "Var loss:  tensor(5.0643e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008665521326460054\n",
            "E_s_wdiff_all_sq: 0.008576820181975843\n",
            "E_IS_SCOPE: 0.0017799681905530172\n",
            "E_IS_E_SCOPE: 0.0018327887479081357\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34335097217589045\n",
            "Total Loss: 5.064260250944863e-07\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "Var loss:  tensor(4.5061e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008662582012358502\n",
            "E_s_wdiff_all_sq: 0.008573896283163811\n",
            "E_IS_SCOPE: 0.001780153528087675\n",
            "E_IS_E_SCOPE: 0.0018329942845355745\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34338947699589734\n",
            "Total Loss: 4.5061255001151157e-07\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "Var loss:  tensor(3.9431e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008657014121131642\n",
            "E_s_wdiff_all_sq: 0.008568384293789482\n",
            "E_IS_SCOPE: 0.001780306058352933\n",
            "E_IS_E_SCOPE: 0.0018331470161873972\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434180894375632\n",
            "Total Loss: 3.943079243534653e-07\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "Var loss:  tensor(3.3743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008647492270243855\n",
            "E_s_wdiff_all_sq: 0.008558956501829938\n",
            "E_IS_SCOPE: 0.0017803759032003108\n",
            "E_IS_E_SCOPE: 0.0018331982726330625\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434276917174056\n",
            "Total Loss: 3.3742579953408014e-07\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "Var loss:  tensor(2.8026e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00863420942251381\n",
            "E_s_wdiff_all_sq: 0.008545751083044534\n",
            "E_IS_SCOPE: 0.001780340581521382\n",
            "E_IS_E_SCOPE: 0.0018331528176041517\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434191762633553\n",
            "Total Loss: 2.802635548602994e-07\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "Var loss:  tensor(2.2390e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00862073296766493\n",
            "E_s_wdiff_all_sq: 0.008532333352125946\n",
            "E_IS_SCOPE: 0.0017802589154294998\n",
            "E_IS_E_SCOPE: 0.0018330699714269468\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434036560264939\n",
            "Total Loss: 2.2389979521114656e-07\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "Var loss:  tensor(1.6805e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008608290736115324\n",
            "E_s_wdiff_all_sq: 0.00851992694620218\n",
            "E_IS_SCOPE: 0.0017802131106201189\n",
            "E_IS_E_SCOPE: 0.0018330341790296276\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433969507504876\n",
            "Total Loss: 1.6804934524841664e-07\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "Var loss:  tensor(1.1171e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008598342375334883\n",
            "E_s_wdiff_all_sq: 0.008510002862666613\n",
            "E_IS_SCOPE: 0.001780206416487636\n",
            "E_IS_E_SCOPE: 0.001833043518364564\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433987003627839\n",
            "Total Loss: 1.1170516553415943e-07\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "Var loss:  tensor(5.6485e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008590121093900782\n",
            "E_s_wdiff_all_sq: 0.008501800497343953\n",
            "E_IS_SCOPE: 0.0017802353908199257\n",
            "E_IS_E_SCOPE: 0.0018330906449551003\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434075289638403\n",
            "Total Loss: 5.648453760102867e-08\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "Var loss:  tensor(1.6587e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008584920142834076\n",
            "E_s_wdiff_all_sq: 0.00849665752436302\n",
            "E_IS_SCOPE: 0.00178003944498103\n",
            "E_IS_E_SCOPE: 0.0018328931230110594\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34337052559856435\n",
            "Total Loss: 1.6586621191111428e-09\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "Var loss:  tensor(-5.4364e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00858001733024621\n",
            "E_s_wdiff_all_sq: 0.008491856207844973\n",
            "E_IS_SCOPE: 0.0017799784888408894\n",
            "E_IS_E_SCOPE: 0.001832809430282401\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433548467704497\n",
            "Total Loss: -5.436423066579321e-08\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "Var loss:  tensor(-1.1045e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008576315921517206\n",
            "E_s_wdiff_all_sq: 0.008488240552640813\n",
            "E_IS_SCOPE: 0.0017800497021996777\n",
            "E_IS_E_SCOPE: 0.0018328658082347102\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433654085030862\n",
            "Total Loss: -1.1044694255175902e-07\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "Var loss:  tensor(-1.6615e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008573932554537879\n",
            "E_s_wdiff_all_sq: 0.008485918989849867\n",
            "E_IS_SCOPE: 0.0017802093521472493\n",
            "E_IS_E_SCOPE: 0.0018330224088275186\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433947457444052\n",
            "Total Loss: -1.6615242140645414e-07\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "Var loss:  tensor(-2.2083e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008571867030767856\n",
            "E_s_wdiff_all_sq: 0.008483894887585575\n",
            "E_IS_SCOPE: 0.0017803493927605381\n",
            "E_IS_E_SCOPE: 0.0018331690773339322\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434222223285572\n",
            "Total Loss: -2.208297133852316e-07\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "Var loss:  tensor(-2.7583e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008568708529734976\n",
            "E_s_wdiff_all_sq: 0.008480760031734645\n",
            "E_IS_SCOPE: 0.0017803980109685807\n",
            "E_IS_E_SCOPE: 0.0018332333728678643\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34343426732507265\n",
            "Total Loss: -2.758295471142619e-07\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "Var loss:  tensor(-3.3192e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008563283607438996\n",
            "E_s_wdiff_all_sq: 0.008475382616288963\n",
            "E_IS_SCOPE: 0.0017803633642240627\n",
            "E_IS_E_SCOPE: 0.001833203016839851\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434285804876007\n",
            "Total Loss: -3.3191783042202383e-07\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "Var loss:  tensor(-3.8746e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008555279640888596\n",
            "E_s_wdiff_all_sq: 0.008467407602789946\n",
            "E_IS_SCOPE: 0.0017802466587280743\n",
            "E_IS_E_SCOPE: 0.0018330996058261119\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434092076754632\n",
            "Total Loss: -3.8745984630439434e-07\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "Var loss:  tensor(-4.4225e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008544347585817617\n",
            "E_s_wdiff_all_sq: 0.008456529053201435\n",
            "E_IS_SCOPE: 0.0017801508045244211\n",
            "E_IS_E_SCOPE: 0.0018330043960577038\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34339137126819536\n",
            "Total Loss: -4.4225419926387233e-07\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "Var loss:  tensor(-4.9695e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008532576006523115\n",
            "E_s_wdiff_all_sq: 0.00844480130271189\n",
            "E_IS_SCOPE: 0.0017800672425794797\n",
            "E_IS_E_SCOPE: 0.001832926269230521\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433767351449123\n",
            "Total Loss: -4.969532397362808e-07\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "Var loss:  tensor(-5.5229e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008522702442187459\n",
            "E_s_wdiff_all_sq: 0.008434963640375276\n",
            "E_IS_SCOPE: 0.001780073069891457\n",
            "E_IS_E_SCOPE: 0.0018329418153857433\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34337964753048605\n",
            "Total Loss: -5.522929252699954e-07\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "Var loss:  tensor(-6.0739e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008515200731371169\n",
            "E_s_wdiff_all_sq: 0.008427486890624428\n",
            "E_IS_SCOPE: 0.0017801448511947128\n",
            "E_IS_E_SCOPE: 0.0018330286669676844\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34339591813184617\n",
            "Total Loss: -6.073945480813969e-07\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "Var loss:  tensor(-6.6283e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008508358168997816\n",
            "E_s_wdiff_all_sq: 0.008420705731698622\n",
            "E_IS_SCOPE: 0.0017802822321607156\n",
            "E_IS_E_SCOPE: 0.0018331630630870612\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434210956315975\n",
            "Total Loss: -6.628283023765724e-07\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "Var loss:  tensor(-7.1687e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008501050962837419\n",
            "E_s_wdiff_all_sq: 0.008413487599369837\n",
            "E_IS_SCOPE: 0.0017804098208178555\n",
            "E_IS_E_SCOPE: 0.001833273136716144\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34344171660474543\n",
            "Total Loss: -7.168720778747556e-07\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "Var loss:  tensor(-7.7126e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008493507426009335\n",
            "E_s_wdiff_all_sq: 0.008406008836769572\n",
            "E_IS_SCOPE: 0.0017804750253051368\n",
            "E_IS_E_SCOPE: 0.0018333331492708163\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34345295923650704\n",
            "Total Loss: -7.712624404757062e-07\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "Var loss:  tensor(-8.2654e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008484323895067081\n",
            "E_s_wdiff_all_sq: 0.008396866654918648\n",
            "E_IS_SCOPE: 0.0017804334553685101\n",
            "E_IS_E_SCOPE: 0.0018332985423660526\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343446476048301\n",
            "Total Loss: -8.265375955312376e-07\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "Var loss:  tensor(-8.8166e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00847358542986766\n",
            "E_s_wdiff_all_sq: 0.008386149983682069\n",
            "E_IS_SCOPE: 0.0017803130484069043\n",
            "E_IS_E_SCOPE: 0.0018331948011585174\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434270413783192\n",
            "Total Loss: -8.816630665160752e-07\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "Var loss:  tensor(-9.3287e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008463884131810174\n",
            "E_s_wdiff_all_sq: 0.008376461082872828\n",
            "E_IS_SCOPE: 0.001779853781532586\n",
            "E_IS_E_SCOPE: 0.0018327549397806472\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433446386290189\n",
            "Total Loss: -9.328713076565964e-07\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "Var loss:  tensor(-9.8337e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008458043982327306\n",
            "E_s_wdiff_all_sq: 0.008370635251827416\n",
            "E_IS_SCOPE: 0.0017796333664352787\n",
            "E_IS_E_SCOPE: 0.0018325526161351432\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34330673572261067\n",
            "Total Loss: -9.833726487187139e-07\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "Var loss:  tensor(-1.0407e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00845576835275359\n",
            "E_s_wdiff_all_sq: 0.008368426972087162\n",
            "E_IS_SCOPE: 0.0017797412918588275\n",
            "E_IS_E_SCOPE: 0.0018326555371795095\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433260167448675\n",
            "Total Loss: -1.0407137238169217e-06\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "Var loss:  tensor(-1.0981e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008456354470832024\n",
            "E_s_wdiff_all_sq: 0.008369116573456752\n",
            "E_IS_SCOPE: 0.0017800945449664687\n",
            "E_IS_E_SCOPE: 0.0018329857174368934\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343387872052794\n",
            "Total Loss: -1.0980513144576154e-06\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "Var loss:  tensor(-1.1502e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008454989792390157\n",
            "E_s_wdiff_all_sq: 0.008367835286464318\n",
            "E_IS_SCOPE: 0.0017804061457649635\n",
            "E_IS_E_SCOPE: 0.0018332816780575883\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434433167225397\n",
            "Total Loss: -1.1501624082900508e-06\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "Var loss:  tensor(-1.2021e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008450011786974885\n",
            "E_s_wdiff_all_sq: 0.008362914995449248\n",
            "E_IS_SCOPE: 0.0017805255070496766\n",
            "E_IS_E_SCOPE: 0.0018333981396464578\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34346513440327625\n",
            "Total Loss: -1.2020774168043646e-06\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "Var loss:  tensor(-1.2581e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00844051099174882\n",
            "E_s_wdiff_all_sq: 0.008353445903893149\n",
            "E_IS_SCOPE: 0.0017804348627618782\n",
            "E_IS_E_SCOPE: 0.0018333196775799975\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34345043547693854\n",
            "Total Loss: -1.2581455294449068e-06\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "Var loss:  tensor(-1.3154e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008426499663347005\n",
            "E_s_wdiff_all_sq: 0.008339444440896586\n",
            "E_IS_SCOPE: 0.001780166553596088\n",
            "E_IS_E_SCOPE: 0.001833075076695817\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34340461243733605\n",
            "Total Loss: -1.3154274979190056e-06\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "Var loss:  tensor(-1.3689e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008411476400477166\n",
            "E_s_wdiff_all_sq: 0.008324413636501262\n",
            "E_IS_SCOPE: 0.0017798827835081347\n",
            "E_IS_E_SCOPE: 0.0018328218149076645\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433571668813349\n",
            "Total Loss: -1.3689025720343279e-06\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "Var loss:  tensor(-1.4216e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008399301156985001\n",
            "E_s_wdiff_all_sq: 0.008312271954687332\n",
            "E_IS_SCOPE: 0.0017797867866599358\n",
            "E_IS_E_SCOPE: 0.001832735392986068\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34334097677168296\n",
            "Total Loss: -1.4216141034743834e-06\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "Var loss:  tensor(-1.4770e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008391149946744995\n",
            "E_s_wdiff_all_sq: 0.0083041983338018\n",
            "E_IS_SCOPE: 0.0017799335140493806\n",
            "E_IS_E_SCOPE: 0.0018328710260871834\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343366386005115\n",
            "Total Loss: -1.477014881288638e-06\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "Var loss:  tensor(-1.5328e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008384632550006524\n",
            "E_s_wdiff_all_sq: 0.00829775166259375\n",
            "E_IS_SCOPE: 0.001780160538067592\n",
            "E_IS_E_SCOPE: 0.0018330906033126237\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434075211626222\n",
            "Total Loss: -1.5328468261684852e-06\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "Var loss:  tensor(-1.5840e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008377577398165675\n",
            "E_s_wdiff_all_sq: 0.008290755430218266\n",
            "E_IS_SCOPE: 0.001780354445218564\n",
            "E_IS_E_SCOPE: 0.0018332806221637596\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434431189135052\n",
            "Total Loss: -1.5839896918608959e-06\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "Var loss:  tensor(-1.6418e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008371203686099012\n",
            "E_s_wdiff_all_sq: 0.008284425914201204\n",
            "E_IS_SCOPE: 0.0017801124893193538\n",
            "E_IS_E_SCOPE: 0.0018330454648254524\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34339906500886713\n",
            "Total Loss: -1.641782863269145e-06\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "Var loss:  tensor(-1.6951e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0083637665130413\n",
            "E_s_wdiff_all_sq: 0.008277014366054145\n",
            "E_IS_SCOPE: 0.0017798773121948113\n",
            "E_IS_E_SCOPE: 0.0018328241510316159\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433576045261157\n",
            "Total Loss: -1.695134435333867e-06\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "Var loss:  tensor(-1.7495e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00835717632822516\n",
            "E_s_wdiff_all_sq: 0.008270482589025373\n",
            "E_IS_SCOPE: 0.0017797698844133102\n",
            "E_IS_E_SCOPE: 0.001832714698119688\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34333709983687594\n",
            "Total Loss: -1.7494919618468024e-06\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "Var loss:  tensor(-1.8054e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008351876424473527\n",
            "E_s_wdiff_all_sq: 0.00826526649484918\n",
            "E_IS_SCOPE: 0.0017798332181661618\n",
            "E_IS_E_SCOPE: 0.0018327640904309246\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433463528935092\n",
            "Total Loss: -1.8054186540564232e-06\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "Var loss:  tensor(-1.8604e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008346991090903517\n",
            "E_s_wdiff_all_sq: 0.008260448384979342\n",
            "E_IS_SCOPE: 0.0017799374148490337\n",
            "E_IS_E_SCOPE: 0.0018328621539813901\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34336472392259026\n",
            "Total Loss: -1.8603760894176508e-06\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "Var loss:  tensor(-1.9153e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008341180013077527\n",
            "E_s_wdiff_all_sq: 0.008254685935630841\n",
            "E_IS_SCOPE: 0.0017800039492590865\n",
            "E_IS_E_SCOPE: 0.0018329318519710205\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34337778100433286\n",
            "Total Loss: -1.9153317260614533e-06\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "Var loss:  tensor(-1.9698e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00833248649831121\n",
            "E_s_wdiff_all_sq: 0.008246023389898055\n",
            "E_IS_SCOPE: 0.0017799526417491287\n",
            "E_IS_E_SCOPE: 0.0018328923031779554\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433703720126731\n",
            "Total Loss: -1.9698181933768683e-06\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "Var loss:  tensor(-2.0255e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008321269185735058\n",
            "E_s_wdiff_all_sq: 0.008234854245057927\n",
            "E_IS_SCOPE: 0.0017798727429491977\n",
            "E_IS_E_SCOPE: 0.0018328161795689226\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343356111168265\n",
            "Total Loss: -2.025536311197826e-06\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "Var loss:  tensor(-2.0813e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008308587810008348\n",
            "E_s_wdiff_all_sq: 0.008222236960108776\n",
            "E_IS_SCOPE: 0.0017797996920302093\n",
            "E_IS_E_SCOPE: 0.0018327389407090634\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433416413950013\n",
            "Total Loss: -2.081251207014523e-06\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "Var loss:  tensor(-2.1364e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008296530901531037\n",
            "E_s_wdiff_all_sq: 0.008210222046713586\n",
            "E_IS_SCOPE: 0.0017797049894485656\n",
            "E_IS_E_SCOPE: 0.0018326508118717288\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433251315151747\n",
            "Total Loss: -2.136393777753265e-06\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "Var loss:  tensor(-2.1919e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008286456238511776\n",
            "E_s_wdiff_all_sq: 0.008200169356626982\n",
            "E_IS_SCOPE: 0.0017796327382169157\n",
            "E_IS_E_SCOPE: 0.0018325953419066252\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433147398830422\n",
            "Total Loss: -2.191929243503671e-06\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "Var loss:  tensor(-2.2483e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008276208386988292\n",
            "E_s_wdiff_all_sq: 0.008189935470412179\n",
            "E_IS_SCOPE: 0.0017795864668281559\n",
            "E_IS_E_SCOPE: 0.0018325702910975614\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433100469146596\n",
            "Total Loss: -2.248335711576427e-06\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "Var loss:  tensor(-2.3040e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008267412395917306\n",
            "E_s_wdiff_all_sq: 0.008181151150657269\n",
            "E_IS_SCOPE: 0.0017795952634615062\n",
            "E_IS_E_SCOPE: 0.0018326010930319486\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433158172873383\n",
            "Total Loss: -2.304017629725652e-06\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "Var loss:  tensor(-2.3607e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008260952050360145\n",
            "E_s_wdiff_all_sq: 0.008174743597163412\n",
            "E_IS_SCOPE: 0.001779711398378043\n",
            "E_IS_E_SCOPE: 0.001832719192423639\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34333794179077415\n",
            "Total Loss: -2.3607386433390637e-06\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "Var loss:  tensor(-2.4163e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008255591887093882\n",
            "E_s_wdiff_all_sq: 0.008169464888587923\n",
            "E_IS_SCOPE: 0.0017798996641893562\n",
            "E_IS_E_SCOPE: 0.0018328944880668628\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433707813253838\n",
            "Total Loss: -2.4162529979332437e-06\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "Var loss:  tensor(-2.4729e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008250240445852588\n",
            "E_s_wdiff_all_sq: 0.008164176683734228\n",
            "E_IS_SCOPE: 0.001779687691684478\n",
            "E_IS_E_SCOPE: 0.001832679214919281\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34333045248519967\n",
            "Total Loss: -2.4728881001245817e-06\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "Var loss:  tensor(-2.5263e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008243525242756268\n",
            "E_s_wdiff_all_sq: 0.00815751454223933\n",
            "E_IS_SCOPE: 0.0017795110654970636\n",
            "E_IS_E_SCOPE: 0.0018325027868077856\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34329740079625287\n",
            "Total Loss: -2.5263458533833494e-06\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "Var loss:  tensor(-2.5838e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008237617507499176\n",
            "E_s_wdiff_all_sq: 0.0081516565851692\n",
            "E_IS_SCOPE: 0.001779481748665392\n",
            "E_IS_E_SCOPE: 0.0018324773039773983\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432926268938611\n",
            "Total Loss: -2.583792042916075e-06\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "Var loss:  tensor(-2.6423e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008233886542282189\n",
            "E_s_wdiff_all_sq: 0.008147967766730347\n",
            "E_IS_SCOPE: 0.001779607179941489\n",
            "E_IS_E_SCOPE: 0.0018326109361656662\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34331766128028895\n",
            "Total Loss: -2.6423406453909837e-06\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "Var loss:  tensor(-2.6950e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008229715768565557\n",
            "E_s_wdiff_all_sq: 0.008143853733027272\n",
            "E_IS_SCOPE: 0.0017798253948660932\n",
            "E_IS_E_SCOPE: 0.001832827088748658\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34335815487214083\n",
            "Total Loss: -2.6949559757231956e-06\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "Var loss:  tensor(-2.7527e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008230928356696662\n",
            "E_s_wdiff_all_sq: 0.008145115215879881\n",
            "E_IS_SCOPE: 0.0017801375875095117\n",
            "E_IS_E_SCOPE: 0.001833143689646527\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34341746625006103\n",
            "Total Loss: -2.7526672061288504e-06\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "Var loss:  tensor(-2.8089e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00822601654751343\n",
            "E_s_wdiff_all_sq: 0.008140235349173217\n",
            "E_IS_SCOPE: 0.0017802254441293918\n",
            "E_IS_E_SCOPE: 0.0018332437009144014\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34343620216061943\n",
            "Total Loss: -2.808918978686528e-06\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "Var loss:  tensor(-2.8672e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008215508769983037\n",
            "E_s_wdiff_all_sq: 0.008129792637889122\n",
            "E_IS_SCOPE: 0.001780141485006282\n",
            "E_IS_E_SCOPE: 0.0018331563355290263\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434198353043534\n",
            "Total Loss: -2.867172700453044e-06\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "Var loss:  tensor(-2.9234e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008201088615070174\n",
            "E_s_wdiff_all_sq: 0.008115428458319408\n",
            "E_IS_SCOPE: 0.0017799200027732852\n",
            "E_IS_E_SCOPE: 0.0018329349754276573\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34337836614644157\n",
            "Total Loss: -2.9233923068573003e-06\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "Var loss:  tensor(-2.9779e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00818748678187357\n",
            "E_s_wdiff_all_sq: 0.008101869106643107\n",
            "E_IS_SCOPE: 0.001779724441874546\n",
            "E_IS_E_SCOPE: 0.0018327454489371852\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433428606334189\n",
            "Total Loss: -2.9779426436952333e-06\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "Var loss:  tensor(-3.0348e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00817994028837786\n",
            "E_s_wdiff_all_sq: 0.008094385675284133\n",
            "E_IS_SCOPE: 0.001779806719551817\n",
            "E_IS_E_SCOPE: 0.0018328246191079904\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34335769221460594\n",
            "Total Loss: -3.0347897675003788e-06\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "Var loss:  tensor(-3.0922e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00817729098181544\n",
            "E_s_wdiff_all_sq: 0.008091778579919865\n",
            "E_IS_SCOPE: 0.0017800515221783313\n",
            "E_IS_E_SCOPE: 0.0018330770367045914\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434049796214531\n",
            "Total Loss: -3.0922309058236536e-06\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "Var loss:  tensor(-3.1478e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008174786828471024\n",
            "E_s_wdiff_all_sq: 0.008089301429326238\n",
            "E_IS_SCOPE: 0.0017802473938359714\n",
            "E_IS_E_SCOPE: 0.001833287202975697\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434443517496294\n",
            "Total Loss: -3.14782288354451e-06\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "Var loss:  tensor(-3.1972e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008168412512392623\n",
            "E_s_wdiff_all_sq: 0.00808298500026073\n",
            "E_IS_SCOPE: 0.0017803182850024708\n",
            "E_IS_E_SCOPE: 0.0018333538537207363\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434568379666752\n",
            "Total Loss: -3.19722905351566e-06\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "Var loss:  tensor(-3.2595e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008160713737998801\n",
            "E_s_wdiff_all_sq: 0.008075332938424206\n",
            "E_IS_SCOPE: 0.0017798568169118817\n",
            "E_IS_E_SCOPE: 0.001832900179950237\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433718476314118\n",
            "Total Loss: -3.2595302509944024e-06\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "Var loss:  tensor(-3.3125e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008154032598274751\n",
            "E_s_wdiff_all_sq: 0.008068688654079989\n",
            "E_IS_SCOPE: 0.0017794786627399212\n",
            "E_IS_E_SCOPE: 0.0018325300662699379\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34330251127604006\n",
            "Total Loss: -3.312466614150203e-06\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "Var loss:  tensor(-3.3676e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008151085516227254\n",
            "E_s_wdiff_all_sq: 0.008065812508197592\n",
            "E_IS_SCOPE: 0.0017793881305997342\n",
            "E_IS_E_SCOPE: 0.0018324316465728732\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432840735271686\n",
            "Total Loss: -3.3676276654948795e-06\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "Var loss:  tensor(-3.4248e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008151745149765202\n",
            "E_s_wdiff_all_sq: 0.008066526171110347\n",
            "E_IS_SCOPE: 0.0017795520771065512\n",
            "E_IS_E_SCOPE: 0.0018325971409502743\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34331507691227514\n",
            "Total Loss: -3.4247527814709744e-06\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "Var loss:  tensor(-3.4806e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00815345016281578\n",
            "E_s_wdiff_all_sq: 0.008068261027199767\n",
            "E_IS_SCOPE: 0.001779825564780132\n",
            "E_IS_E_SCOPE: 0.0018328836390005233\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34336874888303104\n",
            "Total Loss: -3.4806165736481903e-06\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "Var loss:  tensor(-3.5330e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008148489311141375\n",
            "E_s_wdiff_all_sq: 0.008063344174965814\n",
            "E_IS_SCOPE: 0.001779963043054823\n",
            "E_IS_E_SCOPE: 0.0018330253228286012\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34339529164753\n",
            "Total Loss: -3.5330271208749986e-06\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "Var loss:  tensor(-3.5890e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00814133676064295\n",
            "E_s_wdiff_all_sq: 0.008056228449283276\n",
            "E_IS_SCOPE: 0.001779966881734647\n",
            "E_IS_E_SCOPE: 0.0018330387512300462\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433978072973539\n",
            "Total Loss: -3.5890313800045204e-06\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "Var loss:  tensor(-3.6459e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008131910996502918\n",
            "E_s_wdiff_all_sq: 0.008046830107251985\n",
            "E_IS_SCOPE: 0.0017798320632823998\n",
            "E_IS_E_SCOPE: 0.0018329186733931386\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34337531215595474\n",
            "Total Loss: -3.645934719423427e-06\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "Var loss:  tensor(-3.7015e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008121068423027174\n",
            "E_s_wdiff_all_sq: 0.00803604364989349\n",
            "E_IS_SCOPE: 0.0017796826218474393\n",
            "E_IS_E_SCOPE: 0.0018327689485286025\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433472629997953\n",
            "Total Loss: -3.7014839775195707e-06\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "Var loss:  tensor(-3.7558e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008108283552240437\n",
            "E_s_wdiff_all_sq: 0.008023307300773731\n",
            "E_IS_SCOPE: 0.001779498636349489\n",
            "E_IS_E_SCOPE: 0.0018325878559495722\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433133374788454\n",
            "Total Loss: -3.755791482340856e-06\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "Var loss:  tensor(-3.8118e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008098039691657509\n",
            "E_s_wdiff_all_sq: 0.00801310494355316\n",
            "E_IS_SCOPE: 0.0017794262845662555\n",
            "E_IS_E_SCOPE: 0.0018325227694019515\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34330114429541025\n",
            "Total Loss: -3.8118253159209053e-06\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "Var loss:  tensor(-3.8691e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008094050032895837\n",
            "E_s_wdiff_all_sq: 0.008009180398217715\n",
            "E_IS_SCOPE: 0.001779599672657433\n",
            "E_IS_E_SCOPE: 0.001832692234882952\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433328916191093\n",
            "Total Loss: -3.86909352179457e-06\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "Var loss:  tensor(-3.9254e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008091633132730822\n",
            "E_s_wdiff_all_sq: 0.008006813250794985\n",
            "E_IS_SCOPE: 0.0017798412987875658\n",
            "E_IS_E_SCOPE: 0.001832937132042703\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433787701623836\n",
            "Total Loss: -3.92538832331632e-06\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "Var loss:  tensor(-3.9756e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008085300818983359\n",
            "E_s_wdiff_all_sq: 0.008000517582042848\n",
            "E_IS_SCOPE: 0.0017799424063233297\n",
            "E_IS_E_SCOPE: 0.0018330450367854449\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433989848207097\n",
            "Total Loss: -3.9756277325983524e-06\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "Var loss:  tensor(-4.0378e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008075412851277627\n",
            "E_s_wdiff_all_sq: 0.007990692710061979\n",
            "E_IS_SCOPE: 0.0017795541881105244\n",
            "E_IS_E_SCOPE: 0.0018326563615393323\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34332617117878517\n",
            "Total Loss: -4.037809390847885e-06\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "Var loss:  tensor(-4.0914e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00806699560467089\n",
            "E_s_wdiff_all_sq: 0.00798232460164554\n",
            "E_IS_SCOPE: 0.0017792502785936516\n",
            "E_IS_E_SCOPE: 0.0018323546931066788\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34326965721898234\n",
            "Total Loss: -4.091429749582612e-06\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "Var loss:  tensor(-4.1471e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00806269734463007\n",
            "E_s_wdiff_all_sq: 0.007978064323551463\n",
            "E_IS_SCOPE: 0.0017791560755939077\n",
            "E_IS_E_SCOPE: 0.001832269343663548\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34325366802529755\n",
            "Total Loss: -4.147118809553693e-06\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "Var loss:  tensor(-4.2052e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008060225203852939\n",
            "E_s_wdiff_all_sq: 0.007975659865152123\n",
            "E_IS_SCOPE: 0.0017792738304001935\n",
            "E_IS_E_SCOPE: 0.0018323823188781925\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34327483257567154\n",
            "Total Loss: -4.205242004061069e-06\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "Var loss:  tensor(-4.2616e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008057852050575479\n",
            "E_s_wdiff_all_sq: 0.00797334079563381\n",
            "E_IS_SCOPE: 0.0017794453656092923\n",
            "E_IS_E_SCOPE: 0.0018325549899737845\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433071804327859\n",
            "Total Loss: -4.261597536194331e-06\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "Var loss:  tensor(-4.3163e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008054727604000288\n",
            "E_s_wdiff_all_sq: 0.007970253907777922\n",
            "E_IS_SCOPE: 0.0017795649544377987\n",
            "E_IS_E_SCOPE: 0.001832683144392757\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34333118862488826\n",
            "Total Loss: -4.316287436429561e-06\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "Var loss:  tensor(-4.3728e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00804894938636798\n",
            "E_s_wdiff_all_sq: 0.007964538412027048\n",
            "E_IS_SCOPE: 0.0017795880296122522\n",
            "E_IS_E_SCOPE: 0.0018327031122542378\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34333492936405396\n",
            "Total Loss: -4.3727946919171895e-06\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "Var loss:  tensor(-4.4305e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008036757084467114\n",
            "E_s_wdiff_all_sq: 0.007952393016554548\n",
            "E_IS_SCOPE: 0.0017793972156282323\n",
            "E_IS_E_SCOPE: 0.0018325176992793543\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433001944688005\n",
            "Total Loss: -4.430503138558306e-06\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "Var loss:  tensor(-4.4869e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008022543990224545\n",
            "E_s_wdiff_all_sq: 0.007938238399091087\n",
            "E_IS_SCOPE: 0.001779183082327104\n",
            "E_IS_E_SCOPE: 0.0018323025149253043\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432598822630188\n",
            "Total Loss: -4.486877811821222e-06\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "Var loss:  tensor(-4.5410e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008008641936919943\n",
            "E_s_wdiff_all_sq: 0.007924367787146506\n",
            "E_IS_SCOPE: 0.001779004899790487\n",
            "E_IS_E_SCOPE: 0.0018321356605981185\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34322862410764415\n",
            "Total Loss: -4.540975590704502e-06\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "Var loss:  tensor(-4.5987e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.008000267595139436\n",
            "E_s_wdiff_all_sq: 0.007916021059906502\n",
            "E_IS_SCOPE: 0.0017790312354396122\n",
            "E_IS_E_SCOPE: 0.0018321770695865394\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34323638158457503\n",
            "Total Loss: -4.598736809800427e-06\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "Var loss:  tensor(-4.6550e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007993532593479055\n",
            "E_s_wdiff_all_sq: 0.007909307823878041\n",
            "E_IS_SCOPE: 0.0017791349224032913\n",
            "E_IS_E_SCOPE: 0.0018322980224599226\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432590406535545\n",
            "Total Loss: -4.655034261127899e-06\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "Var loss:  tensor(-4.7111e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007989270310251272\n",
            "E_s_wdiff_all_sq: 0.007905102551336508\n",
            "E_IS_SCOPE: 0.0017793507779723338\n",
            "E_IS_E_SCOPE: 0.0018325134278215315\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34329939426244954\n",
            "Total Loss: -4.711144532511952e-06\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "Var loss:  tensor(-4.7628e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007985913935884534\n",
            "E_s_wdiff_all_sq: 0.007901826264268432\n",
            "E_IS_SCOPE: 0.0017795596960121249\n",
            "E_IS_E_SCOPE: 0.0018327081520309362\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433358735057238\n",
            "Total Loss: -4.762844170400418e-06\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "Var loss:  tensor(-4.8221e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00798149737749201\n",
            "E_s_wdiff_all_sq: 0.00789746555657798\n",
            "E_IS_SCOPE: 0.001779215513428303\n",
            "E_IS_E_SCOPE: 0.0018323656643046196\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34327171254122457\n",
            "Total Loss: -4.822084587482664e-06\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "Var loss:  tensor(-4.8749e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007971844646967971\n",
            "E_s_wdiff_all_sq: 0.007887869536915684\n",
            "E_IS_SCOPE: 0.0017788052665290272\n",
            "E_IS_E_SCOPE: 0.001831953444906527\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431944881850371\n",
            "Total Loss: -4.874850451593027e-06\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "Var loss:  tensor(-4.9310e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007962760871040612\n",
            "E_s_wdiff_all_sq: 0.00787884001898328\n",
            "E_IS_SCOPE: 0.001778588332867395\n",
            "E_IS_E_SCOPE: 0.0018317374713045888\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431540281231372\n",
            "Total Loss: -4.931028565934026e-06\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "Var loss:  tensor(-4.9880e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007958746246089589\n",
            "E_s_wdiff_all_sq: 0.007874867655451999\n",
            "E_IS_SCOPE: 0.0017786579820899572\n",
            "E_IS_E_SCOPE: 0.001831814460326523\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431684510922645\n",
            "Total Loss: -4.987969584419397e-06\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "Var loss:  tensor(-5.0430e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00795710069122013\n",
            "E_s_wdiff_all_sq: 0.007873283508169631\n",
            "E_IS_SCOPE: 0.0017788863499866366\n",
            "E_IS_E_SCOPE: 0.0018320396612218814\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432106397768276\n",
            "Total Loss: -5.04304316887097e-06\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "Var loss:  tensor(-5.0976e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007953620214800953\n",
            "E_s_wdiff_all_sq: 0.007869876582181565\n",
            "E_IS_SCOPE: 0.0017790570834441792\n",
            "E_IS_E_SCOPE: 0.0018322009060117498\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34324084705271946\n",
            "Total Loss: -5.097616264632121e-06\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "Var loss:  tensor(-5.1537e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00794636989531478\n",
            "E_s_wdiff_all_sq: 0.007862671366371421\n",
            "E_IS_SCOPE: 0.0017790102060465695\n",
            "E_IS_E_SCOPE: 0.0018321595208833086\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432330940456693\n",
            "Total Loss: -5.153704478998503e-06\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "Var loss:  tensor(-5.2109e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007934318720451337\n",
            "E_s_wdiff_all_sq: 0.007850650435563893\n",
            "E_IS_SCOPE: 0.0017787863459559365\n",
            "E_IS_E_SCOPE: 0.0018319491339301097\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431936805753518\n",
            "Total Loss: -5.210894809780375e-06\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "Var loss:  tensor(-5.2656e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007919886296060528\n",
            "E_s_wdiff_all_sq: 0.00783622916757606\n",
            "E_IS_SCOPE: 0.001778483393768165\n",
            "E_IS_E_SCOPE: 0.0018316679685849266\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34314100762287925\n",
            "Total Loss: -5.265624897936305e-06\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "Var loss:  tensor(-5.3204e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007907030764573724\n",
            "E_s_wdiff_all_sq: 0.007823413777338152\n",
            "E_IS_SCOPE: 0.0017782885430918426\n",
            "E_IS_E_SCOPE: 0.0018314804473053214\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431058777620431\n",
            "Total Loss: -5.320424940263163e-06\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "Var loss:  tensor(-5.3766e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007898375182877695\n",
            "E_s_wdiff_all_sq: 0.007814828897172475\n",
            "E_IS_SCOPE: 0.0017783079528507194\n",
            "E_IS_E_SCOPE: 0.0018314925742310285\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34310814959600966\n",
            "Total Loss: -5.376560804277661e-06\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "Var loss:  tensor(-5.4325e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007892729760589847\n",
            "E_s_wdiff_all_sq: 0.007809241766895736\n",
            "E_IS_SCOPE: 0.0017784259598160226\n",
            "E_IS_E_SCOPE: 0.0018316094120433748\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431300377576987\n",
            "Total Loss: -5.432514509471145e-06\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "Var loss:  tensor(-5.4873e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007889554942548954\n",
            "E_s_wdiff_all_sq: 0.007806095000212178\n",
            "E_IS_SCOPE: 0.0017785471234452786\n",
            "E_IS_E_SCOPE: 0.0018317439399558476\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34315523994730457\n",
            "Total Loss: -5.487294433241877e-06\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "Var loss:  tensor(-5.5423e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007886956024865234\n",
            "E_s_wdiff_all_sq: 0.007803496166556757\n",
            "E_IS_SCOPE: 0.0017781896443971141\n",
            "E_IS_E_SCOPE: 0.0018314139171943604\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34309341414434386\n",
            "Total Loss: -5.542291034894842e-06\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "Var loss:  tensor(-5.5948e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007883717404864767\n",
            "E_s_wdiff_all_sq: 0.007800292490277477\n",
            "E_IS_SCOPE: 0.0017779858356487808\n",
            "E_IS_E_SCOPE: 0.0018312188772152509\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34305687574540566\n",
            "Total Loss: -5.594772294529801e-06\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "Var loss:  tensor(-5.6495e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007879423380175254\n",
            "E_s_wdiff_all_sq: 0.007796034606409788\n",
            "E_IS_SCOPE: 0.0017779141172117128\n",
            "E_IS_E_SCOPE: 0.0018311564460228185\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430451800108917\n",
            "Total Loss: -5.649487605624212e-06\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "Var loss:  tensor(-5.7053e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007875990327936322\n",
            "E_s_wdiff_all_sq: 0.0077926720104672985\n",
            "E_IS_SCOPE: 0.0017780604619694656\n",
            "E_IS_E_SCOPE: 0.0018312954599451266\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34307122260059275\n",
            "Total Loss: -5.705282231178478e-06\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "Var loss:  tensor(-5.7597e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00787210845356575\n",
            "E_s_wdiff_all_sq: 0.007788834927532094\n",
            "E_IS_SCOPE: 0.0017782022773599774\n",
            "E_IS_E_SCOPE: 0.0018314420794460166\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430986900041481\n",
            "Total Loss: -5.75968188730111e-06\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "Var loss:  tensor(-5.8142e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007865649904097929\n",
            "E_s_wdiff_all_sq: 0.007782418255271876\n",
            "E_IS_SCOPE: 0.0017782483336059689\n",
            "E_IS_E_SCOPE: 0.0018314944405097959\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343108499220935\n",
            "Total Loss: -5.814168730479061e-06\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "Var loss:  tensor(-5.8686e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007859378663403558\n",
            "E_s_wdiff_all_sq: 0.007776170403470009\n",
            "E_IS_SCOPE: 0.0017782499222070327\n",
            "E_IS_E_SCOPE: 0.0018315115649353208\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431117072765053\n",
            "Total Loss: -5.868629271907171e-06\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "Var loss:  tensor(-5.9235e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007850790720521647\n",
            "E_s_wdiff_all_sq: 0.007767632529982282\n",
            "E_IS_SCOPE: 0.0017782241017447\n",
            "E_IS_E_SCOPE: 0.0018314881522579036\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34310732119242354\n",
            "Total Loss: -5.923514235920899e-06\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "Var loss:  tensor(-5.9773e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007838370884139084\n",
            "E_s_wdiff_all_sq: 0.007755304365311193\n",
            "E_IS_SCOPE: 0.0017781501437810327\n",
            "E_IS_E_SCOPE: 0.0018313952599048084\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34308991892509766\n",
            "Total Loss: -5.977317168539588e-06\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "Var loss:  tensor(-6.0311e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00782613486626925\n",
            "E_s_wdiff_all_sq: 0.00774314892562043\n",
            "E_IS_SCOPE: 0.0017780707181790068\n",
            "E_IS_E_SCOPE: 0.0018313024394494201\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34307253012694416\n",
            "Total Loss: -6.031105640887623e-06\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "Var loss:  tensor(-6.0854e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00781658310769683\n",
            "E_s_wdiff_all_sq: 0.007733661308121185\n",
            "E_IS_SCOPE: 0.001778048688873757\n",
            "E_IS_E_SCOPE: 0.0018312754932618878\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34306748208215654\n",
            "Total Loss: -6.085412949495203e-06\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "Var loss:  tensor(-6.1400e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007809030667814782\n",
            "E_s_wdiff_all_sq: 0.007726153708785826\n",
            "E_IS_SCOPE: 0.0017780865030560826\n",
            "E_IS_E_SCOPE: 0.001831318176265769\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430754782305914\n",
            "Total Loss: -6.139991139296995e-06\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "Var loss:  tensor(-6.1909e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007801772878327047\n",
            "E_s_wdiff_all_sq: 0.007718912169297255\n",
            "E_IS_SCOPE: 0.0017781366911327457\n",
            "E_IS_E_SCOPE: 0.0018313856774025623\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430881237583247\n",
            "Total Loss: -6.190867258721103e-06\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "Var loss:  tensor(-6.2466e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007795629027425886\n",
            "E_s_wdiff_all_sq: 0.007712795195469623\n",
            "E_IS_SCOPE: 0.0017778558376792858\n",
            "E_IS_E_SCOPE: 0.001831119265832827\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430382147485865\n",
            "Total Loss: -6.24662809969867e-06\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "Var loss:  tensor(-6.2981e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0077881022601122285\n",
            "E_s_wdiff_all_sq: 0.0077053392694021216\n",
            "E_IS_SCOPE: 0.0017777096937380272\n",
            "E_IS_E_SCOPE: 0.001830963446267499\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34300902382339093\n",
            "Total Loss: -6.298118097716569e-06\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "Var loss:  tensor(-6.3525e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007781953777439286\n",
            "E_s_wdiff_all_sq: 0.007699263074999833\n",
            "E_IS_SCOPE: 0.0017777366187551361\n",
            "E_IS_E_SCOPE: 0.001830981396658908\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430123866137552\n",
            "Total Loss: -6.352457116969544e-06\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "Var loss:  tensor(-6.4076e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007778412261949237\n",
            "E_s_wdiff_all_sq: 0.007695779444503212\n",
            "E_IS_SCOPE: 0.001777912401268457\n",
            "E_IS_E_SCOPE: 0.0018311557861756583\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34304505639644667\n",
            "Total Loss: -6.407556117258087e-06\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "Var loss:  tensor(-6.4609e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007776114646046564\n",
            "E_s_wdiff_all_sq: 0.0076935182369177475\n",
            "E_IS_SCOPE: 0.0017780959989636457\n",
            "E_IS_E_SCOPE: 0.0018313478699945103\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34308104099424463\n",
            "Total Loss: -6.4609366817909575e-06\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "Var loss:  tensor(-6.5138e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0077725452411171745\n",
            "E_s_wdiff_all_sq: 0.007689949694562345\n",
            "E_IS_SCOPE: 0.0017781446778815926\n",
            "E_IS_E_SCOPE: 0.0018314225729196137\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430950356905717\n",
            "Total Loss: -6.513847270092285e-06\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "Var loss:  tensor(-6.5688e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00776323044040368\n",
            "E_s_wdiff_all_sq: 0.007680674598437183\n",
            "E_IS_SCOPE: 0.001778017977032065\n",
            "E_IS_E_SCOPE: 0.0018313034893781244\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34307272681848416\n",
            "Total Loss: -6.56878647449944e-06\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "Var loss:  tensor(-6.6236e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0077494107175542495\n",
            "E_s_wdiff_all_sq: 0.0076669294935584505\n",
            "E_IS_SCOPE: 0.00177778309791617\n",
            "E_IS_E_SCOPE: 0.001831058720325648\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34302687227457\n",
            "Total Loss: -6.623624572035455e-06\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "Var loss:  tensor(-6.6766e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007734012121862681\n",
            "E_s_wdiff_all_sq: 0.007651570449475483\n",
            "E_IS_SCOPE: 0.0017775340683909469\n",
            "E_IS_E_SCOPE: 0.001830816419575801\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429814801375254\n",
            "Total Loss: -6.676633731389145e-06\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "Var loss:  tensor(-6.7298e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007720951957263668\n",
            "E_s_wdiff_all_sq: 0.0076385395101321975\n",
            "E_IS_SCOPE: 0.0017774233016108038\n",
            "E_IS_E_SCOPE: 0.0018307176440724002\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429629757326077\n",
            "Total Loss: -6.729841540602417e-06\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "Var loss:  tensor(-6.7845e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007712581410110646\n",
            "E_s_wdiff_all_sq: 0.007630187021395027\n",
            "E_IS_SCOPE: 0.0017775115976227517\n",
            "E_IS_E_SCOPE: 0.0018308242581106123\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.342982948592933\n",
            "Total Loss: -6.784536008982989e-06\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "Var loss:  tensor(-6.8334e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007706632639480276\n",
            "E_s_wdiff_all_sq: 0.007624252142958337\n",
            "E_IS_SCOPE: 0.0017776763263618964\n",
            "E_IS_E_SCOPE: 0.0018310064526494655\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430170805528284\n",
            "Total Loss: -6.833359802077381e-06\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "Var loss:  tensor(-6.8895e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007700256923142419\n",
            "E_s_wdiff_all_sq: 0.007617928211272149\n",
            "E_IS_SCOPE: 0.0017774479678563874\n",
            "E_IS_E_SCOPE: 0.001830780261009889\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34297470626422843\n",
            "Total Loss: -6.889478185612141e-06\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "Var loss:  tensor(-6.9429e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0076929767154967155\n",
            "E_s_wdiff_all_sq: 0.00761072250941175\n",
            "E_IS_SCOPE: 0.0017773212640067818\n",
            "E_IS_E_SCOPE: 0.0018306430145675963\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34294899479069246\n",
            "Total Loss: -6.942898785542752e-06\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "Var loss:  tensor(-6.9961e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007687213182437304\n",
            "E_s_wdiff_all_sq: 0.007605043911993707\n",
            "E_IS_SCOPE: 0.0017773760080395363\n",
            "E_IS_E_SCOPE: 0.00183068190549798\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429562805396754\n",
            "Total Loss: -6.996128222169426e-06\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "Var loss:  tensor(-7.0491e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007685812401087915\n",
            "E_s_wdiff_all_sq: 0.00760370557413405\n",
            "E_IS_SCOPE: 0.0017775632983510277\n",
            "E_IS_E_SCOPE: 0.0018308644747932375\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34299048270568483\n",
            "Total Loss: -7.049129679434149e-06\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "Var loss:  tensor(-7.1024e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007685437795901885\n",
            "E_s_wdiff_all_sq: 0.007603368270916785\n",
            "E_IS_SCOPE: 0.001777726178669291\n",
            "E_IS_E_SCOPE: 0.0018310353629744842\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34302249655519773\n",
            "Total Loss: -7.102447374164773e-06\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "Var loss:  tensor(-7.1565e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007680726814545332\n",
            "E_s_wdiff_all_sq: 0.0075986805714639855\n",
            "E_IS_SCOPE: 0.001777705198045045\n",
            "E_IS_E_SCOPE: 0.0018310297495584668\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430214449490871\n",
            "Total Loss: -7.156463694375781e-06\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "Var loss:  tensor(-7.2108e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007669650809286489\n",
            "E_s_wdiff_all_sq: 0.007587622709519959\n",
            "E_IS_SCOPE: 0.0017774618048068678\n",
            "E_IS_E_SCOPE: 0.0018308044297586218\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429792339891957\n",
            "Total Loss: -7.2107538858570686e-06\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "Var loss:  tensor(-7.2650e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007657236909643572\n",
            "E_s_wdiff_all_sq: 0.00757522681263462\n",
            "E_IS_SCOPE: 0.0017772332869503955\n",
            "E_IS_E_SCOPE: 0.0018305940520016658\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34293982224168396\n",
            "Total Loss: -7.2650368424676676e-06\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "Var loss:  tensor(-7.3182e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007643564285096747\n",
            "E_s_wdiff_all_sq: 0.00756161129321687\n",
            "E_IS_SCOPE: 0.0017771012869131188\n",
            "E_IS_E_SCOPE: 0.0018304600842643235\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429147249941647\n",
            "Total Loss: -7.318206571411967e-06\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "Var loss:  tensor(-7.3719e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0076325672136750965\n",
            "E_s_wdiff_all_sq: 0.007550701144844192\n",
            "E_IS_SCOPE: 0.0017771528835014492\n",
            "E_IS_E_SCOPE: 0.001830495044118341\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34292127430317687\n",
            "Total Loss: -7.371856151758803e-06\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "Var loss:  tensor(-7.4256e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007625204271583071\n",
            "E_s_wdiff_all_sq: 0.00754339577171996\n",
            "E_IS_SCOPE: 0.0017773197702191151\n",
            "E_IS_E_SCOPE: 0.0018306599995103758\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429521767158447\n",
            "Total Loss: -7.425562468289099e-06\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "Var loss:  tensor(-7.4727e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0076193517615176405\n",
            "E_s_wdiff_all_sq: 0.007537572171546555\n",
            "E_IS_SCOPE: 0.0017775186425010474\n",
            "E_IS_E_SCOPE: 0.0018308679723721502\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429911379351112\n",
            "Total Loss: -7.472673519998141e-06\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "Var loss:  tensor(-7.5301e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007611452188556609\n",
            "E_s_wdiff_all_sq: 0.007529689032487752\n",
            "E_IS_SCOPE: 0.0017771803496248254\n",
            "E_IS_E_SCOPE: 0.0018305501723897943\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429316019231055\n",
            "Total Loss: -7.5300932099600995e-06\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "Var loss:  tensor(-7.5819e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007604280699549032\n",
            "E_s_wdiff_all_sq: 0.007522539325678701\n",
            "E_IS_SCOPE: 0.0017769712568683751\n",
            "E_IS_E_SCOPE: 0.0018303560735802808\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3428952398409939\n",
            "Total Loss: -7.581863302359715e-06\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "Var loss:  tensor(-7.6366e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00759808040524411\n",
            "E_s_wdiff_all_sq: 0.007516403823225471\n",
            "E_IS_SCOPE: 0.0017769851814667494\n",
            "E_IS_E_SCOPE: 0.0018303649678323441\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34289690607235646\n",
            "Total Loss: -7.636594461428968e-06\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "Var loss:  tensor(-7.6901e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007593994954596985\n",
            "E_s_wdiff_all_sq: 0.007512381388156291\n",
            "E_IS_SCOPE: 0.0017771509590861286\n",
            "E_IS_E_SCOPE: 0.0018305259985066003\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34292707323625854\n",
            "Total Loss: -7.690116149127943e-06\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "Var loss:  tensor(-7.7419e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007589916404127752\n",
            "E_s_wdiff_all_sq: 0.0075083552559496395\n",
            "E_IS_SCOPE: 0.0017773012688260834\n",
            "E_IS_E_SCOPE: 0.0018306759717794604\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34295516892873573\n",
            "Total Loss: -7.741861477521608e-06\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "Var loss:  tensor(-7.7944e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007584043432703008\n",
            "E_s_wdiff_all_sq: 0.007502553352317861\n",
            "E_IS_SCOPE: 0.0017774113369078209\n",
            "E_IS_E_SCOPE: 0.0018307767849530714\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34297405506670825\n",
            "Total Loss: -7.794419454233703e-06\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "Var loss:  tensor(-7.8485e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007574498833420871\n",
            "E_s_wdiff_all_sq: 0.007493059904934455\n",
            "E_IS_SCOPE: 0.0017773537683646232\n",
            "E_IS_E_SCOPE: 0.0018307206557939943\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429635399424974\n",
            "Total Loss: -7.848450121204602e-06\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "Var loss:  tensor(-7.9013e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007560485069303705\n",
            "E_s_wdiff_all_sq: 0.007479082255463695\n",
            "E_IS_SCOPE: 0.0017771052758119683\n",
            "E_IS_E_SCOPE: 0.0018304805427844385\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429185576523359\n",
            "Total Loss: -7.901323853811218e-06\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "Var loss:  tensor(-7.9539e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007546971021737392\n",
            "E_s_wdiff_all_sq: 0.0074655953615987165\n",
            "E_IS_SCOPE: 0.0017768811170400128\n",
            "E_IS_E_SCOPE: 0.001830269070266991\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3428789408145869\n",
            "Total Loss: -7.953850064159468e-06\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "Var loss:  tensor(-8.0065e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007537559108357597\n",
            "E_s_wdiff_all_sq: 0.007456206777955908\n",
            "E_IS_SCOPE: 0.0017768454475335985\n",
            "E_IS_E_SCOPE: 0.0018302480827662537\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3428750090582457\n",
            "Total Loss: -8.006543812499878e-06\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "Var loss:  tensor(-8.0599e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007532985964659223\n",
            "E_s_wdiff_all_sq: 0.007451644567030134\n",
            "E_IS_SCOPE: 0.0017769756607574076\n",
            "E_IS_E_SCOPE: 0.0018303994970830732\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34290337471301124\n",
            "Total Loss: -8.059878771122207e-06\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "Var loss:  tensor(-8.1061e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007530330989290816\n",
            "E_s_wdiff_all_sq: 0.007448997817467071\n",
            "E_IS_SCOPE: 0.0017771735561370918\n",
            "E_IS_E_SCOPE: 0.0018306164076285613\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429440103000387\n",
            "Total Loss: -8.106134908072472e-06\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "Var loss:  tensor(-8.1632e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007527047180943543\n",
            "E_s_wdiff_all_sq: 0.007445725552353919\n",
            "E_IS_SCOPE: 0.001776952181145558\n",
            "E_IS_E_SCOPE: 0.0018304178034344932\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34290680418821085\n",
            "Total Loss: -8.163219737125464e-06\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "Var loss:  tensor(-8.2145e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007520576000926846\n",
            "E_s_wdiff_all_sq: 0.007439316071539108\n",
            "E_IS_SCOPE: 0.0017768652022080353\n",
            "E_IS_E_SCOPE: 0.0018303256197626217\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3428895346838056\n",
            "Total Loss: -8.21450947031347e-06\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "Var loss:  tensor(-8.2678e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007513589219883572\n",
            "E_s_wdiff_all_sq: 0.007432404071715724\n",
            "E_IS_SCOPE: 0.0017769053712231508\n",
            "E_IS_E_SCOPE: 0.0018303550533305618\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34289504870945553\n",
            "Total Loss: -8.267819795853767e-06\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "Var loss:  tensor(-8.3203e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007508424193026835\n",
            "E_s_wdiff_all_sq: 0.007427307446248586\n",
            "E_IS_SCOPE: 0.0017770570519267301\n",
            "E_IS_E_SCOPE: 0.0018304987755190783\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429219733363154\n",
            "Total Loss: -8.320304155326821e-06\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "Var loss:  tensor(-8.3720e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007506255293873601\n",
            "E_s_wdiff_all_sq: 0.00742522560020667\n",
            "E_IS_SCOPE: 0.001777308146007204\n",
            "E_IS_E_SCOPE: 0.0018307322150739416\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34296570543484456\n",
            "Total Loss: -8.372048215423387e-06\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "Var loss:  tensor(-8.4239e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007502534211607082\n",
            "E_s_wdiff_all_sq: 0.007421572174088016\n",
            "E_IS_SCOPE: 0.0017774371163398071\n",
            "E_IS_E_SCOPE: 0.0018308532643293918\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429883825598473\n",
            "Total Loss: -8.423862208983487e-06\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "Var loss:  tensor(-8.4770e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007494592182180527\n",
            "E_s_wdiff_all_sq: 0.007413680457657149\n",
            "E_IS_SCOPE: 0.0017773590773200259\n",
            "E_IS_E_SCOPE: 0.001830776625228323\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429740251441939\n",
            "Total Loss: -8.476975042095991e-06\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "Var loss:  tensor(-8.5291e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007481675716415125\n",
            "E_s_wdiff_all_sq: 0.007400835153725069\n",
            "E_IS_SCOPE: 0.0017771392723170039\n",
            "E_IS_E_SCOPE: 0.0018305473025598633\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429310642949157\n",
            "Total Loss: -8.529101544542048e-06\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "Var loss:  tensor(-8.5815e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007468811392870122\n",
            "E_s_wdiff_all_sq: 0.007387999664301993\n",
            "E_IS_SCOPE: 0.0017769461554195587\n",
            "E_IS_E_SCOPE: 0.00183036598655885\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34289709691853915\n",
            "Total Loss: -8.581537459332808e-06\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "Var loss:  tensor(-8.6334e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007460095532260944\n",
            "E_s_wdiff_all_sq: 0.00737927513865028\n",
            "E_IS_SCOPE: 0.001776923893345705\n",
            "E_IS_E_SCOPE: 0.0018303739728214301\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.342898593048971\n",
            "Total Loss: -8.633369089666026e-06\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "Var loss:  tensor(-8.6866e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007456516460804482\n",
            "E_s_wdiff_all_sq: 0.007375719498551067\n",
            "E_IS_SCOPE: 0.001777121908862031\n",
            "E_IS_E_SCOPE: 0.0018305868777438855\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34293847823060447\n",
            "Total Loss: -8.68657925917355e-06\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "Var loss:  tensor(-8.7338e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007455665236807161\n",
            "E_s_wdiff_all_sq: 0.0073748906804732665\n",
            "E_IS_SCOPE: 0.0017773910687393253\n",
            "E_IS_E_SCOPE: 0.0018308684696708751\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.342991231098058\n",
            "Total Loss: -8.733849278085709e-06\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "Var loss:  tensor(-8.7882e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007453280109933113\n",
            "E_s_wdiff_all_sq: 0.007372529183436965\n",
            "E_IS_SCOPE: 0.001777178929185182\n",
            "E_IS_E_SCOPE: 0.0018306716959431294\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429543679021238\n",
            "Total Loss: -8.788210768626535e-06\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "Var loss:  tensor(-8.8387e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007446783585906695\n",
            "E_s_wdiff_all_sq: 0.007366102984936681\n",
            "E_IS_SCOPE: 0.0017770315170567567\n",
            "E_IS_E_SCOPE: 0.0018305143719340195\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34292489513744423\n",
            "Total Loss: -8.838712533391392e-06\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "Var loss:  tensor(-8.8918e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00743963088922595\n",
            "E_s_wdiff_all_sq: 0.007359025625224734\n",
            "E_IS_SCOPE: 0.0017770047068720461\n",
            "E_IS_E_SCOPE: 0.001830476424927548\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429177862212759\n",
            "Total Loss: -8.89177585866683e-06\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "Var loss:  tensor(-8.9440e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007435570492217463\n",
            "E_s_wdiff_all_sq: 0.007355028568277989\n",
            "E_IS_SCOPE: 0.0017771335325975491\n",
            "E_IS_E_SCOPE: 0.0018305997097966752\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.342940882161666\n",
            "Total Loss: -8.944034207656985e-06\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "Var loss:  tensor(-8.9956e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007433950576597725\n",
            "E_s_wdiff_all_sq: 0.007353448750531292\n",
            "E_IS_SCOPE: 0.0017773398330870117\n",
            "E_IS_E_SCOPE: 0.0018308117382193556\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429806031415876\n",
            "Total Loss: -8.995587947133177e-06\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "Var loss:  tensor(-9.0469e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007429925995676623\n",
            "E_s_wdiff_all_sq: 0.007349449367705259\n",
            "E_IS_SCOPE: 0.0017774422037225564\n",
            "E_IS_E_SCOPE: 0.001830927184159837\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34300223055279\n",
            "Total Loss: -9.046936652076613e-06\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "Var loss:  tensor(-9.0998e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007420360184031026\n",
            "E_s_wdiff_all_sq: 0.007339940582041331\n",
            "E_IS_SCOPE: 0.001777373850293737\n",
            "E_IS_E_SCOPE: 0.0018308567564793883\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429890367722314\n",
            "Total Loss: -9.099814130486376e-06\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "Var loss:  tensor(-9.1535e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007405565871067565\n",
            "E_s_wdiff_all_sq: 0.007325234833594968\n",
            "E_IS_SCOPE: 0.001777188192476978\n",
            "E_IS_E_SCOPE: 0.0018306536396029383\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34295098526352696\n",
            "Total Loss: -9.153460528202838e-06\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "Var loss:  tensor(-9.2049e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007390327508182531\n",
            "E_s_wdiff_all_sq: 0.0073100649933914115\n",
            "E_IS_SCOPE: 0.001776980346628671\n",
            "E_IS_E_SCOPE: 0.0018304372413827908\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429104456545024\n",
            "Total Loss: -9.2048784660001e-06\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "Var loss:  tensor(-9.2571e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0073799078875651505\n",
            "E_s_wdiff_all_sq: 0.007299690287105127\n",
            "E_IS_SCOPE: 0.0017769284804768492\n",
            "E_IS_E_SCOPE: 0.0018303890202002804\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429014119947785\n",
            "Total Loss: -9.25708273571968e-06\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "Var loss:  tensor(-9.3105e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007376203806683148\n",
            "E_s_wdiff_all_sq: 0.007296040720284461\n",
            "E_IS_SCOPE: 0.001777114531544958\n",
            "E_IS_E_SCOPE: 0.0018305745235773928\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429361638258044\n",
            "Total Loss: -9.31050141506247e-06\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "Var loss:  tensor(-9.3579e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007374877535682255\n",
            "E_s_wdiff_all_sq: 0.0072947430941867\n",
            "E_IS_SCOPE: 0.0017773265119572735\n",
            "E_IS_E_SCOPE: 0.0018307958620874135\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34297762893883627\n",
            "Total Loss: -9.357862513604577e-06\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "Var loss:  tensor(-9.4127e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007371529502852886\n",
            "E_s_wdiff_all_sq: 0.007291378566256236\n",
            "E_IS_SCOPE: 0.001777026968946988\n",
            "E_IS_E_SCOPE: 0.0018305320013179943\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429281977909189\n",
            "Total Loss: -9.412731894241702e-06\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "Var loss:  tensor(-9.4634e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007364925016699982\n",
            "E_s_wdiff_all_sq: 0.007284795222524033\n",
            "E_IS_SCOPE: 0.0017768468179550406\n",
            "E_IS_E_SCOPE: 0.0018303665920484957\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3428972103497563\n",
            "Total Loss: -9.463357759840335e-06\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "Var loss:  tensor(-9.5161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007359846418645953\n",
            "E_s_wdiff_all_sq: 0.007279777726537914\n",
            "E_IS_SCOPE: 0.0017769105891999612\n",
            "E_IS_E_SCOPE: 0.0018304261664553148\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429083708997769\n",
            "Total Loss: -9.516066151547993e-06\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "Var loss:  tensor(-9.5680e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0073591662800483095\n",
            "E_s_wdiff_all_sq: 0.007279144449363841\n",
            "E_IS_SCOPE: 0.0017771592197664532\n",
            "E_IS_E_SCOPE: 0.0018306773257626998\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429554225812432\n",
            "Total Loss: -9.567985056904357e-06\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "Var loss:  tensor(-9.6193e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007360089777896751\n",
            "E_s_wdiff_all_sq: 0.007280096655586296\n",
            "E_IS_SCOPE: 0.0017774237431984453\n",
            "E_IS_E_SCOPE: 0.0018309531299573606\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34300709118651757\n",
            "Total Loss: -9.619254956255534e-06\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "Var loss:  tensor(-9.6711e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007358994440483762\n",
            "E_s_wdiff_all_sq: 0.007279017095602208\n",
            "E_IS_SCOPE: 0.0017775456753333914\n",
            "E_IS_E_SCOPE: 0.0018310930851345509\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430333101090225\n",
            "Total Loss: -9.671078469644136e-06\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "Var loss:  tensor(-9.7240e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0073521788341665145\n",
            "E_s_wdiff_all_sq: 0.007272215505061258\n",
            "E_IS_SCOPE: 0.00177743643844885\n",
            "E_IS_E_SCOPE: 0.0018310032899267637\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34301648805469376\n",
            "Total Loss: -9.723977599449853e-06\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "Var loss:  tensor(-9.7760e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007336783364896607\n",
            "E_s_wdiff_all_sq: 0.007256844652354477\n",
            "E_IS_SCOPE: 0.0017770978047256666\n",
            "E_IS_E_SCOPE: 0.0018306783636885652\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429556170241954\n",
            "Total Loss: -9.776009132545817e-06\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "Var loss:  tensor(-9.8271e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007319817763742702\n",
            "E_s_wdiff_all_sq: 0.007239947380376929\n",
            "E_IS_SCOPE: 0.0017768226628816497\n",
            "E_IS_E_SCOPE: 0.0018303946109790878\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34290245936007957\n",
            "Total Loss: -9.827116577981222e-06\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "Var loss:  tensor(-9.8797e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0073085240010556905\n",
            "E_s_wdiff_all_sq: 0.007228749825762038\n",
            "E_IS_SCOPE: 0.0017768607871111713\n",
            "E_IS_E_SCOPE: 0.001830410898079932\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34290551055292173\n",
            "Total Loss: -9.879650392747436e-06\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "Var loss:  tensor(-9.9318e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0073032430201835025\n",
            "E_s_wdiff_all_sq: 0.007223577604946168\n",
            "E_IS_SCOPE: 0.0017771640677299138\n",
            "E_IS_E_SCOPE: 0.0018306858664866284\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34295702258335325\n",
            "Total Loss: -9.931786024973757e-06\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "Var loss:  tensor(-9.9782e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007300893987436462\n",
            "E_s_wdiff_all_sq: 0.0072212876012031765\n",
            "E_IS_SCOPE: 0.0017774936492063894\n",
            "E_IS_E_SCOPE: 0.0018310091476996598\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430175854381325\n",
            "Total Loss: -9.978214502134701e-06\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "Var loss:  tensor(-1.0032e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007296515612820261\n",
            "E_s_wdiff_all_sq: 0.007216921600159792\n",
            "E_IS_SCOPE: 0.001777243864737494\n",
            "E_IS_E_SCOPE: 0.0018307802780272097\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429747094522192\n",
            "Total Loss: -1.0032417667840514e-05\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "Var loss:  tensor(-1.0082e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007288828460142038\n",
            "E_s_wdiff_all_sq: 0.007209244210478304\n",
            "E_IS_SCOPE: 0.001777006566158213\n",
            "E_IS_E_SCOPE: 0.0018305629649042988\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429339984471439\n",
            "Total Loss: -1.0082151577317337e-05\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "Var loss:  tensor(-1.0135e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007281684886350573\n",
            "E_s_wdiff_all_sq: 0.007202115674806878\n",
            "E_IS_SCOPE: 0.0017769436587759557\n",
            "E_IS_E_SCOPE: 0.001830518751742057\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429257156419073\n",
            "Total Loss: -1.0134578137387974e-05\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "Var loss:  tensor(-1.0186e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0072795241847582945\n",
            "E_s_wdiff_all_sq: 0.007199965832634233\n",
            "E_IS_SCOPE: 0.001777111854436393\n",
            "E_IS_E_SCOPE: 0.0018307073382961463\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34296104506913117\n",
            "Total Loss: -1.0186219344324524e-05\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "Var loss:  tensor(-1.0236e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007279986745716618\n",
            "E_s_wdiff_all_sq: 0.007200437260858561\n",
            "E_IS_SCOPE: 0.0017773534248223413\n",
            "E_IS_E_SCOPE: 0.0018309691605883612\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34301009433281304\n",
            "Total Loss: -1.0235590422860708e-05\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "Var loss:  tensor(-1.0286e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007277070320147873\n",
            "E_s_wdiff_all_sq: 0.007197572555121145\n",
            "E_IS_SCOPE: 0.0017775537811817693\n",
            "E_IS_E_SCOPE: 0.0018311690395042839\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430475392484793\n",
            "Total Loss: -1.028635536718097e-05\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "Var loss:  tensor(-1.0339e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007267836399108413\n",
            "E_s_wdiff_all_sq: 0.007188435490622062\n",
            "E_IS_SCOPE: 0.0017775632051129115\n",
            "E_IS_E_SCOPE: 0.0018311565709765384\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34304520341947126\n",
            "Total Loss: -1.0339426989781908e-05\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "Var loss:  tensor(-1.0391e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007251108154340161\n",
            "E_s_wdiff_all_sq: 0.007171797487212461\n",
            "E_IS_SCOPE: 0.001777379600360733\n",
            "E_IS_E_SCOPE: 0.0018309537378554232\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34300720506892274\n",
            "Total Loss: -1.0391211610560024e-05\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "Var loss:  tensor(-1.0441e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007234068626536114\n",
            "E_s_wdiff_all_sq: 0.007154831165805418\n",
            "E_IS_SCOPE: 0.001777190507757992\n",
            "E_IS_E_SCOPE: 0.0018307528765749944\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.342969576119058\n",
            "Total Loss: -1.0440880652188775e-05\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "Var loss:  tensor(-1.0492e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007224514794913083\n",
            "E_s_wdiff_all_sq: 0.007145322017839368\n",
            "E_IS_SCOPE: 0.0017772019417545324\n",
            "E_IS_E_SCOPE: 0.0018307675486999467\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.342972324765552\n",
            "Total Loss: -1.049204056599324e-05\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "Var loss:  tensor(-1.0544e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00722250553386321\n",
            "E_s_wdiff_all_sq: 0.007143329779792345\n",
            "E_IS_SCOPE: 0.0017774048059626768\n",
            "E_IS_E_SCOPE: 0.0018309881024753285\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430136428679688\n",
            "Total Loss: -1.0544442703316198e-05\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "Var loss:  tensor(-1.0590e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00722115539664656\n",
            "E_s_wdiff_all_sq: 0.0071420140831327085\n",
            "E_IS_SCOPE: 0.001777645622147809\n",
            "E_IS_E_SCOPE: 0.0018312345142197143\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430598051504943\n",
            "Total Loss: -1.0590074378837716e-05\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "Var loss:  tensor(-1.0644e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00721734429848365\n",
            "E_s_wdiff_all_sq: 0.007138254176060492\n",
            "E_IS_SCOPE: 0.0017773617060033047\n",
            "E_IS_E_SCOPE: 0.0018309521262540535\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34300690315475085\n",
            "Total Loss: -1.0644321827219146e-05\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "Var loss:  tensor(-1.0693e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0072100247930577226\n",
            "E_s_wdiff_all_sq: 0.0071310058390894725\n",
            "E_IS_SCOPE: 0.0017771601314254138\n",
            "E_IS_E_SCOPE: 0.001830739449943389\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429670608007923\n",
            "Total Loss: -1.0693286816579155e-05\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "Var loss:  tensor(-1.0744e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0072043294602186945\n",
            "E_s_wdiff_all_sq: 0.007125363069730538\n",
            "E_IS_SCOPE: 0.001777111879968811\n",
            "E_IS_E_SCOPE: 0.0018306904002374756\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34295787192715393\n",
            "Total Loss: -1.074425379805205e-05\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "Var loss:  tensor(-1.0796e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007204365803275201\n",
            "E_s_wdiff_all_sq: 0.007125422964108269\n",
            "E_IS_SCOPE: 0.001777275364474835\n",
            "E_IS_E_SCOPE: 0.001830867740760865\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429910945455171\n",
            "Total Loss: -1.0795517154007193e-05\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "Var loss:  tensor(-1.0846e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007208153878918154\n",
            "E_s_wdiff_all_sq: 0.007129207095753838\n",
            "E_IS_SCOPE: 0.0017775109479142973\n",
            "E_IS_E_SCOPE: 0.0018311306563598185\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343040348627093\n",
            "Total Loss: -1.084623747560614e-05\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "Var loss:  tensor(-1.0896e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007208931621282639\n",
            "E_s_wdiff_all_sq: 0.007129967444064669\n",
            "E_IS_SCOPE: 0.0017776028119938381\n",
            "E_IS_E_SCOPE: 0.0018312559702149977\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34306382467366514\n",
            "Total Loss: -1.0895742973228428e-05\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "Var loss:  tensor(-1.0947e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007201398612222507\n",
            "E_s_wdiff_all_sq: 0.00712245303512519\n",
            "E_IS_SCOPE: 0.0017775285863054877\n",
            "E_IS_E_SCOPE: 0.0018311980515833288\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343052974313244\n",
            "Total Loss: -1.0946957207243549e-05\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "Var loss:  tensor(-1.0999e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007189013192566799\n",
            "E_s_wdiff_all_sq: 0.00711009962226079\n",
            "E_IS_SCOPE: 0.0017773815943617336\n",
            "E_IS_E_SCOPE: 0.0018310609085723816\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430272822163291\n",
            "Total Loss: -1.0998661864166683e-05\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "Var loss:  tensor(-1.1048e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007175455844959934\n",
            "E_s_wdiff_all_sq: 0.007096573221759321\n",
            "E_IS_SCOPE: 0.0017772200332337484\n",
            "E_IS_E_SCOPE: 0.001830908630180297\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429987546874345\n",
            "Total Loss: -1.1048174441363745e-05\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "Var loss:  tensor(-1.1099e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007166808626892009\n",
            "E_s_wdiff_all_sq: 0.0070879559145993745\n",
            "E_IS_SCOPE: 0.0017772397757506962\n",
            "E_IS_E_SCOPE: 0.0018309387066212288\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430043891476227\n",
            "Total Loss: -1.1098753197309394e-05\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "Var loss:  tensor(-1.1150e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007162777353013477\n",
            "E_s_wdiff_all_sq: 0.007083958418906392\n",
            "E_IS_SCOPE: 0.0017774503049645717\n",
            "E_IS_E_SCOPE: 0.0018311580536727685\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34304548118481254\n",
            "Total Loss: -1.1150167058188165e-05\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "Var loss:  tensor(-1.1196e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007158580495965663\n",
            "E_s_wdiff_all_sq: 0.007079802420979465\n",
            "E_IS_SCOPE: 0.001777665426079214\n",
            "E_IS_E_SCOPE: 0.0018313755636079532\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430862290603049\n",
            "Total Loss: -1.1195803820160909e-05\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "Var loss:  tensor(-1.1248e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007151350729586909\n",
            "E_s_wdiff_all_sq: 0.007072619801908075\n",
            "E_IS_SCOPE: 0.0017773308407558926\n",
            "E_IS_E_SCOPE: 0.0018310437447700658\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34302406678398967\n",
            "Total Loss: -1.1248484098391742e-05\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "Var loss:  tensor(-1.1298e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0071418246775320285\n",
            "E_s_wdiff_all_sq: 0.007063191354682761\n",
            "E_IS_SCOPE: 0.0017771481063812138\n",
            "E_IS_E_SCOPE: 0.0018308368927081504\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429853155331233\n",
            "Total Loss: -1.1297853553484359e-05\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "Var loss:  tensor(-1.1349e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007134441645924963\n",
            "E_s_wdiff_all_sq: 0.007055939632660861\n",
            "E_IS_SCOPE: 0.0017772359146865533\n",
            "E_IS_E_SCOPE: 0.0018308846786155677\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3429942676492833\n",
            "Total Loss: -1.1349118342805949e-05\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "Var loss:  tensor(-1.1399e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0071310296204514815\n",
            "E_s_wdiff_all_sq: 0.007052627316812272\n",
            "E_IS_SCOPE: 0.0017775287068679433\n",
            "E_IS_E_SCOPE: 0.001831152534821902\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430444472943478\n",
            "Total Loss: -1.1398956017586413e-05\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "Var loss:  tensor(-1.1449e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007131986351658751\n",
            "E_s_wdiff_all_sq: 0.007053616275926136\n",
            "E_IS_SCOPE: 0.001777888446684279\n",
            "E_IS_E_SCOPE: 0.0018315212143853185\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431135149851359\n",
            "Total Loss: -1.1449063418342807e-05\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "Var loss:  tensor(-1.1499e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007130173613565566\n",
            "E_s_wdiff_all_sq: 0.0070518065077520365\n",
            "E_IS_SCOPE: 0.001778032643657286\n",
            "E_IS_E_SCOPE: 0.0018316891296384823\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431449718922578\n",
            "Total Loss: -1.1499469897742996e-05\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "Var loss:  tensor(-1.1551e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007121883635149274\n",
            "E_s_wdiff_all_sq: 0.007043507673120919\n",
            "E_IS_SCOPE: 0.001777896356093585\n",
            "E_IS_E_SCOPE: 0.0018315830336220734\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431250960770993\n",
            "Total Loss: -1.1550996777501613e-05\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "Var loss:  tensor(-1.1602e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007106851751825996\n",
            "E_s_wdiff_all_sq: 0.007028500436530314\n",
            "E_IS_SCOPE: 0.001777601262221034\n",
            "E_IS_E_SCOPE: 0.0018313008906970045\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34307223998676944\n",
            "Total Loss: -1.1601545405136825e-05\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "Var loss:  tensor(-1.1651e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007092662515940733\n",
            "E_s_wdiff_all_sq: 0.007014361845206113\n",
            "E_IS_SCOPE: 0.0017774147885536579\n",
            "E_IS_E_SCOPE: 0.0018311140383219112\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430372354371644\n",
            "Total Loss: -1.1651432550765714e-05\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "Var loss:  tensor(-1.1703e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007085508914781796\n",
            "E_s_wdiff_all_sq: 0.007007277555272467\n",
            "E_IS_SCOPE: 0.0017775124313100302\n",
            "E_IS_E_SCOPE: 0.0018312026481513465\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34305383542508755\n",
            "Total Loss: -1.1702677922183387e-05\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "Var loss:  tensor(-1.1754e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007083007718792921\n",
            "E_s_wdiff_all_sq: 0.0070048276964423655\n",
            "E_IS_SCOPE: 0.0017777552899778109\n",
            "E_IS_E_SCOPE: 0.0018314453935136328\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34309931085493584\n",
            "Total Loss: -1.1753788469967032e-05\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "Var loss:  tensor(-1.1799e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0070808648846142136\n",
            "E_s_wdiff_all_sq: 0.007002719638396125\n",
            "E_IS_SCOPE: 0.0017779649665473336\n",
            "E_IS_E_SCOPE: 0.0018316605015463925\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34313960876283994\n",
            "Total Loss: -1.1799427528907946e-05\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "Var loss:  tensor(-1.1853e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007075021279463457\n",
            "E_s_wdiff_all_sq: 0.006996894624471483\n",
            "E_IS_SCOPE: 0.0017776003160312843\n",
            "E_IS_E_SCOPE: 0.0018313130989473583\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430745270559324\n",
            "Total Loss: -1.1852514589053356e-05\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "Var loss:  tensor(-1.1901e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007065626770276962\n",
            "E_s_wdiff_all_sq: 0.006987519268341955\n",
            "E_IS_SCOPE: 0.0017773047921143849\n",
            "E_IS_E_SCOPE: 0.0018310321393438939\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34302189264670124\n",
            "Total Loss: -1.1900796272889223e-05\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "Var loss:  tensor(-1.1951e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0070583654088488615\n",
            "E_s_wdiff_all_sq: 0.006980284167554825\n",
            "E_IS_SCOPE: 0.0017772479385641915\n",
            "E_IS_E_SCOPE: 0.0018309871691891803\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430134680280116\n",
            "Total Loss: -1.1950823704820653e-05\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "Var loss:  tensor(-1.2001e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007057552588722795\n",
            "E_s_wdiff_all_sq: 0.006979529504833641\n",
            "E_IS_SCOPE: 0.0017775532147122854\n",
            "E_IS_E_SCOPE: 0.0018312886395570494\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3430699448827545\n",
            "Total Loss: -1.200136954925251e-05\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "Var loss:  tensor(-1.2050e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007062085233408587\n",
            "E_s_wdiff_all_sq: 0.006984114687967401\n",
            "E_IS_SCOPE: 0.0017780304622042732\n",
            "E_IS_E_SCOPE: 0.001831764101133221\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431590169018823\n",
            "Total Loss: -1.2050336165589717e-05\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "Var loss:  tensor(-1.2098e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007060882138290215\n",
            "E_s_wdiff_all_sq: 0.006982950507280417\n",
            "E_IS_SCOPE: 0.0017782386827228996\n",
            "E_IS_E_SCOPE: 0.0018319769182335343\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431988856310916\n",
            "Total Loss: -1.2098443760349964e-05\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "Var loss:  tensor(-1.2149e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007051325771832845\n",
            "E_s_wdiff_all_sq: 0.006973427070871903\n",
            "E_IS_SCOPE: 0.001778111470338399\n",
            "E_IS_E_SCOPE: 0.0018318587388234532\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431767461371707\n",
            "Total Loss: -1.2149439758045444e-05\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "Var loss:  tensor(-1.2200e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007036263399104732\n",
            "E_s_wdiff_all_sq: 0.006958391269111813\n",
            "E_IS_SCOPE: 0.001777792152173397\n",
            "E_IS_E_SCOPE: 0.0018315512144394376\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34311913513517167\n",
            "Total Loss: -1.2199598288040701e-05\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "Var loss:  tensor(-1.2248e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007022428836796268\n",
            "E_s_wdiff_all_sq: 0.00694457204090071\n",
            "E_IS_SCOPE: 0.0017775253462000097\n",
            "E_IS_E_SCOPE: 0.0018313008398809722\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34307223046699575\n",
            "Total Loss: -1.2247795215245168e-05\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "Var loss:  tensor(-1.2298e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00701506769218743\n",
            "E_s_wdiff_all_sq: 0.006937253506396084\n",
            "E_IS_SCOPE: 0.0017775502520760576\n",
            "E_IS_E_SCOPE: 0.001831329458333349\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34307759179052905\n",
            "Total Loss: -1.2297830472116078e-05\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "Var loss:  tensor(-1.2348e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0070122634067223645\n",
            "E_s_wdiff_all_sq: 0.006934515557429996\n",
            "E_IS_SCOPE: 0.0017778563440578844\n",
            "E_IS_E_SCOPE: 0.0018316275048598117\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431334272296823\n",
            "Total Loss: -1.2348076060364303e-05\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "Var loss:  tensor(-1.2394e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.007009270615983613\n",
            "E_s_wdiff_all_sq: 0.0069315740983294195\n",
            "E_IS_SCOPE: 0.0017781776830415737\n",
            "E_IS_E_SCOPE: 0.0018319460364520802\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431931003000233\n",
            "Total Loss: -1.2393792915698677e-05\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "Var loss:  tensor(-1.2444e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0070018050334317225\n",
            "E_s_wdiff_all_sq: 0.006924144216805676\n",
            "E_IS_SCOPE: 0.0017778758313794962\n",
            "E_IS_E_SCOPE: 0.0018316516772234391\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34313795563185673\n",
            "Total Loss: -1.2444478810717113e-05\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "Var loss:  tensor(-1.2491e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006991647822431869\n",
            "E_s_wdiff_all_sq: 0.006914021237601443\n",
            "E_IS_SCOPE: 0.001777598261948965\n",
            "E_IS_E_SCOPE: 0.0018313804576758803\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34308714590518546\n",
            "Total Loss: -1.2491410372284656e-05\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "Var loss:  tensor(-1.2540e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006985093636396235\n",
            "E_s_wdiff_all_sq: 0.006907501319310432\n",
            "E_IS_SCOPE: 0.0017775857081302035\n",
            "E_IS_E_SCOPE: 0.0018313751895638075\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343086158987624\n",
            "Total Loss: -1.2540249530284577e-05\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "Var loss:  tensor(-1.2589e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006986036730413429\n",
            "E_s_wdiff_all_sq: 0.0069084847685159665\n",
            "E_IS_SCOPE: 0.0017779305810968803\n",
            "E_IS_E_SCOPE: 0.001831724121796965\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431515272531237\n",
            "Total Loss: -1.2588723251585367e-05\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "Var loss:  tensor(-1.2635e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006989628941844123\n",
            "E_s_wdiff_all_sq: 0.006912131628505994\n",
            "E_IS_SCOPE: 0.0017783767825163806\n",
            "E_IS_E_SCOPE: 0.0018321661649289343\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.343234338727866\n",
            "Total Loss: -1.263505523585711e-05\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "Var loss:  tensor(-1.2681e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006989559806471041\n",
            "E_s_wdiff_all_sq: 0.006912102097912383\n",
            "E_IS_SCOPE: 0.0017786240888690579\n",
            "E_IS_E_SCOPE: 0.0018324166149467603\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34328125753244737\n",
            "Total Loss: -1.2680947345624846e-05\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "Var loss:  tensor(-1.2729e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006982024675482987\n",
            "E_s_wdiff_all_sq: 0.006904599764848782\n",
            "E_IS_SCOPE: 0.0017785604190953422\n",
            "E_IS_E_SCOPE: 0.0018323607556938494\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432707929719169\n",
            "Total Loss: -1.2729366311688833e-05\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "Var loss:  tensor(-1.2777e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006966773475023247\n",
            "E_s_wdiff_all_sq: 0.006889375768418001\n",
            "E_IS_SCOPE: 0.0017782334547030829\n",
            "E_IS_E_SCOPE: 0.0018320440536816847\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34321146265144714\n",
            "Total Loss: -1.2777095100837202e-05\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "Var loss:  tensor(-1.2823e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0069532151474424354\n",
            "E_s_wdiff_all_sq: 0.0068758316273689\n",
            "E_IS_SCOPE: 0.0017779677730670933\n",
            "E_IS_E_SCOPE: 0.0018317940720719975\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431646315975081\n",
            "Total Loss: -1.282268168515191e-05\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "Var loss:  tensor(-1.2870e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006947589584156042\n",
            "E_s_wdiff_all_sq: 0.006870245926500103\n",
            "E_IS_SCOPE: 0.0017780383346120633\n",
            "E_IS_E_SCOPE: 0.0018318684825473323\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431785715068814\n",
            "Total Loss: -1.2870241963478662e-05\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "Var loss:  tensor(-1.2918e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006946056999297841\n",
            "E_s_wdiff_all_sq: 0.0068687817395104754\n",
            "E_IS_SCOPE: 0.001778322288154005\n",
            "E_IS_E_SCOPE: 0.0018321422448442717\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34322985758712743\n",
            "Total Loss: -1.2918257342046761e-05\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "Var loss:  tensor(-1.2964e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.00694265549314759\n",
            "E_s_wdiff_all_sq: 0.006865437667008845\n",
            "E_IS_SCOPE: 0.0017785322390496902\n",
            "E_IS_E_SCOPE: 0.0018323462666262186\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34326807861901476\n",
            "Total Loss: -1.2963832763192122e-05\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "Var loss:  tensor(-1.3009e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006935539598212614\n",
            "E_s_wdiff_all_sq: 0.006858363596109926\n",
            "E_IS_SCOPE: 0.0017781757522889925\n",
            "E_IS_E_SCOPE: 0.0018319914361315868\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432016053850272\n",
            "Total Loss: -1.3008969331380037e-05\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "Var loss:  tensor(-1.3053e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006925636494294756\n",
            "E_s_wdiff_all_sq: 0.006848497418236891\n",
            "E_IS_SCOPE: 0.0017778968200383662\n",
            "E_IS_E_SCOPE: 0.0018317161401050913\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431500319789588\n",
            "Total Loss: -1.3053167824464244e-05\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "Var loss:  tensor(-1.3100e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006919082326722719\n",
            "E_s_wdiff_all_sq: 0.006842011635752933\n",
            "E_IS_SCOPE: 0.0017779326878972288\n",
            "E_IS_E_SCOPE: 0.0018317412490781095\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431547358436601\n",
            "Total Loss: -1.3100035140854033e-05\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "Var loss:  tensor(-1.3147e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006919322102180422\n",
            "E_s_wdiff_all_sq: 0.006842300363995781\n",
            "E_IS_SCOPE: 0.0017782529940661735\n",
            "E_IS_E_SCOPE: 0.001832060588917376\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432145603293744\n",
            "Total Loss: -1.3147055266642636e-05\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "Var loss:  tensor(-1.3192e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006923247645505012\n",
            "E_s_wdiff_all_sq: 0.006846231293108018\n",
            "E_IS_SCOPE: 0.0017786385404619097\n",
            "E_IS_E_SCOPE: 0.001832466051460476\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34329051886988443\n",
            "Total Loss: -1.3192273349017444e-05\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "Var loss:  tensor(-1.3238e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006922242011503988\n",
            "E_s_wdiff_all_sq: 0.006845252352447772\n",
            "E_IS_SCOPE: 0.0017788437290442956\n",
            "E_IS_E_SCOPE: 0.0018326805367937598\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34333070012251626\n",
            "Total Loss: -1.3237560191591176e-05\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "Var loss:  tensor(-1.3285e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0069144115463223655\n",
            "E_s_wdiff_all_sq: 0.0068374370960992345\n",
            "E_IS_SCOPE: 0.0017787437475854943\n",
            "E_IS_E_SCOPE: 0.001832596703424643\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34331499494709994\n",
            "Total Loss: -1.3285065204045321e-05\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "Var loss:  tensor(-1.3331e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006900601701702439\n",
            "E_s_wdiff_all_sq: 0.006823635745523949\n",
            "E_IS_SCOPE: 0.001778440995202709\n",
            "E_IS_E_SCOPE: 0.0018323128097346467\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432618108719761\n",
            "Total Loss: -1.3331276634263346e-05\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "Var loss:  tensor(-1.3376e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006885400233193296\n",
            "E_s_wdiff_all_sq: 0.006808472862606233\n",
            "E_IS_SCOPE: 0.0017782419749952116\n",
            "E_IS_E_SCOPE: 0.0018321168642034787\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34322510282872953\n",
            "Total Loss: -1.3376011578350964e-05\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "Var loss:  tensor(-1.3422e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006877009588900985\n",
            "E_s_wdiff_all_sq: 0.006800113534847879\n",
            "E_IS_SCOPE: 0.0017782945438455243\n",
            "E_IS_E_SCOPE: 0.001832176706678279\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432363135980686\n",
            "Total Loss: -1.3421875361282164e-05\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "Var loss:  tensor(-1.3468e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006875649602116976\n",
            "E_s_wdiff_all_sq: 0.006798809077664672\n",
            "E_IS_SCOPE: 0.0017786041705991685\n",
            "E_IS_E_SCOPE: 0.0018324817246944468\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432934550621364\n",
            "Total Loss: -1.3468187487130842e-05\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "Var loss:  tensor(-1.3513e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006873874039940911\n",
            "E_s_wdiff_all_sq: 0.006797076825706838\n",
            "E_IS_SCOPE: 0.0017788436982973657\n",
            "E_IS_E_SCOPE: 0.001832721907386199\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433384504064209\n",
            "Total Loss: -1.3512807692473046e-05\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "Var loss:  tensor(-1.3556e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006867255260330399\n",
            "E_s_wdiff_all_sq: 0.006790493955265966\n",
            "E_IS_SCOPE: 0.001778861420523701\n",
            "E_IS_E_SCOPE: 0.0018327432386747629\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433424465672848\n",
            "Total Loss: -1.3555934986570102e-05\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "Var loss:  tensor(-1.3601e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0068571321669060326\n",
            "E_s_wdiff_all_sq: 0.006780392921419188\n",
            "E_IS_SCOPE: 0.0017782990189007472\n",
            "E_IS_E_SCOPE: 0.0018321924623369323\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432392652315954\n",
            "Total Loss: -1.36012451344052e-05\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "Var loss:  tensor(-1.3641e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006847676491076374\n",
            "E_s_wdiff_all_sq: 0.0067709933780408125\n",
            "E_IS_SCOPE: 0.0017779656778014181\n",
            "E_IS_E_SCOPE: 0.001831851136109396\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3431753218599507\n",
            "Total Loss: -1.364140732927361e-05\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "Var loss:  tensor(-1.3689e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006846190721529877\n",
            "E_s_wdiff_all_sq: 0.0067695930003538185\n",
            "E_IS_SCOPE: 0.0017781336135044945\n",
            "E_IS_E_SCOPE: 0.0018320001337336423\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34320323477637127\n",
            "Total Loss: -1.3688923031116365e-05\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "Var loss:  tensor(-1.3736e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006852650964131004\n",
            "E_s_wdiff_all_sq: 0.006776112658010885\n",
            "E_IS_SCOPE: 0.0017786472662725437\n",
            "E_IS_E_SCOPE: 0.001832507794067405\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432983388462383\n",
            "Total Loss: -1.3736353218483412e-05\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "Var loss:  tensor(-1.3778e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006857714270123826\n",
            "E_s_wdiff_all_sq: 0.006781206181010225\n",
            "E_IS_SCOPE: 0.001779069627611586\n",
            "E_IS_E_SCOPE: 0.001832935784979176\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433785178062012\n",
            "Total Loss: -1.3777829370458135e-05\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "Var loss:  tensor(-1.3822e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006856547113753923\n",
            "E_s_wdiff_all_sq: 0.006780032731837563\n",
            "E_IS_SCOPE: 0.0017791516262055886\n",
            "E_IS_E_SCOPE: 0.0018330431388395823\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433986292633342\n",
            "Total Loss: -1.3822247100506863e-05\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "Var loss:  tensor(-1.3871e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006847063400940559\n",
            "E_s_wdiff_all_sq: 0.006770535654251535\n",
            "E_IS_SCOPE: 0.0017788974972874076\n",
            "E_IS_E_SCOPE: 0.0018328199628161975\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34335681991423\n",
            "Total Loss: -1.3870788117435924e-05\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "Var loss:  tensor(-1.3914e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006833773188344066\n",
            "E_s_wdiff_all_sq: 0.006757231497892931\n",
            "E_IS_SCOPE: 0.001778506763921337\n",
            "E_IS_E_SCOPE: 0.0018324579501476632\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432890011861725\n",
            "Total Loss: -1.3914285750396722e-05\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "Var loss:  tensor(-1.3956e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006822781082339777\n",
            "E_s_wdiff_all_sq: 0.0067462692341785134\n",
            "E_IS_SCOPE: 0.0017783336687270588\n",
            "E_IS_E_SCOPE: 0.0018322908017195916\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3432576879345271\n",
            "Total Loss: -1.3956021572681873e-05\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "Var loss:  tensor(-1.4002e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006819130232086232\n",
            "E_s_wdiff_all_sq: 0.006742691795178515\n",
            "E_IS_SCOPE: 0.0017785791402725997\n",
            "E_IS_E_SCOPE: 0.0018325227395369096\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433011387005531\n",
            "Total Loss: -1.400236536978211e-05\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "Var loss:  tensor(-1.4048e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006819353615150824\n",
            "E_s_wdiff_all_sq: 0.006743011478081604\n",
            "E_IS_SCOPE: 0.0017791003113828828\n",
            "E_IS_E_SCOPE: 0.0018330183962680722\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433939940395574\n",
            "Total Loss: -1.4047636450037308e-05\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "Var loss:  tensor(-1.4086e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006817107972186929\n",
            "E_s_wdiff_all_sq: 0.0067408414899666645\n",
            "E_IS_SCOPE: 0.001779476363788762\n",
            "E_IS_E_SCOPE: 0.0018333760330574455\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34346099299917965\n",
            "Total Loss: -1.4086460065981798e-05\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "Var loss:  tensor(-1.4134e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006810078303728815\n",
            "E_s_wdiff_all_sq: 0.006733862341777682\n",
            "E_IS_SCOPE: 0.0017791015992212672\n",
            "E_IS_E_SCOPE: 0.0018329999821297233\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34339054437177047\n",
            "Total Loss: -1.4134407614657153e-05\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "Var loss:  tensor(-1.4175e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0068024820033227\n",
            "E_s_wdiff_all_sq: 0.006726291173419933\n",
            "E_IS_SCOPE: 0.001778740711626731\n",
            "E_IS_E_SCOPE: 0.0018326468335649413\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34332438622715133\n",
            "Total Loss: -1.4175017722532594e-05\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "Var loss:  tensor(-1.4219e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006797892046620017\n",
            "E_s_wdiff_all_sq: 0.006721714957127475\n",
            "E_IS_SCOPE: 0.001778626120696387\n",
            "E_IS_E_SCOPE: 0.0018325474742652372\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433057724550038\n",
            "Total Loss: -1.4219221394036995e-05\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "Var loss:  tensor(-1.4265e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0067981179485944185\n",
            "E_s_wdiff_all_sq: 0.006721943889189703\n",
            "E_IS_SCOPE: 0.0017787867144235087\n",
            "E_IS_E_SCOPE: 0.001832729469683699\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34333986711208403\n",
            "Total Loss: -1.4265054864543748e-05\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "Var loss:  tensor(-1.4307e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0068005108409524805\n",
            "E_s_wdiff_all_sq: 0.006724361780075819\n",
            "E_IS_SCOPE: 0.0017790970351583368\n",
            "E_IS_E_SCOPE: 0.001833048346805163\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3433996049131723\n",
            "Total Loss: -1.4307166165869988e-05\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "Var loss:  tensor(-1.4349e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0067987266494115815\n",
            "E_s_wdiff_all_sq: 0.0067226311882754375\n",
            "E_IS_SCOPE: 0.0017792787355761376\n",
            "E_IS_E_SCOPE: 0.0018332243083193913\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434325691907219\n",
            "Total Loss: -1.4349288099243553e-05\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "Var loss:  tensor(-1.4395e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006789915684735217\n",
            "E_s_wdiff_all_sq: 0.006713864211819286\n",
            "E_IS_SCOPE: 0.0017791906642520053\n",
            "E_IS_E_SCOPE: 0.0018331369366315772\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34341620115376953\n",
            "Total Loss: -1.4394675592091857e-05\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "Var loss:  tensor(-1.4439e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006776624228672\n",
            "E_s_wdiff_all_sq: 0.0067006032955471695\n",
            "E_IS_SCOPE: 0.001778956551708027\n",
            "E_IS_E_SCOPE: 0.0018329097961023624\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34337364910208573\n",
            "Total Loss: -1.4439159412720642e-05\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "Var loss:  tensor(-1.4481e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0067640049320347815\n",
            "E_s_wdiff_all_sq: 0.00668800340701262\n",
            "E_IS_SCOPE: 0.0017787675284066822\n",
            "E_IS_E_SCOPE: 0.0018327321479140234\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34334036884638736\n",
            "Total Loss: -1.4481317741400247e-05\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "Var loss:  tensor(-1.4525e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006756834546800979\n",
            "E_s_wdiff_all_sq: 0.006680845500065329\n",
            "E_IS_SCOPE: 0.0017788075837403912\n",
            "E_IS_E_SCOPE: 0.0018327875907127968\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34335075538923404\n",
            "Total Loss: -1.4524570958039662e-05\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "Var loss:  tensor(-1.4570e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006755338980686577\n",
            "E_s_wdiff_all_sq: 0.0066793912434912695\n",
            "E_IS_SCOPE: 0.001779130293827835\n",
            "E_IS_E_SCOPE: 0.0018331121308456583\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34341155408753204\n",
            "Total Loss: -1.4569540589219089e-05\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "Var loss:  tensor(-1.4612e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.0067547010954641705\n",
            "E_s_wdiff_all_sq: 0.0066788159773432405\n",
            "E_IS_SCOPE: 0.0017794939461938612\n",
            "E_IS_E_SCOPE: 0.0018334657610389088\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.3434778024594636\n",
            "Total Loss: -1.4612115318044828e-05\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "Var loss:  tensor(-1.4651e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 4.59400575122907e-05\n",
            "E_IS_all_sq: 2.849366126116997e-05\n",
            "E_s_wdiff_sq: 0.006753017036135768\n",
            "E_s_wdiff_all_sq: 0.006677155201190729\n",
            "E_IS_SCOPE: 0.0017796726673345565\n",
            "E_IS_E_SCOPE: 0.001833652332214189\n",
            "E_IS: 0.00533794541571661\n",
            "E_SCOPE: 0.34351275432965894\n",
            "Total Loss: -1.4651098563105668e-05\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.9769,  0.0724],\n",
            "        [ 0.6969,  0.4488],\n",
            "        [-1.5896,  0.3752],\n",
            "        [-0.0221,  0.2940],\n",
            "        [-0.6047, -0.3891],\n",
            "        [-0.0771,  0.5528],\n",
            "        [-0.1005,  0.3221],\n",
            "        [-0.5039, -0.3187],\n",
            "        [ 0.4633,  0.4756],\n",
            "        [ 0.1364,  0.2327],\n",
            "        [ 0.1394,  0.3708],\n",
            "        [-0.7176,  0.4508],\n",
            "        [-0.4361, -0.3395],\n",
            "        [ 0.0741,  0.2789],\n",
            "        [ 0.0727,  0.4698],\n",
            "        [ 0.4663,  0.4804]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.2933, -0.8144, -1.1794, -1.0311,  1.4529, -0.7313, -0.0736, -0.1389,\n",
            "        -1.2731, -0.5037, -1.1173, -0.8247,  1.4548, -0.2017, -0.0043, -0.3454],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-4.7614e-01, -1.4910e-01, -1.0205e-01, -4.1658e-01, -5.7170e-01,\n",
            "         -1.4432e-01, -1.8820e-01, -2.0606e-01,  4.2297e-01, -3.6056e-01,\n",
            "         -3.1370e-01, -1.8842e-01, -1.9301e+00, -9.0380e-02,  4.9186e-01,\n",
            "         -2.2888e-02],\n",
            "        [-1.0728e+00, -2.3505e-01, -1.2268e-01,  5.4058e-01,  1.9815e+00,\n",
            "          2.7314e-01,  5.7328e-01,  1.8707e-01, -1.5496e+00, -9.5550e-01,\n",
            "         -1.4232e+00, -7.6373e-01, -6.9622e-01,  2.4819e-01, -5.5479e-01,\n",
            "          2.2723e-01],\n",
            "        [-4.7531e-01,  5.1908e-02,  1.8855e-01, -3.4588e-01, -1.4600e-01,\n",
            "          1.2124e-01, -1.7821e-01,  1.3262e-01, -3.3575e-02,  2.9383e-02,\n",
            "          3.1331e-01, -9.3203e-02, -7.0437e-01, -1.1321e-02, -1.3066e-01,\n",
            "          4.8148e-02],\n",
            "        [-1.7937e-01, -1.0029e-01,  5.4967e-01,  2.2687e-01, -1.1784e-01,\n",
            "          8.2857e-03, -9.8037e-02,  2.0990e-01,  2.8726e-01, -3.9050e-01,\n",
            "         -1.1403e-01, -2.9402e-01,  5.7405e-02,  1.8943e-01, -1.9784e+00,\n",
            "         -3.7708e-03],\n",
            "        [ 6.0260e-02, -1.7511e-01, -9.5208e-02, -1.1249e-01, -2.2511e-02,\n",
            "         -4.5419e-02, -2.2311e-01,  1.3308e-01, -9.3237e-02, -1.7998e-01,\n",
            "         -8.9013e-02, -1.7759e-01, -1.9166e-01, -7.7538e-02, -1.1132e-01,\n",
            "         -1.4784e-01],\n",
            "        [-3.2977e-01,  4.3845e-02, -3.1738e-01,  9.1152e-02, -2.0538e-02,\n",
            "         -2.8111e-02, -1.5515e-01, -1.2071e-01,  7.7202e-02, -1.0712e-01,\n",
            "         -2.1193e-01,  4.4626e-01, -1.1359e+00,  1.1682e-02, -7.9946e-03,\n",
            "         -2.4046e-01],\n",
            "        [-6.9682e-01, -2.0948e-01, -3.4558e+00, -7.5938e-01, -8.8985e-02,\n",
            "         -1.2825e+00,  1.3403e-02, -8.5113e-02,  2.3566e-01,  9.2149e-01,\n",
            "         -2.0930e+00,  4.4495e-01,  6.9820e-01,  3.8841e-01,  3.5530e-01,\n",
            "         -4.0712e-01],\n",
            "        [-6.3668e-01,  2.0454e-01, -1.6401e+00, -4.0572e-01, -9.1571e-01,\n",
            "         -9.7896e-01, -9.4767e-02,  2.0256e-01, -1.3078e+00,  6.4319e-01,\n",
            "         -3.9522e-02, -2.1109e-01,  4.3717e-01, -3.8140e-01, -5.9230e-02,\n",
            "          1.3835e-01],\n",
            "        [-8.3148e-01,  1.9619e-02,  3.5535e-01, -2.7664e-01, -4.5328e-01,\n",
            "         -1.8351e-01,  5.6378e-02,  1.2121e-01, -1.7310e-01, -1.6140e-01,\n",
            "         -4.1801e-01,  4.2884e-01, -1.6019e+00,  2.6687e-01, -5.5326e-03,\n",
            "          1.6769e-01],\n",
            "        [-5.2804e-01, -1.0095e-01, -2.9166e-01,  1.2226e-01, -2.5855e-01,\n",
            "         -1.4747e-01,  2.7398e-02, -7.6229e-02, -2.3592e-01, -1.5132e-01,\n",
            "         -2.1204e-01, -2.6907e-01, -1.3194e-01, -5.7363e-03, -1.8427e-01,\n",
            "          1.2010e-01],\n",
            "        [-8.7448e-01, -3.2822e-01, -1.5802e+00, -7.7296e-01,  9.4348e-01,\n",
            "         -2.0198e-02,  1.3901e-02,  1.5158e-01,  5.7351e-01, -3.5397e-01,\n",
            "          4.9544e-01, -1.0385e-01, -8.7939e-01, -3.6197e-01, -2.1529e-01,\n",
            "          1.7177e-01],\n",
            "        [-2.0534e-01, -2.6942e-01, -6.1973e-02,  3.9810e-03,  2.1372e-01,\n",
            "         -3.4348e-01, -6.0143e-02,  2.0823e-01,  1.1023e-02,  4.6047e-01,\n",
            "          2.3347e-01,  2.5122e-01, -3.7165e-01, -5.6489e-02, -1.3146e-01,\n",
            "         -2.0067e-01],\n",
            "        [-8.5625e-02, -6.3145e-01, -4.2588e-01, -1.1835e-01,  6.7335e-01,\n",
            "         -6.6232e-01, -6.5663e-01,  1.6418e-01, -6.6383e-01, -7.2889e-01,\n",
            "         -6.6826e-01, -6.5961e-01, -6.7999e-01, -6.6731e-01,  2.5676e-01,\n",
            "         -1.9131e-01],\n",
            "        [-6.0008e-01,  1.7827e-01, -1.9500e-02, -1.9735e-01, -3.1242e-01,\n",
            "         -1.0063e-02,  2.2509e-02,  1.9790e-02,  1.0495e-01, -4.1060e-02,\n",
            "         -4.3218e-02,  4.2709e-03,  2.2795e-01, -2.4273e-01, -1.0406e-01,\n",
            "          1.0861e-01],\n",
            "        [-3.3897e-01, -7.2774e-01, -9.3320e-01,  8.5963e-01,  7.6245e-01,\n",
            "          2.2956e-02,  2.4257e-02,  3.7099e-02,  8.2831e-01, -9.0598e-01,\n",
            "         -2.4396e+00, -8.5502e-01, -1.0724e+00,  5.5989e-01, -6.3063e-01,\n",
            "         -7.1798e-01],\n",
            "        [-9.6088e-01,  1.7483e-01,  4.2253e-01, -6.6650e-02,  3.6868e-02,\n",
            "         -3.0713e-03,  1.0189e-01,  7.6178e-02, -3.5303e-01,  4.8398e-02,\n",
            "         -1.2035e-01, -1.8584e-01,  8.5943e-02,  1.8892e-01, -4.0218e-02,\n",
            "         -1.5862e-01],\n",
            "        [-4.8227e-01,  1.8177e-01, -1.8283e-02, -1.8421e-01, -5.0877e-02,\n",
            "         -2.4720e-02,  8.9918e-02, -2.3155e-02, -7.0982e-02, -4.7723e-02,\n",
            "         -1.0714e-01, -1.3463e-01, -3.2453e-01,  8.9568e-02,  1.1575e-01,\n",
            "         -2.3582e-01],\n",
            "        [ 1.4505e-01, -3.2823e-01, -1.8609e-01, -1.1955e-01, -3.3027e-01,\n",
            "          4.6619e-02,  2.8335e-02,  1.1343e-01,  1.8845e-01, -7.3289e-01,\n",
            "         -1.1930e-01,  2.1179e-01, -4.4385e-01, -1.2722e-01, -1.1158e-01,\n",
            "          1.0917e-01],\n",
            "        [-5.9077e-01, -2.2605e-01, -3.8453e-01, -3.1827e-01, -4.4023e-01,\n",
            "          3.2823e-01,  3.1466e-01,  1.7340e-01, -5.0002e-01,  7.4433e-01,\n",
            "          1.3979e-01, -2.8922e-02,  3.1274e-01, -6.4029e-01, -8.7809e-02,\n",
            "         -3.8343e-01],\n",
            "        [-2.7170e-01,  2.4171e-01,  3.1363e-01,  1.6837e-01,  2.1372e-01,\n",
            "         -2.5282e-02, -3.3091e-01, -4.8768e-02,  1.7934e-02, -2.1352e-02,\n",
            "         -4.4300e-01,  1.4544e-01,  3.6780e-01,  1.3548e-01,  5.3026e-02,\n",
            "         -4.3632e-01],\n",
            "        [-4.5283e-01, -1.6012e-01,  3.2549e-01, -8.3630e-02,  4.3380e-01,\n",
            "          1.6669e-02, -1.1964e-01, -1.4217e-01,  1.7927e-01, -3.0818e-01,\n",
            "         -2.4350e-01, -2.1982e-01,  8.6054e-02, -1.4051e-02,  2.0717e-01,\n",
            "         -5.2584e-02],\n",
            "        [-5.5177e-01,  1.6577e-01, -9.7562e-02, -9.5355e-02, -8.0661e-01,\n",
            "          7.4383e-02,  3.1139e-01,  4.1258e-02, -2.8141e-01, -3.1842e-01,\n",
            "         -3.1748e-01, -2.8432e-01, -1.5020e+00, -3.3172e-01,  2.0610e-01,\n",
            "         -3.6456e-02],\n",
            "        [-5.5507e-01,  2.5897e-02,  2.1300e-01,  3.0303e-01, -2.5300e-01,\n",
            "         -2.4900e-02, -5.1500e-02, -2.0634e-01, -8.8717e-02,  8.5337e-02,\n",
            "         -1.2231e-02, -2.8665e-01,  1.4953e-01, -9.2724e-02, -4.8803e-02,\n",
            "         -9.1286e-02],\n",
            "        [-1.0503e+00, -3.0663e-01,  2.1998e-01, -2.7986e-01,  6.4077e-01,\n",
            "          2.5511e-01, -5.0431e-01,  3.4968e-02,  1.8737e-01,  1.2465e-02,\n",
            "         -5.7497e-01, -1.0084e-01, -8.5351e-01, -1.3784e-01,  9.5989e-02,\n",
            "          6.9369e-02],\n",
            "        [-3.1488e-01, -2.3693e-01,  1.9029e-02, -4.8956e-02, -5.5540e-01,\n",
            "         -1.7323e-01,  2.5129e-01,  1.2421e-01,  2.0781e-01,  2.3179e-01,\n",
            "          3.9133e-01,  1.1188e-01,  8.2027e-02, -1.1049e-01, -9.4004e-02,\n",
            "         -1.7661e-01],\n",
            "        [ 2.0457e-01,  3.4666e-01, -5.8925e-01,  3.5945e-02, -2.5725e+00,\n",
            "         -2.8277e-01,  3.0667e-01,  1.9735e-01, -4.2343e-01,  1.6826e-01,\n",
            "          7.0740e-02, -2.0550e-01, -5.5267e-01, -2.9680e-01, -2.9145e-01,\n",
            "         -7.2828e-03],\n",
            "        [-4.2699e-01, -3.9614e-01, -2.3178e-01,  1.1008e-01, -4.3318e-01,\n",
            "         -2.0670e-02, -2.4767e-01, -1.9318e-01,  2.9174e-01, -1.1854e-01,\n",
            "          1.1491e-02, -2.4902e-01, -8.2660e-01,  1.2924e-01, -6.1424e-02,\n",
            "          2.1175e-01],\n",
            "        [-4.2356e-01, -1.7814e-01, -2.7557e-01,  7.6894e-01, -1.8242e+00,\n",
            "          2.2851e-02,  1.1327e-01, -2.2396e-01, -3.9337e-01,  9.9625e-02,\n",
            "         -3.2372e-02,  7.2727e-03,  3.8481e-01, -3.0005e-01,  1.5320e-01,\n",
            "         -1.4462e-01],\n",
            "        [-4.5472e-01, -5.7308e-02, -4.2522e-02, -3.5891e-01,  1.0794e+00,\n",
            "          1.3928e-01,  4.0495e-02, -1.6101e-01, -1.8592e-01, -2.3352e-01,\n",
            "          2.1383e-02, -1.1270e-01,  8.6461e-02,  4.4739e-01,  6.4710e-03,\n",
            "         -6.0807e-02],\n",
            "        [-7.4895e-01, -1.8998e-01,  1.5388e-01, -3.3101e-01, -5.5339e-01,\n",
            "         -3.5757e-01,  1.0418e-01,  1.2268e-02, -3.2199e-01,  1.3750e-01,\n",
            "          2.2693e-02,  8.9345e-02, -5.9779e-01,  4.7710e-01, -8.3099e-03,\n",
            "          5.5549e-02],\n",
            "        [-4.5722e-01, -2.3438e-01, -1.1004e-01,  9.6238e-02, -2.2165e-01,\n",
            "          1.4829e-01, -1.4968e-01, -9.6302e-02, -2.2475e-02,  4.8599e-01,\n",
            "         -2.6578e-01,  1.4427e-01, -6.7987e-01, -1.8571e-01, -1.9237e-01,\n",
            "          1.9399e-01],\n",
            "        [-5.8105e-01,  1.6370e-01, -4.9422e-02, -1.6259e-02,  4.1006e-01,\n",
            "         -2.5211e-02, -2.6734e-01, -1.7969e-01, -1.3759e-01, -1.6161e-01,\n",
            "          2.5151e-01,  8.5548e-02, -1.2453e-01, -4.4118e-01,  2.6598e-01,\n",
            "         -1.1054e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.2741,  0.1855,  0.2864,  0.1002, -0.0589, -0.0922, -0.9872,  0.6741,\n",
            "        -0.0221, -0.2129,  0.2163, -0.0224,  0.7326, -0.0059,  0.7926, -0.0012,\n",
            "        -0.0055, -0.0723,  0.0878, -0.1708, -0.1365, -0.0552,  0.4148,  0.3129,\n",
            "         0.2752, -0.5527, -0.1272, -0.2919, -0.6591, -0.0499,  0.1583, -0.0450],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.4725, -1.3076,  0.0564,  0.2994, -0.0656,  0.1322, -1.3779, -1.3205,\n",
            "          0.0800, -0.0314, -0.9267,  0.0677, -1.3160,  0.1819, -2.4958,  0.1375,\n",
            "          0.1413,  0.3218,  0.2385,  0.0051,  0.1704,  0.0360,  0.1971, -0.5084,\n",
            "          0.1268,  0.6387,  0.3282,  0.1390,  0.2706,  0.1321,  0.2046,  0.1589]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0096], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "KSJyBHPzRNxa",
        "outputId": "a0b1bfb7-01d7-4046-c89a-002a9965ec98"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'state_tensors' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-4b4a7e04ff2f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'state_tensors' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_psi_tensors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZB8qyrwNoUs",
        "outputId": "c250c5d9-04b7-4566-8ca0-3e3150ec68e6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 58, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLAXsU4iDCSM",
        "outputId": "19515bc6-0814-45bc-b433-6f07486d0493"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 400 Trajectories"
      ],
      "metadata": {
        "id": "yPC_HXwnofdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "400 Trajectories:"
      ],
      "metadata": {
        "id": "Scyb9IqfnsrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(400, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(400, env, P_pi_e)"
      ],
      "metadata": {
        "id": "doNhEhzfn1gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_400 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "xdkFnhHDn1gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_400 = SCOPE_variance_play(model_400, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "hGLJ8iDxn1g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing_400.prepare()"
      ],
      "metadata": {
        "id": "yMk8bwNKn1g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_400 = train_var_play(model_400, 800, 0.0007, padded_state_tensors, states_first_tensor, states_last_tensor, testing_400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCPsi8VmoFGu",
        "outputId": "6462a410-c38e-4c68-f343-3e8dc651c28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "E_s_wdiff_sq: 3.818623501816317e-06\n",
            "E_s_wdiff_all_sq: 5.1504677041227486e-08\n",
            "E_IS_SCOPE: -1.5581479430685247e-06\n",
            "E_IS_E_SCOPE: 4.658730291707227e-08\n",
            "Total Loss: 1.9661124687824543e-06\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "Var loss:  tensor(1.9614e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.820825995560044e-06\n",
            "E_s_wdiff_all_sq: 5.349843717599916e-08\n",
            "E_IS_SCOPE: -1.5618117588208178e-06\n",
            "E_IS_E_SCOPE: 4.537144321640203e-08\n",
            "Total Loss: 1.9614252902881636e-06\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "Var loss:  tensor(1.9567e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.817179748592323e-06\n",
            "E_s_wdiff_all_sq: 5.362001030560776e-08\n",
            "E_IS_SCOPE: -1.5574684865952953e-06\n",
            "E_IS_E_SCOPE: 5.019030585161591e-08\n",
            "Total Loss: 1.9567062893714516e-06\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "Var loss:  tensor(1.9520e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.8102695496245794e-06\n",
            "E_s_wdiff_all_sq: 5.351965390706791e-08\n",
            "E_IS_SCOPE: -1.5496881090180883e-06\n",
            "E_IS_E_SCOPE: 5.692225929859327e-08\n",
            "Total Loss: 1.951993295062707e-06\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "Var loss:  tensor(1.9473e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.8042120855996862e-06\n",
            "E_s_wdiff_all_sq: 5.426719255537616e-08\n",
            "E_IS_SCOPE: -1.5483929261767892e-06\n",
            "E_IS_E_SCOPE: 5.716407988774271e-08\n",
            "Total Loss: 1.9472950168938054e-06\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "Var loss:  tensor(1.9426e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.804982542069374e-06\n",
            "E_s_wdiff_all_sq: 5.652200043327136e-08\n",
            "E_IS_SCOPE: -1.5548999760581681e-06\n",
            "E_IS_E_SCOPE: 5.227641349899561e-08\n",
            "Total Loss: 1.942571898500334e-06\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "Var loss:  tensor(1.9378e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.8055618655664216e-06\n",
            "E_s_wdiff_all_sq: 5.757077220552158e-08\n",
            "E_IS_SCOPE: -1.5552189103616716e-06\n",
            "E_IS_E_SCOPE: 5.4087554592914954e-08\n",
            "Total Loss: 1.9378422994302857e-06\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "Var loss:  tensor(1.9331e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.798510727209711e-06\n",
            "E_s_wdiff_all_sq: 5.552828002125418e-08\n",
            "E_IS_SCOPE: -1.5405495333573405e-06\n",
            "E_IS_E_SCOPE: 6.862668615973915e-08\n",
            "Total Loss: 1.9330941441328564e-06\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "Var loss:  tensor(1.9283e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.790270148934778e-06\n",
            "E_s_wdiff_all_sq: 5.453871222568934e-08\n",
            "E_IS_SCOPE: -1.526064641576727e-06\n",
            "E_IS_E_SCOPE: 8.187589334726548e-08\n",
            "Total Loss: 1.9283145028396626e-06\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "Var loss:  tensor(1.9235e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7904909764953464e-06\n",
            "E_s_wdiff_all_sq: 5.804889935451536e-08\n",
            "E_IS_SCOPE: -1.525884690446034e-06\n",
            "E_IS_E_SCOPE: 8.282463292799453e-08\n",
            "Total Loss: 1.9234875663713328e-06\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "Var loss:  tensor(1.9187e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7955571837747704e-06\n",
            "E_s_wdiff_all_sq: 6.22212492840062e-08\n",
            "E_IS_SCOPE: -1.5302552007573844e-06\n",
            "E_IS_E_SCOPE: 8.130789834674959e-08\n",
            "Total Loss: 1.9186738722610547e-06\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "Var loss:  tensor(1.9138e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7961569280716486e-06\n",
            "E_s_wdiff_all_sq: 6.32911379046613e-08\n",
            "E_IS_SCOPE: -1.520454075290415e-06\n",
            "E_IS_E_SCOPE: 9.331385745585897e-08\n",
            "Total Loss: 1.9137940606529974e-06\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "Var loss:  tensor(1.9090e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.786826922531497e-06\n",
            "E_s_wdiff_all_sq: 6.279261447199095e-08\n",
            "E_IS_SCOPE: -1.5020486290623589e-06\n",
            "E_IS_E_SCOPE: 1.0972541021573765e-07\n",
            "Total Loss: 1.9089503654818712e-06\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "Var loss:  tensor(1.9041e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7803770914590023e-06\n",
            "E_s_wdiff_all_sq: 6.524564717558048e-08\n",
            "E_IS_SCOPE: -1.4966451475433453e-06\n",
            "E_IS_E_SCOPE: 1.1311330835956638e-07\n",
            "Total Loss: 1.9040786684561571e-06\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "Var loss:  tensor(1.8992e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7854346408474362e-06\n",
            "E_s_wdiff_all_sq: 7.059717420984574e-08\n",
            "E_IS_SCOPE: -1.509038371437111e-06\n",
            "E_IS_E_SCOPE: 1.0300913241957995e-07\n",
            "Total Loss: 1.899206594902767e-06\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "Var loss:  tensor(1.8943e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.790529699127186e-06\n",
            "E_s_wdiff_all_sq: 7.327126745700238e-08\n",
            "E_IS_SCOPE: -1.5142739244543384e-06\n",
            "E_IS_E_SCOPE: 1.0144351016462772e-07\n",
            "Total Loss: 1.8942876984108102e-06\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "Var loss:  tensor(1.8894e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.784337306223748e-06\n",
            "E_s_wdiff_all_sq: 7.185574116858227e-08\n",
            "E_IS_SCOPE: -1.5034674115412997e-06\n",
            "E_IS_E_SCOPE: 1.1231163642986695e-07\n",
            "Total Loss: 1.8893876050913911e-06\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "Var loss:  tensor(1.8845e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.775160057954662e-06\n",
            "E_s_wdiff_all_sq: 7.111456637286677e-08\n",
            "E_IS_SCOPE: -1.491516488524886e-06\n",
            "E_IS_E_SCOPE: 1.2250551507475027e-07\n",
            "Total Loss: 1.8844656203610816e-06\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "Var loss:  tensor(1.8796e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7721808310783007e-06\n",
            "E_s_wdiff_all_sq: 7.287105642659794e-08\n",
            "E_IS_SCOPE: -1.4879690464282344e-06\n",
            "E_IS_E_SCOPE: 1.2613027706393712e-07\n",
            "Total Loss: 1.8795752636459187e-06\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "Var loss:  tensor(1.8747e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.77234942339239e-06\n",
            "E_s_wdiff_all_sq: 7.42446496567738e-08\n",
            "E_IS_SCOPE: -1.4875964440226083e-06\n",
            "E_IS_E_SCOPE: 1.2834126577762234e-07\n",
            "Total Loss: 1.8746934901137132e-06\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "Var loss:  tensor(1.8698e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.770752326655044e-06\n",
            "E_s_wdiff_all_sq: 7.506216453541281e-08\n",
            "E_IS_SCOPE: -1.4864272481605577e-06\n",
            "E_IS_E_SCOPE: 1.307279170841289e-07\n",
            "Total Loss: 1.8698439676088166e-06\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "Var loss:  tensor(1.8650e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.767129891637057e-06\n",
            "E_s_wdiff_all_sq: 7.709446967845876e-08\n",
            "E_IS_SCOPE: -1.4842984384256124e-06\n",
            "E_IS_E_SCOPE: 1.324603360923526e-07\n",
            "Total Loss: 1.8649820089012273e-06\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "Var loss:  tensor(1.8601e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.765181548532679e-06\n",
            "E_s_wdiff_all_sq: 8.095025465855577e-08\n",
            "E_IS_SCOPE: -1.4844289737992038e-06\n",
            "E_IS_E_SCOPE: 1.3185627707224403e-07\n",
            "Total Loss: 1.860124928109786e-06\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "Var loss:  tensor(1.8553e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7658642025493426e-06\n",
            "E_s_wdiff_all_sq: 8.40229706435564e-08\n",
            "E_IS_SCOPE: -1.4798727318029115e-06\n",
            "E_IS_E_SCOPE: 1.3765119477300723e-07\n",
            "Total Loss: 1.8552575147325072e-06\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "Var loss:  tensor(1.8504e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7660326784611444e-06\n",
            "E_s_wdiff_all_sq: 8.497646873087636e-08\n",
            "E_IS_SCOPE: -1.468849553543189e-06\n",
            "E_IS_E_SCOPE: 1.5071685731312529e-07\n",
            "Total Loss: 1.8503875239961976e-06\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "Var loss:  tensor(1.8455e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7619343606472476e-06\n",
            "E_s_wdiff_all_sq: 8.544964234426646e-08\n",
            "E_IS_SCOPE: -1.4579249354077354e-06\n",
            "E_IS_E_SCOPE: 1.6178454674744187e-07\n",
            "Total Loss: 1.8455298899711852e-06\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "Var loss:  tensor(1.8406e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7600946228670487e-06\n",
            "E_s_wdiff_all_sq: 8.809450522234825e-08\n",
            "E_IS_SCOPE: -1.451416259351488e-06\n",
            "E_IS_E_SCOPE: 1.6849118292055114e-07\n",
            "Total Loss: 1.8406493690791807e-06\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "Var loss:  tensor(1.8359e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.757682342016531e-06\n",
            "E_s_wdiff_all_sq: 9.00458463095084e-08\n",
            "E_IS_SCOPE: -1.447039587416338e-06\n",
            "E_IS_E_SCOPE: 1.7306437678869136e-07\n",
            "Total Loss: 1.8358927032755224e-06\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "Var loss:  tensor(1.8312e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.75551507572102e-06\n",
            "E_s_wdiff_all_sq: 9.182863367047385e-08\n",
            "E_IS_SCOPE: -1.4435375108617628e-06\n",
            "E_IS_E_SCOPE: 1.7695480182390263e-07\n",
            "Total Loss: 1.8311659526577743e-06\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "Var loss:  tensor(1.8265e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7544158042732373e-06\n",
            "E_s_wdiff_all_sq: 9.472205138403982e-08\n",
            "E_IS_SCOPE: -1.4428416693245636e-06\n",
            "E_IS_E_SCOPE: 1.780022642462238e-07\n",
            "Total Loss: 1.826470021726181e-06\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "Var loss:  tensor(1.8218e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7575855619220727e-06\n",
            "E_s_wdiff_all_sq: 1.0064280470814462e-07\n",
            "E_IS_SCOPE: -1.4439179643524032e-06\n",
            "E_IS_E_SCOPE: 1.7790018014021756e-07\n",
            "Total Loss: 1.8217706042072454e-06\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "Var loss:  tensor(1.8171e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7575885667816687e-06\n",
            "E_s_wdiff_all_sq: 1.0474023214216893e-07\n",
            "E_IS_SCOPE: -1.4374300987860145e-06\n",
            "E_IS_E_SCOPE: 1.846938871137807e-07\n",
            "Total Loss: 1.8170644988184686e-06\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "Var loss:  tensor(1.8124e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7551798133805533e-06\n",
            "E_s_wdiff_all_sq: 1.0675741232987876e-07\n",
            "E_IS_SCOPE: -1.4272305366414886e-06\n",
            "E_IS_E_SCOPE: 1.9500581185486548e-07\n",
            "Total Loss: 1.8124138400365254e-06\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "Var loss:  tensor(1.8077e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7576141519037626e-06\n",
            "E_s_wdiff_all_sq: 1.1116752776569916e-07\n",
            "E_IS_SCOPE: -1.424151582533098e-06\n",
            "E_IS_E_SCOPE: 1.994640913343094e-07\n",
            "Total Loss: 1.8076794123818077e-06\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "Var loss:  tensor(1.8030e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7584396618938392e-06\n",
            "E_s_wdiff_all_sq: 1.1533044203138325e-07\n",
            "E_IS_SCOPE: -1.4223715772081997e-06\n",
            "E_IS_E_SCOPE: 2.0191730685428918e-07\n",
            "Total Loss: 1.8029955877160362e-06\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "Var loss:  tensor(1.7982e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7567478209384725e-06\n",
            "E_s_wdiff_all_sq: 1.1827526883093285e-07\n",
            "E_IS_SCOPE: -1.4217130358130593e-06\n",
            "E_IS_E_SCOPE: 2.026406721772029e-07\n",
            "Total Loss: 1.7982292721055736e-06\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "Var loss:  tensor(1.7935e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7556132728851553e-06\n",
            "E_s_wdiff_all_sq: 1.199461052158855e-07\n",
            "E_IS_SCOPE: -1.424675153612149e-06\n",
            "E_IS_E_SCOPE: 2.0065871131143753e-07\n",
            "Total Loss: 1.7934635738006547e-06\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "Var loss:  tensor(1.7887e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7584566417691074e-06\n",
            "E_s_wdiff_all_sq: 1.232436856877907e-07\n",
            "E_IS_SCOPE: -1.4321889419080717e-06\n",
            "E_IS_E_SCOPE: 1.953038850081046e-07\n",
            "Total Loss: 1.7886914382275232e-06\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "Var loss:  tensor(1.7839e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.751909393234119e-06\n",
            "E_s_wdiff_all_sq: 1.2300531513482188e-07\n",
            "E_IS_SCOPE: -1.4301044991237712e-06\n",
            "E_IS_E_SCOPE: 1.9661735392965532e-07\n",
            "Total Loss: 1.783924507971003e-06\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "Var loss:  tensor(1.7792e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7426702296057616e-06\n",
            "E_s_wdiff_all_sq: 1.2102976332236097e-07\n",
            "E_IS_SCOPE: -1.4225149171005258e-06\n",
            "E_IS_E_SCOPE: 2.0295571758882008e-07\n",
            "Total Loss: 1.7791633328832678e-06\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "Var loss:  tensor(1.7744e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740613562403396e-06\n",
            "E_s_wdiff_all_sq: 1.2129520375643128e-07\n",
            "E_IS_SCOPE: -1.421493970805026e-06\n",
            "E_IS_E_SCOPE: 2.0520371671411655e-07\n",
            "Total Loss: 1.7743871195872385e-06\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "Var loss:  tensor(1.7696e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7454435670910924e-06\n",
            "E_s_wdiff_all_sq: 1.2530839961673778e-07\n",
            "E_IS_SCOPE: -1.4276185079663123e-06\n",
            "E_IS_E_SCOPE: 2.0187165068873773e-07\n",
            "Total Loss: 1.7696189861428132e-06\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "Var loss:  tensor(1.7648e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7459221415122328e-06\n",
            "E_s_wdiff_all_sq: 1.291212062427238e-07\n",
            "E_IS_SCOPE: -1.4272799753946659e-06\n",
            "E_IS_E_SCOPE: 2.0293544445274298e-07\n",
            "Total Loss: 1.7648342315532504e-06\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "Var loss:  tensor(1.7600e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7399299154704283e-06\n",
            "E_s_wdiff_all_sq: 1.3072748312426112e-07\n",
            "E_IS_SCOPE: -1.4184960631559778e-06\n",
            "E_IS_E_SCOPE: 2.1031858057901672e-07\n",
            "Total Loss: 1.760037280854737e-06\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "Var loss:  tensor(1.7552e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7406837829684978e-06\n",
            "E_s_wdiff_all_sq: 1.3506336664358868e-07\n",
            "E_IS_SCOPE: -1.4137671276307386e-06\n",
            "E_IS_E_SCOPE: 2.1565822352646195e-07\n",
            "Total Loss: 1.755233849989067e-06\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "Var loss:  tensor(1.7504e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743654280630289e-06\n",
            "E_s_wdiff_all_sq: 1.3996351476917186e-07\n",
            "E_IS_SCOPE: -1.412867440924263e-06\n",
            "E_IS_E_SCOPE: 2.1798604547829635e-07\n",
            "Total Loss: 1.7504479290345572e-06\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "Var loss:  tensor(1.7456e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7452597737330147e-06\n",
            "E_s_wdiff_all_sq: 1.4489302309243449e-07\n",
            "E_IS_SCOPE: -1.411155266132268e-06\n",
            "E_IS_E_SCOPE: 2.2043579042434372e-07\n",
            "Total Loss: 1.7456487735059155e-06\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "Var loss:  tensor(1.7408e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.742935734773599e-06\n",
            "E_s_wdiff_all_sq: 1.4824170450959423e-07\n",
            "E_IS_SCOPE: -1.4071952729822862e-06\n",
            "E_IS_E_SCOPE: 2.2396555480479237e-07\n",
            "Total Loss: 1.7408365106684064e-06\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "Var loss:  tensor(1.7360e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.742488938219067e-06\n",
            "E_s_wdiff_all_sq: 1.5197996303608735e-07\n",
            "E_IS_SCOPE: -1.4070947990651948e-06\n",
            "E_IS_E_SCOPE: 2.2437819815570512e-07\n",
            "Total Loss: 1.736027116719738e-06\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "Var loss:  tensor(1.7312e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7472165992098974e-06\n",
            "E_s_wdiff_all_sq: 1.5714471267095792e-07\n",
            "E_IS_SCOPE: -1.4139285904421034e-06\n",
            "E_IS_E_SCOPE: 2.1973647611496104e-07\n",
            "Total Loss: 1.731205889403369e-06\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "Var loss:  tensor(1.7264e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7478797292148425e-06\n",
            "E_s_wdiff_all_sq: 1.603551335452879e-07\n",
            "E_IS_SCOPE: -1.416830747439832e-06\n",
            "E_IS_E_SCOPE: 2.1795558749652212e-07\n",
            "Total Loss: 1.7264160617754051e-06\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "Var loss:  tensor(1.7216e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.747125464557556e-06\n",
            "E_s_wdiff_all_sq: 1.6376491046864126e-07\n",
            "E_IS_SCOPE: -1.4171718278892545e-06\n",
            "E_IS_E_SCOPE: 2.1794605881402009e-07\n",
            "Total Loss: 1.7215889166609243e-06\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "Var loss:  tensor(1.7168e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743677530338166e-06\n",
            "E_s_wdiff_all_sq: 1.6536708407784184e-07\n",
            "E_IS_SCOPE: -1.4133458031491908e-06\n",
            "E_IS_E_SCOPE: 2.2163739987140744e-07\n",
            "Total Loss: 1.7168081761976867e-06\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "Var loss:  tensor(1.7120e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743135663728983e-06\n",
            "E_s_wdiff_all_sq: 1.6805534344425272e-07\n",
            "E_IS_SCOPE: -1.4103977949929978e-06\n",
            "E_IS_E_SCOPE: 2.25376434877616e-07\n",
            "Total Loss: 1.7119959965220617e-06\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "Var loss:  tensor(1.7072e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7464769811575023e-06\n",
            "E_s_wdiff_all_sq: 1.7297790838333208e-07\n",
            "E_IS_SCOPE: -1.411372401843724e-06\n",
            "E_IS_E_SCOPE: 2.2602025910766937e-07\n",
            "Total Loss: 1.7071778868499418e-06\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "Var loss:  tensor(1.7023e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.742690478060719e-06\n",
            "E_s_wdiff_all_sq: 1.7469352512173506e-07\n",
            "E_IS_SCOPE: -1.402651821751086e-06\n",
            "E_IS_E_SCOPE: 2.344387526909342e-07\n",
            "Total Loss: 1.702279940033502e-06\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "Var loss:  tensor(1.6974e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740070497218484e-06\n",
            "E_s_wdiff_all_sq: 1.7689496259153805e-07\n",
            "E_IS_SCOPE: -1.3948534541085544e-06\n",
            "E_IS_E_SCOPE: 2.4225427373524025e-07\n",
            "Total Loss: 1.6974242149179154e-06\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "Var loss:  tensor(1.6925e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7459210321486768e-06\n",
            "E_s_wdiff_all_sq: 1.8417374814302758e-07\n",
            "E_IS_SCOPE: -1.396955224597356e-06\n",
            "E_IS_E_SCOPE: 2.4190074952931134e-07\n",
            "Total Loss: 1.692499471730873e-06\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "Var loss:  tensor(1.6877e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7502183338530655e-06\n",
            "E_s_wdiff_all_sq: 1.9073759554846822e-07\n",
            "E_IS_SCOPE: -1.3996379264033374e-06\n",
            "E_IS_E_SCOPE: 2.4050724203488344e-07\n",
            "Total Loss: 1.6876545374067142e-06\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "Var loss:  tensor(1.6828e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7463995776071264e-06\n",
            "E_s_wdiff_all_sq: 1.9217561524712215e-07\n",
            "E_IS_SCOPE: -1.3918575403442332e-06\n",
            "E_IS_E_SCOPE: 2.480801264846274e-07\n",
            "Total Loss: 1.6828127646808418e-06\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "Var loss:  tensor(1.6780e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.739305576892997e-06\n",
            "E_s_wdiff_all_sq: 1.9146786191367652e-07\n",
            "E_IS_SCOPE: -1.380567570855371e-06\n",
            "E_IS_E_SCOPE: 2.585787639672729e-07\n",
            "Total Loss: 1.6780091813125916e-06\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "Var loss:  tensor(1.6732e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7410151775673873e-06\n",
            "E_s_wdiff_all_sq: 1.9549242251886063e-07\n",
            "E_IS_SCOPE: -1.3779588562947253e-06\n",
            "E_IS_E_SCOPE: 2.624393516898577e-07\n",
            "Total Loss: 1.6731904750579195e-06\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "Var loss:  tensor(1.6684e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7455530745300376e-06\n",
            "E_s_wdiff_all_sq: 2.01158412097493e-07\n",
            "E_IS_SCOPE: -1.38334563855428e-06\n",
            "E_IS_E_SCOPE: 2.588716606512735e-07\n",
            "Total Loss: 1.668424199999996e-06\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "Var loss:  tensor(1.6636e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7501052772351773e-06\n",
            "E_s_wdiff_all_sq: 2.0742591861500623e-07\n",
            "E_IS_SCOPE: -1.3860683019681373e-06\n",
            "E_IS_E_SCOPE: 2.5770096230991907e-07\n",
            "Total Loss: 1.6636049660426175e-06\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "Var loss:  tensor(1.6588e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.751099399516157e-06\n",
            "E_s_wdiff_all_sq: 2.1262164529500984e-07\n",
            "E_IS_SCOPE: -1.3792124210670561e-06\n",
            "E_IS_E_SCOPE: 2.648487392210459e-07\n",
            "Total Loss: 1.6588195696235012e-06\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "Var loss:  tensor(1.6541e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7472180455995486e-06\n",
            "E_s_wdiff_all_sq: 2.1505658122803808e-07\n",
            "E_IS_SCOPE: -1.3668088352684067e-06\n",
            "E_IS_E_SCOPE: 2.7647569318881015e-07\n",
            "Total Loss: 1.6540565434356356e-06\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "Var loss:  tensor(1.6493e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7460206580818403e-06\n",
            "E_s_wdiff_all_sq: 2.1772452818406725e-07\n",
            "E_IS_SCOPE: -1.3593780695239962e-06\n",
            "E_IS_E_SCOPE: 2.8434016107163497e-07\n",
            "Total Loss: 1.6493238046850694e-06\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "Var loss:  tensor(1.6445e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.749322940113768e-06\n",
            "E_s_wdiff_all_sq: 2.213497710932818e-07\n",
            "E_IS_SCOPE: -1.359077015244714e-06\n",
            "E_IS_E_SCOPE: 2.868813943877622e-07\n",
            "Total Loss: 1.6445204857340927e-06\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "Var loss:  tensor(1.6397e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.751085476935327e-06\n",
            "E_s_wdiff_all_sq: 2.2440283954132547e-07\n",
            "E_IS_SCOPE: -1.3589898115617542e-06\n",
            "E_IS_E_SCOPE: 2.8871694145279737e-07\n",
            "Total Loss: 1.6397332673434577e-06\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "Var loss:  tensor(1.6350e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7488744400602235e-06\n",
            "E_s_wdiff_all_sq: 2.2706389181355593e-07\n",
            "E_IS_SCOPE: -1.3567963216485892e-06\n",
            "E_IS_E_SCOPE: 2.9086140833976304e-07\n",
            "Total Loss: 1.6349592242485213e-06\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "Var loss:  tensor(1.6302e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7453884821816675e-06\n",
            "E_s_wdiff_all_sq: 2.2967286991824668e-07\n",
            "E_IS_SCOPE: -1.354037450894136e-06\n",
            "E_IS_E_SCOPE: 2.9293482473688615e-07\n",
            "Total Loss: 1.6302351969799352e-06\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "Var loss:  tensor(1.6255e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.745579093843386e-06\n",
            "E_s_wdiff_all_sq: 2.3228658053430124e-07\n",
            "E_IS_SCOPE: -1.365751038023357e-06\n",
            "E_IS_E_SCOPE: 2.8238184335064324e-07\n",
            "Total Loss: 1.6254908865396433e-06\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "Var loss:  tensor(1.6208e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7466368694702266e-06\n",
            "E_s_wdiff_all_sq: 2.2705108223306518e-07\n",
            "E_IS_SCOPE: -1.3673089839566357e-06\n",
            "E_IS_E_SCOPE: 2.863336112846768e-07\n",
            "Total Loss: 1.6207647327330956e-06\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "Var loss:  tensor(1.6161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7375278461262e-06\n",
            "E_s_wdiff_all_sq: 2.2098184848318766e-07\n",
            "E_IS_SCOPE: -1.3642222554430255e-06\n",
            "E_IS_E_SCOPE: 2.90256742464175e-07\n",
            "Total Loss: 1.61605213780717e-06\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "Var loss:  tensor(1.6113e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.720502086214623e-06\n",
            "E_s_wdiff_all_sq: 2.1725404238589962e-07\n",
            "E_IS_SCOPE: -1.353322662874933e-06\n",
            "E_IS_E_SCOPE: 2.9686151329541016e-07\n",
            "Total Loss: 1.6113438274665955e-06\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "Var loss:  tensor(1.6065e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.712703118201409e-06\n",
            "E_s_wdiff_all_sq: 2.149431397466573e-07\n",
            "E_IS_SCOPE: -1.3382770086223922e-06\n",
            "E_IS_E_SCOPE: 3.1156094268531476e-07\n",
            "Total Loss: 1.6065482118178968e-06\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "Var loss:  tensor(1.6019e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7251849971683343e-06\n",
            "E_s_wdiff_all_sq: 2.2349395161766086e-07\n",
            "E_IS_SCOPE: -1.3425902736630272e-06\n",
            "E_IS_E_SCOPE: 3.1154206701379904e-07\n",
            "Total Loss: 1.6018905001755793e-06\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "Var loss:  tensor(1.5971e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7373969395080364e-06\n",
            "E_s_wdiff_all_sq: 2.384194880786483e-07\n",
            "E_IS_SCOPE: -1.3512160726635145e-06\n",
            "E_IS_E_SCOPE: 3.0392982637468794e-07\n",
            "Total Loss: 1.5971497893315418e-06\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "Var loss:  tensor(1.5924e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7392545157030625e-06\n",
            "E_s_wdiff_all_sq: 2.495504532859129e-07\n",
            "E_IS_SCOPE: -1.3477076154061413e-06\n",
            "E_IS_E_SCOPE: 3.051568355030115e-07\n",
            "Total Loss: 1.592439296577403e-06\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "Var loss:  tensor(1.5877e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7409323118094446e-06\n",
            "E_s_wdiff_all_sq: 2.548608922213331e-07\n",
            "E_IS_SCOPE: -1.342025435620398e-06\n",
            "E_IS_E_SCOPE: 3.1139431764437166e-07\n",
            "Total Loss: 1.587696049037131e-06\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "Var loss:  tensor(1.5830e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.748567610954559e-06\n",
            "E_s_wdiff_all_sq: 2.615906875608306e-07\n",
            "E_IS_SCOPE: -1.3449718900186018e-06\n",
            "E_IS_E_SCOPE: 3.112651543621337e-07\n",
            "Total Loss: 1.5829669706108162e-06\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "Var loss:  tensor(1.5782e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.759652988542204e-06\n",
            "E_s_wdiff_all_sq: 2.7418898696117585e-07\n",
            "E_IS_SCOPE: -1.356542395276024e-06\n",
            "E_IS_E_SCOPE: 3.0132635434269886e-07\n",
            "Total Loss: 1.578190638322141e-06\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "Var loss:  tensor(1.5735e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7618154766621997e-06\n",
            "E_s_wdiff_all_sq: 2.8210032607811246e-07\n",
            "E_IS_SCOPE: -1.3560982069093842e-06\n",
            "E_IS_E_SCOPE: 3.012565088407858e-07\n",
            "Total Loss: 1.5734698550623055e-06\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "Var loss:  tensor(1.5687e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.758254989233864e-06\n",
            "E_s_wdiff_all_sq: 2.8183095522839206e-07\n",
            "E_IS_SCOPE: -1.3444956353737346e-06\n",
            "E_IS_E_SCOPE: 3.1359420840800636e-07\n",
            "Total Loss: 1.5687084824205487e-06\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "Var loss:  tensor(1.5640e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.755043489220429e-06\n",
            "E_s_wdiff_all_sq: 2.8067314710883147e-07\n",
            "E_IS_SCOPE: -1.3323661147600035e-06\n",
            "E_IS_E_SCOPE: 3.2704234041358693e-07\n",
            "Total Loss: 1.5640175677429752e-06\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "Var loss:  tensor(1.5594e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7625846336782344e-06\n",
            "E_s_wdiff_all_sq: 2.906330252911993e-07\n",
            "E_IS_SCOPE: -1.3437126650934921e-06\n",
            "E_IS_E_SCOPE: 3.1681796035712197e-07\n",
            "Total Loss: 1.5593544934643657e-06\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "Var loss:  tensor(1.5546e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.762547634438664e-06\n",
            "E_s_wdiff_all_sq: 2.922522754478302e-07\n",
            "E_IS_SCOPE: -1.3379844211646806e-06\n",
            "E_IS_E_SCOPE: 3.2408548016188727e-07\n",
            "Total Loss: 1.5546196923162562e-06\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "Var loss:  tensor(1.5499e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.753189705947865e-06\n",
            "E_s_wdiff_all_sq: 2.868534118545917e-07\n",
            "E_IS_SCOPE: -1.3147036320283895e-06\n",
            "E_IS_E_SCOPE: 3.4776432736449364e-07\n",
            "Total Loss: 1.5498645112860658e-06\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "Var loss:  tensor(1.5451e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.752215430533863e-06\n",
            "E_s_wdiff_all_sq: 2.9281913586413326e-07\n",
            "E_IS_SCOPE: -1.3134717719000487e-06\n",
            "E_IS_E_SCOPE: 3.47913784844198e-07\n",
            "Total Loss: 1.5450893171597948e-06\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "Var loss:  tensor(1.5403e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.75487814348829e-06\n",
            "E_s_wdiff_all_sq: 2.9831710795449065e-07\n",
            "E_IS_SCOPE: -1.3125516701270509e-06\n",
            "E_IS_E_SCOPE: 3.4980927764650574e-07\n",
            "Total Loss: 1.5403032759652447e-06\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "Var loss:  tensor(1.5355e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.755177046278001e-06\n",
            "E_s_wdiff_all_sq: 2.989732586061748e-07\n",
            "E_IS_SCOPE: -1.3062496971230502e-06\n",
            "E_IS_E_SCOPE: 3.58321502842614e-07\n",
            "Total Loss: 1.5355255237190563e-06\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "Var loss:  tensor(1.5308e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.752468427954843e-06\n",
            "E_s_wdiff_all_sq: 3.0089541563336845e-07\n",
            "E_IS_SCOPE: -1.3012178510730047e-06\n",
            "E_IS_E_SCOPE: 3.6342197609071736e-07\n",
            "Total Loss: 1.5307574939725887e-06\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "Var loss:  tensor(1.5259e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7600367114648257e-06\n",
            "E_s_wdiff_all_sq: 3.1236374093555465e-07\n",
            "E_IS_SCOPE: -1.309320581109729e-06\n",
            "E_IS_E_SCOPE: 3.5578475583458984e-07\n",
            "Total Loss: 1.5259264326191921e-06\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "Var loss:  tensor(1.5213e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.756094318116278e-06\n",
            "E_s_wdiff_all_sq: 3.121064595646069e-07\n",
            "E_IS_SCOPE: -1.302936584048671e-06\n",
            "E_IS_E_SCOPE: 3.626635461363251e-07\n",
            "Total Loss: 1.5212517341602377e-06\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "Var loss:  tensor(1.5166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7474764836068174e-06\n",
            "E_s_wdiff_all_sq: 3.0397611191504755e-07\n",
            "E_IS_SCOPE: -1.2866927611447982e-06\n",
            "E_IS_E_SCOPE: 3.80983708024956e-07\n",
            "Total Loss: 1.5166115693308203e-06\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "Var loss:  tensor(1.5120e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7539559920475177e-06\n",
            "E_s_wdiff_all_sq: 3.0839886551085054e-07\n",
            "E_IS_SCOPE: -1.2872832263561059e-06\n",
            "E_IS_E_SCOPE: 3.837313864896423e-07\n",
            "Total Loss: 1.51199203682373e-06\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "Var loss:  tensor(1.5074e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740737000661189e-06\n",
            "E_s_wdiff_all_sq: 3.0169994041305435e-07\n",
            "E_IS_SCOPE: -1.2636705185887066e-06\n",
            "E_IS_E_SCOPE: 4.064026897954621e-07\n",
            "Total Loss: 1.5073547794583557e-06\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "Var loss:  tensor(1.5028e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7278571314921667e-06\n",
            "E_s_wdiff_all_sq: 2.94747608294448e-07\n",
            "E_IS_SCOPE: -1.2466123027637484e-06\n",
            "E_IS_E_SCOPE: 4.2279484864373064e-07\n",
            "Total Loss: 1.502759356361319e-06\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "Var loss:  tensor(1.4981e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.725483374065858e-06\n",
            "E_s_wdiff_all_sq: 2.904339128789451e-07\n",
            "E_IS_SCOPE: -1.2323050473859563e-06\n",
            "E_IS_E_SCOPE: 4.403818091713779e-07\n",
            "Total Loss: 1.4981398840508035e-06\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "Var loss:  tensor(1.4935e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7366223147538553e-06\n",
            "E_s_wdiff_all_sq: 2.988428166898859e-07\n",
            "E_IS_SCOPE: -1.2349199781380993e-06\n",
            "E_IS_E_SCOPE: 4.414482696978233e-07\n",
            "Total Loss: 1.4935071383706828e-06\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "Var loss:  tensor(1.4888e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.722593824490437e-06\n",
            "E_s_wdiff_all_sq: 2.941718101689284e-07\n",
            "E_IS_SCOPE: -1.2064584311039298e-06\n",
            "E_IS_E_SCOPE: 4.6756157132480894e-07\n",
            "Total Loss: 1.4888461454425902e-06\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "Var loss:  tensor(1.4843e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7061335766712023e-06\n",
            "E_s_wdiff_all_sq: 2.866564002074007e-07\n",
            "E_IS_SCOPE: -1.1710859838790565e-06\n",
            "E_IS_E_SCOPE: 5.007566719636895e-07\n",
            "Total Loss: 1.4842560007568688e-06\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "Var loss:  tensor(1.4796e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7189337950232425e-06\n",
            "E_s_wdiff_all_sq: 2.9563104953641707e-07\n",
            "E_IS_SCOPE: -1.1770483979169515e-06\n",
            "E_IS_E_SCOPE: 4.990418264715687e-07\n",
            "Total Loss: 1.4795864326883438e-06\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "Var loss:  tensor(1.4749e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.72112850651415e-06\n",
            "E_s_wdiff_all_sq: 2.959918044232878e-07\n",
            "E_IS_SCOPE: -1.1692935334654473e-06\n",
            "E_IS_E_SCOPE: 5.100507928800983e-07\n",
            "Total Loss: 1.47491218537833e-06\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "Var loss:  tensor(1.4703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.701307205934347e-06\n",
            "E_s_wdiff_all_sq: 2.8542510510415807e-07\n",
            "E_IS_SCOPE: -1.1362016822438057e-06\n",
            "E_IS_E_SCOPE: 5.408393081750521e-07\n",
            "Total Loss: 1.470264255971032e-06\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "Var loss:  tensor(1.4656e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7036067926532814e-06\n",
            "E_s_wdiff_all_sq: 2.927366336885657e-07\n",
            "E_IS_SCOPE: -1.1307752969213912e-06\n",
            "E_IS_E_SCOPE: 5.460997362049857e-07\n",
            "Total Loss: 1.4655842286905205e-06\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "Var loss:  tensor(1.4610e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7107308609997365e-06\n",
            "E_s_wdiff_all_sq: 2.998801820890259e-07\n",
            "E_IS_SCOPE: -1.112060850149784e-06\n",
            "E_IS_E_SCOPE: 5.671193485342748e-07\n",
            "Total Loss: 1.4609544175211516e-06\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "Var loss:  tensor(1.4563e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7073832957764196e-06\n",
            "E_s_wdiff_all_sq: 3.003135579709834e-07\n",
            "E_IS_SCOPE: -1.070969577014724e-06\n",
            "E_IS_E_SCOPE: 6.086241867557526e-07\n",
            "Total Loss: 1.456346346243042e-06\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "Var loss:  tensor(1.4517e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.711183108731413e-06\n",
            "E_s_wdiff_all_sq: 3.095989715065367e-07\n",
            "E_IS_SCOPE: -1.0403316321263186e-06\n",
            "E_IS_E_SCOPE: 6.388194344499697e-07\n",
            "Total Loss: 1.4517461400508576e-06\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "Var loss:  tensor(1.4471e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7138121633721766e-06\n",
            "E_s_wdiff_all_sq: 3.1595078627347233e-07\n",
            "E_IS_SCOPE: -1.0106825893833673e-06\n",
            "E_IS_E_SCOPE: 6.689095343399825e-07\n",
            "Total Loss: 1.4471412656305633e-06\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "Var loss:  tensor(1.4425e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.717041075296832e-06\n",
            "E_s_wdiff_all_sq: 3.1878800334639753e-07\n",
            "E_IS_SCOPE: -9.889551286483555e-07\n",
            "E_IS_E_SCOPE: 6.93148032694191e-07\n",
            "Total Loss: 1.4425108852439005e-06\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "Var loss:  tensor(1.4379e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7275789113781396e-06\n",
            "E_s_wdiff_all_sq: 3.296381045853426e-07\n",
            "E_IS_SCOPE: -9.8469828593951e-07\n",
            "E_IS_E_SCOPE: 6.995774071769918e-07\n",
            "Total Loss: 1.437853556538352e-06\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "Var loss:  tensor(1.4333e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.715838720156469e-06\n",
            "E_s_wdiff_all_sq: 3.257874921906111e-07\n",
            "E_IS_SCOPE: -9.584520895988967e-07\n",
            "E_IS_E_SCOPE: 7.241689071885246e-07\n",
            "Total Loss: 1.4332733703695735e-06\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "Var loss:  tensor(1.4286e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.708255918302871e-06\n",
            "E_s_wdiff_all_sq: 3.221182711131142e-07\n",
            "E_IS_SCOPE: -9.284794460953982e-07\n",
            "E_IS_E_SCOPE: 7.54497271866315e-07\n",
            "Total Loss: 1.4286483472448896e-06\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "Var loss:  tensor(1.4240e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7251369517226818e-06\n",
            "E_s_wdiff_all_sq: 3.365281045530681e-07\n",
            "E_IS_SCOPE: -9.292150582936742e-07\n",
            "E_IS_E_SCOPE: 7.5730880232476e-07\n",
            "Total Loss: 1.4240252619113036e-06\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "Var loss:  tensor(1.4194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.72744964036164e-06\n",
            "E_s_wdiff_all_sq: 3.413379691140472e-07\n",
            "E_IS_SCOPE: -9.088756325548706e-07\n",
            "E_IS_E_SCOPE: 7.787148994098935e-07\n",
            "Total Loss: 1.4193947432966233e-06\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "Var loss:  tensor(1.4148e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7174960765215632e-06\n",
            "E_s_wdiff_all_sq: 3.3905800039700267e-07\n",
            "E_IS_SCOPE: -8.735584500414855e-07\n",
            "E_IS_E_SCOPE: 8.125051535324349e-07\n",
            "Total Loss: 1.4147750049552784e-06\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "Var loss:  tensor(1.4101e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7247134728654896e-06\n",
            "E_s_wdiff_all_sq: 3.4964853697414283e-07\n",
            "E_IS_SCOPE: -8.596682622577166e-07\n",
            "E_IS_E_SCOPE: 8.270379061569652e-07\n",
            "Total Loss: 1.4101167350405418e-06\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "Var loss:  tensor(1.4055e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7453445371596323e-06\n",
            "E_s_wdiff_all_sq: 3.6754034482146097e-07\n",
            "E_IS_SCOPE: -8.612777410335783e-07\n",
            "E_IS_E_SCOPE: 8.291069435615396e-07\n",
            "Total Loss: 1.405498959126494e-06\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "Var loss:  tensor(1.4009e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.745564364312256e-06\n",
            "E_s_wdiff_all_sq: 3.69290933310109e-07\n",
            "E_IS_SCOPE: -8.471947699105281e-07\n",
            "E_IS_E_SCOPE: 8.447198839361625e-07\n",
            "Total Loss: 1.400908259287324e-06\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "Var loss:  tensor(1.3962e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743307666757351e-06\n",
            "E_s_wdiff_all_sq: 3.71329037774109e-07\n",
            "E_IS_SCOPE: -8.40325914106005e-07\n",
            "E_IS_E_SCOPE: 8.517784403424936e-07\n",
            "Total Loss: 1.3962340560648037e-06\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "Var loss:  tensor(1.3915e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740737120430676e-06\n",
            "E_s_wdiff_all_sq: 3.7436745475053383e-07\n",
            "E_IS_SCOPE: -8.304732731095192e-07\n",
            "E_IS_E_SCOPE: 8.611840247497515e-07\n",
            "Total Loss: 1.3915192059401594e-06\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "Var loss:  tensor(1.3868e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.722972043391154e-06\n",
            "E_s_wdiff_all_sq: 3.627565786164752e-07\n",
            "E_IS_SCOPE: -7.967301987972164e-07\n",
            "E_IS_E_SCOPE: 8.941869815145724e-07\n",
            "Total Loss: 1.3868452401296596e-06\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "Var loss:  tensor(1.3821e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7234338088890284e-06\n",
            "E_s_wdiff_all_sq: 3.636145233051429e-07\n",
            "E_IS_SCOPE: -7.864448866277558e-07\n",
            "E_IS_E_SCOPE: 9.066366692220122e-07\n",
            "Total Loss: 1.3821203098629088e-06\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "Var loss:  tensor(1.3774e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7196165205281044e-06\n",
            "E_s_wdiff_all_sq: 3.605660297946987e-07\n",
            "E_IS_SCOPE: -7.672509450290234e-07\n",
            "E_IS_E_SCOPE: 9.278102227404734e-07\n",
            "Total Loss: 1.3773922911729707e-06\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "Var loss:  tensor(1.3727e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.709122403254167e-06\n",
            "E_s_wdiff_all_sq: 3.5315071270738495e-07\n",
            "E_IS_SCOPE: -7.384426585372165e-07\n",
            "E_IS_E_SCOPE: 9.5742099995424e-07\n",
            "Total Loss: 1.3727085095424283e-06\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "Var loss:  tensor(1.3680e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7052186909483435e-06\n",
            "E_s_wdiff_all_sq: 3.5090121267833935e-07\n",
            "E_IS_SCOPE: -7.172211194756187e-07\n",
            "E_IS_E_SCOPE: 9.801821453638037e-07\n",
            "Total Loss: 1.367975084569718e-06\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "Var loss:  tensor(1.3632e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7053520543423403e-06\n",
            "E_s_wdiff_all_sq: 3.540269779905107e-07\n",
            "E_IS_SCOPE: -7.019967594788145e-07\n",
            "E_IS_E_SCOPE: 9.962859068039721e-07\n",
            "Total Loss: 1.3632238797648153e-06\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "Var loss:  tensor(1.3587e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7049906949673404e-06\n",
            "E_s_wdiff_all_sq: 3.594510382908651e-07\n",
            "E_IS_SCOPE: -6.927479029122061e-07\n",
            "E_IS_E_SCOPE: 1.004922125467472e-06\n",
            "Total Loss: 1.3586637358956783e-06\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "Var loss:  tensor(1.3540e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.684894341476923e-06\n",
            "E_s_wdiff_all_sq: 3.444793092830471e-07\n",
            "E_IS_SCOPE: -6.609904172128256e-07\n",
            "E_IS_E_SCOPE: 1.0364532849590214e-06\n",
            "Total Loss: 1.35399176382874e-06\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "Var loss:  tensor(1.3493e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6842293358547605e-06\n",
            "E_s_wdiff_all_sq: 3.4278917735311077e-07\n",
            "E_IS_SCOPE: -6.527745853790643e-07\n",
            "E_IS_E_SCOPE: 1.0475354877759652e-06\n",
            "Total Loss: 1.3492841481701497e-06\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "Var loss:  tensor(1.3447e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6931913604960196e-06\n",
            "E_s_wdiff_all_sq: 3.5117272378026866e-07\n",
            "E_IS_SCOPE: -6.55310041063344e-07\n",
            "E_IS_E_SCOPE: 1.0475709943210972e-06\n",
            "Total Loss: 1.344720701925427e-06\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "Var loss:  tensor(1.3400e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6688525884057924e-06\n",
            "E_s_wdiff_all_sq: 3.3454902167581115e-07\n",
            "E_IS_SCOPE: -6.20728128629836e-07\n",
            "E_IS_E_SCOPE: 1.0806689627654011e-06\n",
            "Total Loss: 1.3399735199180662e-06\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "Var loss:  tensor(1.3354e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6506737067700954e-06\n",
            "E_s_wdiff_all_sq: 3.225442689258651e-07\n",
            "E_IS_SCOPE: -5.904343829066517e-07\n",
            "E_IS_E_SCOPE: 1.1101762266275103e-06\n",
            "Total Loss: 1.3353723547544648e-06\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "Var loss:  tensor(1.3307e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.67012449735074e-06\n",
            "E_s_wdiff_all_sq: 3.388453089776718e-07\n",
            "E_IS_SCOPE: -5.988028461405958e-07\n",
            "E_IS_E_SCOPE: 1.1057354207249696e-06\n",
            "Total Loss: 1.330666790620496e-06\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "Var loss:  tensor(1.3260e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6764452517959514e-06\n",
            "E_s_wdiff_all_sq: 3.464867799201417e-07\n",
            "E_IS_SCOPE: -5.980970440678996e-07\n",
            "E_IS_E_SCOPE: 1.1080969099132497e-06\n",
            "Total Loss: 1.3260346998920704e-06\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "Var loss:  tensor(1.3213e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6602887153357954e-06\n",
            "E_s_wdiff_all_sq: 3.384652210883837e-07\n",
            "E_IS_SCOPE: -5.697098015919344e-07\n",
            "E_IS_E_SCOPE: 1.1347735428484275e-06\n",
            "Total Loss: 1.3213209413452468e-06\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "Var loss:  tensor(1.3167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6518039988815964e-06\n",
            "E_s_wdiff_all_sq: 3.358485190144739e-07\n",
            "E_IS_SCOPE: -5.494345060661692e-07\n",
            "E_IS_E_SCOPE: 1.154416602163211e-06\n",
            "Total Loss: 1.3167173993869206e-06\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "Var loss:  tensor(1.3121e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6734349789204215e-06\n",
            "E_s_wdiff_all_sq: 3.542595761603766e-07\n",
            "E_IS_SCOPE: -5.690013307291845e-07\n",
            "E_IS_E_SCOPE: 1.1387916937001761e-06\n",
            "Total Loss: 1.3120534898798826e-06\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "Var loss:  tensor(1.3073e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.67665439723695e-06\n",
            "E_s_wdiff_all_sq: 3.553254703187007e-07\n",
            "E_IS_SCOPE: -5.597407204733542e-07\n",
            "E_IS_E_SCOPE: 1.1514923032417123e-06\n",
            "Total Loss: 1.3073270154666756e-06\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "Var loss:  tensor(1.3028e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.656420350347485e-06\n",
            "E_s_wdiff_all_sq: 3.43169780077778e-07\n",
            "E_IS_SCOPE: -5.207055724448497e-07\n",
            "E_IS_E_SCOPE: 1.188765962374532e-06\n",
            "Total Loss: 1.3027716366095021e-06\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "Var loss:  tensor(1.2980e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.657639173793408e-06\n",
            "E_s_wdiff_all_sq: 3.5260250044506715e-07\n",
            "E_IS_SCOPE: -5.161867804789939e-07\n",
            "E_IS_E_SCOPE: 1.191563267272757e-06\n",
            "Total Loss: 1.2980007138233978e-06\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "Var loss:  tensor(1.2934e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6658378971273284e-06\n",
            "E_s_wdiff_all_sq: 3.589546642980271e-07\n",
            "E_IS_SCOPE: -5.137367652874253e-07\n",
            "E_IS_E_SCOPE: 1.1972563830260448e-06\n",
            "Total Loss: 1.2933610721809207e-06\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "Var loss:  tensor(1.2887e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.665170767759705e-06\n",
            "E_s_wdiff_all_sq: 3.547676503966962e-07\n",
            "E_IS_SCOPE: -4.98137472450447e-07\n",
            "E_IS_E_SCOPE: 1.2169301764082806e-06\n",
            "Total Loss: 1.2887319556241125e-06\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "Var loss:  tensor(1.2841e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.66337748467118e-06\n",
            "E_s_wdiff_all_sq: 3.593580316941041e-07\n",
            "E_IS_SCOPE: -4.930735032023892e-07\n",
            "E_IS_E_SCOPE: 1.2211358927371779e-06\n",
            "Total Loss: 1.2840647970765002e-06\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "Var loss:  tensor(1.2794e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6481303306288423e-06\n",
            "E_s_wdiff_all_sq: 3.5446873981014144e-07\n",
            "E_IS_SCOPE: -4.7517195383065676e-07\n",
            "E_IS_E_SCOPE: 1.2361773360811475e-06\n",
            "Total Loss: 1.2794271469736514e-06\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "Var loss:  tensor(1.2748e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6484291868625776e-06\n",
            "E_s_wdiff_all_sq: 3.5194010206331017e-07\n",
            "E_IS_SCOPE: -4.681770176758478e-07\n",
            "E_IS_E_SCOPE: 1.2469015048648512e-06\n",
            "Total Loss: 1.2747961756964282e-06\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "Var loss:  tensor(1.2701e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.655330293986913e-06\n",
            "E_s_wdiff_all_sq: 3.5588760831577515e-07\n",
            "E_IS_SCOPE: -4.770702681223267e-07\n",
            "E_IS_E_SCOPE: 1.2418190311004153e-06\n",
            "Total Loss: 1.2701282232042117e-06\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "Var loss:  tensor(1.2654e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6380200122257304e-06\n",
            "E_s_wdiff_all_sq: 3.453374052018818e-07\n",
            "E_IS_SCOPE: -4.542794409011055e-07\n",
            "E_IS_E_SCOPE: 1.2635779705779653e-06\n",
            "Total Loss: 1.2654319200442663e-06\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "Var loss:  tensor(1.2609e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6127329069354105e-06\n",
            "E_s_wdiff_all_sq: 3.296337368249763e-07\n",
            "E_IS_SCOPE: -4.1985657318941675e-07\n",
            "E_IS_E_SCOPE: 1.2954949301673838e-06\n",
            "Total Loss: 1.2608602993753916e-06\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "Var loss:  tensor(1.2561e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.624626709786013e-06\n",
            "E_s_wdiff_all_sq: 3.384330782440186e-07\n",
            "E_IS_SCOPE: -4.350812319838775e-07\n",
            "E_IS_E_SCOPE: 1.2841925473810677e-06\n",
            "Total Loss: 1.2561102087906624e-06\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "Var loss:  tensor(1.2514e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6274774965519695e-06\n",
            "E_s_wdiff_all_sq: 3.371782655468369e-07\n",
            "E_IS_SCOPE: -4.3615717909493693e-07\n",
            "E_IS_E_SCOPE: 1.287510435784748e-06\n",
            "Total Loss: 1.2514281372243222e-06\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "Var loss:  tensor(1.2467e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6090682181265514e-06\n",
            "E_s_wdiff_all_sq: 3.2606445907943604e-07\n",
            "E_IS_SCOPE: -4.112748865842019e-07\n",
            "E_IS_E_SCOPE: 1.3110980477202574e-06\n",
            "Total Loss: 1.2467220264167562e-06\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "Var loss:  tensor(1.2420e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6043023738013406e-06\n",
            "E_s_wdiff_all_sq: 3.306992658496966e-07\n",
            "E_IS_SCOPE: -4.093905695203989e-07\n",
            "E_IS_E_SCOPE: 1.310630979272599e-06\n",
            "Total Loss: 1.2420241463442078e-06\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "Var loss:  tensor(1.2373e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6028323969153168e-06\n",
            "E_s_wdiff_all_sq: 3.301461512934993e-07\n",
            "E_IS_SCOPE: -4.027179353864232e-07\n",
            "E_IS_E_SCOPE: 1.3191946959029834e-06\n",
            "Total Loss: 1.2373251190215627e-06\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "Var loss:  tensor(1.2326e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.602423585482048e-06\n",
            "E_s_wdiff_all_sq: 3.2613945801074136e-07\n",
            "E_IS_SCOPE: -3.894080461043317e-07\n",
            "E_IS_E_SCOPE: 1.3366518294729172e-06\n",
            "Total Loss: 1.2326285122953682e-06\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "Var loss:  tensor(1.2279e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6002941348766907e-06\n",
            "E_s_wdiff_all_sq: 3.2914595761856106e-07\n",
            "E_IS_SCOPE: -3.776772494163136e-07\n",
            "E_IS_E_SCOPE: 1.348196492851575e-06\n",
            "Total Loss: 1.227864828700911e-06\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "Var loss:  tensor(1.2233e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6062507022259564e-06\n",
            "E_s_wdiff_all_sq: 3.406286059980217e-07\n",
            "E_IS_SCOPE: -3.833109980330767e-07\n",
            "E_IS_E_SCOPE: 1.342087704079982e-06\n",
            "Total Loss: 1.2232888279803754e-06\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5944311783900964e-06\n",
            "E_s_wdiff_all_sq: 3.260843579370695e-07\n",
            "E_IS_SCOPE: -3.6624450968369543e-07\n",
            "E_IS_E_SCOPE: 1.3629349348629589e-06\n",
            "Total Loss: 1.218452067338277e-06\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "Var loss:  tensor(1.2139e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.588392377153539e-06\n",
            "E_s_wdiff_all_sq: 3.1460288260310413e-07\n",
            "E_IS_SCOPE: -3.566548733662667e-07\n",
            "E_IS_E_SCOPE: 1.3774993597158968e-06\n",
            "Total Loss: 1.2139451643646664e-06\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "Var loss:  tensor(1.2091e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5858137149028245e-06\n",
            "E_s_wdiff_all_sq: 3.248301013552922e-07\n",
            "E_IS_SCOPE: -3.6759749803127946e-07\n",
            "E_IS_E_SCOPE: 1.3625722379761376e-06\n",
            "Total Loss: 1.2091082775112562e-06\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "Var loss:  tensor(1.2044e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5676226845114784e-06\n",
            "E_s_wdiff_all_sq: 3.1724046796797173e-07\n",
            "E_IS_SCOPE: -3.4928904516306433e-07\n",
            "E_IS_E_SCOPE: 1.3779278617553458e-06\n",
            "Total Loss: 1.2044125386852446e-06\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "Var loss:  tensor(1.1998e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.552115093582697e-06\n",
            "E_s_wdiff_all_sq: 2.9671958057661634e-07\n",
            "E_IS_SCOPE: -3.251725548647698e-07\n",
            "E_IS_E_SCOPE: 1.4068794512567106e-06\n",
            "Total Loss: 1.199755636741678e-06\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "Var loss:  tensor(1.1949e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5670716365731242e-06\n",
            "E_s_wdiff_all_sq: 3.058961915772816e-07\n",
            "E_IS_SCOPE: -3.4649380644341864e-07\n",
            "E_IS_E_SCOPE: 1.3908754326247297e-06\n",
            "Total Loss: 1.1949011028381054e-06\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "Var loss:  tensor(1.1903e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5522815306847804e-06\n",
            "E_s_wdiff_all_sq: 3.0303673931773955e-07\n",
            "E_IS_SCOPE: -3.3883030984845536e-07\n",
            "E_IS_E_SCOPE: 1.394873639808846e-06\n",
            "Total Loss: 1.1903010280309976e-06\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "Var loss:  tensor(1.1854e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5307691197474295e-06\n",
            "E_s_wdiff_all_sq: 2.8861386466366956e-07\n",
            "E_IS_SCOPE: -3.1332336215917054e-07\n",
            "E_IS_E_SCOPE: 1.4192689708507235e-06\n",
            "Total Loss: 1.1854347250425312e-06\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "Var loss:  tensor(1.1807e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5310952663841764e-06\n",
            "E_s_wdiff_all_sq: 2.856752674045547e-07\n",
            "E_IS_SCOPE: -3.112673245747488e-07\n",
            "E_IS_E_SCOPE: 1.4253444780443323e-06\n",
            "Total Loss: 1.1806605297200177e-06\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "Var loss:  tensor(1.1763e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5439879118109864e-06\n",
            "E_s_wdiff_all_sq: 2.9833835268361765e-07\n",
            "E_IS_SCOPE: -3.398376464326774e-07\n",
            "E_IS_E_SCOPE: 1.3990499782035256e-06\n",
            "Total Loss: 1.1763384458335222e-06\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "Var loss:  tensor(1.1717e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.523267616828793e-06\n",
            "E_s_wdiff_all_sq: 2.858504248740101e-07\n",
            "E_IS_SCOPE: -3.147568598110546e-07\n",
            "E_IS_E_SCOPE: 1.4223536613818165e-06\n",
            "Total Loss: 1.1716602855476002e-06\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "Var loss:  tensor(1.1669e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5111527833469365e-06\n",
            "E_s_wdiff_all_sq: 2.76095715784863e-07\n",
            "E_IS_SCOPE: -2.7971585854232595e-07\n",
            "E_IS_E_SCOPE: 1.4585743269271751e-06\n",
            "Total Loss: 1.1669408326016309e-06\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "Var loss:  tensor(1.1619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5452715477127113e-06\n",
            "E_s_wdiff_all_sq: 3.063036292871815e-07\n",
            "E_IS_SCOPE: -3.035400612288751e-07\n",
            "E_IS_E_SCOPE: 1.4392440902151802e-06\n",
            "Total Loss: 1.1618637515159777e-06\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "Var loss:  tensor(1.1568e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5666294062931416e-06\n",
            "E_s_wdiff_all_sq: 3.313364607337118e-07\n",
            "E_IS_SCOPE: -2.9901660533893945e-07\n",
            "E_IS_E_SCOPE: 1.4444703338020722e-06\n",
            "Total Loss: 1.1567832032559658e-06\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "Var loss:  tensor(1.1520e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5522898352250197e-06\n",
            "E_s_wdiff_all_sq: 3.300578559025089e-07\n",
            "E_IS_SCOPE: -2.545240438189341e-07\n",
            "E_IS_E_SCOPE: 1.484806468037377e-06\n",
            "Total Loss: 1.152035091588448e-06\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "Var loss:  tensor(1.1472e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.574759226415247e-06\n",
            "E_s_wdiff_all_sq: 3.5124092545962335e-07\n",
            "E_IS_SCOPE: -2.560800460447048e-07\n",
            "E_IS_E_SCOPE: 1.486322406816008e-06\n",
            "Total Loss: 1.1471775312127564e-06\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "Var loss:  tensor(1.1425e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6151598375966348e-06\n",
            "E_s_wdiff_all_sq: 3.837623745627552e-07\n",
            "E_IS_SCOPE: -2.7164040315312084e-07\n",
            "E_IS_E_SCOPE: 1.4770583163841091e-06\n",
            "Total Loss: 1.1424641599379786e-06\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "Var loss:  tensor(1.1377e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5966670072784368e-06\n",
            "E_s_wdiff_all_sq: 3.749540017223243e-07\n",
            "E_IS_SCOPE: -2.300635852588895e-07\n",
            "E_IS_E_SCOPE: 1.5161990752487697e-06\n",
            "Total Loss: 1.1376518205193522e-06\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "Var loss:  tensor(1.1329e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.563717018182249e-06\n",
            "E_s_wdiff_all_sq: 3.5065680614558654e-07\n",
            "E_IS_SCOPE: -1.753706522282408e-07\n",
            "E_IS_E_SCOPE: 1.5689563040878393e-06\n",
            "Total Loss: 1.1328704353830611e-06\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "Var loss:  tensor(1.1279e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5775804686306615e-06\n",
            "E_s_wdiff_all_sq: 3.5708371471849924e-07\n",
            "E_IS_SCOPE: -1.8871209763990661e-07\n",
            "E_IS_E_SCOPE: 1.5617980374542223e-06\n",
            "Total Loss: 1.1279406197024632e-06\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "Var loss:  tensor(1.1231e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5785497299628545e-06\n",
            "E_s_wdiff_all_sq: 3.554789180354352e-07\n",
            "E_IS_SCOPE: -1.9421090597116048e-07\n",
            "E_IS_E_SCOPE: 1.5600016057719315e-06\n",
            "Total Loss: 1.1231099244197943e-06\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "Var loss:  tensor(1.1181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5383568396543407e-06\n",
            "E_s_wdiff_all_sq: 3.294208887378156e-07\n",
            "E_IS_SCOPE: -1.630648650978581e-07\n",
            "E_IS_E_SCOPE: 1.586567600342272e-06\n",
            "Total Loss: 1.1181351560148237e-06\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "Var loss:  tensor(1.1132e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5279845343856435e-06\n",
            "E_s_wdiff_all_sq: 3.2309526926079003e-07\n",
            "E_IS_SCOPE: -1.589709907138961e-07\n",
            "E_IS_E_SCOPE: 1.5910911524173708e-06\n",
            "Total Loss: 1.113229114840879e-06\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "Var loss:  tensor(1.1085e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5439871784071778e-06\n",
            "E_s_wdiff_all_sq: 3.3321895674672623e-07\n",
            "E_IS_SCOPE: -1.88579701816442e-07\n",
            "E_IS_E_SCOPE: 1.5667987083756743e-06\n",
            "Total Loss: 1.108475537254778e-06\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "Var loss:  tensor(1.1034e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5164694099650797e-06\n",
            "E_s_wdiff_all_sq: 3.115646712449736e-07\n",
            "E_IS_SCOPE: -1.578153267550474e-07\n",
            "E_IS_E_SCOPE: 1.5971700489893454e-06\n",
            "Total Loss: 1.1033981232098801e-06\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "Var loss:  tensor(1.0985e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.483104198168579e-06\n",
            "E_s_wdiff_all_sq: 2.8778581097846616e-07\n",
            "E_IS_SCOPE: -1.2972428091473122e-07\n",
            "E_IS_E_SCOPE: 1.622906243743605e-06\n",
            "Total Loss: 1.0985214738519987e-06\n",
            "----------------------------------------\n",
            "Epoch 501\n",
            "Var loss:  tensor(1.0936e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4849916467112685e-06\n",
            "E_s_wdiff_all_sq: 2.872598495613236e-07\n",
            "E_IS_SCOPE: -1.452391977904693e-07\n",
            "E_IS_E_SCOPE: 1.6110820540271775e-06\n",
            "Total Loss: 1.09355342949321e-06\n",
            "----------------------------------------\n",
            "Epoch 502\n",
            "Var loss:  tensor(1.0886e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.478667769516438e-06\n",
            "E_s_wdiff_all_sq: 2.7883543588256686e-07\n",
            "E_IS_SCOPE: -1.432553024370776e-07\n",
            "E_IS_E_SCOPE: 1.6165959351903953e-06\n",
            "Total Loss: 1.088593994357484e-06\n",
            "----------------------------------------\n",
            "Epoch 503\n",
            "Var loss:  tensor(1.0837e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4565458640844045e-06\n",
            "E_s_wdiff_all_sq: 2.631715958131597e-07\n",
            "E_IS_SCOPE: -1.1956570898491096e-07\n",
            "E_IS_E_SCOPE: 1.6395166137309017e-06\n",
            "Total Loss: 1.083673758818178e-06\n",
            "----------------------------------------\n",
            "Epoch 504\n",
            "Var loss:  tensor(1.0787e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4548831351813566e-06\n",
            "E_s_wdiff_all_sq: 2.650946240422019e-07\n",
            "E_IS_SCOPE: -1.155052288157122e-07\n",
            "E_IS_E_SCOPE: 1.6442569100500567e-06\n",
            "Total Loss: 1.0787283693861757e-06\n",
            "----------------------------------------\n",
            "Epoch 505\n",
            "Var loss:  tensor(1.0738e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.465087808469193e-06\n",
            "E_s_wdiff_all_sq: 2.758110009278863e-07\n",
            "E_IS_SCOPE: -1.113295887784626e-07\n",
            "E_IS_E_SCOPE: 1.650629754236833e-06\n",
            "Total Loss: 1.073822257489274e-06\n",
            "----------------------------------------\n",
            "Epoch 506\n",
            "Var loss:  tensor(1.0688e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4701431272946627e-06\n",
            "E_s_wdiff_all_sq: 2.8297003950673194e-07\n",
            "E_IS_SCOPE: -8.883718003764979e-08\n",
            "E_IS_E_SCOPE: 1.6745620430586162e-06\n",
            "Total Loss: 1.0688387775739574e-06\n",
            "----------------------------------------\n",
            "Epoch 507\n",
            "Var loss:  tensor(1.0639e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.479558632450947e-06\n",
            "E_s_wdiff_all_sq: 2.9625651263771743e-07\n",
            "E_IS_SCOPE: -7.411651194172792e-08\n",
            "E_IS_E_SCOPE: 1.689816200102954e-06\n",
            "Total Loss: 1.0639008317024248e-06\n",
            "----------------------------------------\n",
            "Epoch 508\n",
            "Var loss:  tensor(1.0589e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.494518711439973e-06\n",
            "E_s_wdiff_all_sq: 3.1697249082094597e-07\n",
            "E_IS_SCOPE: -7.161354398856198e-08\n",
            "E_IS_E_SCOPE: 1.6919241144335295e-06\n",
            "Total Loss: 1.0589350397534022e-06\n",
            "----------------------------------------\n",
            "Epoch 509\n",
            "Var loss:  tensor(1.0541e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5182283382487674e-06\n",
            "E_s_wdiff_all_sq: 3.4082589421245063e-07\n",
            "E_IS_SCOPE: -8.384262878065107e-08\n",
            "E_IS_E_SCOPE: 1.6820374974735112e-06\n",
            "Total Loss: 1.054106327506551e-06\n",
            "----------------------------------------\n",
            "Epoch 510\n",
            "Var loss:  tensor(1.0491e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.508065782611709e-06\n",
            "E_s_wdiff_all_sq: 3.326114617527011e-07\n",
            "E_IS_SCOPE: -4.860318181738458e-08\n",
            "E_IS_E_SCOPE: 1.7188263603833655e-06\n",
            "Total Loss: 1.0490593724360664e-06\n",
            "----------------------------------------\n",
            "Epoch 511\n",
            "Var loss:  tensor(1.0440e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4972270238243245e-06\n",
            "E_s_wdiff_all_sq: 3.245245732985573e-07\n",
            "E_IS_SCOPE: -2.0794457659769346e-08\n",
            "E_IS_E_SCOPE: 1.7477772843165786e-06\n",
            "Total Loss: 1.0440231025516304e-06\n",
            "----------------------------------------\n",
            "Epoch 512\n",
            "Var loss:  tensor(1.0390e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5040246122140136e-06\n",
            "E_s_wdiff_all_sq: 3.2979533141986e-07\n",
            "E_IS_SCOPE: 1.7583021453380573e-09\n",
            "E_IS_E_SCOPE: 1.7735934405987265e-06\n",
            "Total Loss: 1.0390231398659363e-06\n",
            "----------------------------------------\n",
            "Epoch 513\n",
            "Var loss:  tensor(1.0338e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.511331025423321e-06\n",
            "E_s_wdiff_all_sq: 3.395054552692379e-07\n",
            "E_IS_SCOPE: 3.8476661175087284e-08\n",
            "E_IS_E_SCOPE: 1.8117166591286964e-06\n",
            "Total Loss: 1.033809710225424e-06\n",
            "----------------------------------------\n",
            "Epoch 514\n",
            "Var loss:  tensor(1.0286e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5241897883428174e-06\n",
            "E_s_wdiff_all_sq: 3.5620939611105895e-07\n",
            "E_IS_SCOPE: 6.920002924773044e-08\n",
            "E_IS_E_SCOPE: 1.8431176398549179e-06\n",
            "Total Loss: 1.028609306995943e-06\n",
            "----------------------------------------\n",
            "Epoch 515\n",
            "Var loss:  tensor(1.0233e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.529468609956791e-06\n",
            "E_s_wdiff_all_sq: 3.7248924205169757e-07\n",
            "E_IS_SCOPE: 9.132871273982721e-08\n",
            "E_IS_E_SCOPE: 1.8623799509293993e-06\n",
            "Total Loss: 1.0233410275045073e-06\n",
            "----------------------------------------\n",
            "Epoch 516\n",
            "Var loss:  tensor(1.0182e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5359721053216926e-06\n",
            "E_s_wdiff_all_sq: 3.755604612772865e-07\n",
            "E_IS_SCOPE: 1.0861843096253558e-07\n",
            "E_IS_E_SCOPE: 1.883935739862553e-06\n",
            "Total Loss: 1.0182411622229307e-06\n",
            "----------------------------------------\n",
            "Epoch 517\n",
            "Var loss:  tensor(1.0131e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5167741066266598e-06\n",
            "E_s_wdiff_all_sq: 3.5432769309532145e-07\n",
            "E_IS_SCOPE: 1.6390066609524085e-07\n",
            "E_IS_E_SCOPE: 1.942788625242543e-06\n",
            "Total Loss: 1.0131346312152934e-06\n",
            "----------------------------------------\n",
            "Epoch 518\n",
            "Var loss:  tensor(1.0078e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4989745680307993e-06\n",
            "E_s_wdiff_all_sq: 3.437604540204291e-07\n",
            "E_IS_SCOPE: 1.9395057051719974e-07\n",
            "E_IS_E_SCOPE: 1.971895286643644e-06\n",
            "Total Loss: 1.007788817736041e-06\n",
            "----------------------------------------\n",
            "Epoch 519\n",
            "Var loss:  tensor(1.0026e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.477694584050073e-06\n",
            "E_s_wdiff_all_sq: 3.2995746663107966e-07\n",
            "E_IS_SCOPE: 2.2807655885630748e-07\n",
            "E_IS_E_SCOPE: 2.0048924803563488e-06\n",
            "Total Loss: 1.002569410397469e-06\n",
            "----------------------------------------\n",
            "Epoch 520\n",
            "Var loss:  tensor(9.9739e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4648311696786713e-06\n",
            "E_s_wdiff_all_sq: 3.1410498897722506e-07\n",
            "E_IS_SCOPE: 2.6342053454882864e-07\n",
            "E_IS_E_SCOPE: 2.0443224765256672e-06\n",
            "Total Loss: 9.973864327263275e-07\n",
            "----------------------------------------\n",
            "Epoch 521\n",
            "Var loss:  tensor(9.9241e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4493259041314948e-06\n",
            "E_s_wdiff_all_sq: 2.998450127260865e-07\n",
            "E_IS_SCOPE: 2.9151293984649727e-07\n",
            "E_IS_E_SCOPE: 2.0742814270167033e-06\n",
            "Total Loss: 9.924080530435554e-07\n",
            "----------------------------------------\n",
            "Epoch 522\n",
            "Var loss:  tensor(9.8730e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4340537426367405e-06\n",
            "E_s_wdiff_all_sq: 2.92550120950839e-07\n",
            "E_IS_SCOPE: 3.136378635543762e-07\n",
            "E_IS_E_SCOPE: 2.0949726417353936e-06\n",
            "Total Loss: 9.872982013024261e-07\n",
            "----------------------------------------\n",
            "Epoch 523\n",
            "Var loss:  tensor(9.8222e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4107512852180625e-06\n",
            "E_s_wdiff_all_sq: 2.749367678009918e-07\n",
            "E_IS_SCOPE: 3.4875055307737153e-07\n",
            "E_IS_E_SCOPE: 2.129781434059878e-06\n",
            "Total Loss: 9.82216891430616e-07\n",
            "----------------------------------------\n",
            "Epoch 524\n",
            "Var loss:  tensor(9.7714e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3881162221668003e-06\n",
            "E_s_wdiff_all_sq: 2.49648914192941e-07\n",
            "E_IS_SCOPE: 3.878757895189034e-07\n",
            "E_IS_E_SCOPE: 2.1727737457859645e-06\n",
            "Total Loss: 9.771355314182957e-07\n",
            "----------------------------------------\n",
            "Epoch 525\n",
            "Var loss:  tensor(9.7211e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.375535360053185e-06\n",
            "E_s_wdiff_all_sq: 2.3624399751505148e-07\n",
            "E_IS_SCOPE: 4.180962125437981e-07\n",
            "E_IS_E_SCOPE: 2.205921092099959e-06\n",
            "Total Loss: 9.721057394043713e-07\n",
            "----------------------------------------\n",
            "Epoch 526\n",
            "Var loss:  tensor(9.6697e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.374041214750001e-06\n",
            "E_s_wdiff_all_sq: 2.397109233794132e-07\n",
            "E_IS_SCOPE: 4.2220140820767134e-07\n",
            "E_IS_E_SCOPE: 2.2101135157819226e-06\n",
            "Total Loss: 9.669702122006458e-07\n",
            "----------------------------------------\n",
            "Epoch 527\n",
            "Var loss:  tensor(9.6186e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3684811263663434e-06\n",
            "E_s_wdiff_all_sq: 2.406802859674399e-07\n",
            "E_IS_SCOPE: 4.303277070029541e-07\n",
            "E_IS_E_SCOPE: 2.2175326488834573e-06\n",
            "Total Loss: 9.618550926164564e-07\n",
            "----------------------------------------\n",
            "Epoch 528\n",
            "Var loss:  tensor(9.5683e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.358535269797179e-06\n",
            "E_s_wdiff_all_sq: 2.323200046314562e-07\n",
            "E_IS_SCOPE: 4.5110311429922485e-07\n",
            "E_IS_E_SCOPE: 2.240026973126505e-06\n",
            "Total Loss: 9.568316834897216e-07\n",
            "----------------------------------------\n",
            "Epoch 529\n",
            "Var loss:  tensor(9.5170e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3620020369289875e-06\n",
            "E_s_wdiff_all_sq: 2.3250695195186088e-07\n",
            "E_IS_SCOPE: 4.504298982350662e-07\n",
            "E_IS_E_SCOPE: 2.2435584879318826e-06\n",
            "Total Loss: 9.51702041562053e-07\n",
            "----------------------------------------\n",
            "Epoch 530\n",
            "Var loss:  tensor(9.4662e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3500387913000986e-06\n",
            "E_s_wdiff_all_sq: 2.2563479422573821e-07\n",
            "E_IS_SCOPE: 4.747231070875723e-07\n",
            "E_IS_E_SCOPE: 2.2678462701723916e-06\n",
            "Total Loss: 9.466218068832802e-07\n",
            "----------------------------------------\n",
            "Epoch 531\n",
            "Var loss:  tensor(9.4147e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3196778271908347e-06\n",
            "E_s_wdiff_all_sq: 2.0390468247378302e-07\n",
            "E_IS_SCOPE: 5.249494163242715e-07\n",
            "E_IS_E_SCOPE: 2.316334840994085e-06\n",
            "Total Loss: 9.414664313559847e-07\n",
            "----------------------------------------\n",
            "Epoch 532\n",
            "Var loss:  tensor(9.3634e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3218431358265216e-06\n",
            "E_s_wdiff_all_sq: 2.0243242527511517e-07\n",
            "E_IS_SCOPE: 5.280742812763871e-07\n",
            "E_IS_E_SCOPE: 2.323840154996881e-06\n",
            "Total Loss: 9.363430990889774e-07\n",
            "----------------------------------------\n",
            "Epoch 533\n",
            "Var loss:  tensor(9.3115e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.342172868691773e-06\n",
            "E_s_wdiff_all_sq: 2.194594294825539e-07\n",
            "E_IS_SCOPE: 4.967995098551083e-07\n",
            "E_IS_E_SCOPE: 2.296815094714371e-06\n",
            "Total Loss: 9.31146405469253e-07\n",
            "----------------------------------------\n",
            "Epoch 534\n",
            "Var loss:  tensor(9.2598e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.327762116871752e-06\n",
            "E_s_wdiff_all_sq: 2.170625207192059e-07\n",
            "E_IS_SCOPE: 5.13309360879156e-07\n",
            "E_IS_E_SCOPE: 2.309899750934738e-06\n",
            "Total Loss: 9.259829520199418e-07\n",
            "----------------------------------------\n",
            "Epoch 535\n",
            "Var loss:  tensor(9.2078e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3119972708255965e-06\n",
            "E_s_wdiff_all_sq: 2.0564178625416984e-07\n",
            "E_IS_SCOPE: 5.501371890321096e-07\n",
            "E_IS_E_SCOPE: 2.3471558553751172e-06\n",
            "Total Loss: 9.207822878639707e-07\n",
            "----------------------------------------\n",
            "Epoch 536\n",
            "Var loss:  tensor(9.1558e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3253801975728497e-06\n",
            "E_s_wdiff_all_sq: 2.109767497081109e-07\n",
            "E_IS_SCOPE: 5.562859486609559e-07\n",
            "E_IS_E_SCOPE: 2.3599284475257275e-06\n",
            "Total Loss: 9.155825861137541e-07\n",
            "----------------------------------------\n",
            "Epoch 537\n",
            "Var loss:  tensor(9.1059e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.337550332161378e-06\n",
            "E_s_wdiff_all_sq: 2.2528703872876508e-07\n",
            "E_IS_SCOPE: 5.46760145956851e-07\n",
            "E_IS_E_SCOPE: 2.3518266021462456e-06\n",
            "Total Loss: 9.105945170323835e-07\n",
            "----------------------------------------\n",
            "Epoch 538\n",
            "Var loss:  tensor(9.0516e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.314824321668004e-06\n",
            "E_s_wdiff_all_sq: 2.1680207403452635e-07\n",
            "E_IS_SCOPE: 5.844538868358498e-07\n",
            "E_IS_E_SCOPE: 2.3851159495944985e-06\n",
            "Total Loss: 9.051622580947388e-07\n",
            "----------------------------------------\n",
            "Epoch 539\n",
            "Var loss:  tensor(9.0024e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.321349796331393e-06\n",
            "E_s_wdiff_all_sq: 2.2059596149437426e-07\n",
            "E_IS_SCOPE: 5.964055187885204e-07\n",
            "E_IS_E_SCOPE: 2.4008938099048138e-06\n",
            "Total Loss: 9.002413885829908e-07\n",
            "----------------------------------------\n",
            "Epoch 540\n",
            "Var loss:  tensor(8.9482e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.363158581773909e-06\n",
            "E_s_wdiff_all_sq: 2.553644584754136e-07\n",
            "E_IS_SCOPE: 5.624322985627716e-07\n",
            "E_IS_E_SCOPE: 2.3731490307337948e-06\n",
            "Total Loss: 8.948247949350081e-07\n",
            "----------------------------------------\n",
            "Epoch 541\n",
            "Var loss:  tensor(8.8967e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.360509131830154e-06\n",
            "E_s_wdiff_all_sq: 2.671528440987714e-07\n",
            "E_IS_SCOPE: 5.925885455038943e-07\n",
            "E_IS_E_SCOPE: 2.3986643423545854e-06\n",
            "Total Loss: 8.896688300085596e-07\n",
            "----------------------------------------\n",
            "Epoch 542\n",
            "Var loss:  tensor(8.8446e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3485736396592803e-06\n",
            "E_s_wdiff_all_sq: 2.6366212927795933e-07\n",
            "E_IS_SCOPE: 6.383123001918757e-07\n",
            "E_IS_E_SCOPE: 2.44277206711968e-06\n",
            "Total Loss: 8.84456112504271e-07\n",
            "----------------------------------------\n",
            "Epoch 543\n",
            "Var loss:  tensor(8.7920e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.382536755359707e-06\n",
            "E_s_wdiff_all_sq: 2.855849285969228e-07\n",
            "E_IS_SCOPE: 6.26025592869842e-07\n",
            "E_IS_E_SCOPE: 2.4391355105526775e-06\n",
            "Total Loss: 8.791961273756725e-07\n",
            "----------------------------------------\n",
            "Epoch 544\n",
            "Var loss:  tensor(8.7395e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4111496776856536e-06\n",
            "E_s_wdiff_all_sq: 3.1385171851739187e-07\n",
            "E_IS_SCOPE: 6.07573696435432e-07\n",
            "E_IS_E_SCOPE: 2.4234816174814246e-06\n",
            "Total Loss: 8.739462530548367e-07\n",
            "----------------------------------------\n",
            "Epoch 545\n",
            "Var loss:  tensor(8.6865e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.39190018510043e-06\n",
            "E_s_wdiff_all_sq: 3.11750779570572e-07\n",
            "E_IS_SCOPE: 6.385865772324036e-07\n",
            "E_IS_E_SCOPE: 2.4485703763529165e-06\n",
            "Total Loss: 8.686459432673921e-07\n",
            "----------------------------------------\n",
            "Epoch 546\n",
            "Var loss:  tensor(8.6339e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.385550073317731e-06\n",
            "E_s_wdiff_all_sq: 3.049868780979512e-07\n",
            "E_IS_SCOPE: 6.631253473645205e-07\n",
            "E_IS_E_SCOPE: 2.475946060957529e-06\n",
            "Total Loss: 8.633859040123226e-07\n",
            "----------------------------------------\n",
            "Epoch 547\n",
            "Var loss:  tensor(8.5816e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4136156409642333e-06\n",
            "E_s_wdiff_all_sq: 3.203966626129653e-07\n",
            "E_IS_SCOPE: 6.358985878724776e-07\n",
            "E_IS_E_SCOPE: 2.457660941943333e-06\n",
            "Total Loss: 8.581584061881171e-07\n",
            "----------------------------------------\n",
            "Epoch 548\n",
            "Var loss:  tensor(8.5293e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4028237450551566e-06\n",
            "E_s_wdiff_all_sq: 3.181367955926596e-07\n",
            "E_IS_SCOPE: 6.598797607274771e-07\n",
            "E_IS_E_SCOPE: 2.479989448063332e-06\n",
            "Total Loss: 8.529317107693466e-07\n",
            "----------------------------------------\n",
            "Epoch 549\n",
            "Var loss:  tensor(8.4758e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3742837054722646e-06\n",
            "E_s_wdiff_all_sq: 3.041193285133988e-07\n",
            "E_IS_SCOPE: 7.145141413028322e-07\n",
            "E_IS_E_SCOPE: 2.5300398215614535e-06\n",
            "Total Loss: 8.475771524201818e-07\n",
            "----------------------------------------\n",
            "Epoch 550\n",
            "Var loss:  tensor(8.4228e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3886530909878345e-06\n",
            "E_s_wdiff_all_sq: 3.127574044352277e-07\n",
            "E_IS_SCOPE: 7.287337673638515e-07\n",
            "E_IS_E_SCOPE: 2.5497760318600706e-06\n",
            "Total Loss: 8.422752935387266e-07\n",
            "----------------------------------------\n",
            "Epoch 551\n",
            "Var loss:  tensor(8.3717e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4096685433341626e-06\n",
            "E_s_wdiff_all_sq: 3.283089858929502e-07\n",
            "E_IS_SCOPE: 7.133035892236453e-07\n",
            "E_IS_E_SCOPE: 2.5396288049708485e-06\n",
            "Total Loss: 8.371732619253656e-07\n",
            "----------------------------------------\n",
            "Epoch 552\n",
            "Var loss:  tensor(8.3168e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.365715142557619e-06\n",
            "E_s_wdiff_all_sq: 3.001793636042781e-07\n",
            "E_IS_SCOPE: 7.635050298302513e-07\n",
            "E_IS_E_SCOPE: 2.5846628890965473e-06\n",
            "Total Loss: 8.316841963993083e-07\n",
            "----------------------------------------\n",
            "Epoch 553\n",
            "Var loss:  tensor(8.2655e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3357859880676876e-06\n",
            "E_s_wdiff_all_sq: 2.7473434659939234e-07\n",
            "E_IS_SCOPE: 7.98510586119516e-07\n",
            "E_IS_E_SCOPE: 2.619993395727129e-06\n",
            "Total Loss: 8.265501582316279e-07\n",
            "----------------------------------------\n",
            "Epoch 554\n",
            "Var loss:  tensor(8.2112e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.360619460922551e-06\n",
            "E_s_wdiff_all_sq: 2.8695176854611784e-07\n",
            "E_IS_SCOPE: 7.580564628876725e-07\n",
            "E_IS_E_SCOPE: 2.588562026033967e-06\n",
            "Total Loss: 8.211207020624032e-07\n",
            "----------------------------------------\n",
            "Epoch 555\n",
            "Var loss:  tensor(8.1582e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3360509003450214e-06\n",
            "E_s_wdiff_all_sq: 2.71697104015717e-07\n",
            "E_IS_SCOPE: 7.724734973689556e-07\n",
            "E_IS_E_SCOPE: 2.600971226624614e-06\n",
            "Total Loss: 8.158224737965464e-07\n",
            "----------------------------------------\n",
            "Epoch 556\n",
            "Var loss:  tensor(8.1054e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.293044923825829e-06\n",
            "E_s_wdiff_all_sq: 2.433512101694557e-07\n",
            "E_IS_SCOPE: 8.247794193773799e-07\n",
            "E_IS_E_SCOPE: 2.6485878266891566e-06\n",
            "Total Loss: 8.10541035011379e-07\n",
            "----------------------------------------\n",
            "Epoch 557\n",
            "Var loss:  tensor(8.0509e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3237435271787477e-06\n",
            "E_s_wdiff_all_sq: 2.6078814302389933e-07\n",
            "E_IS_SCOPE: 8.093561853480716e-07\n",
            "E_IS_E_SCOPE: 2.6425205287706166e-06\n",
            "Total Loss: 8.050908332883164e-07\n",
            "----------------------------------------\n",
            "Epoch 558\n",
            "Var loss:  tensor(7.9986e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3481078208938927e-06\n",
            "E_s_wdiff_all_sq: 2.835182640307836e-07\n",
            "E_IS_SCOPE: 7.974583444265722e-07\n",
            "E_IS_E_SCOPE: 2.6340576728982256e-06\n",
            "Total Loss: 7.998550358983602e-07\n",
            "----------------------------------------\n",
            "Epoch 559\n",
            "Var loss:  tensor(7.9425e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3152878849611015e-06\n",
            "E_s_wdiff_all_sq: 2.7368967796703703e-07\n",
            "E_IS_SCOPE: 8.565788856113689e-07\n",
            "E_IS_E_SCOPE: 2.6844830769333082e-06\n",
            "Total Loss: 7.942539603287457e-07\n",
            "----------------------------------------\n",
            "Epoch 560\n",
            "Var loss:  tensor(7.8877e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3196744874502874e-06\n",
            "E_s_wdiff_all_sq: 2.7581113541973036e-07\n",
            "E_IS_SCOPE: 8.801671849796558e-07\n",
            "E_IS_E_SCOPE: 2.7119456810305083e-06\n",
            "Total Loss: 7.887704959074106e-07\n",
            "----------------------------------------\n",
            "Epoch 561\n",
            "Var loss:  tensor(7.8307e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.359977945636433e-06\n",
            "E_s_wdiff_all_sq: 3.0120599238277874e-07\n",
            "E_IS_SCOPE: 8.540437190806817e-07\n",
            "E_IS_E_SCOPE: 2.696126083290906e-06\n",
            "Total Loss: 7.830713608117638e-07\n",
            "----------------------------------------\n",
            "Epoch 562\n",
            "Var loss:  tensor(7.7737e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3434260313169704e-06\n",
            "E_s_wdiff_all_sq: 3.004792332012123e-07\n",
            "E_IS_SCOPE: 8.767247077018864e-07\n",
            "E_IS_E_SCOPE: 2.713744536288786e-06\n",
            "Total Loss: 7.773712769205187e-07\n",
            "----------------------------------------\n",
            "Epoch 563\n",
            "Var loss:  tensor(7.7156e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3132141055767504e-06\n",
            "E_s_wdiff_all_sq: 2.839358197315507e-07\n",
            "E_IS_SCOPE: 9.284779350008981e-07\n",
            "E_IS_E_SCOPE: 2.7615714038299336e-06\n",
            "Total Loss: 7.715554841656873e-07\n",
            "----------------------------------------\n",
            "Epoch 564\n",
            "Var loss:  tensor(7.6568e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.327260328666214e-06\n",
            "E_s_wdiff_all_sq: 2.8459144578216434e-07\n",
            "E_IS_SCOPE: 9.183533886726573e-07\n",
            "E_IS_E_SCOPE: 2.7610791942494697e-06\n",
            "Total Loss: 7.656814077089839e-07\n",
            "----------------------------------------\n",
            "Epoch 565\n",
            "Var loss:  tensor(7.5985e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.313065907773008e-06\n",
            "E_s_wdiff_all_sq: 2.7111636150155737e-07\n",
            "E_IS_SCOPE: 9.275580941112353e-07\n",
            "E_IS_E_SCOPE: 2.772841870614562e-06\n",
            "Total Loss: 7.598461292433556e-07\n",
            "----------------------------------------\n",
            "Epoch 566\n",
            "Var loss:  tensor(7.5400e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2747675496398786e-06\n",
            "E_s_wdiff_all_sq: 2.4966599967107475e-07\n",
            "E_IS_SCOPE: 9.54882593483937e-07\n",
            "E_IS_E_SCOPE: 2.794666691557691e-06\n",
            "Total Loss: 7.539974897998555e-07\n",
            "----------------------------------------\n",
            "Epoch 567\n",
            "Var loss:  tensor(7.4809e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2758471234957413e-06\n",
            "E_s_wdiff_all_sq: 2.4919380508846974e-07\n",
            "E_IS_SCOPE: 9.528831033253221e-07\n",
            "E_IS_E_SCOPE: 2.796399307660811e-06\n",
            "Total Loss: 7.480850457148536e-07\n",
            "----------------------------------------\n",
            "Epoch 568\n",
            "Var loss:  tensor(7.4222e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.28534784546399e-06\n",
            "E_s_wdiff_all_sq: 2.5328436686638846e-07\n",
            "E_IS_SCOPE: 9.521969573341137e-07\n",
            "E_IS_E_SCOPE: 2.8013516714726305e-06\n",
            "Total Loss: 7.42218186299128e-07\n",
            "----------------------------------------\n",
            "Epoch 569\n",
            "Var loss:  tensor(7.3642e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.26876202014923e-06\n",
            "E_s_wdiff_all_sq: 2.474010169668449e-07\n",
            "E_IS_SCOPE: 9.620718804151543e-07\n",
            "E_IS_E_SCOPE: 2.8087732421960435e-06\n",
            "Total Loss: 7.364224155991663e-07\n",
            "----------------------------------------\n",
            "Epoch 570\n",
            "Var loss:  tensor(7.3059e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2380850026762347e-06\n",
            "E_s_wdiff_all_sq: 2.2708536917950652e-07\n",
            "E_IS_SCOPE: 9.879423762282973e-07\n",
            "E_IS_E_SCOPE: 2.8323774983897072e-06\n",
            "Total Loss: 7.305935251524686e-07\n",
            "----------------------------------------\n",
            "Epoch 571\n",
            "Var loss:  tensor(7.2476e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.242436625429426e-06\n",
            "E_s_wdiff_all_sq: 2.2283247953127813e-07\n",
            "E_IS_SCOPE: 9.719357859589976e-07\n",
            "E_IS_E_SCOPE: 2.8235881377075237e-06\n",
            "Total Loss: 7.247635783796555e-07\n",
            "----------------------------------------\n",
            "Epoch 572\n",
            "Var loss:  tensor(7.1895e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.245431335916404e-06\n",
            "E_s_wdiff_all_sq: 2.253343637762248e-07\n",
            "E_IS_SCOPE: 9.479160903770389e-07\n",
            "E_IS_E_SCOPE: 2.8027207618430355e-06\n",
            "Total Loss: 7.189517651867441e-07\n",
            "----------------------------------------\n",
            "Epoch 573\n",
            "Var loss:  tensor(7.1316e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2242145034961603e-06\n",
            "E_s_wdiff_all_sq: 2.179519422330686e-07\n",
            "E_IS_SCOPE: 9.536334886719746e-07\n",
            "E_IS_E_SCOPE: 2.8044152235614846e-06\n",
            "Total Loss: 7.131632274626307e-07\n",
            "----------------------------------------\n",
            "Epoch 574\n",
            "Var loss:  tensor(7.0751e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2175548987348582e-06\n",
            "E_s_wdiff_all_sq: 2.1357076724375218e-07\n",
            "E_IS_SCOPE: 9.55035417457024e-07\n",
            "E_IS_E_SCOPE: 2.8075069580042206e-06\n",
            "Total Loss: 7.075051863752712e-07\n",
            "----------------------------------------\n",
            "Epoch 575\n",
            "Var loss:  tensor(7.0162e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2443120809384886e-06\n",
            "E_s_wdiff_all_sq: 2.303126884631337e-07\n",
            "E_IS_SCOPE: 9.460544644619706e-07\n",
            "E_IS_E_SCOPE: 2.8064753725579298e-06\n",
            "Total Loss: 7.016217122619957e-07\n",
            "----------------------------------------\n",
            "Epoch 576\n",
            "Var loss:  tensor(6.9590e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.256966186647496e-06\n",
            "E_s_wdiff_all_sq: 2.4853295466455e-07\n",
            "E_IS_SCOPE: 9.605822843952324e-07\n",
            "E_IS_E_SCOPE: 2.8210821803351186e-06\n",
            "Total Loss: 6.958975760817337e-07\n",
            "----------------------------------------\n",
            "Epoch 577\n",
            "Var loss:  tensor(6.9018e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2481963600095037e-06\n",
            "E_s_wdiff_all_sq: 2.5245817604058577e-07\n",
            "E_IS_SCOPE: 9.953626566780299e-07\n",
            "E_IS_E_SCOPE: 2.8523734069939096e-06\n",
            "Total Loss: 6.901808193157171e-07\n",
            "----------------------------------------\n",
            "Epoch 578\n",
            "Var loss:  tensor(6.8444e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2630195807514883e-06\n",
            "E_s_wdiff_all_sq: 2.620398413360083e-07\n",
            "E_IS_SCOPE: 9.86636227250106e-07\n",
            "E_IS_E_SCOPE: 2.8491384384127056e-06\n",
            "Total Loss: 6.844394530688394e-07\n",
            "----------------------------------------\n",
            "Epoch 579\n",
            "Var loss:  tensor(6.7866e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.259966896968272e-06\n",
            "E_s_wdiff_all_sq: 2.5726983027610436e-07\n",
            "E_IS_SCOPE: 9.91336332246803e-07\n",
            "E_IS_E_SCOPE: 2.8575879645287056e-06\n",
            "Total Loss: 6.786579381069211e-07\n",
            "----------------------------------------\n",
            "Epoch 580\n",
            "Var loss:  tensor(6.7292e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2377891808439822e-06\n",
            "E_s_wdiff_all_sq: 2.460655023019545e-07\n",
            "E_IS_SCOPE: 1.0069740327810735e-06\n",
            "E_IS_E_SCOPE: 2.870607562117859e-06\n",
            "Total Loss: 6.729207558470156e-07\n",
            "----------------------------------------\n",
            "Epoch 581\n",
            "Var loss:  tensor(6.6717e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2396206617120114e-06\n",
            "E_s_wdiff_all_sq: 2.4896257524898126e-07\n",
            "E_IS_SCOPE: 1.0103404212662166e-06\n",
            "E_IS_E_SCOPE: 2.876318513696291e-06\n",
            "Total Loss: 6.671660375814393e-07\n",
            "----------------------------------------\n",
            "Epoch 582\n",
            "Var loss:  tensor(6.6145e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2515026209267924e-06\n",
            "E_s_wdiff_all_sq: 2.5508822580974487e-07\n",
            "E_IS_SCOPE: 1.0217880822326667e-06\n",
            "E_IS_E_SCOPE: 2.8935019958460915e-06\n",
            "Total Loss: 6.614507038687561e-07\n",
            "----------------------------------------\n",
            "Epoch 583\n",
            "Var loss:  tensor(6.5569e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2386554800298082e-06\n",
            "E_s_wdiff_all_sq: 2.496319742964593e-07\n",
            "E_IS_SCOPE: 1.056521790259119e-06\n",
            "E_IS_E_SCOPE: 2.9274197008362333e-06\n",
            "Total Loss: 6.556918205576788e-07\n",
            "----------------------------------------\n",
            "Epoch 584\n",
            "Var loss:  tensor(6.4997e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2346614154506105e-06\n",
            "E_s_wdiff_all_sq: 2.5247205584933055e-07\n",
            "E_IS_SCOPE: 1.0739716834098287e-06\n",
            "E_IS_E_SCOPE: 2.944314608438794e-06\n",
            "Total Loss: 6.499676455219086e-07\n",
            "----------------------------------------\n",
            "Epoch 585\n",
            "Var loss:  tensor(6.4424e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2544586100178715e-06\n",
            "E_s_wdiff_all_sq: 2.671753970777127e-07\n",
            "E_IS_SCOPE: 1.0605874796125552e-06\n",
            "E_IS_E_SCOPE: 2.9363394351522946e-06\n",
            "Total Loss: 6.442434378392392e-07\n",
            "----------------------------------------\n",
            "Epoch 586\n",
            "Var loss:  tensor(6.3832e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2328612122660064e-06\n",
            "E_s_wdiff_all_sq: 2.5190805239984467e-07\n",
            "E_IS_SCOPE: 1.091219356054754e-06\n",
            "E_IS_E_SCOPE: 2.9667690462757404e-06\n",
            "Total Loss: 6.383179154027489e-07\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "Var loss:  tensor(6.3260e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2186032915325535e-06\n",
            "E_s_wdiff_all_sq: 2.4297226274069125e-07\n",
            "E_IS_SCOPE: 1.1066325904542337e-06\n",
            "E_IS_E_SCOPE: 2.982381391458476e-06\n",
            "Total Loss: 6.325975627619371e-07\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "Var loss:  tensor(6.2667e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.245450229569289e-06\n",
            "E_s_wdiff_all_sq: 2.643781986539962e-07\n",
            "E_IS_SCOPE: 1.0828514917318629e-06\n",
            "E_IS_E_SCOPE: 2.9642866123561433e-06\n",
            "Total Loss: 6.26665925645291e-07\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "Var loss:  tensor(6.2087e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2506931005722597e-06\n",
            "E_s_wdiff_all_sq: 2.731598519289033e-07\n",
            "E_IS_SCOPE: 1.1001358648993774e-06\n",
            "E_IS_E_SCOPE: 2.9826987669571877e-06\n",
            "Total Loss: 6.208715805062946e-07\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "Var loss:  tensor(6.1496e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.224578514839616e-06\n",
            "E_s_wdiff_all_sq: 2.5776070367807746e-07\n",
            "E_IS_SCOPE: 1.1526845079833364e-06\n",
            "E_IS_E_SCOPE: 3.0328451075844708e-06\n",
            "Total Loss: 6.1496074793783e-07\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "Var loss:  tensor(6.0907e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2338171935493808e-06\n",
            "E_s_wdiff_all_sq: 2.6247295333835034e-07\n",
            "E_IS_SCOPE: 1.1577970066024917e-06\n",
            "E_IS_E_SCOPE: 3.0431653404325645e-06\n",
            "Total Loss: 6.090717085294444e-07\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "Var loss:  tensor(6.0319e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.255812124927235e-06\n",
            "E_s_wdiff_all_sq: 2.8037102912613373e-07\n",
            "E_IS_SCOPE: 1.1407861260691787e-06\n",
            "E_IS_E_SCOPE: 3.031144127141823e-06\n",
            "Total Loss: 6.031892296343713e-07\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "Var loss:  tensor(5.9724e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2373597155475642e-06\n",
            "E_s_wdiff_all_sq: 2.751042362829088e-07\n",
            "E_IS_SCOPE: 1.1687487227325792e-06\n",
            "E_IS_E_SCOPE: 3.0554879458425094e-06\n",
            "Total Loss: 5.972411690233541e-07\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "Var loss:  tensor(5.9135e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.236311794409092e-06\n",
            "E_s_wdiff_all_sq: 2.7554724281664347e-07\n",
            "E_IS_SCOPE: 1.1999130952292998e-06\n",
            "E_IS_E_SCOPE: 3.088854478596763e-06\n",
            "Total Loss: 5.913459208360809e-07\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "Var loss:  tensor(5.8534e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.259056513968531e-06\n",
            "E_s_wdiff_all_sq: 2.921823138868684e-07\n",
            "E_IS_SCOPE: 1.2016164648519363e-06\n",
            "E_IS_E_SCOPE: 3.096614818317503e-06\n",
            "Total Loss: 5.853416291290886e-07\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "Var loss:  tensor(5.7946e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2603674142689595e-06\n",
            "E_s_wdiff_all_sq: 2.9862288665872444e-07\n",
            "E_IS_SCOPE: 1.2186685531483593e-06\n",
            "E_IS_E_SCOPE: 3.1140406149983536e-06\n",
            "Total Loss: 5.794645398888054e-07\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "Var loss:  tensor(5.7351e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2493606345147583e-06\n",
            "E_s_wdiff_all_sq: 2.94017530014984e-07\n",
            "E_IS_SCOPE: 1.2583283525569934e-06\n",
            "E_IS_E_SCOPE: 3.1534770755035275e-06\n",
            "Total Loss: 5.735097945852653e-07\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "Var loss:  tensor(5.6760e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2648275807414475e-06\n",
            "E_s_wdiff_all_sq: 3.059412412976035e-07\n",
            "E_IS_SCOPE: 1.2515249232587657e-06\n",
            "E_IS_E_SCOPE: 3.1513992129459098e-06\n",
            "Total Loss: 5.67601896048115e-07\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "Var loss:  tensor(5.6170e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2683119282771434e-06\n",
            "E_s_wdiff_all_sq: 3.1193924330705117e-07\n",
            "E_IS_SCOPE: 1.2651455914750896e-06\n",
            "E_IS_E_SCOPE: 3.1667149436453927e-06\n",
            "Total Loss: 5.616981166080451e-07\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "Var loss:  tensor(5.5566e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.262860249660549e-06\n",
            "E_s_wdiff_all_sq: 3.1366037323848016e-07\n",
            "E_IS_SCOPE: 1.297199785871814e-06\n",
            "E_IS_E_SCOPE: 3.1982020546143883e-06\n",
            "Total Loss: 5.556594749154793e-07\n",
            "----------------------------------------\n",
            "Epoch 601\n",
            "Var loss:  tensor(5.4969e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2703606043011167e-06\n",
            "E_s_wdiff_all_sq: 3.2060713648989347e-07\n",
            "E_IS_SCOPE: 1.3235397288968974e-06\n",
            "E_IS_E_SCOPE: 3.2278022194288265e-06\n",
            "Total Loss: 5.496926227259242e-07\n",
            "----------------------------------------\n",
            "Epoch 602\n",
            "Var loss:  tensor(5.4372e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2697680734298e-06\n",
            "E_s_wdiff_all_sq: 3.196204264181271e-07\n",
            "E_IS_SCOPE: 1.3480231068186936e-06\n",
            "E_IS_E_SCOPE: 3.2554711827819735e-06\n",
            "Total Loss: 5.437156310636709e-07\n",
            "----------------------------------------\n",
            "Epoch 603\n",
            "Var loss:  tensor(5.3771e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2524601652807135e-06\n",
            "E_s_wdiff_all_sq: 3.073298066734993e-07\n",
            "E_IS_SCOPE: 1.3772414289651956e-06\n",
            "E_IS_E_SCOPE: 3.285184003140716e-06\n",
            "Total Loss: 5.377093462347327e-07\n",
            "----------------------------------------\n",
            "Epoch 604\n",
            "Var loss:  tensor(5.3169e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.24185760120832e-06\n",
            "E_s_wdiff_all_sq: 2.994421034708892e-07\n",
            "E_IS_SCOPE: 1.3884126024038948e-06\n",
            "E_IS_E_SCOPE: 3.2980070785378944e-06\n",
            "Total Loss: 5.316906814479915e-07\n",
            "----------------------------------------\n",
            "Epoch 605\n",
            "Var loss:  tensor(5.2563e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.248607857830798e-06\n",
            "E_s_wdiff_all_sq: 3.0396387269468115e-07\n",
            "E_IS_SCOPE: 1.3774438794764842e-06\n",
            "E_IS_E_SCOPE: 3.2911825218383936e-06\n",
            "Total Loss: 5.25630836390858e-07\n",
            "----------------------------------------\n",
            "Epoch 606\n",
            "Var loss:  tensor(5.1966e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2445200607587246e-06\n",
            "E_s_wdiff_all_sq: 3.0443667617570873e-07\n",
            "E_IS_SCOPE: 1.3795284815736202e-06\n",
            "E_IS_E_SCOPE: 3.2939715949572012e-06\n",
            "Total Loss: 5.196612937944133e-07\n",
            "----------------------------------------\n",
            "Epoch 607\n",
            "Var loss:  tensor(5.1370e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2339100196109417e-06\n",
            "E_s_wdiff_all_sq: 2.999064497742989e-07\n",
            "E_IS_SCOPE: 1.4005414695064846e-06\n",
            "E_IS_E_SCOPE: 3.3149260067031952e-06\n",
            "Total Loss: 5.13698631421781e-07\n",
            "----------------------------------------\n",
            "Epoch 608\n",
            "Var loss:  tensor(5.0767e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2474089085945262e-06\n",
            "E_s_wdiff_all_sq: 3.090719138220447e-07\n",
            "E_IS_SCOPE: 1.4111958381512922e-06\n",
            "E_IS_E_SCOPE: 3.330759768156135e-06\n",
            "Total Loss: 5.076732707413548e-07\n",
            "----------------------------------------\n",
            "Epoch 609\n",
            "Var loss:  tensor(5.0157e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2283751821163657e-06\n",
            "E_s_wdiff_all_sq: 2.941630005280119e-07\n",
            "E_IS_SCOPE: 1.461473452852798e-06\n",
            "E_IS_E_SCOPE: 3.3820260028339968e-06\n",
            "Total Loss: 5.015712176045159e-07\n",
            "----------------------------------------\n",
            "Epoch 610\n",
            "Var loss:  tensor(4.9555e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2253938355385383e-06\n",
            "E_s_wdiff_all_sq: 2.916215801783846e-07\n",
            "E_IS_SCOPE: 1.5021794932598151e-06\n",
            "E_IS_E_SCOPE: 3.4255246355886665e-06\n",
            "Total Loss: 4.955461066810106e-07\n",
            "----------------------------------------\n",
            "Epoch 611\n",
            "Var loss:  tensor(4.8957e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2369926623585634e-06\n",
            "E_s_wdiff_all_sq: 3.0349467552556477e-07\n",
            "E_IS_SCOPE: 1.509484363856347e-06\n",
            "E_IS_E_SCOPE: 3.435682227540257e-06\n",
            "Total Loss: 4.895663954437371e-07\n",
            "----------------------------------------\n",
            "Epoch 612\n",
            "Var loss:  tensor(4.8344e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2411539812723383e-06\n",
            "E_s_wdiff_all_sq: 3.1038036726619944e-07\n",
            "E_IS_SCOPE: 1.5276020175121659e-06\n",
            "E_IS_E_SCOPE: 3.4555013077409027e-06\n",
            "Total Loss: 4.834391695272244e-07\n",
            "----------------------------------------\n",
            "Epoch 613\n",
            "Var loss:  tensor(4.7742e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.236210509755638e-06\n",
            "E_s_wdiff_all_sq: 3.093381307434432e-07\n",
            "E_IS_SCOPE: 1.5509363462286457e-06\n",
            "E_IS_E_SCOPE: 3.4798957107565637e-06\n",
            "Total Loss: 4.77417785934918e-07\n",
            "----------------------------------------\n",
            "Epoch 614\n",
            "Var loss:  tensor(4.7144e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2411157037868107e-06\n",
            "E_s_wdiff_all_sq: 3.154044169670031e-07\n",
            "E_IS_SCOPE: 1.5601004371754655e-06\n",
            "E_IS_E_SCOPE: 3.491467353143743e-06\n",
            "Total Loss: 4.7144159086181054e-07\n",
            "----------------------------------------\n",
            "Epoch 615\n",
            "Var loss:  tensor(4.6542e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.255977162871443e-06\n",
            "E_s_wdiff_all_sq: 3.3002967116542693e-07\n",
            "E_IS_SCOPE: 1.5758054723984116e-06\n",
            "E_IS_E_SCOPE: 3.5103031986305652e-06\n",
            "Total Loss: 4.654161752202675e-07\n",
            "----------------------------------------\n",
            "Epoch 616\n",
            "Var loss:  tensor(4.5936e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.262139180139065e-06\n",
            "E_s_wdiff_all_sq: 3.3824121584286047e-07\n",
            "E_IS_SCOPE: 1.6241902957967752e-06\n",
            "E_IS_E_SCOPE: 3.560692986682212e-06\n",
            "Total Loss: 4.5935671850388954e-07\n",
            "----------------------------------------\n",
            "Epoch 617\n",
            "Var loss:  tensor(4.5343e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.258246892995184e-06\n",
            "E_s_wdiff_all_sq: 3.392610865360801e-07\n",
            "E_IS_SCOPE: 1.6825371484604408e-06\n",
            "E_IS_E_SCOPE: 3.619548082462443e-06\n",
            "Total Loss: 4.5342807443365795e-07\n",
            "----------------------------------------\n",
            "Epoch 618\n",
            "Var loss:  tensor(4.4742e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.271098463660864e-06\n",
            "E_s_wdiff_all_sq: 3.519092089353212e-07\n",
            "E_IS_SCOPE: 1.7017096076100197e-06\n",
            "E_IS_E_SCOPE: 3.6418239847815672e-06\n",
            "Total Loss: 4.474246363610073e-07\n",
            "----------------------------------------\n",
            "Epoch 619\n",
            "Var loss:  tensor(4.4137e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.260784366413786e-06\n",
            "E_s_wdiff_all_sq: 3.433957072542021e-07\n",
            "E_IS_SCOPE: 1.7395763553163468e-06\n",
            "E_IS_E_SCOPE: 3.6818182077071913e-06\n",
            "Total Loss: 4.4136909035645504e-07\n",
            "----------------------------------------\n",
            "Epoch 620\n",
            "Var loss:  tensor(4.3540e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.244331577786646e-06\n",
            "E_s_wdiff_all_sq: 3.2985247931569267e-07\n",
            "E_IS_SCOPE: 1.7742486251398483e-06\n",
            "E_IS_E_SCOPE: 3.7180184475059403e-06\n",
            "Total Loss: 4.3540358971732795e-07\n",
            "----------------------------------------\n",
            "Epoch 621\n",
            "Var loss:  tensor(4.2926e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2462736541017063e-06\n",
            "E_s_wdiff_all_sq: 3.328562377262064e-07\n",
            "E_IS_SCOPE: 1.7756284541919687e-06\n",
            "E_IS_E_SCOPE: 3.7219368639357985e-06\n",
            "Total Loss: 4.292647328663994e-07\n",
            "----------------------------------------\n",
            "Epoch 622\n",
            "Var loss:  tensor(4.2323e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2426472388389147e-06\n",
            "E_s_wdiff_all_sq: 3.3209011374722853e-07\n",
            "E_IS_SCOPE: 1.7713313656761881e-06\n",
            "E_IS_E_SCOPE: 3.7192249391182126e-06\n",
            "Total Loss: 4.232341141861951e-07\n",
            "----------------------------------------\n",
            "Epoch 623\n",
            "Var loss:  tensor(4.1723e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.225430846563035e-06\n",
            "E_s_wdiff_all_sq: 3.1664773408779603e-07\n",
            "E_IS_SCOPE: 1.7868687048432554e-06\n",
            "E_IS_E_SCOPE: 3.7368767815882548e-06\n",
            "Total Loss: 4.1723109496379933e-07\n",
            "----------------------------------------\n",
            "Epoch 624\n",
            "Var loss:  tensor(4.1117e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2266819022807336e-06\n",
            "E_s_wdiff_all_sq: 3.1524439814264154e-07\n",
            "E_IS_SCOPE: 1.800910216802975e-06\n",
            "E_IS_E_SCOPE: 3.755278054555724e-06\n",
            "Total Loss: 4.1116596461115303e-07\n",
            "----------------------------------------\n",
            "Epoch 625\n",
            "Var loss:  tensor(4.0515e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.232707061654333e-06\n",
            "E_s_wdiff_all_sq: 3.244018384611563e-07\n",
            "E_IS_SCOPE: 1.8212656364516573e-06\n",
            "E_IS_E_SCOPE: 3.7770748579451977e-06\n",
            "Total Loss: 4.0515091618465476e-07\n",
            "----------------------------------------\n",
            "Epoch 626\n",
            "Var loss:  tensor(3.9902e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2344898824431702e-06\n",
            "E_s_wdiff_all_sq: 3.307909705194295e-07\n",
            "E_IS_SCOPE: 1.8552415168141906e-06\n",
            "E_IS_E_SCOPE: 3.8118136778402394e-06\n",
            "Total Loss: 3.990187258502019e-07\n",
            "----------------------------------------\n",
            "Epoch 627\n",
            "Var loss:  tensor(3.9292e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.248367576496485e-06\n",
            "E_s_wdiff_all_sq: 3.43862129643813e-07\n",
            "E_IS_SCOPE: 1.8726897216058854e-06\n",
            "E_IS_E_SCOPE: 3.8327137779035945e-06\n",
            "Total Loss: 3.929214702358144e-07\n",
            "----------------------------------------\n",
            "Epoch 628\n",
            "Var loss:  tensor(3.8679e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.260869063382661e-06\n",
            "E_s_wdiff_all_sq: 3.6069737381370897e-07\n",
            "E_IS_SCOPE: 1.8801491230879224e-06\n",
            "E_IS_E_SCOPE: 3.8410706121151966e-06\n",
            "Total Loss: 3.8679284749296443e-07\n",
            "----------------------------------------\n",
            "Epoch 629\n",
            "Var loss:  tensor(3.8067e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.264616896994879e-06\n",
            "E_s_wdiff_all_sq: 3.682851366391215e-07\n",
            "E_IS_SCOPE: 1.8943935062112193e-06\n",
            "E_IS_E_SCOPE: 3.856456126225359e-06\n",
            "Total Loss: 3.8067065630603817e-07\n",
            "----------------------------------------\n",
            "Epoch 630\n",
            "Var loss:  tensor(3.7452e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2572150824266753e-06\n",
            "E_s_wdiff_all_sq: 3.607300366438496e-07\n",
            "E_IS_SCOPE: 1.9206233529533897e-06\n",
            "E_IS_E_SCOPE: 3.885836010835969e-06\n",
            "Total Loss: 3.745238659962272e-07\n",
            "----------------------------------------\n",
            "Epoch 631\n",
            "Var loss:  tensor(3.6834e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2580045290487592e-06\n",
            "E_s_wdiff_all_sq: 3.59086048450775e-07\n",
            "E_IS_SCOPE: 1.951631221834988e-06\n",
            "E_IS_E_SCOPE: 3.921153279813743e-06\n",
            "Total Loss: 3.683385006190324e-07\n",
            "----------------------------------------\n",
            "Epoch 632\n",
            "Var loss:  tensor(3.6217e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2549791378680485e-06\n",
            "E_s_wdiff_all_sq: 3.5994234711898803e-07\n",
            "E_IS_SCOPE: 1.9768041458399792e-06\n",
            "E_IS_E_SCOPE: 3.947470724443539e-06\n",
            "Total Loss: 3.621677695205016e-07\n",
            "----------------------------------------\n",
            "Epoch 633\n",
            "Var loss:  tensor(3.5599e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.245187905299043e-06\n",
            "E_s_wdiff_all_sq: 3.551960195024832e-07\n",
            "E_IS_SCOPE: 2.00172149623202e-06\n",
            "E_IS_E_SCOPE: 3.972956032475408e-06\n",
            "Total Loss: 3.559869492883433e-07\n",
            "----------------------------------------\n",
            "Epoch 634\n",
            "Var loss:  tensor(3.4981e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2465072993399152e-06\n",
            "E_s_wdiff_all_sq: 3.541057065301905e-07\n",
            "E_IS_SCOPE: 2.0272032385386057e-06\n",
            "E_IS_E_SCOPE: 4.002731448984982e-06\n",
            "Total Loss: 3.4980930789553057e-07\n",
            "----------------------------------------\n",
            "Epoch 635\n",
            "Var loss:  tensor(3.4356e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2491637759123156e-06\n",
            "E_s_wdiff_all_sq: 3.5752096802892586e-07\n",
            "E_IS_SCOPE: 2.029248788347472e-06\n",
            "E_IS_E_SCOPE: 4.007522705921879e-06\n",
            "Total Loss: 3.435591087131344e-07\n",
            "----------------------------------------\n",
            "Epoch 636\n",
            "Var loss:  tensor(3.3715e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.218155327345463e-06\n",
            "E_s_wdiff_all_sq: 3.3565485004275365e-07\n",
            "E_IS_SCOPE: 2.0627585028486317e-06\n",
            "E_IS_E_SCOPE: 4.039667479989844e-06\n",
            "Total Loss: 3.3714665899884415e-07\n",
            "----------------------------------------\n",
            "Epoch 637\n",
            "Var loss:  tensor(3.3083e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.214276610319048e-06\n",
            "E_s_wdiff_all_sq: 3.276810249641645e-07\n",
            "E_IS_SCOPE: 2.0687528059994885e-06\n",
            "E_IS_E_SCOPE: 4.0508692251862965e-06\n",
            "Total Loss: 3.3082688295982615e-07\n",
            "----------------------------------------\n",
            "Epoch 638\n",
            "Var loss:  tensor(3.2436e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.223425138507047e-06\n",
            "E_s_wdiff_all_sq: 3.367636720942219e-07\n",
            "E_IS_SCOPE: 2.0686714879413473e-06\n",
            "E_IS_E_SCOPE: 4.05405444516103e-06\n",
            "Total Loss: 3.243596879520188e-07\n",
            "----------------------------------------\n",
            "Epoch 639\n",
            "Var loss:  tensor(3.1793e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2005812260195713e-06\n",
            "E_s_wdiff_all_sq: 3.2630361330439466e-07\n",
            "E_IS_SCOPE: 2.097007097911657e-06\n",
            "E_IS_E_SCOPE: 4.079411682920377e-06\n",
            "Total Loss: 3.179325786762952e-07\n",
            "----------------------------------------\n",
            "Epoch 640\n",
            "Var loss:  tensor(3.1147e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2032392870881816e-06\n",
            "E_s_wdiff_all_sq: 3.2223829777810466e-07\n",
            "E_IS_SCOPE: 2.106631353276159e-06\n",
            "E_IS_E_SCOPE: 4.095627284646267e-06\n",
            "Total Loss: 3.114732625484206e-07\n",
            "----------------------------------------\n",
            "Epoch 641\n",
            "Var loss:  tensor(3.0500e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2165749105955744e-06\n",
            "E_s_wdiff_all_sq: 3.3160252721753573e-07\n",
            "E_IS_SCOPE: 2.1168202711440745e-06\n",
            "E_IS_E_SCOPE: 4.111037282931814e-06\n",
            "Total Loss: 3.050024957811201e-07\n",
            "----------------------------------------\n",
            "Epoch 642\n",
            "Var loss:  tensor(2.9852e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1985805243726655e-06\n",
            "E_s_wdiff_all_sq: 3.2944675124329226e-07\n",
            "E_IS_SCOPE: 2.151706422022086e-06\n",
            "E_IS_E_SCOPE: 4.141244383912663e-06\n",
            "Total Loss: 2.985219853267777e-07\n",
            "----------------------------------------\n",
            "Epoch 643\n",
            "Var loss:  tensor(2.9196e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2014093753835503e-06\n",
            "E_s_wdiff_all_sq: 3.2927412838136677e-07\n",
            "E_IS_SCOPE: 2.1714671013577705e-06\n",
            "E_IS_E_SCOPE: 4.165784430989039e-06\n",
            "Total Loss: 2.9196472371820533e-07\n",
            "----------------------------------------\n",
            "Epoch 644\n",
            "Var loss:  tensor(2.8548e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2153522326579296e-06\n",
            "E_s_wdiff_all_sq: 3.3625427255201523e-07\n",
            "E_IS_SCOPE: 2.176964936786311e-06\n",
            "E_IS_E_SCOPE: 4.1780076569731285e-06\n",
            "Total Loss: 2.854766557108393e-07\n",
            "----------------------------------------\n",
            "Epoch 645\n",
            "Var loss:  tensor(2.7891e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.207290320937804e-06\n",
            "E_s_wdiff_all_sq: 3.409992874475864e-07\n",
            "E_IS_SCOPE: 2.202420876625219e-06\n",
            "E_IS_E_SCOPE: 4.20034544887669e-06\n",
            "Total Loss: 2.789060249658347e-07\n",
            "----------------------------------------\n",
            "Epoch 646\n",
            "Var loss:  tensor(2.7237e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2219898924947574e-06\n",
            "E_s_wdiff_all_sq: 3.55972586045192e-07\n",
            "E_IS_SCOPE: 2.2196038711529585e-06\n",
            "E_IS_E_SCOPE: 4.220660610605615e-06\n",
            "Total Loss: 2.7236796352281136e-07\n",
            "----------------------------------------\n",
            "Epoch 647\n",
            "Var loss:  tensor(2.6578e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.242007600763104e-06\n",
            "E_s_wdiff_all_sq: 3.704228191913165e-07\n",
            "E_IS_SCOPE: 2.2257822598856357e-06\n",
            "E_IS_E_SCOPE: 4.2329164882856714e-06\n",
            "Total Loss: 2.6578046075027464e-07\n",
            "----------------------------------------\n",
            "Epoch 648\n",
            "Var loss:  tensor(2.5917e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.234759966936325e-06\n",
            "E_s_wdiff_all_sq: 3.711542004520499e-07\n",
            "E_IS_SCOPE: 2.247656604695954e-06\n",
            "E_IS_E_SCOPE: 4.254107199829561e-06\n",
            "Total Loss: 2.591687121956201e-07\n",
            "----------------------------------------\n",
            "Epoch 649\n",
            "Var loss:  tensor(2.5249e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2389468845821076e-06\n",
            "E_s_wdiff_all_sq: 3.772520219882266e-07\n",
            "E_IS_SCOPE: 2.270816283522902e-06\n",
            "E_IS_E_SCOPE: 4.27964868209955e-06\n",
            "Total Loss: 2.5249420141914345e-07\n",
            "----------------------------------------\n",
            "Epoch 650\n",
            "Var loss:  tensor(2.4587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.246734408239045e-06\n",
            "E_s_wdiff_all_sq: 3.8188370945548316e-07\n",
            "E_IS_SCOPE: 2.284497072633958e-06\n",
            "E_IS_E_SCOPE: 4.298220488394748e-06\n",
            "Total Loss: 2.458680032405411e-07\n",
            "----------------------------------------\n",
            "Epoch 651\n",
            "Var loss:  tensor(2.3921e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2398732584382196e-06\n",
            "E_s_wdiff_all_sq: 3.8049429669704534e-07\n",
            "E_IS_SCOPE: 2.303701660149864e-06\n",
            "E_IS_E_SCOPE: 4.3180202019836855e-06\n",
            "Total Loss: 2.3920601405209076e-07\n",
            "----------------------------------------\n",
            "Epoch 652\n",
            "Var loss:  tensor(2.3257e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2570998837393893e-06\n",
            "E_s_wdiff_all_sq: 3.9763588834061256e-07\n",
            "E_IS_SCOPE: 2.302122399532701e-06\n",
            "E_IS_E_SCOPE: 4.319799633003183e-06\n",
            "Total Loss: 2.3257366443637271e-07\n",
            "----------------------------------------\n",
            "Epoch 653\n",
            "Var loss:  tensor(2.2572e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2487263200924656e-06\n",
            "E_s_wdiff_all_sq: 3.9350040767359296e-07\n",
            "E_IS_SCOPE: 2.325695806428968e-06\n",
            "E_IS_E_SCOPE: 4.344683054459093e-06\n",
            "Total Loss: 2.2571555233718153e-07\n",
            "----------------------------------------\n",
            "Epoch 654\n",
            "Var loss:  tensor(2.1893e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2412212393661758e-06\n",
            "E_s_wdiff_all_sq: 3.8879511596531374e-07\n",
            "E_IS_SCOPE: 2.3414048259137336e-06\n",
            "E_IS_E_SCOPE: 4.3623850673042e-06\n",
            "Total Loss: 2.1892977659848854e-07\n",
            "----------------------------------------\n",
            "Epoch 655\n",
            "Var loss:  tensor(2.1206e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2479970421876607e-06\n",
            "E_s_wdiff_all_sq: 3.947274892870171e-07\n",
            "E_IS_SCOPE: 2.3348581666094702e-06\n",
            "E_IS_E_SCOPE: 4.3596944993372585e-06\n",
            "Total Loss: 2.1206102342362628e-07\n",
            "----------------------------------------\n",
            "Epoch 656\n",
            "Var loss:  tensor(2.0520e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2339635315825162e-06\n",
            "E_s_wdiff_all_sq: 3.844018133698357e-07\n",
            "E_IS_SCOPE: 2.346557263040534e-06\n",
            "E_IS_E_SCOPE: 4.372971564161654e-06\n",
            "Total Loss: 2.0519725194900078e-07\n",
            "----------------------------------------\n",
            "Epoch 657\n",
            "Var loss:  tensor(1.9833e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2205388662363778e-06\n",
            "E_s_wdiff_all_sq: 3.7274134122040383e-07\n",
            "E_IS_SCOPE: 2.3740470411101714e-06\n",
            "E_IS_E_SCOPE: 4.403012227765751e-06\n",
            "Total Loss: 1.9833128768337412e-07\n",
            "----------------------------------------\n",
            "Epoch 658\n",
            "Var loss:  tensor(1.9140e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2248885560726926e-06\n",
            "E_s_wdiff_all_sq: 3.7549395818298113e-07\n",
            "E_IS_SCOPE: 2.379264954457476e-06\n",
            "E_IS_E_SCOPE: 4.412492695295546e-06\n",
            "Total Loss: 1.9140325219213023e-07\n",
            "----------------------------------------\n",
            "Epoch 659\n",
            "Var loss:  tensor(1.8447e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2205181739947852e-06\n",
            "E_s_wdiff_all_sq: 3.7681578702998515e-07\n",
            "E_IS_SCOPE: 2.3915451687938433e-06\n",
            "E_IS_E_SCOPE: 4.425391640058188e-06\n",
            "Total Loss: 1.8447358041466998e-07\n",
            "----------------------------------------\n",
            "Epoch 660\n",
            "Var loss:  tensor(1.7753e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2066982178729144e-06\n",
            "E_s_wdiff_all_sq: 3.657486106293631e-07\n",
            "E_IS_SCOPE: 2.417758113108464e-06\n",
            "E_IS_E_SCOPE: 4.4536987405378595e-06\n",
            "Total Loss: 1.7753248836331821e-07\n",
            "----------------------------------------\n",
            "Epoch 661\n",
            "Var loss:  tensor(1.7053e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.214022114399888e-06\n",
            "E_s_wdiff_all_sq: 3.6733575601006134e-07\n",
            "E_IS_SCOPE: 2.4426972488885567e-06\n",
            "E_IS_E_SCOPE: 4.485005305041184e-06\n",
            "Total Loss: 1.7053438206313275e-07\n",
            "----------------------------------------\n",
            "Epoch 662\n",
            "Var loss:  tensor(1.6354e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.206137412145002e-06\n",
            "E_s_wdiff_all_sq: 3.6865937071009277e-07\n",
            "E_IS_SCOPE: 2.468569393324447e-06\n",
            "E_IS_E_SCOPE: 4.509772171447652e-06\n",
            "Total Loss: 1.6353662116705657e-07\n",
            "----------------------------------------\n",
            "Epoch 663\n",
            "Var loss:  tensor(1.5649e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2124525750186468e-06\n",
            "E_s_wdiff_all_sq: 3.767388825823589e-07\n",
            "E_IS_SCOPE: 2.4754162560248673e-06\n",
            "E_IS_E_SCOPE: 4.519258361521757e-06\n",
            "Total Loss: 1.5649361742106732e-07\n",
            "----------------------------------------\n",
            "Epoch 664\n",
            "Var loss:  tensor(1.4945e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2248339704008734e-06\n",
            "E_s_wdiff_all_sq: 3.8490516519282626e-07\n",
            "E_IS_SCOPE: 2.474739778043193e-06\n",
            "E_IS_E_SCOPE: 4.524210960346207e-06\n",
            "Total Loss: 1.494505765805798e-07\n",
            "----------------------------------------\n",
            "Epoch 665\n",
            "Var loss:  tensor(1.4239e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2269800221462008e-06\n",
            "E_s_wdiff_all_sq: 3.9261517892597944e-07\n",
            "E_IS_SCOPE: 2.4994624871682766e-06\n",
            "E_IS_E_SCOPE: 4.549683695255213e-06\n",
            "Total Loss: 1.423865630249059e-07\n",
            "----------------------------------------\n",
            "Epoch 666\n",
            "Var loss:  tensor(1.3528e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.221661133561339e-06\n",
            "E_s_wdiff_all_sq: 3.944651808145178e-07\n",
            "E_IS_SCOPE: 2.528040470007649e-06\n",
            "E_IS_E_SCOPE: 4.578231325275946e-06\n",
            "Total Loss: 1.3527837818878599e-07\n",
            "----------------------------------------\n",
            "Epoch 667\n",
            "Var loss:  tensor(1.2816e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.230141934987435e-06\n",
            "E_s_wdiff_all_sq: 3.970999121424454e-07\n",
            "E_IS_SCOPE: 2.540352555526112e-06\n",
            "E_IS_E_SCOPE: 4.5970231660103335e-06\n",
            "Total Loss: 1.2816493785510673e-07\n",
            "----------------------------------------\n",
            "Epoch 668\n",
            "Var loss:  tensor(1.2104e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.222622133813054e-06\n",
            "E_s_wdiff_all_sq: 3.9312473121636056e-07\n",
            "E_IS_SCOPE: 2.5560931543532927e-06\n",
            "E_IS_E_SCOPE: 4.614554102840906e-06\n",
            "Total Loss: 1.2103964160002676e-07\n",
            "----------------------------------------\n",
            "Epoch 669\n",
            "Var loss:  tensor(1.1394e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.237442028358048e-06\n",
            "E_s_wdiff_all_sq: 4.085595275811587e-07\n",
            "E_IS_SCOPE: 2.5562405120262396e-06\n",
            "E_IS_E_SCOPE: 4.6179433188798005e-06\n",
            "Total Loss: 1.139410230483267e-07\n",
            "----------------------------------------\n",
            "Epoch 670\n",
            "Var loss:  tensor(1.0670e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.219833436629302e-06\n",
            "E_s_wdiff_all_sq: 3.9519493939255096e-07\n",
            "E_IS_SCOPE: 2.5888784987358574e-06\n",
            "E_IS_E_SCOPE: 4.652079872229377e-06\n",
            "Total Loss: 1.0669988622827038e-07\n",
            "----------------------------------------\n",
            "Epoch 671\n",
            "Var loss:  tensor(9.9560e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2179417698391487e-06\n",
            "E_s_wdiff_all_sq: 3.912730294567337e-07\n",
            "E_IS_SCOPE: 2.604621424182304e-06\n",
            "E_IS_E_SCOPE: 4.672407824936846e-06\n",
            "Total Loss: 9.956007485188981e-08\n",
            "----------------------------------------\n",
            "Epoch 672\n",
            "Var loss:  tensor(9.2390e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.239969242618583e-06\n",
            "E_s_wdiff_all_sq: 4.120811604776457e-07\n",
            "E_IS_SCOPE: 2.6093328720222905e-06\n",
            "E_IS_E_SCOPE: 4.681313856339143e-06\n",
            "Total Loss: 9.239024948578986e-08\n",
            "----------------------------------------\n",
            "Epoch 673\n",
            "Var loss:  tensor(8.5174e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.218249656883264e-06\n",
            "E_s_wdiff_all_sq: 4.0388497269451034e-07\n",
            "E_IS_SCOPE: 2.648579602258282e-06\n",
            "E_IS_E_SCOPE: 4.717406843806228e-06\n",
            "Total Loss: 8.517433707141983e-08\n",
            "----------------------------------------\n",
            "Epoch 674\n",
            "Var loss:  tensor(7.8165e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.219244329124313e-06\n",
            "E_s_wdiff_all_sq: 3.9907255397436496e-07\n",
            "E_IS_SCOPE: 2.6618092943317736e-06\n",
            "E_IS_E_SCOPE: 4.737044733077263e-06\n",
            "Total Loss: 7.816503363752776e-08\n",
            "----------------------------------------\n",
            "Epoch 675\n",
            "Var loss:  tensor(7.1034e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2311028027516063e-06\n",
            "E_s_wdiff_all_sq: 4.0752270807000004e-07\n",
            "E_IS_SCOPE: 2.6497953447688235e-06\n",
            "E_IS_E_SCOPE: 4.7303003501949066e-06\n",
            "Total Loss: 7.103421980800053e-08\n",
            "----------------------------------------\n",
            "Epoch 676\n",
            "Var loss:  tensor(6.4026e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2136506769488574e-06\n",
            "E_s_wdiff_all_sq: 4.019766030158652e-07\n",
            "E_IS_SCOPE: 2.658413986767181e-06\n",
            "E_IS_E_SCOPE: 4.736470318388636e-06\n",
            "Total Loss: 6.402554666864195e-08\n",
            "----------------------------------------\n",
            "Epoch 677\n",
            "Var loss:  tensor(5.6904e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.217226240723488e-06\n",
            "E_s_wdiff_all_sq: 3.991001956603457e-07\n",
            "E_IS_SCOPE: 2.677503019811535e-06\n",
            "E_IS_E_SCOPE: 4.762345948756039e-06\n",
            "Total Loss: 5.690432315269246e-08\n",
            "----------------------------------------\n",
            "Epoch 678\n",
            "Var loss:  tensor(4.9829e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2259802611471376e-06\n",
            "E_s_wdiff_all_sq: 4.0558208641675033e-07\n",
            "E_IS_SCOPE: 2.7181638404328417e-06\n",
            "E_IS_E_SCOPE: 4.8076806572741305e-06\n",
            "Total Loss: 4.9828677026369124e-08\n",
            "----------------------------------------\n",
            "Epoch 679\n",
            "Var loss:  tensor(4.2727e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2160419020424935e-06\n",
            "E_s_wdiff_all_sq: 4.1104971141012735e-07\n",
            "E_IS_SCOPE: 2.755885116637818e-06\n",
            "E_IS_E_SCOPE: 4.84124982964535e-06\n",
            "Total Loss: 4.272690059586125e-08\n",
            "----------------------------------------\n",
            "Epoch 680\n",
            "Var loss:  tensor(3.5568e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.232510576964226e-06\n",
            "E_s_wdiff_all_sq: 4.2220155578569636e-07\n",
            "E_IS_SCOPE: 2.7600485524319895e-06\n",
            "E_IS_E_SCOPE: 4.85165121203897e-06\n",
            "Total Loss: 3.55678379431267e-08\n",
            "----------------------------------------\n",
            "Epoch 681\n",
            "Var loss:  tensor(2.8353e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.234523568397558e-06\n",
            "E_s_wdiff_all_sq: 4.1878277227783956e-07\n",
            "E_IS_SCOPE: 2.765806558426553e-06\n",
            "E_IS_E_SCOPE: 4.863732584522189e-06\n",
            "Total Loss: 2.8352879907004707e-08\n",
            "----------------------------------------\n",
            "Epoch 682\n",
            "Var loss:  tensor(2.1068e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2138873931998373e-06\n",
            "E_s_wdiff_all_sq: 4.1079884777412644e-07\n",
            "E_IS_SCOPE: 2.7784712623707886e-06\n",
            "E_IS_E_SCOPE: 4.873713697461967e-06\n",
            "Total Loss: 2.1067811221913172e-08\n",
            "----------------------------------------\n",
            "Epoch 683\n",
            "Var loss:  tensor(1.3764e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.218517778787585e-06\n",
            "E_s_wdiff_all_sq: 4.1361715760921757e-07\n",
            "E_IS_SCOPE: 2.7657590317054747e-06\n",
            "E_IS_E_SCOPE: 4.865559470430571e-06\n",
            "Total Loss: 1.3763879706734249e-08\n",
            "----------------------------------------\n",
            "Epoch 684\n",
            "Var loss:  tensor(6.4754e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.216419957893575e-06\n",
            "E_s_wdiff_all_sq: 4.0593360974084905e-07\n",
            "E_IS_SCOPE: 2.764133565171533e-06\n",
            "E_IS_E_SCOPE: 4.870371088192987e-06\n",
            "Total Loss: 6.4754380883766755e-09\n",
            "----------------------------------------\n",
            "Epoch 685\n",
            "Var loss:  tensor(-8.7346e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.192023810815136e-06\n",
            "E_s_wdiff_all_sq: 3.917722140356828e-07\n",
            "E_IS_SCOPE: 2.8005205297130975e-06\n",
            "E_IS_E_SCOPE: 4.905315125480908e-06\n",
            "Total Loss: -8.734587776073519e-10\n",
            "----------------------------------------\n",
            "Epoch 686\n",
            "Var loss:  tensor(-8.1300e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.198966065080738e-06\n",
            "E_s_wdiff_all_sq: 3.9721632945296996e-07\n",
            "E_IS_SCOPE: 2.8222695926208903e-06\n",
            "E_IS_E_SCOPE: 4.931441543804423e-06\n",
            "Total Loss: -8.130030760738776e-09\n",
            "----------------------------------------\n",
            "Epoch 687\n",
            "Var loss:  tensor(-1.5540e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.19664384581796e-06\n",
            "E_s_wdiff_all_sq: 3.9372311542898034e-07\n",
            "E_IS_SCOPE: 2.842225184623148e-06\n",
            "E_IS_E_SCOPE: 4.955687696675159e-06\n",
            "Total Loss: -1.5540157736482686e-08\n",
            "----------------------------------------\n",
            "Epoch 688\n",
            "Var loss:  tensor(-2.2913e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1758770228611676e-06\n",
            "E_s_wdiff_all_sq: 3.7833399758750514e-07\n",
            "E_IS_SCOPE: 2.8642699617149128e-06\n",
            "E_IS_E_SCOPE: 4.978730044557252e-06\n",
            "Total Loss: -2.2913004432458894e-08\n",
            "----------------------------------------\n",
            "Epoch 689\n",
            "Var loss:  tensor(-3.0377e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.165711171252185e-06\n",
            "E_s_wdiff_all_sq: 3.701717544263617e-07\n",
            "E_IS_SCOPE: 2.8625782464171955e-06\n",
            "E_IS_E_SCOPE: 4.979768379703445e-06\n",
            "Total Loss: -3.0376713768115125e-08\n",
            "----------------------------------------\n",
            "Epoch 690\n",
            "Var loss:  tensor(-3.7802e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1578267367809873e-06\n",
            "E_s_wdiff_all_sq: 3.611305089646108e-07\n",
            "E_IS_SCOPE: 2.8568876364340063e-06\n",
            "E_IS_E_SCOPE: 4.978368821670012e-06\n",
            "Total Loss: -3.780200667707595e-08\n",
            "----------------------------------------\n",
            "Epoch 691\n",
            "Var loss:  tensor(-4.5234e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.142587040652238e-06\n",
            "E_s_wdiff_all_sq: 3.48900420131752e-07\n",
            "E_IS_SCOPE: 2.8638578739285097e-06\n",
            "E_IS_E_SCOPE: 4.987550066043329e-06\n",
            "Total Loss: -4.523362773059468e-08\n",
            "----------------------------------------\n",
            "Epoch 692\n",
            "Var loss:  tensor(-5.2582e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1343480863200594e-06\n",
            "E_s_wdiff_all_sq: 3.44549991828731e-07\n",
            "E_IS_SCOPE: 2.8698952818452054e-06\n",
            "E_IS_E_SCOPE: 4.995317220430851e-06\n",
            "Total Loss: -5.258164670140358e-08\n",
            "----------------------------------------\n",
            "Epoch 693\n",
            "Var loss:  tensor(-6.0074e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1532292420893308e-06\n",
            "E_s_wdiff_all_sq: 3.588089947823437e-07\n",
            "E_IS_SCOPE: 2.8770197534503663e-06\n",
            "E_IS_E_SCOPE: 5.008499089993374e-06\n",
            "Total Loss: -6.007428980046829e-08\n",
            "----------------------------------------\n",
            "Epoch 694\n",
            "Var loss:  tensor(-6.7624e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1540187497757097e-06\n",
            "E_s_wdiff_all_sq: 3.647603869189331e-07\n",
            "E_IS_SCOPE: 2.925601228676869e-06\n",
            "E_IS_E_SCOPE: 5.058274287775611e-06\n",
            "Total Loss: -6.762361936214938e-08\n",
            "----------------------------------------\n",
            "Epoch 695\n",
            "Var loss:  tensor(-7.5057e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1461448107593807e-06\n",
            "E_s_wdiff_all_sq: 3.627639499753416e-07\n",
            "E_IS_SCOPE: 2.9727680416739703e-06\n",
            "E_IS_E_SCOPE: 5.106218838060197e-06\n",
            "Total Loss: -7.505659600985647e-08\n",
            "----------------------------------------\n",
            "Epoch 696\n",
            "Var loss:  tensor(-8.2509e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.168610354038713e-06\n",
            "E_s_wdiff_all_sq: 3.771637732812805e-07\n",
            "E_IS_SCOPE: 2.9760128338689633e-06\n",
            "E_IS_E_SCOPE: 5.117222726946844e-06\n",
            "Total Loss: -8.250906941977129e-08\n",
            "----------------------------------------\n",
            "Epoch 697\n",
            "Var loss:  tensor(-9.0098e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1631263389906168e-06\n",
            "E_s_wdiff_all_sq: 3.7886717648543557e-07\n",
            "E_IS_SCOPE: 2.9903937979974394e-06\n",
            "E_IS_E_SCOPE: 5.131804516063354e-06\n",
            "Total Loss: -9.009813764808906e-08\n",
            "----------------------------------------\n",
            "Epoch 698\n",
            "Var loss:  tensor(-9.7598e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1513108983343003e-06\n",
            "E_s_wdiff_all_sq: 3.7246799101047157e-07\n",
            "E_IS_SCOPE: 3.003060633319871e-06\n",
            "E_IS_E_SCOPE: 5.1455130753156614e-06\n",
            "Total Loss: -9.759784068919363e-08\n",
            "----------------------------------------\n",
            "Epoch 699\n",
            "Var loss:  tensor(-1.0518e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1694999826964936e-06\n",
            "E_s_wdiff_all_sq: 3.824302165580049e-07\n",
            "E_IS_SCOPE: 2.986393996952071e-06\n",
            "E_IS_E_SCOPE: 5.136752657404982e-06\n",
            "Total Loss: -1.0518341878877455e-07\n",
            "----------------------------------------\n",
            "Epoch 700\n",
            "Var loss:  tensor(-1.1276e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1634131803429882e-06\n",
            "E_s_wdiff_all_sq: 3.849534748473212e-07\n",
            "E_IS_SCOPE: 2.991501467808162e-06\n",
            "E_IS_E_SCOPE: 5.141343473501514e-06\n",
            "Total Loss: -1.1276016991247555e-07\n",
            "----------------------------------------\n",
            "Epoch 701\n",
            "Var loss:  tensor(-1.2051e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.168711884278917e-06\n",
            "E_s_wdiff_all_sq: 3.909251585004982e-07\n",
            "E_IS_SCOPE: 3.017478458870808e-06\n",
            "E_IS_E_SCOPE: 5.170856621322277e-06\n",
            "Total Loss: -1.2050546314596074e-07\n",
            "----------------------------------------\n",
            "Epoch 702\n",
            "Var loss:  tensor(-1.2818e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.187866968294477e-06\n",
            "E_s_wdiff_all_sq: 4.036823321257661e-07\n",
            "E_IS_SCOPE: 3.05396627639253e-06\n",
            "E_IS_E_SCOPE: 5.214383083334594e-06\n",
            "Total Loss: -1.2818484173686007e-07\n",
            "----------------------------------------\n",
            "Epoch 703\n",
            "Var loss:  tensor(-1.3586e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.176922352476698e-06\n",
            "E_s_wdiff_all_sq: 4.0422159818280197e-07\n",
            "E_IS_SCOPE: 3.0968558740180356e-06\n",
            "E_IS_E_SCOPE: 5.25536605419755e-06\n",
            "Total Loss: -1.3585547008657246e-07\n",
            "----------------------------------------\n",
            "Epoch 704\n",
            "Var loss:  tensor(-1.4361e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.186610518042121e-06\n",
            "E_s_wdiff_all_sq: 4.102687798323156e-07\n",
            "E_IS_SCOPE: 3.1049086105441973e-06\n",
            "E_IS_E_SCOPE: 5.269117003515328e-06\n",
            "Total Loss: -1.4361091175389688e-07\n",
            "----------------------------------------\n",
            "Epoch 705\n",
            "Var loss:  tensor(-1.5143e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1802172087106727e-06\n",
            "E_s_wdiff_all_sq: 4.0188429889342385e-07\n",
            "E_IS_SCOPE: 3.1130656673006285e-06\n",
            "E_IS_E_SCOPE: 5.282177455153178e-06\n",
            "Total Loss: -1.5142652990929133e-07\n",
            "----------------------------------------\n",
            "Epoch 706\n",
            "Var loss:  tensor(-1.5928e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1452255888893165e-06\n",
            "E_s_wdiff_all_sq: 3.803186916924095e-07\n",
            "E_IS_SCOPE: 3.1314473245382724e-06\n",
            "E_IS_E_SCOPE: 5.297772148867724e-06\n",
            "Total Loss: -1.592786154834378e-07\n",
            "----------------------------------------\n",
            "Epoch 707\n",
            "Var loss:  tensor(-1.6709e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.155409829654846e-06\n",
            "E_s_wdiff_all_sq: 3.81153807022229e-07\n",
            "E_IS_SCOPE: 3.106863489872129e-06\n",
            "E_IS_E_SCOPE: 5.281770723597994e-06\n",
            "Total Loss: -1.6709430884055352e-07\n",
            "----------------------------------------\n",
            "Epoch 708\n",
            "Var loss:  tensor(-1.7503e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.136453626385599e-06\n",
            "E_s_wdiff_all_sq: 3.667476783225624e-07\n",
            "E_IS_SCOPE: 3.1179172153262666e-06\n",
            "E_IS_E_SCOPE: 5.294516746641607e-06\n",
            "Total Loss: -1.7502897858908568e-07\n",
            "----------------------------------------\n",
            "Epoch 709\n",
            "Var loss:  tensor(-1.8296e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1241163914761923e-06\n",
            "E_s_wdiff_all_sq: 3.592087020909724e-07\n",
            "E_IS_SCOPE: 3.1573390198471316e-06\n",
            "E_IS_E_SCOPE: 5.335505638050516e-06\n",
            "Total Loss: -1.8296141104298901e-07\n",
            "----------------------------------------\n",
            "Epoch 710\n",
            "Var loss:  tensor(-1.9092e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.124286545389344e-06\n",
            "E_s_wdiff_all_sq: 3.587385404126041e-07\n",
            "E_IS_SCOPE: 3.185488271773368e-06\n",
            "E_IS_E_SCOPE: 5.367954355410877e-06\n",
            "Total Loss: -1.909200263197181e-07\n",
            "----------------------------------------\n",
            "Epoch 711\n",
            "Var loss:  tensor(-1.9889e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1226179705285843e-06\n",
            "E_s_wdiff_all_sq: 3.5597927412710063e-07\n",
            "E_IS_SCOPE: 3.2109899538314583e-06\n",
            "E_IS_E_SCOPE: 5.39798661134649e-06\n",
            "Total Loss: -1.9889048265002177e-07\n",
            "----------------------------------------\n",
            "Epoch 712\n",
            "Var loss:  tensor(-2.0691e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.105652481774636e-06\n",
            "E_s_wdiff_all_sq: 3.4397952088840187e-07\n",
            "E_IS_SCOPE: 3.243341585794253e-06\n",
            "E_IS_E_SCOPE: 5.431867492194809e-06\n",
            "Total Loss: -2.0691471593631847e-07\n",
            "----------------------------------------\n",
            "Epoch 713\n",
            "Var loss:  tensor(-2.1498e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1075416311182507e-06\n",
            "E_s_wdiff_all_sq: 3.4246578648589413e-07\n",
            "E_IS_SCOPE: 3.2501495293829724e-06\n",
            "E_IS_E_SCOPE: 5.444409016254061e-06\n",
            "Total Loss: -2.1497899313126103e-07\n",
            "----------------------------------------\n",
            "Epoch 714\n",
            "Var loss:  tensor(-2.2301e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1099030756869733e-06\n",
            "E_s_wdiff_all_sq: 3.459868492970389e-07\n",
            "E_IS_SCOPE: 3.25275936805232e-06\n",
            "E_IS_E_SCOPE: 5.450453954421132e-06\n",
            "Total Loss: -2.2300881036913072e-07\n",
            "----------------------------------------\n",
            "Epoch 715\n",
            "Var loss:  tensor(-2.3103e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.107323640706436e-06\n",
            "E_s_wdiff_all_sq: 3.499325185512293e-07\n",
            "E_IS_SCOPE: 3.2849624682961487e-06\n",
            "E_IS_E_SCOPE: 5.483403854393409e-06\n",
            "Total Loss: -2.3102751406075509e-07\n",
            "----------------------------------------\n",
            "Epoch 716\n",
            "Var loss:  tensor(-2.3922e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1179054726252854e-06\n",
            "E_s_wdiff_all_sq: 3.5883367818620923e-07\n",
            "E_IS_SCOPE: 3.3230168410047516e-06\n",
            "E_IS_E_SCOPE: 5.526396628866261e-06\n",
            "Total Loss: -2.3922364530538257e-07\n",
            "----------------------------------------\n",
            "Epoch 717\n",
            "Var loss:  tensor(-2.4732e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1245205834678274e-06\n",
            "E_s_wdiff_all_sq: 3.648458748225593e-07\n",
            "E_IS_SCOPE: 3.3538746536054863e-06\n",
            "E_IS_E_SCOPE: 5.561605623315239e-06\n",
            "Total Loss: -2.4732309479567937e-07\n",
            "----------------------------------------\n",
            "Epoch 718\n",
            "Var loss:  tensor(-2.5533e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.127594949515942e-06\n",
            "E_s_wdiff_all_sq: 3.7319424596456715e-07\n",
            "E_IS_SCOPE: 3.3713082442443526e-06\n",
            "E_IS_E_SCOPE: 5.580407739513489e-06\n",
            "Total Loss: -2.5533415100834017e-07\n",
            "----------------------------------------\n",
            "Epoch 719\n",
            "Var loss:  tensor(-2.6350e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.109224818069403e-06\n",
            "E_s_wdiff_all_sq: 3.674608664147079e-07\n",
            "E_IS_SCOPE: 3.382674124659334e-06\n",
            "E_IS_E_SCOPE: 5.589537529161913e-06\n",
            "Total Loss: -2.634987213719061e-07\n",
            "----------------------------------------\n",
            "Epoch 720\n",
            "Var loss:  tensor(-2.7188e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1238002692976843e-06\n",
            "E_s_wdiff_all_sq: 3.6924797287982615e-07\n",
            "E_IS_SCOPE: 3.3558921797260775e-06\n",
            "E_IS_E_SCOPE: 5.573341382589681e-06\n",
            "Total Loss: -2.7188197333078773e-07\n",
            "----------------------------------------\n",
            "Epoch 721\n",
            "Var loss:  tensor(-2.8014e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.103008914657725e-06\n",
            "E_s_wdiff_all_sq: 3.524267890220313e-07\n",
            "E_IS_SCOPE: 3.3669356175350163e-06\n",
            "E_IS_E_SCOPE: 5.586526320379058e-06\n",
            "Total Loss: -2.8013514407383055e-07\n",
            "----------------------------------------\n",
            "Epoch 722\n",
            "Var loss:  tensor(-2.8843e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0786766142257008e-06\n",
            "E_s_wdiff_all_sq: 3.3244651114402825e-07\n",
            "E_IS_SCOPE: 3.401397183307897e-06\n",
            "E_IS_E_SCOPE: 5.622961262198842e-06\n",
            "Total Loss: -2.884339187216588e-07\n",
            "----------------------------------------\n",
            "Epoch 723\n",
            "Var loss:  tensor(-2.9685e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0761669359793313e-06\n",
            "E_s_wdiff_all_sq: 3.2404463718489614e-07\n",
            "E_IS_SCOPE: 3.4294435872171873e-06\n",
            "E_IS_E_SCOPE: 5.6581608671347e-06\n",
            "Total Loss: -2.9684812506203107e-07\n",
            "----------------------------------------\n",
            "Epoch 724\n",
            "Var loss:  tensor(-3.0512e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.062894178701117e-06\n",
            "E_s_wdiff_all_sq: 3.1945953827691666e-07\n",
            "E_IS_SCOPE: 3.4800837625988977e-06\n",
            "E_IS_E_SCOPE: 5.708595257357734e-06\n",
            "Total Loss: -3.0512421311491384e-07\n",
            "----------------------------------------\n",
            "Epoch 725\n",
            "Var loss:  tensor(-3.1352e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.057828298933219e-06\n",
            "E_s_wdiff_all_sq: 3.167609887407062e-07\n",
            "E_IS_SCOPE: 3.5125891269353406e-06\n",
            "E_IS_E_SCOPE: 5.744114261752265e-06\n",
            "Total Loss: -3.135188234627771e-07\n",
            "----------------------------------------\n",
            "Epoch 726\n",
            "Var loss:  tensor(-3.2196e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0686168680589623e-06\n",
            "E_s_wdiff_all_sq: 3.173708441928323e-07\n",
            "E_IS_SCOPE: 3.5188134865739183e-06\n",
            "E_IS_E_SCOPE: 5.759648174094778e-06\n",
            "Total Loss: -3.2195921519702957e-07\n",
            "----------------------------------------\n",
            "Epoch 727\n",
            "Var loss:  tensor(-3.3041e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.047781534838904e-06\n",
            "E_s_wdiff_all_sq: 3.0420771208301935e-07\n",
            "E_IS_SCOPE: 3.5447682185362727e-06\n",
            "E_IS_E_SCOPE: 5.785993119921861e-06\n",
            "Total Loss: -3.3041184403673155e-07\n",
            "----------------------------------------\n",
            "Epoch 728\n",
            "Var loss:  tensor(-3.3895e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0383349548343983e-06\n",
            "E_s_wdiff_all_sq: 2.978050985821209e-07\n",
            "E_IS_SCOPE: 3.5574460679082086e-06\n",
            "E_IS_E_SCOPE: 5.8014176852758055e-06\n",
            "Total Loss: -3.389492425043577e-07\n",
            "----------------------------------------\n",
            "Epoch 729\n",
            "Var loss:  tensor(-3.4748e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0319265106654663e-06\n",
            "E_s_wdiff_all_sq: 2.94510434230972e-07\n",
            "E_IS_SCOPE: 3.5589077610890363e-06\n",
            "E_IS_E_SCOPE: 5.805585375263834e-06\n",
            "Total Loss: -3.4747501593654147e-07\n",
            "----------------------------------------\n",
            "Epoch 730\n",
            "Var loss:  tensor(-3.5601e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0319111465337423e-06\n",
            "E_s_wdiff_all_sq: 2.995058499450461e-07\n",
            "E_IS_SCOPE: 3.560268357163045e-06\n",
            "E_IS_E_SCOPE: 5.808707839807212e-06\n",
            "Total Loss: -3.560095327210797e-07\n",
            "----------------------------------------\n",
            "Epoch 731\n",
            "Var loss:  tensor(-3.6455e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0447726832261414e-06\n",
            "E_s_wdiff_all_sq: 3.101694441526059e-07\n",
            "E_IS_SCOPE: 3.564110529182254e-06\n",
            "E_IS_E_SCOPE: 5.817919078255877e-06\n",
            "Total Loss: -3.6454972309515247e-07\n",
            "----------------------------------------\n",
            "Epoch 732\n",
            "Var loss:  tensor(-3.7316e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0400345920438134e-06\n",
            "E_s_wdiff_all_sq: 3.0633408419870785e-07\n",
            "E_IS_SCOPE: 3.587066553742199e-06\n",
            "E_IS_E_SCOPE: 5.8447266774264856e-06\n",
            "Total Loss: -3.7315560354490776e-07\n",
            "----------------------------------------\n",
            "Epoch 733\n",
            "Var loss:  tensor(-3.8180e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0471060803784323e-06\n",
            "E_s_wdiff_all_sq: 3.0897245822012535e-07\n",
            "E_IS_SCOPE: 3.6006079186489196e-06\n",
            "E_IS_E_SCOPE: 5.86480856749889e-06\n",
            "Total Loss: -3.8180353956307454e-07\n",
            "----------------------------------------\n",
            "Epoch 734\n",
            "Var loss:  tensor(-3.9044e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0413076141775414e-06\n",
            "E_s_wdiff_all_sq: 3.1051617571744453e-07\n",
            "E_IS_SCOPE: 3.62115977546814e-06\n",
            "E_IS_E_SCOPE: 5.886006356256191e-06\n",
            "Total Loss: -3.904375871374455e-07\n",
            "----------------------------------------\n",
            "Epoch 735\n",
            "Var loss:  tensor(-3.9915e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.052332140002009e-06\n",
            "E_s_wdiff_all_sq: 3.218573869325448e-07\n",
            "E_IS_SCOPE: 3.623395575816802e-06\n",
            "E_IS_E_SCOPE: 5.8924410077439845e-06\n",
            "Total Loss: -3.9915197480634147e-07\n",
            "----------------------------------------\n",
            "Epoch 736\n",
            "Var loss:  tensor(-4.0779e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0743407879542705e-06\n",
            "E_s_wdiff_all_sq: 3.4361902913480013e-07\n",
            "E_IS_SCOPE: 3.6069181728785595e-06\n",
            "E_IS_E_SCOPE: 5.880406116508807e-06\n",
            "Total Loss: -4.077899924624655e-07\n",
            "----------------------------------------\n",
            "Epoch 737\n",
            "Var loss:  tensor(-4.1648e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0786159991261933e-06\n",
            "E_s_wdiff_all_sq: 3.5505263720969733e-07\n",
            "E_IS_SCOPE: 3.62265510825836e-06\n",
            "E_IS_E_SCOPE: 5.896909376658757e-06\n",
            "Total Loss: -4.164810389057407e-07\n",
            "----------------------------------------\n",
            "Epoch 738\n",
            "Var loss:  tensor(-4.2530e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0882113208343096e-06\n",
            "E_s_wdiff_all_sq: 3.602326821572391e-07\n",
            "E_IS_SCOPE: 3.6528662796464826e-06\n",
            "E_IS_E_SCOPE: 5.933737262962837e-06\n",
            "Total Loss: -4.2529919197708057e-07\n",
            "----------------------------------------\n",
            "Epoch 739\n",
            "Var loss:  tensor(-4.3411e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0642948391944915e-06\n",
            "E_s_wdiff_all_sq: 3.4236332246993466e-07\n",
            "E_IS_SCOPE: 3.6979202389928883e-06\n",
            "E_IS_E_SCOPE: 5.980172160093632e-06\n",
            "Total Loss: -4.341081894983701e-07\n",
            "----------------------------------------\n",
            "Epoch 740\n",
            "Var loss:  tensor(-4.4291e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0652530072399695e-06\n",
            "E_s_wdiff_all_sq: 3.376169002655587e-07\n",
            "E_IS_SCOPE: 3.7022957209876627e-06\n",
            "E_IS_E_SCOPE: 5.991798666360888e-06\n",
            "Total Loss: -4.429056477934809e-07\n",
            "----------------------------------------\n",
            "Epoch 741\n",
            "Var loss:  tensor(-4.5178e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0537555122186042e-06\n",
            "E_s_wdiff_all_sq: 3.3029125673973804e-07\n",
            "E_IS_SCOPE: 3.705163304286882e-06\n",
            "E_IS_E_SCOPE: 5.997015048402889e-06\n",
            "Total Loss: -4.517750967745895e-07\n",
            "----------------------------------------\n",
            "Epoch 742\n",
            "Var loss:  tensor(-4.6060e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.03900920917432e-06\n",
            "E_s_wdiff_all_sq: 3.2316636454005534e-07\n",
            "E_IS_SCOPE: 3.703140054801031e-06\n",
            "E_IS_E_SCOPE: 5.995595972794404e-06\n",
            "Total Loss: -4.6060485537392393e-07\n",
            "----------------------------------------\n",
            "Epoch 743\n",
            "Var loss:  tensor(-4.6951e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0783177025873812e-06\n",
            "E_s_wdiff_all_sq: 3.4575741338047373e-07\n",
            "E_IS_SCOPE: 3.680149975731143e-06\n",
            "E_IS_E_SCOPE: 5.98541819377382e-06\n",
            "Total Loss: -4.695120108998878e-07\n",
            "----------------------------------------\n",
            "Epoch 744\n",
            "Var loss:  tensor(-4.7844e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.027732188777844e-06\n",
            "E_s_wdiff_all_sq: 3.262678370164713e-07\n",
            "E_IS_SCOPE: 3.7617703530210137e-06\n",
            "E_IS_E_SCOPE: 6.055954382135507e-06\n",
            "Total Loss: -4.784395704890537e-07\n",
            "----------------------------------------\n",
            "Epoch 745\n",
            "Var loss:  tensor(-4.8739e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.055411551874332e-06\n",
            "E_s_wdiff_all_sq: 3.3458214470726427e-07\n",
            "E_IS_SCOPE: 3.7704412606527694e-06\n",
            "E_IS_E_SCOPE: 6.078783723847466e-06\n",
            "Total Loss: -4.873913832437676e-07\n",
            "----------------------------------------\n",
            "Epoch 746\n",
            "Var loss:  tensor(-4.9638e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0512168625873768e-06\n",
            "E_s_wdiff_all_sq: 3.33163438920146e-07\n",
            "E_IS_SCOPE: 3.78868974206363e-06\n",
            "E_IS_E_SCOPE: 6.100140050768993e-06\n",
            "Total Loss: -4.963830577649354e-07\n",
            "----------------------------------------\n",
            "Epoch 747\n",
            "Var loss:  tensor(-5.0533e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0313573659213543e-06\n",
            "E_s_wdiff_all_sq: 3.264368681271281e-07\n",
            "E_IS_SCOPE: 3.8121620147823774e-06\n",
            "E_IS_E_SCOPE: 6.1215188311129815e-06\n",
            "Total Loss: -5.053289988884228e-07\n",
            "----------------------------------------\n",
            "Epoch 748\n",
            "Var loss:  tensor(-5.1432e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0744923706999868e-06\n",
            "E_s_wdiff_all_sq: 3.46938199612164e-07\n",
            "E_IS_SCOPE: 3.7833857218673302e-06\n",
            "E_IS_E_SCOPE: 6.108553759398549e-06\n",
            "Total Loss: -5.143177679960562e-07\n",
            "----------------------------------------\n",
            "Epoch 749\n",
            "Var loss:  tensor(-5.2335e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0386783087216076e-06\n",
            "E_s_wdiff_all_sq: 3.381153400866165e-07\n",
            "E_IS_SCOPE: 3.819235245775253e-06\n",
            "E_IS_E_SCOPE: 6.13542399047777e-06\n",
            "Total Loss: -5.233503847914826e-07\n",
            "----------------------------------------\n",
            "Epoch 750\n",
            "Var loss:  tensor(-5.3238e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.059994697913937e-06\n",
            "E_s_wdiff_all_sq: 3.519304239747502e-07\n",
            "E_IS_SCOPE: 3.80836076133578e-06\n",
            "E_IS_E_SCOPE: 6.132815692177749e-06\n",
            "Total Loss: -5.323814517661912e-07\n",
            "----------------------------------------\n",
            "Epoch 751\n",
            "Var loss:  tensor(-5.4133e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.070301346742258e-06\n",
            "E_s_wdiff_all_sq: 3.565867574786752e-07\n",
            "E_IS_SCOPE: 3.810397379214318e-06\n",
            "E_IS_E_SCOPE: 6.142149766366932e-06\n",
            "Total Loss: -5.41326049063086e-07\n",
            "----------------------------------------\n",
            "Epoch 752\n",
            "Var loss:  tensor(-5.5034e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0521703936787464e-06\n",
            "E_s_wdiff_all_sq: 3.521147000170833e-07\n",
            "E_IS_SCOPE: 3.850546963449476e-06\n",
            "E_IS_E_SCOPE: 6.179975632902327e-06\n",
            "Total Loss: -5.503375092654792e-07\n",
            "----------------------------------------\n",
            "Epoch 753\n",
            "Var loss:  tensor(-5.5944e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0846144797706574e-06\n",
            "E_s_wdiff_all_sq: 3.6975960542903886e-07\n",
            "E_IS_SCOPE: 3.86519459060483e-06\n",
            "E_IS_E_SCOPE: 6.206574606928937e-06\n",
            "Total Loss: -5.594410223280377e-07\n",
            "----------------------------------------\n",
            "Epoch 754\n",
            "Var loss:  tensor(-5.6851e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0361606432999415e-06\n",
            "E_s_wdiff_all_sq: 3.435527471985542e-07\n",
            "E_IS_SCOPE: 3.929959647182713e-06\n",
            "E_IS_E_SCOPE: 6.2647496623949235e-06\n",
            "Total Loss: -5.685079983444743e-07\n",
            "----------------------------------------\n",
            "Epoch 755\n",
            "Var loss:  tensor(-5.7761e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0778771995937987e-06\n",
            "E_s_wdiff_all_sq: 3.5948439261209797e-07\n",
            "E_IS_SCOPE: 3.90165337162576e-06\n",
            "E_IS_E_SCOPE: 6.253885553565891e-06\n",
            "Total Loss: -5.776074209200019e-07\n",
            "----------------------------------------\n",
            "Epoch 756\n",
            "Var loss:  tensor(-5.8683e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0379451623391963e-06\n",
            "E_s_wdiff_all_sq: 3.412981827102453e-07\n",
            "E_IS_SCOPE: 3.935093503820433e-06\n",
            "E_IS_E_SCOPE: 6.281061904643728e-06\n",
            "Total Loss: -5.868256860390779e-07\n",
            "----------------------------------------\n",
            "Epoch 757\n",
            "Var loss:  tensor(-5.9600e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.038319496816368e-06\n",
            "E_s_wdiff_all_sq: 3.375432256615336e-07\n",
            "E_IS_SCOPE: 3.936436839013202e-06\n",
            "E_IS_E_SCOPE: 6.289056852939141e-06\n",
            "Total Loss: -5.959996207184835e-07\n",
            "----------------------------------------\n",
            "Epoch 758\n",
            "Var loss:  tensor(-6.0516e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0640838014452687e-06\n",
            "E_s_wdiff_all_sq: 3.521273868603615e-07\n",
            "E_IS_SCOPE: 3.919839491785449e-06\n",
            "E_IS_E_SCOPE: 6.282630881107641e-06\n",
            "Total Loss: -6.051622280809183e-07\n",
            "----------------------------------------\n",
            "Epoch 759\n",
            "Var loss:  tensor(-6.1437e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0088320476867788e-06\n",
            "E_s_wdiff_all_sq: 3.309480713339651e-07\n",
            "E_IS_SCOPE: 3.975953413339222e-06\n",
            "E_IS_E_SCOPE: 6.326310847171899e-06\n",
            "Total Loss: -6.143667553339804e-07\n",
            "----------------------------------------\n",
            "Epoch 760\n",
            "Var loss:  tensor(-6.2357e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0808448131253804e-06\n",
            "E_s_wdiff_all_sq: 3.6516256061058247e-07\n",
            "E_IS_SCOPE: 3.948899070839503e-06\n",
            "E_IS_E_SCOPE: 6.322755425777901e-06\n",
            "Total Loss: -6.235663213834382e-07\n",
            "----------------------------------------\n",
            "Epoch 761\n",
            "Var loss:  tensor(-6.3289e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0174085972526533e-06\n",
            "E_s_wdiff_all_sq: 3.383472904444125e-07\n",
            "E_IS_SCOPE: 4.025271317685544e-06\n",
            "E_IS_E_SCOPE: 6.385479921541343e-06\n",
            "Total Loss: -6.328917649247992e-07\n",
            "----------------------------------------\n",
            "Epoch 762\n",
            "Var loss:  tensor(-6.4227e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.068098922457691e-06\n",
            "E_s_wdiff_all_sq: 3.6191634774684413e-07\n",
            "E_IS_SCOPE: 4.00150455722143e-06\n",
            "E_IS_E_SCOPE: 6.379962217026623e-06\n",
            "Total Loss: -6.4226860892098e-07\n",
            "----------------------------------------\n",
            "Epoch 763\n",
            "Var loss:  tensor(-6.5161e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.045923490519792e-06\n",
            "E_s_wdiff_all_sq: 3.503289610563573e-07\n",
            "E_IS_SCOPE: 4.034391232533908e-06\n",
            "E_IS_E_SCOPE: 6.412225052916715e-06\n",
            "Total Loss: -6.516089753236196e-07\n",
            "----------------------------------------\n",
            "Epoch 764\n",
            "Var loss:  tensor(-6.6098e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.032554056536242e-06\n",
            "E_s_wdiff_all_sq: 3.4313920637561816e-07\n",
            "E_IS_SCOPE: 4.0586818170206864e-06\n",
            "E_IS_E_SCOPE: 6.438112073353694e-06\n",
            "Total Loss: -6.609815265268321e-07\n",
            "----------------------------------------\n",
            "Epoch 765\n",
            "Var loss:  tensor(-6.7052e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.034854670523985e-06\n",
            "E_s_wdiff_all_sq: 3.502246619691924e-07\n",
            "E_IS_SCOPE: 4.062111169146976e-06\n",
            "E_IS_E_SCOPE: 6.443919297300515e-06\n",
            "Total Loss: -6.70522111773726e-07\n",
            "----------------------------------------\n",
            "Epoch 766\n",
            "Var loss:  tensor(-6.8001e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.066876412807272e-06\n",
            "E_s_wdiff_all_sq: 3.6713648371796174e-07\n",
            "E_IS_SCOPE: 4.04105858349118e-06\n",
            "E_IS_E_SCOPE: 6.4351667041354534e-06\n",
            "Total Loss: -6.800121762206762e-07\n",
            "----------------------------------------\n",
            "Epoch 767\n",
            "Var loss:  tensor(-6.8968e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0500978691180493e-06\n",
            "E_s_wdiff_all_sq: 3.636693538338914e-07\n",
            "E_IS_SCOPE: 4.081218621374629e-06\n",
            "E_IS_E_SCOPE: 6.473506817170802e-06\n",
            "Total Loss: -6.896837403296295e-07\n",
            "----------------------------------------\n",
            "Epoch 768\n",
            "Var loss:  tensor(-6.9936e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0387106811367784e-06\n",
            "E_s_wdiff_all_sq: 3.5905047796792627e-07\n",
            "E_IS_SCOPE: 4.112049156263923e-06\n",
            "E_IS_E_SCOPE: 6.5057922519417e-06\n",
            "Total Loss: -6.993618522081422e-07\n",
            "----------------------------------------\n",
            "Epoch 769\n",
            "Var loss:  tensor(-7.0910e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0675448197973273e-06\n",
            "E_s_wdiff_all_sq: 3.685929263658305e-07\n",
            "E_IS_SCOPE: 4.112753908574567e-06\n",
            "E_IS_E_SCOPE: 6.521012915330103e-06\n",
            "Total Loss: -7.091019841010166e-07\n",
            "----------------------------------------\n",
            "Epoch 770\n",
            "Var loss:  tensor(-7.1879e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.033958944222384e-06\n",
            "E_s_wdiff_all_sq: 3.516758197577221e-07\n",
            "E_IS_SCOPE: 4.161718787332086e-06\n",
            "E_IS_E_SCOPE: 6.566488948714031e-06\n",
            "Total Loss: -7.187930623206686e-07\n",
            "----------------------------------------\n",
            "Epoch 771\n",
            "Var loss:  tensor(-7.2867e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0602669333541986e-06\n",
            "E_s_wdiff_all_sq: 3.732567687349644e-07\n",
            "E_IS_SCOPE: 4.168844129144753e-06\n",
            "E_IS_E_SCOPE: 6.580918431599129e-06\n",
            "Total Loss: -7.286743043109576e-07\n",
            "----------------------------------------\n",
            "Epoch 772\n",
            "Var loss:  tensor(-7.3851e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.063643731465503e-06\n",
            "E_s_wdiff_all_sq: 3.7778048760762687e-07\n",
            "E_IS_SCOPE: 4.188846306924983e-06\n",
            "E_IS_E_SCOPE: 6.6052628771347706e-06\n",
            "Total Loss: -7.385057605831386e-07\n",
            "----------------------------------------\n",
            "Epoch 773\n",
            "Var loss:  tensor(-7.4831e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.053578707676068e-06\n",
            "E_s_wdiff_all_sq: 3.7379372268945334e-07\n",
            "E_IS_SCOPE: 4.208789234631935e-06\n",
            "E_IS_E_SCOPE: 6.627070065296009e-06\n",
            "Total Loss: -7.483125403629736e-07\n",
            "----------------------------------------\n",
            "Epoch 774\n",
            "Var loss:  tensor(-7.5806e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0605687061960756e-06\n",
            "E_s_wdiff_all_sq: 3.7733101838150575e-07\n",
            "E_IS_SCOPE: 4.2047444729654745e-06\n",
            "E_IS_E_SCOPE: 6.6296263485037105e-06\n",
            "Total Loss: -7.580619272833421e-07\n",
            "----------------------------------------\n",
            "Epoch 775\n",
            "Var loss:  tensor(-7.6780e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.037281486752338e-06\n",
            "E_s_wdiff_all_sq: 3.598870244396641e-07\n",
            "E_IS_SCOPE: 4.223802736145082e-06\n",
            "E_IS_E_SCOPE: 6.650630805532408e-06\n",
            "Total Loss: -7.677975404834171e-07\n",
            "----------------------------------------\n",
            "Epoch 776\n",
            "Var loss:  tensor(-7.7760e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0469147495204895e-06\n",
            "E_s_wdiff_all_sq: 3.6378422746896024e-07\n",
            "E_IS_SCOPE: 4.235551414327332e-06\n",
            "E_IS_E_SCOPE: 6.670146915876548e-06\n",
            "Total Loss: -7.77596345068342e-07\n",
            "----------------------------------------\n",
            "Epoch 777\n",
            "Var loss:  tensor(-7.8740e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0417879956615836e-06\n",
            "E_s_wdiff_all_sq: 3.643132118868019e-07\n",
            "E_IS_SCOPE: 4.257923970658039e-06\n",
            "E_IS_E_SCOPE: 6.694595883989451e-06\n",
            "Total Loss: -7.874049069094815e-07\n",
            "----------------------------------------\n",
            "Epoch 778\n",
            "Var loss:  tensor(-7.9728e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0456905814243524e-06\n",
            "E_s_wdiff_all_sq: 3.6829748977334657e-07\n",
            "E_IS_SCOPE: 4.279311790877318e-06\n",
            "E_IS_E_SCOPE: 6.720880273398584e-06\n",
            "Total Loss: -7.972797374129676e-07\n",
            "----------------------------------------\n",
            "Epoch 779\n",
            "Var loss:  tensor(-8.0718e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.047025358808702e-06\n",
            "E_s_wdiff_all_sq: 3.697834083077351e-07\n",
            "E_IS_SCOPE: 4.301610919141212e-06\n",
            "E_IS_E_SCOPE: 6.748052578133692e-06\n",
            "Total Loss: -8.071772315054321e-07\n",
            "----------------------------------------\n",
            "Epoch 780\n",
            "Var loss:  tensor(-8.1707e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0461294213040288e-06\n",
            "E_s_wdiff_all_sq: 3.7153755311488405e-07\n",
            "E_IS_SCOPE: 4.314251990000706e-06\n",
            "E_IS_E_SCOPE: 6.764313370064592e-06\n",
            "Total Loss: -8.17066755960068e-07\n",
            "----------------------------------------\n",
            "Epoch 781\n",
            "Var loss:  tensor(-8.2702e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0378265482864607e-06\n",
            "E_s_wdiff_all_sq: 3.656290915995199e-07\n",
            "E_IS_SCOPE: 4.3316311791046965e-06\n",
            "E_IS_E_SCOPE: 6.785473505728808e-06\n",
            "Total Loss: -8.270230605827223e-07\n",
            "----------------------------------------\n",
            "Epoch 782\n",
            "Var loss:  tensor(-8.3700e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0540634187364966e-06\n",
            "E_s_wdiff_all_sq: 3.730796519704696e-07\n",
            "E_IS_SCOPE: 4.349047450982452e-06\n",
            "E_IS_E_SCOPE: 6.812272602353364e-06\n",
            "Total Loss: -8.370023999972383e-07\n",
            "----------------------------------------\n",
            "Epoch 783\n",
            "Var loss:  tensor(-8.4693e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.025820587393504e-06\n",
            "E_s_wdiff_all_sq: 3.5779382016998275e-07\n",
            "E_IS_SCOPE: 4.402405167748186e-06\n",
            "E_IS_E_SCOPE: 6.864117201469917e-06\n",
            "Total Loss: -8.469331642413797e-07\n",
            "----------------------------------------\n",
            "Epoch 784\n",
            "Var loss:  tensor(-8.5700e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.040870792478602e-06\n",
            "E_s_wdiff_all_sq: 3.6551280855800986e-07\n",
            "E_IS_SCOPE: 4.402904312010249e-06\n",
            "E_IS_E_SCOPE: 6.873312944806299e-06\n",
            "Total Loss: -8.569951456929499e-07\n",
            "----------------------------------------\n",
            "Epoch 785\n",
            "Var loss:  tensor(-8.6702e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.040750094335649e-06\n",
            "E_s_wdiff_all_sq: 3.674692639166787e-07\n",
            "E_IS_SCOPE: 4.411050847861418e-06\n",
            "E_IS_E_SCOPE: 6.885435553072269e-06\n",
            "Total Loss: -8.670244440241705e-07\n",
            "----------------------------------------\n",
            "Epoch 786\n",
            "Var loss:  tensor(-8.7715e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0123251882406296e-06\n",
            "E_s_wdiff_all_sq: 3.5396420514422423e-07\n",
            "E_IS_SCOPE: 4.44209508743256e-06\n",
            "E_IS_E_SCOPE: 6.9140823146932825e-06\n",
            "Total Loss: -8.771493354464799e-07\n",
            "----------------------------------------\n",
            "Epoch 787\n",
            "Var loss:  tensor(-8.8725e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.055684304113495e-06\n",
            "E_s_wdiff_all_sq: 3.7780670135583337e-07\n",
            "E_IS_SCOPE: 4.411957899075286e-06\n",
            "E_IS_E_SCOPE: 6.898752324498526e-06\n",
            "Total Loss: -8.87247112110258e-07\n",
            "----------------------------------------\n",
            "Epoch 788\n",
            "Var loss:  tensor(-8.9743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0252919242764872e-06\n",
            "E_s_wdiff_all_sq: 3.6571292117889163e-07\n",
            "E_IS_SCOPE: 4.449863126438341e-06\n",
            "E_IS_E_SCOPE: 6.9325985394216905e-06\n",
            "Total Loss: -8.974276868905454e-07\n",
            "----------------------------------------\n",
            "Epoch 789\n",
            "Var loss:  tensor(-9.0765e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0301619336670165e-06\n",
            "E_s_wdiff_all_sq: 3.668977394341801e-07\n",
            "E_IS_SCOPE: 4.468705782773913e-06\n",
            "E_IS_E_SCOPE: 6.958394407759049e-06\n",
            "Total Loss: -9.076489197588761e-07\n",
            "----------------------------------------\n",
            "Epoch 790\n",
            "Var loss:  tensor(-9.1781e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0536565231403957e-06\n",
            "E_s_wdiff_all_sq: 3.770607403085796e-07\n",
            "E_IS_SCOPE: 4.480029674728229e-06\n",
            "E_IS_E_SCOPE: 6.9814664315787665e-06\n",
            "Total Loss: -9.178135948906999e-07\n",
            "----------------------------------------\n",
            "Epoch 791\n",
            "Var loss:  tensor(-9.2812e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0210649696846432e-06\n",
            "E_s_wdiff_all_sq: 3.6463538609427086e-07\n",
            "E_IS_SCOPE: 4.53656558186158e-06\n",
            "E_IS_E_SCOPE: 7.033071291371119e-06\n",
            "Total Loss: -9.281176994501453e-07\n",
            "----------------------------------------\n",
            "Epoch 792\n",
            "Var loss:  tensor(-9.3841e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.047564159354765e-06\n",
            "E_s_wdiff_all_sq: 3.8029164952458495e-07\n",
            "E_IS_SCOPE: 4.533444915923928e-06\n",
            "E_IS_E_SCOPE: 7.0405192489034726e-06\n",
            "Total Loss: -9.384120201503481e-07\n",
            "----------------------------------------\n",
            "Epoch 793\n",
            "Var loss:  tensor(-9.4872e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.049996955768787e-06\n",
            "E_s_wdiff_all_sq: 3.8343599880537776e-07\n",
            "E_IS_SCOPE: 4.54529371596278e-06\n",
            "E_IS_E_SCOPE: 7.057166333054909e-06\n",
            "Total Loss: -9.487201412422898e-07\n",
            "----------------------------------------\n",
            "Epoch 794\n",
            "Var loss:  tensor(-9.5903e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0395068576079766e-06\n",
            "E_s_wdiff_all_sq: 3.827065524153703e-07\n",
            "E_IS_SCOPE: 4.568952787874859e-06\n",
            "E_IS_E_SCOPE: 7.081099462047242e-06\n",
            "Total Loss: -9.590289071736007e-07\n",
            "----------------------------------------\n",
            "Epoch 795\n",
            "Var loss:  tensor(-9.6941e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0746225349984714e-06\n",
            "E_s_wdiff_all_sq: 4.04933745229206e-07\n",
            "E_IS_SCOPE: 4.569498240934756e-06\n",
            "E_IS_E_SCOPE: 7.093278765512181e-06\n",
            "Total Loss: -9.694081234070247e-07\n",
            "----------------------------------------\n",
            "Epoch 796\n",
            "Var loss:  tensor(-9.7987e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.043896229358623e-06\n",
            "E_s_wdiff_all_sq: 3.9214733516951315e-07\n",
            "E_IS_SCOPE: 4.6367800458094015e-06\n",
            "E_IS_E_SCOPE: 7.156819749051491e-06\n",
            "Total Loss: -9.798663763165084e-07\n",
            "----------------------------------------\n",
            "Epoch 797\n",
            "Var loss:  tensor(-9.9034e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.07928840870102e-06\n",
            "E_s_wdiff_all_sq: 4.144918568912612e-07\n",
            "E_IS_SCOPE: 4.648476512774259e-06\n",
            "E_IS_E_SCOPE: 7.180276656975907e-06\n",
            "Total Loss: -9.903396006149787e-07\n",
            "----------------------------------------\n",
            "Epoch 798\n",
            "Var loss:  tensor(-1.0008e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0780719935220448e-06\n",
            "E_s_wdiff_all_sq: 4.1902959465881336e-07\n",
            "E_IS_SCOPE: 4.68180222620281e-06\n",
            "E_IS_E_SCOPE: 7.215977640868414e-06\n",
            "Total Loss: -1.0008442944894167e-06\n",
            "----------------------------------------\n",
            "Epoch 799\n",
            "Var loss:  tensor(-1.0114e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0661765077220837e-06\n",
            "E_s_wdiff_all_sq: 4.142220359928117e-07\n",
            "E_IS_SCOPE: 4.717416946911178e-06\n",
            "E_IS_E_SCOPE: 7.253311642677324e-06\n",
            "Total Loss: -1.0113707838244597e-06\n",
            "----------------------------------------\n",
            "Epoch 800\n",
            "Var loss:  tensor(-1.0219e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.091108202447605e-06\n",
            "E_s_wdiff_all_sq: 4.260959702009109e-07\n",
            "E_IS_SCOPE: 4.7175237866153015e-06\n",
            "E_IS_E_SCOPE: 7.2652323297086695e-06\n",
            "Total Loss: -1.021940717961484e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.8062,  0.5339],\n",
            "        [-0.1972, -0.4208],\n",
            "        [ 0.6107,  0.1833],\n",
            "        [ 0.1100, -0.3393],\n",
            "        [-0.0469,  0.4383],\n",
            "        [ 0.1967,  0.3041],\n",
            "        [-0.0265, -0.4809],\n",
            "        [ 0.6737, -0.2494],\n",
            "        [ 0.1594, -0.6898],\n",
            "        [-0.3210,  0.0304],\n",
            "        [ 0.3898,  0.0076],\n",
            "        [ 0.1543,  0.5288],\n",
            "        [-0.6948, -0.0398],\n",
            "        [-0.2316,  0.1893],\n",
            "        [-0.2966, -0.2733],\n",
            "        [ 0.0087, -0.1834]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.3518, -0.0830, -0.0474,  0.5771,  0.3440, -0.1348,  0.3951, -0.3842,\n",
            "        -0.4929, -0.6301,  0.5189,  0.0884,  0.2289,  0.2196, -0.0453, -0.4175],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-8.0332e-02, -9.6393e-02, -3.0631e-01, -5.3021e-02, -6.4791e-02,\n",
            "          1.5885e-01,  1.7243e-01, -1.9679e-01,  8.0992e-02, -3.4376e-02,\n",
            "          8.6558e-02,  6.0149e-02, -1.5966e-01, -1.9643e-01,  2.6262e-02,\n",
            "          9.7768e-02],\n",
            "        [-1.8631e-01, -4.7563e-02,  1.0468e-01,  7.8847e-02, -1.8044e-01,\n",
            "          9.0671e-02,  1.6094e-01,  1.6128e-01,  1.0846e-01,  7.4880e-02,\n",
            "          1.3432e-01,  1.1134e-01,  1.9639e-01,  2.1434e-01, -8.8973e-02,\n",
            "          5.1494e-02],\n",
            "        [-8.3696e-02,  2.3390e-02, -1.9553e-01,  2.0819e-01,  3.3464e-02,\n",
            "          9.1040e-02, -2.2174e-01, -4.0349e-02, -1.7039e-01, -1.2196e-01,\n",
            "          2.3892e-01,  4.4670e-02,  9.1598e-02, -1.4442e-01, -9.2240e-03,\n",
            "         -1.5019e-01],\n",
            "        [ 1.6635e-01,  1.3661e-01,  4.7544e-02, -1.2729e-01, -1.9802e-01,\n",
            "          1.0363e-01,  2.1950e-01,  1.1609e-01, -9.6209e-02,  1.6007e-01,\n",
            "          1.9251e-02, -9.7342e-02, -3.6885e-02, -9.6853e-02,  2.4558e-01,\n",
            "         -2.0681e-01],\n",
            "        [-4.0992e-01, -2.0711e-01, -3.3693e-02,  2.6252e-01,  1.2579e-01,\n",
            "          1.3540e-01,  1.0068e-01,  1.5353e-01,  2.2798e-01,  2.0321e-01,\n",
            "          1.2280e-02, -8.3059e-02, -2.9253e-02,  1.4174e-01, -6.7642e-02,\n",
            "          5.7888e-03],\n",
            "        [-1.2552e-01,  1.9502e-01,  1.5227e-01, -2.1612e-01,  1.2873e-01,\n",
            "         -2.4643e-01, -1.4887e-01,  5.0036e-02, -7.1466e-02,  7.1605e-02,\n",
            "         -8.6758e-04,  1.8790e-01, -2.4318e-01,  7.5170e-02, -2.1491e-01,\n",
            "          2.4828e-01],\n",
            "        [ 4.5420e-02, -9.1232e-02,  2.7557e-01,  5.1251e-01,  2.1220e-02,\n",
            "         -1.7437e-01,  1.9662e-03,  6.1231e-01,  1.6596e-01,  9.9712e-02,\n",
            "         -2.2019e-01, -4.1986e-01, -7.0665e-02, -1.3922e-01,  2.9088e-02,\n",
            "         -1.1662e-04],\n",
            "        [-1.0585e-01,  1.3251e-02, -1.9701e-01, -9.0187e-02,  1.0414e-01,\n",
            "         -3.2789e-01,  7.0949e-02, -7.2965e-02,  1.0380e-01, -2.0536e-01,\n",
            "         -5.2456e-02, -2.2061e-01,  1.8478e-01,  8.2254e-02, -2.2522e-01,\n",
            "         -2.3713e-01],\n",
            "        [ 1.2925e-01,  7.9379e-02, -2.2730e-01, -2.0200e-01, -2.1043e-01,\n",
            "         -1.3539e-01, -1.5416e-01,  2.3083e-01, -1.4306e-01,  1.7335e-01,\n",
            "          1.6987e-01,  1.8717e-01, -2.1875e-01, -2.0191e-01,  4.6794e-02,\n",
            "          7.6969e-02],\n",
            "        [ 8.7817e-02, -2.2005e-01,  4.2939e-02,  3.7799e-01, -3.1136e-01,\n",
            "          1.2048e-01, -1.4484e-01,  1.7240e-01,  1.0482e-01,  1.3989e-01,\n",
            "         -7.7966e-02,  1.7182e-01,  8.7622e-02, -6.1079e-02,  1.6320e-01,\n",
            "          1.0936e-01],\n",
            "        [ 1.6316e-01,  1.0953e-01, -1.8309e-01, -2.4273e-01, -2.3144e-01,\n",
            "          1.1643e-01,  1.4265e-02, -4.2267e-01, -4.9015e-02,  2.4643e-01,\n",
            "         -1.5186e-01,  1.2151e-01,  1.0054e-01, -7.1616e-02,  7.7135e-02,\n",
            "         -1.9369e-01],\n",
            "        [ 1.3604e-01, -1.6816e-01,  2.9183e-02,  1.0745e-02, -6.1637e-02,\n",
            "         -2.4122e-01,  9.9546e-02,  1.1543e-01,  2.1404e-01,  6.1753e-02,\n",
            "          1.7705e-01, -1.0031e-01,  1.3965e-01, -8.4073e-02, -1.6164e-02,\n",
            "          4.7825e-02],\n",
            "        [-3.9372e-02, -1.2222e-01, -1.0357e-01,  2.2564e-01,  1.3276e-01,\n",
            "          1.7604e-01, -4.6910e-03, -1.7045e-01, -2.1251e-01,  1.6377e-01,\n",
            "         -2.0832e-01, -6.5124e-04, -2.2523e-01,  5.1690e-03,  8.2869e-02,\n",
            "          2.9326e-03],\n",
            "        [ 1.4313e-01,  6.1983e-02, -1.7447e-01,  1.0219e-01,  3.5456e-03,\n",
            "         -9.1232e-02,  5.5059e-02,  1.2665e-02, -9.5868e-02,  2.0192e-01,\n",
            "          1.8017e-02, -1.1104e-01,  1.7337e-01,  2.1884e-01, -9.2691e-02,\n",
            "         -1.8502e-01],\n",
            "        [-2.8324e-02,  1.0509e-01, -2.3856e-01,  2.2916e-02, -1.5650e-01,\n",
            "          8.7366e-03, -1.3547e-02,  8.6640e-02,  2.4301e-01,  1.2325e-01,\n",
            "         -1.4718e-01,  2.4406e-01,  3.1490e-01,  5.0178e-02,  1.1804e-01,\n",
            "         -9.6842e-03],\n",
            "        [ 8.1960e-02,  1.7264e-01,  2.3116e-02,  5.1466e-02, -1.7134e-02,\n",
            "         -2.5587e-01, -3.5853e-02, -2.7169e-01, -1.9165e-01, -1.4184e-01,\n",
            "          1.3712e-01,  3.2616e-02, -1.5610e-01, -5.0204e-02,  1.3383e-02,\n",
            "         -1.4695e-01],\n",
            "        [ 1.1471e-01, -1.2229e-01, -7.9304e-02,  1.6964e-01,  8.6664e-02,\n",
            "          2.1409e-01, -1.5925e-01, -1.0394e-01,  2.0021e-01,  1.4388e-01,\n",
            "          4.4371e-02, -1.0489e-01, -5.4600e-02, -1.5409e-01,  2.2961e-02,\n",
            "         -4.8558e-02],\n",
            "        [ 4.2582e-02, -1.1919e-01, -2.0727e-01,  2.8174e-01,  1.2924e-01,\n",
            "         -6.2074e-02,  1.9561e-01,  2.2852e-01, -2.1636e-01, -6.1592e-02,\n",
            "          8.9014e-02, -1.6651e-01,  3.0950e-01,  1.6304e-01, -2.8709e-02,\n",
            "         -1.5392e-01],\n",
            "        [-1.9705e-02,  1.0558e-02,  1.1735e-02, -3.7344e-02, -1.7287e-01,\n",
            "          3.6988e-02,  8.8957e-02, -2.0629e-01,  1.1976e-01,  1.4371e-01,\n",
            "          6.3613e-03,  1.5588e-01, -1.6702e-01, -1.0444e-01, -1.5333e-01,\n",
            "         -2.4597e-01],\n",
            "        [-3.0996e-01, -1.1673e-01,  5.0675e-02, -1.5127e-01,  1.3807e-01,\n",
            "         -4.8340e-02, -1.4436e-01,  6.4084e-02, -2.0163e-01, -1.1742e-01,\n",
            "         -4.6827e-02,  1.4351e-01, -1.3174e-02,  1.4764e-01,  6.0138e-02,\n",
            "         -1.8953e-01],\n",
            "        [-2.0683e-01, -5.6450e-02, -5.8739e-02,  7.7284e-02, -4.1912e-02,\n",
            "         -9.8821e-02, -1.1429e-01, -3.5937e-01,  8.7345e-02, -1.7022e-01,\n",
            "         -1.2511e-01,  1.5426e-01,  3.2253e-01, -1.4470e-02, -2.4544e-01,\n",
            "          1.5933e-01],\n",
            "        [ 1.1519e-01, -5.0207e-02, -8.2738e-02, -8.1500e-02, -2.7266e-01,\n",
            "          1.2192e-01,  1.8188e-01, -9.8487e-02,  1.8022e-01,  8.9168e-02,\n",
            "         -1.7937e-01, -8.3197e-02, -1.2280e-01,  2.0865e-01,  2.4836e-01,\n",
            "         -3.9604e-02],\n",
            "        [ 8.1174e-03, -1.1488e-01,  1.8652e-02, -1.7440e-01, -7.7156e-02,\n",
            "         -1.4428e-01,  7.9087e-02,  3.8629e-02, -1.1265e-01, -1.1626e-01,\n",
            "          2.6143e-01,  7.3711e-02,  4.5519e-01, -1.4862e-01,  8.1638e-02,\n",
            "          1.8737e-01],\n",
            "        [-2.2407e-01, -1.5138e-01,  6.2191e-02, -1.4322e-01,  1.6100e-01,\n",
            "         -1.7743e-01, -1.8073e-01, -2.1175e-01, -2.2617e-02, -2.2088e-01,\n",
            "         -1.0865e-01,  3.7797e-02,  3.4240e-01, -2.3606e-02, -6.7025e-02,\n",
            "         -1.2654e-01],\n",
            "        [ 1.1590e-01,  1.4031e-01, -3.1718e-02, -1.8930e-01, -2.0172e-01,\n",
            "          1.6705e-01, -3.9715e-03,  1.4416e-02, -1.4847e-01, -8.5948e-02,\n",
            "         -1.5479e-01, -2.0814e-01, -1.0915e-01, -6.4937e-02,  1.3536e-01,\n",
            "         -1.1252e-01],\n",
            "        [ 1.1400e-01,  1.2670e-01, -9.4142e-02,  2.2125e-01,  8.7769e-02,\n",
            "         -1.4122e-01, -2.1704e-01,  2.5342e-01, -2.3804e-01, -2.2721e-01,\n",
            "          1.4857e-01, -6.4671e-02,  1.9436e-01,  1.2261e-02, -1.0116e-01,\n",
            "          1.2413e-01],\n",
            "        [ 1.4834e-01,  8.0033e-02, -2.4048e-01,  1.7771e-01, -2.3158e-01,\n",
            "         -7.6329e-02, -2.0996e-01, -6.3100e-02,  1.5372e-02,  1.3870e-01,\n",
            "         -1.4880e-01, -2.1168e-01,  2.0207e-01,  1.1287e-01,  1.4759e-01,\n",
            "         -6.6902e-02],\n",
            "        [-3.4798e-01,  1.6081e-01,  2.0357e-02,  1.9081e-01,  5.0584e-02,\n",
            "          1.9415e-03,  1.7567e-01, -6.2626e-03, -2.0720e-01, -1.1828e-01,\n",
            "          5.8440e-03,  6.1712e-02,  3.9281e-01, -2.9780e-01, -5.9036e-02,\n",
            "         -1.2758e-01],\n",
            "        [-2.0107e-01,  1.6456e-01,  1.8407e-01, -1.2933e-01,  6.4227e-02,\n",
            "         -1.3238e-01,  2.1583e-01,  1.3864e-01,  2.6785e-02,  1.4554e-01,\n",
            "          1.4246e-01, -2.1732e-01,  3.6441e-01,  1.5745e-01, -2.2281e-01,\n",
            "         -7.5553e-02],\n",
            "        [ 9.3545e-02, -1.8865e-01,  8.2021e-02,  2.0978e-01,  4.2600e-02,\n",
            "         -9.7730e-03, -1.8544e-01, -2.1497e-01,  6.3763e-02, -1.5792e-01,\n",
            "          1.3635e-01, -8.8699e-02, -1.5875e-02, -2.1054e-01, -2.1461e-01,\n",
            "          9.2810e-02],\n",
            "        [-1.9315e-01,  1.2705e-02,  1.6118e-02, -8.3285e-02,  2.0793e-01,\n",
            "          9.9304e-02,  1.7240e-01,  9.4548e-02,  2.2899e-01, -1.2062e-01,\n",
            "         -1.3881e-01,  2.5905e-01, -6.1791e-02, -2.7566e-02, -7.4084e-02,\n",
            "         -1.7856e-01],\n",
            "        [-1.4232e-01, -6.0751e-02, -7.0747e-02,  9.9476e-02,  6.8895e-03,\n",
            "          9.1614e-02,  2.3037e-01,  2.6472e-01,  1.1738e-01, -2.1740e-02,\n",
            "         -3.0149e-01, -7.2115e-02,  6.7484e-02, -3.1745e-02, -2.1295e-01,\n",
            "         -1.7590e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1089,  0.0497, -0.2502,  0.0047, -0.0178,  0.0242, -0.1570,  0.1806,\n",
            "        -0.1977,  0.1025,  0.1536, -0.1971,  0.0304, -0.0693, -0.1604, -0.0634,\n",
            "         0.1852, -0.2088,  0.0131, -0.3451, -0.0474, -0.0816, -0.1148, -0.2092,\n",
            "         0.1305,  0.0433, -0.0430, -0.0532, -0.3834,  0.0726, -0.1029, -0.0379],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0968, -0.0247, -0.0150, -0.0238, -0.0143, -0.0005, -0.1188,  0.2026,\n",
            "          0.0780, -0.0192, -0.0174,  0.1575,  0.0075,  0.0150, -0.0807, -0.0064,\n",
            "         -0.0051, -0.0360,  0.1045,  0.0205,  0.0333,  0.0411, -0.1346, -0.0768,\n",
            "          0.0724,  0.0403, -0.1625, -0.0562,  0.0378, -0.0261,  0.0085, -0.1008]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0030], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1000 Trajectories:"
      ],
      "metadata": {
        "id": "vkoraLdAJMad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# single cumprod\n",
        "# 1000 trajectories\n",
        "model11 = train_var_play(model10, 500, 0.0001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7wNPtMDLjuq",
        "outputId": "7f9ffd94-4372-425f-a352-08a0eeb8e8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8435369920087568e-06\n",
            "E_s_wdiff_all_sq: 9.069579199805096e-08\n",
            "E_IS_SCOPE: -1.1038198776012357e-05\n",
            "E_IS_E_SCOPE: -9.750861916403596e-06\n",
            "Total Loss: 3.032905472266013e-07\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(2.8471e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6681551818117882e-06\n",
            "E_s_wdiff_all_sq: 1.4820307511116906e-10\n",
            "E_IS_SCOPE: -1.013852417975717e-05\n",
            "E_IS_E_SCOPE: -8.884314617475877e-06\n",
            "Total Loss: 2.8471092060750724e-07\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(3.2981e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7046211317725032e-06\n",
            "E_s_wdiff_all_sq: 4.237948817006082e-08\n",
            "E_IS_SCOPE: -9.460547193621885e-06\n",
            "E_IS_E_SCOPE: -8.231770336608416e-06\n",
            "Total Loss: 3.2981099600892257e-07\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(3.4469e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7323293298567792e-06\n",
            "E_s_wdiff_all_sq: 6.635520273798164e-08\n",
            "E_IS_SCOPE: -9.318184677880333e-06\n",
            "E_IS_E_SCOPE: -8.09497858587953e-06\n",
            "Total Loss: 3.446850095506056e-07\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(3.0606e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6771839375519107e-06\n",
            "E_s_wdiff_all_sq: 2.1624156834102108e-08\n",
            "E_IS_SCOPE: -9.697189173535676e-06\n",
            "E_IS_E_SCOPE: -8.4598758712155e-06\n",
            "Total Loss: 3.0605624251087236e-07\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(2.7890e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6809097910442335e-06\n",
            "E_s_wdiff_all_sq: 2.7394327085961113e-09\n",
            "E_IS_SCOPE: -1.0353392876240718e-05\n",
            "E_IS_E_SCOPE: -9.091198577162251e-06\n",
            "Total Loss: 2.789048266121174e-07\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(2.9800e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8017804567123004e-06\n",
            "E_s_wdiff_all_sq: 5.819853221471494e-08\n",
            "E_IS_SCOPE: -1.09555982516869e-05\n",
            "E_IS_E_SCOPE: -9.670246106715022e-06\n",
            "Total Loss: 2.9800070098724416e-07\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(3.2048e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8969961180210046e-06\n",
            "E_s_wdiff_all_sq: 1.1019503763098044e-07\n",
            "E_IS_SCOPE: -1.1214237305682962e-05\n",
            "E_IS_E_SCOPE: -9.91851288625117e-06\n",
            "Total Loss: 3.20475307959855e-07\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(3.0660e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8480626340308605e-06\n",
            "E_s_wdiff_all_sq: 8.716692414689072e-08\n",
            "E_IS_SCOPE: -1.1039250381753849e-05\n",
            "E_IS_E_SCOPE: -9.749540773018597e-06\n",
            "Total Loss: 3.0659955884688105e-07\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(2.8092e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7263589137825757e-06\n",
            "E_s_wdiff_all_sq: 2.7093288370840447e-08\n",
            "E_IS_SCOPE: -1.0549193306570451e-05\n",
            "E_IS_E_SCOPE: -9.277456981699345e-06\n",
            "Total Loss: 2.809160421029356e-07\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(2.8161e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6585675003353047e-06\n",
            "E_s_wdiff_all_sq: 1.5048879050382775e-10\n",
            "E_IS_SCOPE: -9.988300349096995e-06\n",
            "E_IS_E_SCOPE: -8.73733477946256e-06\n",
            "Total Loss: 2.81608938709348e-07\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(2.9975e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.656183210809849e-06\n",
            "E_s_wdiff_all_sq: 7.0180357459615034e-09\n",
            "E_IS_SCOPE: -9.619636655739366e-06\n",
            "E_IS_E_SCOPE: -8.382369874497133e-06\n",
            "Total Loss: 2.9975467901283864e-07\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(3.0090e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6546854679117633e-06\n",
            "E_s_wdiff_all_sq: 6.07679079287042e-09\n",
            "E_IS_SCOPE: -9.597536756834598e-06\n",
            "E_IS_E_SCOPE: -8.361122973005699e-06\n",
            "Total Loss: 3.009041758945099e-07\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(2.8374e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6540051363120575e-06\n",
            "E_s_wdiff_all_sq: 4.834190648879977e-10\n",
            "E_IS_SCOPE: -9.897225454613175e-06\n",
            "E_IS_E_SCOPE: -8.649775199159999e-06\n",
            "Total Loss: 2.8374427277423233e-07\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(2.7597e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7066197763006891e-06\n",
            "E_s_wdiff_all_sq: 2.7509847190423823e-08\n",
            "E_IS_SCOPE: -1.0351394058015706e-05\n",
            "E_IS_E_SCOPE: -9.087261235238343e-06\n",
            "Total Loss: 2.759673499889514e-07\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(2.8587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7992694006032959e-06\n",
            "E_s_wdiff_all_sq: 8.221050283084085e-08\n",
            "E_IS_SCOPE: -1.0736313291300548e-05\n",
            "E_IS_E_SCOPE: -9.458159443730113e-06\n",
            "Total Loss: 2.858742690650022e-07\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(2.9223e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8438440398062562e-06\n",
            "E_s_wdiff_all_sq: 1.1061199634434994e-07\n",
            "E_IS_SCOPE: -1.0875971347590517e-05\n",
            "E_IS_E_SCOPE: -9.592908058398854e-06\n",
            "Total Loss: 2.922285315119952e-07\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(2.8333e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7985129581236776e-06\n",
            "E_s_wdiff_all_sq: 8.522802025912445e-08\n",
            "E_IS_SCOPE: -1.073060654579793e-05\n",
            "E_IS_E_SCOPE: -9.453065219652134e-06\n",
            "Total Loss: 2.8332535200637716e-07\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(2.7433e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7183258676331013e-06\n",
            "E_s_wdiff_all_sq: 3.825185134239775e-08\n",
            "E_IS_SCOPE: -1.040134421201283e-05\n",
            "E_IS_E_SCOPE: -9.135909792211953e-06\n",
            "Total Loss: 2.7432824312236516e-07\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(2.7817e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6695471996792159e-06\n",
            "E_s_wdiff_all_sq: 9.579788770699002e-09\n",
            "E_IS_SCOPE: -1.0070098569364722e-05\n",
            "E_IS_E_SCOPE: -8.816638982144357e-06\n",
            "Total Loss: 2.781713029012037e-07\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(2.8465e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6574289329627577e-06\n",
            "E_s_wdiff_all_sq: 2.383153220342337e-09\n",
            "E_IS_SCOPE: -9.90547208542088e-06\n",
            "E_IS_E_SCOPE: -8.657711996004091e-06\n",
            "Total Loss: 2.8464866734225333e-07\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(2.8093e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6621009246577875e-06\n",
            "E_s_wdiff_all_sq: 4.828221179828129e-09\n",
            "E_IS_SCOPE: -9.9761540331261e-06\n",
            "E_IS_E_SCOPE: -8.72542341588035e-06\n",
            "Total Loss: 2.8093453541987614e-07\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(2.7343e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.688675314338477e-06\n",
            "E_s_wdiff_all_sq: 2.0101730256030135e-08\n",
            "E_IS_SCOPE: -1.02256004733299e-05\n",
            "E_IS_E_SCOPE: -8.965468562112827e-06\n",
            "Total Loss: 2.7343282808171837e-07\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(2.7392e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7395695851463808e-06\n",
            "E_s_wdiff_all_sq: 4.9720805790818394e-08\n",
            "E_IS_SCOPE: -1.0509647848056694e-05\n",
            "E_IS_E_SCOPE: -9.239123962011318e-06\n",
            "Total Loss: 2.7392407369822753e-07\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(2.7874e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7779000417897504e-06\n",
            "E_s_wdiff_all_sq: 7.144356849692458e-08\n",
            "E_IS_SCOPE: -1.0674123965770139e-05\n",
            "E_IS_E_SCOPE: -9.397703046751705e-06\n",
            "Total Loss: 2.7873770168937406e-07\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(2.7748e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7653944115231058e-06\n",
            "E_s_wdiff_all_sq: 6.282728384254235e-08\n",
            "E_IS_SCOPE: -1.0638127519760087e-05\n",
            "E_IS_E_SCOPE: -9.363020197556958e-06\n",
            "Total Loss: 2.774755497077237e-07\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(2.7209e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.71610358233623e-06\n",
            "E_s_wdiff_all_sq: 3.3356438660741866e-08\n",
            "E_IS_SCOPE: -1.043233953055605e-05\n",
            "E_IS_E_SCOPE: -9.164451798514617e-06\n",
            "Total Loss: 2.7209474602603907e-07\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(2.7146e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6743945915731427e-06\n",
            "E_s_wdiff_all_sq: 9.699209097463843e-09\n",
            "E_IS_SCOPE: -1.0177104032858885e-05\n",
            "E_IS_E_SCOPE: -8.91792466823561e-06\n",
            "Total Loss: 2.714597196625433e-07\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(2.7465e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6588719987574969e-06\n",
            "E_s_wdiff_all_sq: 1.569561423769858e-09\n",
            "E_IS_SCOPE: -1.0010334931618548e-05\n",
            "E_IS_E_SCOPE: -8.756444857804298e-06\n",
            "Total Loss: 2.746453561386403e-07\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(2.7412e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.659312993395853e-06\n",
            "E_s_wdiff_all_sq: 9.675658626765192e-10\n",
            "E_IS_SCOPE: -1.0014069263921202e-05\n",
            "E_IS_E_SCOPE: -8.759394030441759e-06\n",
            "Total Loss: 2.7411802700770695e-07\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(2.7031e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.671059484881144e-06\n",
            "E_s_wdiff_all_sq: 4.646271766222259e-09\n",
            "E_IS_SCOPE: -1.0169902172356884e-05\n",
            "E_IS_E_SCOPE: -8.909287000225669e-06\n",
            "Total Loss: 2.7030593528590487e-07\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(2.6953e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6955407571355302e-06\n",
            "E_s_wdiff_all_sq: 1.4921697913525555e-08\n",
            "E_IS_SCOPE: -1.0378385203481073e-05\n",
            "E_IS_E_SCOPE: -9.110281596144436e-06\n",
            "Total Loss: 2.6953491098214627e-07\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(2.7160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7169536650224805e-06\n",
            "E_s_wdiff_all_sq: 2.4886194164612132e-08\n",
            "E_IS_SCOPE: -1.051738333373614e-05\n",
            "E_IS_E_SCOPE: -9.2445875011386e-06\n",
            "Total Loss: 2.715988720962057e-07\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(2.7114e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7144924018112085e-06\n",
            "E_s_wdiff_all_sq: 2.3781199635505362e-08\n",
            "E_IS_SCOPE: -1.0514133680660362e-05\n",
            "E_IS_E_SCOPE: -9.24178548497944e-06\n",
            "Total Loss: 2.711378772472746e-07\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(2.6839e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6915426963399843e-06\n",
            "E_s_wdiff_all_sq: 1.3317684808283942e-08\n",
            "E_IS_SCOPE: -1.038222583466663e-05\n",
            "E_IS_E_SCOPE: -9.114749085637569e-06\n",
            "Total Loss: 2.68394579906992e-07\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(2.6782e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6700411080063385e-06\n",
            "E_s_wdiff_all_sq: 4.535386397575181e-09\n",
            "E_IS_SCOPE: -1.020833430254202e-05\n",
            "E_IS_E_SCOPE: -8.946932347961355e-06\n",
            "Total Loss: 2.6782487888084654e-07\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(2.6908e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6610411768665737e-06\n",
            "E_s_wdiff_all_sq: 1.7326342566753764e-09\n",
            "E_IS_SCOPE: -1.00977639026607e-05\n",
            "E_IS_E_SCOPE: -8.840088954133444e-06\n",
            "Total Loss: 2.6908171198880004e-07\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(2.6843e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6628066778868443e-06\n",
            "E_s_wdiff_all_sq: 3.0908016453067334e-09\n",
            "E_IS_SCOPE: -1.0111004029943194e-05\n",
            "E_IS_E_SCOPE: -8.852801825385503e-06\n",
            "Total Loss: 2.684345335595736e-07\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(2.6645e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6764625717159275e-06\n",
            "E_s_wdiff_all_sq: 1.0667099139353596e-08\n",
            "E_IS_SCOPE: -1.0229238553510087e-05\n",
            "E_IS_E_SCOPE: -8.96700363585541e-06\n",
            "Total Loss: 2.664487037006344e-07\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(2.6617e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7007742196165464e-06\n",
            "E_s_wdiff_all_sq: 2.5642278851107286e-08\n",
            "E_IS_SCOPE: -1.037407816013836e-05\n",
            "E_IS_E_SCOPE: -9.107036118964874e-06\n",
            "Total Loss: 2.661709248518852e-07\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(2.6684e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7205066919778037e-06\n",
            "E_s_wdiff_all_sq: 3.941964509775908e-08\n",
            "E_IS_SCOPE: -1.0457372341022442e-05\n",
            "E_IS_E_SCOPE: -9.18768873797364e-06\n",
            "Total Loss: 2.6684290721585447e-07\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(2.6599e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7201163618590407e-06\n",
            "E_s_wdiff_all_sq: 4.1737694905049835e-08\n",
            "E_IS_SCOPE: -1.0432515549215233e-05\n",
            "E_IS_E_SCOPE: -9.163757980750616e-06\n",
            "Total Loss: 2.659865964581729e-07\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(2.6456e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7033898788555505e-06\n",
            "E_s_wdiff_all_sq: 3.360087996965589e-08\n",
            "E_IS_SCOPE: -1.0323273068031307e-05\n",
            "E_IS_E_SCOPE: -9.058094584576157e-06\n",
            "Total Loss: 2.645550984090112e-07\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(2.6451e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6866974174824644e-06\n",
            "E_s_wdiff_all_sq: 2.449915043027074e-08\n",
            "E_IS_SCOPE: -1.0204731180126292e-05\n",
            "E_IS_E_SCOPE: -8.94332793802133e-06\n",
            "Total Loss: 2.6451484927568523e-07\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(2.6471e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6805090730716287e-06\n",
            "E_s_wdiff_all_sq: 2.1157753439095683e-08\n",
            "E_IS_SCOPE: -1.0153382997093178e-05\n",
            "E_IS_E_SCOPE: -8.893499534188353e-06\n",
            "Total Loss: 2.6470746025629633e-07\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(2.6373e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6859556244337802e-06\n",
            "E_s_wdiff_all_sq: 2.4679244959016808e-08\n",
            "E_IS_SCOPE: -1.0194442276697134e-05\n",
            "E_IS_E_SCOPE: -8.933107365418894e-06\n",
            "Total Loss: 2.6372962335170036e-07\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(2.6277e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6999397898224377e-06\n",
            "E_s_wdiff_all_sq: 3.309090192137437e-08\n",
            "E_IS_SCOPE: -1.0293761592938672e-05\n",
            "E_IS_E_SCOPE: -9.029161518063023e-06\n",
            "Total Loss: 2.6277180458318033e-07\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(2.6278e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.712900179163878e-06\n",
            "E_s_wdiff_all_sq: 4.0354741865224495e-08\n",
            "E_IS_SCOPE: -1.0383789899492356e-05\n",
            "E_IS_E_SCOPE: -9.116343933255279e-06\n",
            "Total Loss: 2.6277657125791473e-07\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(2.6256e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7133490944394828e-06\n",
            "E_s_wdiff_all_sq: 3.976445027982784e-08\n",
            "E_IS_SCOPE: -1.040930318296914e-05\n",
            "E_IS_E_SCOPE: -9.141227590330314e-06\n",
            "Total Loss: 2.625565253154178e-07\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(2.6160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7005683027948266e-06\n",
            "E_s_wdiff_all_sq: 3.1409142139555215e-08\n",
            "E_IS_SCOPE: -1.0358677924371899e-05\n",
            "E_IS_E_SCOPE: -9.092338059636917e-06\n",
            "Total Loss: 2.6160249761872307e-07\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(2.6102e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6846679473639299e-06\n",
            "E_s_wdiff_all_sq: 2.1525628806611662e-08\n",
            "E_IS_SCOPE: -1.0273607892391687e-05\n",
            "E_IS_E_SCOPE: -9.009984759264032e-06\n",
            "Total Loss: 2.6101911873542425e-07\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(2.6095e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6753804916220374e-06\n",
            "E_s_wdiff_all_sq: 1.5767248312170563e-08\n",
            "E_IS_SCOPE: -1.021932237921305e-05\n",
            "E_IS_E_SCOPE: -8.95743031263865e-06\n",
            "Total Loss: 2.609521765944829e-07\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(2.6043e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6754474621028189e-06\n",
            "E_s_wdiff_all_sq: 1.555849222252975e-08\n",
            "E_IS_SCOPE: -1.023144871980216e-05\n",
            "E_IS_E_SCOPE: -8.969156838861936e-06\n",
            "Total Loss: 2.6042827443325253e-07\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(2.5963e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6833450004286785e-06\n",
            "E_s_wdiff_all_sq: 2.00222283492076e-08\n",
            "E_IS_SCOPE: -1.0297261690842088e-05\n",
            "E_IS_E_SCOPE: -9.032854478472763e-06\n",
            "Total Loss: 2.5963141377423665e-07\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(2.5928e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6938466470010356e-06\n",
            "E_s_wdiff_all_sq: 2.6212260038095294e-08\n",
            "E_IS_SCOPE: -1.0368941428475684e-05\n",
            "E_IS_E_SCOPE: -9.102200319473801e-06\n",
            "Total Loss: 2.592752353925906e-07\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(2.5901e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6991444088206006e-06\n",
            "E_s_wdiff_all_sq: 2.968474046573108e-08\n",
            "E_IS_SCOPE: -1.040033976517296e-05\n",
            "E_IS_E_SCOPE: -9.132553826772803e-06\n",
            "Total Loss: 2.5901085798797174e-07\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(2.5836e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6952385391430819e-06\n",
            "E_s_wdiff_all_sq: 2.8056837322549774e-08\n",
            "E_IS_SCOPE: -1.0375143866669837e-05\n",
            "E_IS_E_SCOPE: -9.108169757822188e-06\n",
            "Total Loss: 2.583565505586515e-07\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(2.5774e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6861299915438776e-06\n",
            "E_s_wdiff_all_sq: 2.3616246356267666e-08\n",
            "E_IS_SCOPE: -1.0313852323114753e-05\n",
            "E_IS_E_SCOPE: -9.04890338540679e-06\n",
            "Total Loss: 2.5773893620509985e-07\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(2.5744e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6795925224295217e-06\n",
            "E_s_wdiff_all_sq: 2.0777977201148218e-08\n",
            "E_IS_SCOPE: -1.026252868496401e-05\n",
            "E_IS_E_SCOPE: -8.999280305833908e-06\n",
            "Total Loss: 2.5744085340158523e-07\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(2.5700e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6800677379171797e-06\n",
            "E_s_wdiff_all_sq: 2.178652902639422e-08\n",
            "E_IS_SCOPE: -1.0259703383982257e-05\n",
            "E_IS_E_SCOPE: -8.996499770074034e-06\n",
            "Total Loss: 2.5699704750775524e-07\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(2.5633e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6873302316837961e-06\n",
            "E_s_wdiff_all_sq: 2.6672399417262403e-08\n",
            "E_IS_SCOPE: -1.0302736744762634e-05\n",
            "E_IS_E_SCOPE: -9.038011193109923e-06\n",
            "Total Loss: 2.5632979539452785e-07\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(2.5589e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6969551657655534e-06\n",
            "E_s_wdiff_all_sq: 3.2926729684886056e-08\n",
            "E_IS_SCOPE: -1.0357699113701884e-05\n",
            "E_IS_E_SCOPE: -9.09106912618483e-06\n",
            "Total Loss: 2.558915274799738e-07\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(2.5553e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7018017089726907e-06\n",
            "E_s_wdiff_all_sq: 3.6382618581506375e-08\n",
            "E_IS_SCOPE: -1.0383623092620069e-05\n",
            "E_IS_E_SCOPE: -9.116117253468467e-06\n",
            "Total Loss: 2.555304785213972e-07\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(2.5494e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6986675579630156e-06\n",
            "E_s_wdiff_all_sq: 3.5138170036746104e-08\n",
            "E_IS_SCOPE: -1.0367479227714155e-05\n",
            "E_IS_E_SCOPE: -9.100623491040543e-06\n",
            "Total Loss: 2.5494098101245916e-07\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(2.5439e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.691336738703416e-06\n",
            "E_s_wdiff_all_sq: 3.1319864072879146e-08\n",
            "E_IS_SCOPE: -1.0327295495612857e-05\n",
            "E_IS_E_SCOPE: -9.061919254679542e-06\n",
            "Total Loss: 2.5438745919732187e-07\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(2.5399e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.68625377228405e-06\n",
            "E_s_wdiff_all_sq: 2.8847371466938995e-08\n",
            "E_IS_SCOPE: -1.0297841802881952e-05\n",
            "E_IS_E_SCOPE: -9.033572898476192e-06\n",
            "Total Loss: 2.5399165843900944e-07\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(2.5350e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6869615427594639e-06\n",
            "E_s_wdiff_all_sq: 2.991807328767732e-08\n",
            "E_IS_SCOPE: -1.0303328543166916e-05\n",
            "E_IS_E_SCOPE: -9.038996351620883e-06\n",
            "Total Loss: 2.53502152813134e-07\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(2.5291e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6926371057306124e-06\n",
            "E_s_wdiff_all_sq: 3.401659189511269e-08\n",
            "E_IS_SCOPE: -1.033884027112403e-05\n",
            "E_IS_E_SCOPE: -9.07342309635166e-06\n",
            "Total Loss: 2.5290923072417385e-07\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(2.5245e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6991088449331352e-06\n",
            "E_s_wdiff_all_sq: 3.856102807188364e-08\n",
            "E_IS_SCOPE: -1.0377310638533448e-05\n",
            "E_IS_E_SCOPE: -9.110698742504925e-06\n",
            "Total Loss: 2.524470912376194e-07\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(2.5200e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7009310612530155e-06\n",
            "E_s_wdiff_all_sq: 4.005269032608846e-08\n",
            "E_IS_SCOPE: -1.0392116091667854e-05\n",
            "E_IS_E_SCOPE: -9.125115354444773e-06\n",
            "Total Loss: 2.519999629141794e-07\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(2.5144e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6966764378245395e-06\n",
            "E_s_wdiff_all_sq: 3.771075791094428e-08\n",
            "E_IS_SCOPE: -1.0374844450179033e-05\n",
            "E_IS_E_SCOPE: -9.108519528487823e-06\n",
            "Total Loss: 2.5143890296459267e-07\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(2.5092e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6903567823540141e-06\n",
            "E_s_wdiff_all_sq: 3.3946121441320736e-08\n",
            "E_IS_SCOPE: -1.0343716826748964e-05\n",
            "E_IS_E_SCOPE: -9.078407923984629e-06\n",
            "Total Loss: 2.5091592181743857e-07\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(2.5046e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6868975641107207e-06\n",
            "E_s_wdiff_all_sq: 3.191221886486607e-08\n",
            "E_IS_SCOPE: -1.0326249017078746e-05\n",
            "E_IS_E_SCOPE: -9.06142505098491e-06\n",
            "Total Loss: 2.5046047949159915e-07\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(2.4993e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6877545976774454e-06\n",
            "E_s_wdiff_all_sq: 3.255838336680427e-08\n",
            "E_IS_SCOPE: -1.0337004492665508e-05\n",
            "E_IS_E_SCOPE: -9.071809217210522e-06\n",
            "Total Loss: 2.499287298340844e-07\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(2.4940e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6913967052814574e-06\n",
            "E_s_wdiff_all_sq: 3.499453223176534e-08\n",
            "E_IS_SCOPE: -1.0367684007349612e-05\n",
            "E_IS_E_SCOPE: -9.101620531403742e-06\n",
            "Total Loss: 2.4939828759136826e-07\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(2.4892e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6942272265366266e-06\n",
            "E_s_wdiff_all_sq: 3.718146574746891e-08\n",
            "E_IS_SCOPE: -1.0391048031284924e-05\n",
            "E_IS_E_SCOPE: -9.124421282249255e-06\n",
            "Total Loss: 2.4891532915123697e-07\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(2.4840e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6936831451070829e-06\n",
            "E_s_wdiff_all_sq: 3.7277709581075264e-08\n",
            "E_IS_SCOPE: -1.0391378522643025e-05\n",
            "E_IS_E_SCOPE: -9.124813721269722e-06\n",
            "Total Loss: 2.483988992128177e-07\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(2.4785e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6910714802243535e-06\n",
            "E_s_wdiff_all_sq: 3.5850913573887225e-08\n",
            "E_IS_SCOPE: -1.0373839366150871e-05\n",
            "E_IS_E_SCOPE: -9.107594570107407e-06\n",
            "Total Loss: 2.4785404099695315e-07\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(2.4735e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6885233322919809e-06\n",
            "E_s_wdiff_all_sq: 3.4403133696025766e-08\n",
            "E_IS_SCOPE: -1.0355011283800988e-05\n",
            "E_IS_E_SCOPE: -9.089064857947725e-06\n",
            "Total Loss: 2.47350413322845e-07\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(2.4685e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6879839029304935e-06\n",
            "E_s_wdiff_all_sq: 3.4323003697155966e-08\n",
            "E_IS_SCOPE: -1.0352187993372817e-05\n",
            "E_IS_E_SCOPE: -9.086222531448017e-06\n",
            "Total Loss: 2.4685304181715416e-07\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(2.4630e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.689582004464503e-06\n",
            "E_s_wdiff_all_sq: 3.584407588348409e-08\n",
            "E_IS_SCOPE: -1.0366366812968455e-05\n",
            "E_IS_E_SCOPE: -9.100088251447194e-06\n",
            "Total Loss: 2.463038719719139e-07\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(2.4577e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6922601381365734e-06\n",
            "E_s_wdiff_all_sq: 3.82415669918161e-08\n",
            "E_IS_SCOPE: -1.038658169615555e-05\n",
            "E_IS_E_SCOPE: -9.11989819409313e-06\n",
            "Total Loss: 2.4577463345332984e-07\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(2.4528e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6942455261185151e-06\n",
            "E_s_wdiff_all_sq: 4.0139691320894116e-08\n",
            "E_IS_SCOPE: -1.0398199454984302e-05\n",
            "E_IS_E_SCOPE: -9.131224824202295e-06\n",
            "Total Loss: 2.452796396670227e-07\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(2.4475e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6938742135876403e-06\n",
            "E_s_wdiff_all_sq: 4.037903109110672e-08\n",
            "E_IS_SCOPE: -1.0393696280311245e-05\n",
            "E_IS_E_SCOPE: -9.126760406711929e-06\n",
            "Total Loss: 2.447465017313164e-07\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(2.4420e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6918426142135116e-06\n",
            "E_s_wdiff_all_sq: 3.9567049451739617e-08\n",
            "E_IS_SCOPE: -1.0376156647799441e-05\n",
            "E_IS_E_SCOPE: -9.109558037984783e-06\n",
            "Total Loss: 2.442014115658689e-07\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(2.4368e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6903665787824395e-06\n",
            "E_s_wdiff_all_sq: 3.927720108231916e-08\n",
            "E_IS_SCOPE: -1.0361112924344464e-05\n",
            "E_IS_E_SCOPE: -9.094848024353296e-06\n",
            "Total Loss: 2.436826441511998e-07\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(2.4315e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6910058003735774e-06\n",
            "E_s_wdiff_all_sq: 4.005393060803126e-08\n",
            "E_IS_SCOPE: -1.0363375386530902e-05\n",
            "E_IS_E_SCOPE: -9.096913128895688e-06\n",
            "Total Loss: 2.4315042092853646e-07\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(2.4261e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6934241213630255e-06\n",
            "E_s_wdiff_all_sq: 4.1913488305550946e-08\n",
            "E_IS_SCOPE: -1.0377952679624788e-05\n",
            "E_IS_E_SCOPE: -9.110942065715619e-06\n",
            "Total Loss: 2.4261247167255045e-07\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(2.4210e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6957348936007011e-06\n",
            "E_s_wdiff_all_sq: 4.37335787672969e-08\n",
            "E_IS_SCOPE: -1.039187745577729e-05\n",
            "E_IS_E_SCOPE: -9.12436320385075e-06\n",
            "Total Loss: 2.4209587741373775e-07\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(2.4155e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6955513509714145e-06\n",
            "E_s_wdiff_all_sq: 4.390050913286332e-08\n",
            "E_IS_SCOPE: -1.0393149810482465e-05\n",
            "E_IS_E_SCOPE: -9.125539995224102e-06\n",
            "Total Loss: 2.4155427775523903e-07\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(2.4101e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.693310366680318e-06\n",
            "E_s_wdiff_all_sq: 4.2784238234586944e-08\n",
            "E_IS_SCOPE: -1.0383414445967806e-05\n",
            "E_IS_E_SCOPE: -9.11609238191256e-06\n",
            "Total Loss: 2.4100506676865403e-07\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(2.4047e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6910721691234906e-06\n",
            "E_s_wdiff_all_sq: 4.1670012133977186e-08\n",
            "E_IS_SCOPE: -1.0374398585770705e-05\n",
            "E_IS_E_SCOPE: -9.107370197455367e-06\n",
            "Total Loss: 2.4046844679225396e-07\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(2.3993e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6907452870210213e-06\n",
            "E_s_wdiff_all_sq: 4.180688744621543e-08\n",
            "E_IS_SCOPE: -1.037615061671181e-05\n",
            "E_IS_E_SCOPE: -9.109087350303633e-06\n",
            "Total Loss: 2.3993493319187044e-07\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(2.3939e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6921768464942244e-06\n",
            "E_s_wdiff_all_sq: 4.3324733919751014e-08\n",
            "E_IS_SCOPE: -1.0383226306463651e-05\n",
            "E_IS_E_SCOPE: -9.115933902185967e-06\n",
            "Total Loss: 2.393903704525204e-07\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(2.3884e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6941442222748227e-06\n",
            "E_s_wdiff_all_sq: 4.522637198548534e-08\n",
            "E_IS_SCOPE: -1.0389058919109852e-05\n",
            "E_IS_E_SCOPE: -9.12146036377818e-06\n",
            "Total Loss: 2.388438060594112e-07\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(2.3831e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6955026987577546e-06\n",
            "E_s_wdiff_all_sq: 4.658804669621946e-08\n",
            "E_IS_SCOPE: -1.0390998961024602e-05\n",
            "E_IS_E_SCOPE: -9.1231332967459e-06\n",
            "Total Loss: 2.3830638993754683e-07\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(2.3776e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6954669787093733e-06\n",
            "E_s_wdiff_all_sq: 4.6974658778947935e-08\n",
            "E_IS_SCOPE: -1.0387279545201746e-05\n",
            "E_IS_E_SCOPE: -9.119351867391869e-06\n",
            "Total Loss: 2.377600307440864e-07\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(2.3721e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6943973761721936e-06\n",
            "E_s_wdiff_all_sq: 4.674336415783465e-08\n",
            "E_IS_SCOPE: -1.0381463972924126e-05\n",
            "E_IS_E_SCOPE: -9.113681468071017e-06\n",
            "Total Loss: 2.3721206874155453e-07\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(2.3666e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6937746231358054e-06\n",
            "E_s_wdiff_all_sq: 4.698390400374258e-08\n",
            "E_IS_SCOPE: -1.0380116958032229e-05\n",
            "E_IS_E_SCOPE: -9.112490477741196e-06\n",
            "Total Loss: 2.3666082498341224e-07\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(2.3613e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6942466542058214e-06\n",
            "E_s_wdiff_all_sq: 4.8049587185144714e-08\n",
            "E_IS_SCOPE: -1.0386131933832583e-05\n",
            "E_IS_E_SCOPE: -9.118534410799879e-06\n",
            "Total Loss: 2.3612508738868452e-07\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(2.3557e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6960244447846707e-06\n",
            "E_s_wdiff_all_sq: 4.974454904358387e-08\n",
            "E_IS_SCOPE: -1.0396315503461139e-05\n",
            "E_IS_E_SCOPE: -9.128399292362523e-06\n",
            "Total Loss: 2.355705399772714e-07\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(2.3503e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.697802853075147e-06\n",
            "E_s_wdiff_all_sq: 5.1228372862228884e-08\n",
            "E_IS_SCOPE: -1.0403935574847117e-05\n",
            "E_IS_E_SCOPE: -9.13560020199953e-06\n",
            "Total Loss: 2.3502680095116249e-07\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(2.3447e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6978178911561667e-06\n",
            "E_s_wdiff_all_sq: 5.17062830162525e-08\n",
            "E_IS_SCOPE: -1.0401195667281405e-05\n",
            "E_IS_E_SCOPE: -9.132815290468971e-06\n",
            "Total Loss: 2.3447392094846063e-07\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(2.3391e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6963813834446498e-06\n",
            "E_s_wdiff_all_sq: 5.1389901165742885e-08\n",
            "E_IS_SCOPE: -1.0390740111433067e-05\n",
            "E_IS_E_SCOPE: -9.12263869855524e-06\n",
            "Total Loss: 2.3391172295666906e-07\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(2.3337e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6956038350990175e-06\n",
            "E_s_wdiff_all_sq: 5.1307639145693544e-08\n",
            "E_IS_SCOPE: -1.0385789382678743e-05\n",
            "E_IS_E_SCOPE: -9.117762276342346e-06\n",
            "Total Loss: 2.3336504971394498e-07\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(2.3281e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6964062628256837e-06\n",
            "E_s_wdiff_all_sq: 5.219462837219457e-08\n",
            "E_IS_SCOPE: -1.0388617328441866e-05\n",
            "E_IS_E_SCOPE: -9.120356145481202e-06\n",
            "Total Loss: 2.32812334965574e-07\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(2.3226e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.697969708123644e-06\n",
            "E_s_wdiff_all_sq: 5.356150422228303e-08\n",
            "E_IS_SCOPE: -1.0396512373483222e-05\n",
            "E_IS_E_SCOPE: -9.127874657124376e-06\n",
            "Total Loss: 2.322558376170834e-07\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(2.3170e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6985046476447504e-06\n",
            "E_s_wdiff_all_sq: 5.421227944654942e-08\n",
            "E_IS_SCOPE: -1.0403259580456e-05\n",
            "E_IS_E_SCOPE: -9.13440324291294e-06\n",
            "Total Loss: 2.3170275954549535e-07\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(2.3114e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.697402565253607e-06\n",
            "E_s_wdiff_all_sq: 5.366662050549304e-08\n",
            "E_IS_SCOPE: -1.0404202521657255e-05\n",
            "E_IS_E_SCOPE: -9.135342909318728e-06\n",
            "Total Loss: 2.3113978650447428e-07\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(2.3059e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6958400272508577e-06\n",
            "E_s_wdiff_all_sq: 5.2882884795770964e-08\n",
            "E_IS_SCOPE: -1.0403002927344853e-05\n",
            "E_IS_E_SCOPE: -9.134256792710523e-06\n",
            "Total Loss: 2.3058793961984435e-07\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(2.3004e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6950071719017815e-06\n",
            "E_s_wdiff_all_sq: 5.287300646841153e-08\n",
            "E_IS_SCOPE: -1.0402737494062908e-05\n",
            "E_IS_E_SCOPE: -9.134131168138253e-06\n",
            "Total Loss: 2.300445800174791e-07\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(2.2947e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6957747610661316e-06\n",
            "E_s_wdiff_all_sq: 5.4118831831198214e-08\n",
            "E_IS_SCOPE: -1.0403672859566108e-05\n",
            "E_IS_E_SCOPE: -9.135018404395334e-06\n",
            "Total Loss: 2.2947008532680272e-07\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(2.2891e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.69851863161317e-06\n",
            "E_s_wdiff_all_sq: 5.67128952213179e-08\n",
            "E_IS_SCOPE: -1.0406459704759436e-05\n",
            "E_IS_E_SCOPE: -9.137450141731153e-06\n",
            "Total Loss: 2.2890967676870108e-07\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(2.2835e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7010557006088108e-06\n",
            "E_s_wdiff_all_sq: 5.893392402523617e-08\n",
            "E_IS_SCOPE: -1.0409975838248118e-05\n",
            "E_IS_E_SCOPE: -9.140527125576497e-06\n",
            "Total Loss: 2.2834741767374788e-07\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(2.2778e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7020085298071291e-06\n",
            "E_s_wdiff_all_sq: 6.02912642130195e-08\n",
            "E_IS_SCOPE: -1.0408199075962801e-05\n",
            "E_IS_E_SCOPE: -9.138668603874811e-06\n",
            "Total Loss: 2.2777938785154696e-07\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(2.2723e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.701659749145655e-06\n",
            "E_s_wdiff_all_sq: 6.090723139718416e-08\n",
            "E_IS_SCOPE: -1.0403745362550728e-05\n",
            "E_IS_E_SCOPE: -9.134420515844493e-06\n",
            "Total Loss: 2.2722589076941738e-07\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(2.2666e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700795388892347e-06\n",
            "E_s_wdiff_all_sq: 6.101620390606548e-08\n",
            "E_IS_SCOPE: -1.0400947318483681e-05\n",
            "E_IS_E_SCOPE: -9.131826865352494e-06\n",
            "Total Loss: 2.2666134515732097e-07\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(2.2609e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700873716511624e-06\n",
            "E_s_wdiff_all_sq: 6.167522075369433e-08\n",
            "E_IS_SCOPE: -1.0402518703684154e-05\n",
            "E_IS_E_SCOPE: -9.13340402443894e-06\n",
            "Total Loss: 2.260922037009197e-07\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(2.2553e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7018749746582914e-06\n",
            "E_s_wdiff_all_sq: 6.264836856268655e-08\n",
            "E_IS_SCOPE: -1.040950574467023e-05\n",
            "E_IS_E_SCOPE: -9.140093721868505e-06\n",
            "Total Loss: 2.2552562692556936e-07\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(2.2496e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7022694267960429e-06\n",
            "E_s_wdiff_all_sq: 6.30416565482383e-08\n",
            "E_IS_SCOPE: -1.0415347616012765e-05\n",
            "E_IS_E_SCOPE: -9.14565050009191e-06\n",
            "Total Loss: 2.2495660483951133e-07\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(2.2439e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7013074287000594e-06\n",
            "E_s_wdiff_all_sq: 6.265066625149345e-08\n",
            "E_IS_SCOPE: -1.041671187699621e-05\n",
            "E_IS_E_SCOPE: -9.147014996766318e-06\n",
            "Total Loss: 2.243860684221955e-07\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(2.2382e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6994294308797075e-06\n",
            "E_s_wdiff_all_sq: 6.168922816930543e-08\n",
            "E_IS_SCOPE: -1.0414172975997192e-05\n",
            "E_IS_E_SCOPE: -9.144649020327792e-06\n",
            "Total Loss: 2.23815357805018e-07\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(2.2325e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.698384583052252e-06\n",
            "E_s_wdiff_all_sq: 6.120496692043343e-08\n",
            "E_IS_SCOPE: -1.0409773608868885e-05\n",
            "E_IS_E_SCOPE: -9.140246914816254e-06\n",
            "Total Loss: 2.2324929445997285e-07\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(2.2267e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.698706581263278e-06\n",
            "E_s_wdiff_all_sq: 6.139619114807361e-08\n",
            "E_IS_SCOPE: -1.0410608347198275e-05\n",
            "E_IS_E_SCOPE: -9.140728080671488e-06\n",
            "Total Loss: 2.2267292349504542e-07\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(2.2210e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6996372802864986e-06\n",
            "E_s_wdiff_all_sq: 6.231204021279156e-08\n",
            "E_IS_SCOPE: -1.0414164877965922e-05\n",
            "E_IS_E_SCOPE: -9.1439918637015e-06\n",
            "Total Loss: 2.2210227797827772e-07\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(2.2153e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700150948826653e-06\n",
            "E_s_wdiff_all_sq: 6.337514200244276e-08\n",
            "E_IS_SCOPE: -1.0416964770545659e-05\n",
            "E_IS_E_SCOPE: -9.146780753096974e-06\n",
            "Total Loss: 2.2153083836025473e-07\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(2.2096e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7001853845114823e-06\n",
            "E_s_wdiff_all_sq: 6.40722658488198e-08\n",
            "E_IS_SCOPE: -1.0415142982660786e-05\n",
            "E_IS_E_SCOPE: -9.145002456863424e-06\n",
            "Total Loss: 2.2095513350135527e-07\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(2.2038e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700336935356198e-06\n",
            "E_s_wdiff_all_sq: 6.450455268205415e-08\n",
            "E_IS_SCOPE: -1.0413839856563347e-05\n",
            "E_IS_E_SCOPE: -9.143553208250958e-06\n",
            "Total Loss: 2.2038215248278098e-07\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(2.1980e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.70073000796727e-06\n",
            "E_s_wdiff_all_sq: 6.51601200043887e-08\n",
            "E_IS_SCOPE: -1.0410683402799105e-05\n",
            "E_IS_E_SCOPE: -9.140239063230867e-06\n",
            "Total Loss: 2.1980427525982243e-07\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(2.1923e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7016242297254215e-06\n",
            "E_s_wdiff_all_sq: 6.636783752210958e-08\n",
            "E_IS_SCOPE: -1.04111836054932e-05\n",
            "E_IS_E_SCOPE: -9.140607506436531e-06\n",
            "Total Loss: 2.192272605233931e-07\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(2.1865e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.70209247112664e-06\n",
            "E_s_wdiff_all_sq: 6.750382769594642e-08\n",
            "E_IS_SCOPE: -1.0413373099092052e-05\n",
            "E_IS_E_SCOPE: -9.142843192822936e-06\n",
            "Total Loss: 2.1865189732588006e-07\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(2.1807e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7027760235211135e-06\n",
            "E_s_wdiff_all_sq: 6.864748985716881e-08\n",
            "E_IS_SCOPE: -1.0415065482949937e-05\n",
            "E_IS_E_SCOPE: -9.144473710799512e-06\n",
            "Total Loss: 2.1806805579650863e-07\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(2.1749e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7038463483038857e-06\n",
            "E_s_wdiff_all_sq: 6.979197028130445e-08\n",
            "E_IS_SCOPE: -1.0418568634975906e-05\n",
            "E_IS_E_SCOPE: -9.147726830880647e-06\n",
            "Total Loss: 2.174938362654792e-07\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(2.1691e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7046050242152406e-06\n",
            "E_s_wdiff_all_sq: 7.076870924395614e-08\n",
            "E_IS_SCOPE: -1.0420269067433244e-05\n",
            "E_IS_E_SCOPE: -9.149245575545964e-06\n",
            "Total Loss: 2.1691239763014e-07\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(2.1633e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.704163996941872e-06\n",
            "E_s_wdiff_all_sq: 7.115115355790393e-08\n",
            "E_IS_SCOPE: -1.0419779603439644e-05\n",
            "E_IS_E_SCOPE: -9.148876310733231e-06\n",
            "Total Loss: 2.1632932440455889e-07\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(2.1574e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.703743349986532e-06\n",
            "E_s_wdiff_all_sq: 7.158100394097689e-08\n",
            "E_IS_SCOPE: -1.041949753880683e-05\n",
            "E_IS_E_SCOPE: -9.148724858682339e-06\n",
            "Total Loss: 2.1574005222998985e-07\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(2.1517e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.704881306793064e-06\n",
            "E_s_wdiff_all_sq: 7.29761579605587e-08\n",
            "E_IS_SCOPE: -1.042334750916372e-05\n",
            "E_IS_E_SCOPE: -9.15241677644011e-06\n",
            "Total Loss: 2.1516674981870118e-07\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(2.1457e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.706526462966463e-06\n",
            "E_s_wdiff_all_sq: 7.468658397501789e-08\n",
            "E_IS_SCOPE: -1.0425830804693136e-05\n",
            "E_IS_E_SCOPE: -9.154636642546336e-06\n",
            "Total Loss: 2.1457462113126327e-07\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(2.1398e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7073353526265044e-06\n",
            "E_s_wdiff_all_sq: 7.568064679151796e-08\n",
            "E_IS_SCOPE: -1.0424545452162448e-05\n",
            "E_IS_E_SCOPE: -9.153146914022824e-06\n",
            "Total Loss: 2.1398069598915475e-07\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(2.1339e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7075917525626392e-06\n",
            "E_s_wdiff_all_sq: 7.643839728698429e-08\n",
            "E_IS_SCOPE: -1.0423523362632808e-05\n",
            "E_IS_E_SCOPE: -9.152080233363606e-06\n",
            "Total Loss: 2.1339016317066636e-07\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(2.1280e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7078299536913499e-06\n",
            "E_s_wdiff_all_sq: 7.724555179965625e-08\n",
            "E_IS_SCOPE: -1.0424512142401866e-05\n",
            "E_IS_E_SCOPE: -9.153056235838831e-06\n",
            "Total Loss: 2.1279565519904254e-07\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(2.1220e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7082781032454724e-06\n",
            "E_s_wdiff_all_sq: 7.806736512043233e-08\n",
            "E_IS_SCOPE: -1.0427942903354655e-05\n",
            "E_IS_E_SCOPE: -9.156377872765391e-06\n",
            "Total Loss: 2.1220374337992803e-07\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(2.1160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.708568759826612e-06\n",
            "E_s_wdiff_all_sq: 7.871783454508083e-08\n",
            "E_IS_SCOPE: -1.0433217699207887e-05\n",
            "E_IS_E_SCOPE: -9.161532762380687e-06\n",
            "Total Loss: 2.11604118060549e-07\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(2.1101e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7084688874579642e-06\n",
            "E_s_wdiff_all_sq: 7.909059645483918e-08\n",
            "E_IS_SCOPE: -1.0438542273060671e-05\n",
            "E_IS_E_SCOPE: -9.166796163663358e-06\n",
            "Total Loss: 2.1100913864191442e-07\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(2.1041e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.708303795026502e-06\n",
            "E_s_wdiff_all_sq: 7.926201236738958e-08\n",
            "E_IS_SCOPE: -1.0440453771266503e-05\n",
            "E_IS_E_SCOPE: -9.168577922326337e-06\n",
            "Total Loss: 2.1041315121219585e-07\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(2.0981e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7080340101613432e-06\n",
            "E_s_wdiff_all_sq: 7.923693768346928e-08\n",
            "E_IS_SCOPE: -1.0439586837222441e-05\n",
            "E_IS_E_SCOPE: -9.16753270655807e-06\n",
            "Total Loss: 2.098118775825455e-07\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(2.0923e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7080283953366558e-06\n",
            "E_s_wdiff_all_sq: 7.955349817834871e-08\n",
            "E_IS_SCOPE: -1.0439310461240315e-05\n",
            "E_IS_E_SCOPE: -9.167124172576366e-06\n",
            "Total Loss: 2.092253862638251e-07\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(2.0862e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7079757548128708e-06\n",
            "E_s_wdiff_all_sq: 7.999676288417485e-08\n",
            "E_IS_SCOPE: -1.0436883870383106e-05\n",
            "E_IS_E_SCOPE: -9.164644665974267e-06\n",
            "Total Loss: 2.0862364954443146e-07\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(2.0803e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.708330970077691e-06\n",
            "E_s_wdiff_all_sq: 8.088002561406657e-08\n",
            "E_IS_SCOPE: -1.0433130740160609e-05\n",
            "E_IS_E_SCOPE: -9.160858207723582e-06\n",
            "Total Loss: 2.0802894602298896e-07\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(2.0743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.709019016623315e-06\n",
            "E_s_wdiff_all_sq: 8.207071238494628e-08\n",
            "E_IS_SCOPE: -1.0431320276234265e-05\n",
            "E_IS_E_SCOPE: -9.159000032642425e-06\n",
            "Total Loss: 2.0743088348810276e-07\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(2.0683e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7103031097056667e-06\n",
            "E_s_wdiff_all_sq: 8.380759168718288e-08\n",
            "E_IS_SCOPE: -1.0431156919964509e-05\n",
            "E_IS_E_SCOPE: -9.15876051458732e-06\n",
            "Total Loss: 2.0682577369752173e-07\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(2.0622e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7123492956274973e-06\n",
            "E_s_wdiff_all_sq: 8.606888702136915e-08\n",
            "E_IS_SCOPE: -1.0433878608359117e-05\n",
            "E_IS_E_SCOPE: -9.161289259063609e-06\n",
            "Total Loss: 2.0622477644852845e-07\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(2.0562e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7141243928982958e-06\n",
            "E_s_wdiff_all_sq: 8.800319821687563e-08\n",
            "E_IS_SCOPE: -1.044067593195617e-05\n",
            "E_IS_E_SCOPE: -9.167862827271305e-06\n",
            "Total Loss: 2.0561805174510257e-07\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(2.0501e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.714989118281085e-06\n",
            "E_s_wdiff_all_sq: 8.940586552271192e-08\n",
            "E_IS_SCOPE: -1.04458955906296e-05\n",
            "E_IS_E_SCOPE: -9.173047560859309e-06\n",
            "Total Loss: 2.0501025965120602e-07\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(2.0441e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7150420385287583e-06\n",
            "E_s_wdiff_all_sq: 9.026742676778557e-08\n",
            "E_IS_SCOPE: -1.0447472080533019e-05\n",
            "E_IS_E_SCOPE: -9.174726956670623e-06\n",
            "Total Loss: 2.044074304695993e-07\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(2.0380e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7150233900783379e-06\n",
            "E_s_wdiff_all_sq: 9.076086845161332e-08\n",
            "E_IS_SCOPE: -1.044817350808377e-05\n",
            "E_IS_E_SCOPE: -9.175382120740345e-06\n",
            "Total Loss: 2.0380281337329128e-07\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(2.0319e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.714684134000113e-06\n",
            "E_s_wdiff_all_sq: 9.07823287646796e-08\n",
            "E_IS_SCOPE: -1.044470971861531e-05\n",
            "E_IS_E_SCOPE: -9.17179377110062e-06\n",
            "Total Loss: 2.0319297663946922e-07\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(2.0259e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7142792231291026e-06\n",
            "E_s_wdiff_all_sq: 9.088367823687257e-08\n",
            "E_IS_SCOPE: -1.0439042449084305e-05\n",
            "E_IS_E_SCOPE: -9.166076618949615e-06\n",
            "Total Loss: 2.0258695105626508e-07\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(2.0198e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7143008859048431e-06\n",
            "E_s_wdiff_all_sq: 9.124661605967578e-08\n",
            "E_IS_SCOPE: -1.0437127852287834e-05\n",
            "E_IS_E_SCOPE: -9.164029055795241e-06\n",
            "Total Loss: 2.0197974329339848e-07\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(2.0137e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7149624746731408e-06\n",
            "E_s_wdiff_all_sq: 9.199290324383039e-08\n",
            "E_IS_SCOPE: -1.043745719503757e-05\n",
            "E_IS_E_SCOPE: -9.164098110668817e-06\n",
            "Total Loss: 2.0137446912522212e-07\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(2.0077e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7155454576209854e-06\n",
            "E_s_wdiff_all_sq: 9.274613667832514e-08\n",
            "E_IS_SCOPE: -1.0438348513728235e-05\n",
            "E_IS_E_SCOPE: -9.164771543641058e-06\n",
            "Total Loss: 2.0076844720172417e-07\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(2.0016e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7148375854274172e-06\n",
            "E_s_wdiff_all_sq: 9.244574301399932e-08\n",
            "E_IS_SCOPE: -1.0440679426763994e-05\n",
            "E_IS_E_SCOPE: -9.166999917275983e-06\n",
            "Total Loss: 2.0015588987081168e-07\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(1.9954e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7138531755397577e-06\n",
            "E_s_wdiff_all_sq: 9.214785127596929e-08\n",
            "E_IS_SCOPE: -1.044163319320427e-05\n",
            "E_IS_E_SCOPE: -9.1679899811172e-06\n",
            "Total Loss: 1.9954196652306475e-07\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(1.9893e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.713380769159702e-06\n",
            "E_s_wdiff_all_sq: 9.235520111502931e-08\n",
            "E_IS_SCOPE: -1.0443403545279268e-05\n",
            "E_IS_E_SCOPE: -9.169792338344864e-06\n",
            "Total Loss: 1.989262206092816e-07\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(1.9831e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7133959268449226e-06\n",
            "E_s_wdiff_all_sq: 9.287441100003271e-08\n",
            "E_IS_SCOPE: -1.04463958878327e-05\n",
            "E_IS_E_SCOPE: -9.172729812795862e-06\n",
            "Total Loss: 1.9831243220463044e-07\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(1.9771e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7141422001143662e-06\n",
            "E_s_wdiff_all_sq: 9.37568210317337e-08\n",
            "E_IS_SCOPE: -1.0449494142420649e-05\n",
            "E_IS_E_SCOPE: -9.175595587878242e-06\n",
            "Total Loss: 1.9771133643123513e-07\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(1.9710e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.714938697370858e-06\n",
            "E_s_wdiff_all_sq: 9.484838885739729e-08\n",
            "E_IS_SCOPE: -1.0447289896169832e-05\n",
            "E_IS_E_SCOPE: -9.173233448721395e-06\n",
            "Total Loss: 1.9710048005000065e-07\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(1.9648e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7151310114866889e-06\n",
            "E_s_wdiff_all_sq: 9.591341123458748e-08\n",
            "E_IS_SCOPE: -1.0441534590894248e-05\n",
            "E_IS_E_SCOPE: -9.167603221962683e-06\n",
            "Total Loss: 1.9647792882238765e-07\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(1.9587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.716399036857276e-06\n",
            "E_s_wdiff_all_sq: 9.760001273821185e-08\n",
            "E_IS_SCOPE: -1.0440011478520869e-05\n",
            "E_IS_E_SCOPE: -9.165987537125512e-06\n",
            "Total Loss: 1.9587420776176959e-07\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(1.9526e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7180315134008918e-06\n",
            "E_s_wdiff_all_sq: 9.934578389330224e-08\n",
            "E_IS_SCOPE: -1.0439635198325887e-05\n",
            "E_IS_E_SCOPE: -9.165360814883045e-06\n",
            "Total Loss: 1.9526002905532302e-07\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(1.9466e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.719278945048739e-06\n",
            "E_s_wdiff_all_sq: 1.0073459563086762e-07\n",
            "E_IS_SCOPE: -1.0441331265555423e-05\n",
            "E_IS_E_SCOPE: -9.166825373607993e-06\n",
            "Total Loss: 1.9465563195642943e-07\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(1.9404e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7195051868039151e-06\n",
            "E_s_wdiff_all_sq: 1.0179157921716129e-07\n",
            "E_IS_SCOPE: -1.044177470746082e-05\n",
            "E_IS_E_SCOPE: -9.167375609170886e-06\n",
            "Total Loss: 1.9403847744030355e-07\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(1.9342e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.71971936632737e-06\n",
            "E_s_wdiff_all_sq: 1.0277302578583528e-07\n",
            "E_IS_SCOPE: -1.0441981511066472e-05\n",
            "E_IS_E_SCOPE: -9.167659203949135e-06\n",
            "Total Loss: 1.9342479274027653e-07\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(1.9281e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.720767133913656e-06\n",
            "E_s_wdiff_all_sq: 1.0410892243526958e-07\n",
            "E_IS_SCOPE: -1.0444581593266387e-05\n",
            "E_IS_E_SCOPE: -9.17009570714204e-06\n",
            "Total Loss: 1.9280950566310651e-07\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "Var loss:  tensor(1.9221e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7223746467932628e-06\n",
            "E_s_wdiff_all_sq: 1.0588183463741387e-07\n",
            "E_IS_SCOPE: -1.0449157086870558e-05\n",
            "E_IS_E_SCOPE: -9.17445396007162e-06\n",
            "Total Loss: 1.922096249913897e-07\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "Var loss:  tensor(1.9160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7226960672892019e-06\n",
            "E_s_wdiff_all_sq: 1.0692704899490493e-07\n",
            "E_IS_SCOPE: -1.0447822006216919e-05\n",
            "E_IS_E_SCOPE: -9.173175711528422e-06\n",
            "Total Loss: 1.9159949535071872e-07\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "Var loss:  tensor(1.9096e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7224130672504917e-06\n",
            "E_s_wdiff_all_sq: 1.0720692662475948e-07\n",
            "E_IS_SCOPE: -1.0443916558488135e-05\n",
            "E_IS_E_SCOPE: -9.169232855815979e-06\n",
            "Total Loss: 1.9096180171483554e-07\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "Var loss:  tensor(1.9034e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7227344015824336e-06\n",
            "E_s_wdiff_all_sq: 1.0772253661179434e-07\n",
            "E_IS_SCOPE: -1.0442362299428787e-05\n",
            "E_IS_E_SCOPE: -9.167463164315124e-06\n",
            "Total Loss: 1.9033666117672883e-07\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "Var loss:  tensor(1.8972e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7233639369202324e-06\n",
            "E_s_wdiff_all_sq: 1.0842819253161865e-07\n",
            "E_IS_SCOPE: -1.0443262325054855e-05\n",
            "E_IS_E_SCOPE: -9.168090832328354e-06\n",
            "Total Loss: 1.8971582536903026e-07\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "Var loss:  tensor(1.8908e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7230384519659143e-06\n",
            "E_s_wdiff_all_sq: 1.0866143855188347e-07\n",
            "E_IS_SCOPE: -1.0445539829426368e-05\n",
            "E_IS_E_SCOPE: -9.170327335717571e-06\n",
            "Total Loss: 1.89075092429853e-07\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "Var loss:  tensor(1.8844e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7226990171295225e-06\n",
            "E_s_wdiff_all_sq: 1.0887440998449516e-07\n",
            "E_IS_SCOPE: -1.0449000422631478e-05\n",
            "E_IS_E_SCOPE: -9.17374429138492e-06\n",
            "Total Loss: 1.8843541108532622e-07\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "Var loss:  tensor(1.8780e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7230148480187744e-06\n",
            "E_s_wdiff_all_sq: 1.0957287832379168e-07\n",
            "E_IS_SCOPE: -1.0453193396838864e-05\n",
            "E_IS_E_SCOPE: -9.17781049109356e-06\n",
            "Total Loss: 1.8779922463779116e-07\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "Var loss:  tensor(1.8716e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7230192625681622e-06\n",
            "E_s_wdiff_all_sq: 1.1020617955513921e-07\n",
            "E_IS_SCOPE: -1.045542505775823e-05\n",
            "E_IS_E_SCOPE: -9.180037327734094e-06\n",
            "Total Loss: 1.8716068939816883e-07\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "Var loss:  tensor(1.8652e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.723418170197592e-06\n",
            "E_s_wdiff_all_sq: 1.1132096869441049e-07\n",
            "E_IS_SCOPE: -1.0457086456780676e-05\n",
            "E_IS_E_SCOPE: -9.181735373253577e-06\n",
            "Total Loss: 1.8651810088239956e-07\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "Var loss:  tensor(1.8587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.725134996679335e-06\n",
            "E_s_wdiff_all_sq: 1.1327215750803653e-07\n",
            "E_IS_SCOPE: -1.0457613485451725e-05\n",
            "E_IS_E_SCOPE: -9.182056556914457e-06\n",
            "Total Loss: 1.858720485301789e-07\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "Var loss:  tensor(1.8523e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7263861565252912e-06\n",
            "E_s_wdiff_all_sq: 1.1457308750735867e-07\n",
            "E_IS_SCOPE: -1.0454635683127434e-05\n",
            "E_IS_E_SCOPE: -9.178781067782621e-06\n",
            "Total Loss: 1.8522690476172425e-07\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "Var loss:  tensor(1.8460e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7262274636466883e-06\n",
            "E_s_wdiff_all_sq: 1.1474472310223615e-07\n",
            "E_IS_SCOPE: -1.0448940117619234e-05\n",
            "E_IS_E_SCOPE: -9.172935124474828e-06\n",
            "Total Loss: 1.845958206890553e-07\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "Var loss:  tensor(1.8396e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7252281279163673e-06\n",
            "E_s_wdiff_all_sq: 1.146281708498043e-07\n",
            "E_IS_SCOPE: -1.0442044173968287e-05\n",
            "E_IS_E_SCOPE: -9.166160327899965e-06\n",
            "Total Loss: 1.8395533136333594e-07\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "Var loss:  tensor(1.8331e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7245681465705244e-06\n",
            "E_s_wdiff_all_sq: 1.1478215948688134e-07\n",
            "E_IS_SCOPE: -1.0436700538330691e-05\n",
            "E_IS_E_SCOPE: -9.160903498556177e-06\n",
            "Total Loss: 1.833149739680298e-07\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "Var loss:  tensor(1.8267e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.726202836007298e-06\n",
            "E_s_wdiff_all_sq: 1.1636894732942425e-07\n",
            "E_IS_SCOPE: -1.0437970769880636e-05\n",
            "E_IS_E_SCOPE: -9.161827114107383e-06\n",
            "Total Loss: 1.826696435647838e-07\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "Var loss:  tensor(1.8202e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7281986799814096e-06\n",
            "E_s_wdiff_all_sq: 1.1822123678621458e-07\n",
            "E_IS_SCOPE: -1.044332322256738e-05\n",
            "E_IS_E_SCOPE: -9.166784863441305e-06\n",
            "Total Loss: 1.820237913764627e-07\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "Var loss:  tensor(1.8137e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7286511002036993e-06\n",
            "E_s_wdiff_all_sq: 1.1928660492142464e-07\n",
            "E_IS_SCOPE: -1.0447630709563186e-05\n",
            "E_IS_E_SCOPE: -9.171071307005e-06\n",
            "Total Loss: 1.8136875659931734e-07\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "Var loss:  tensor(1.8072e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7281667532991113e-06\n",
            "E_s_wdiff_all_sq: 1.199473123109744e-07\n",
            "E_IS_SCOPE: -1.0448892381943267e-05\n",
            "E_IS_E_SCOPE: -9.17257926313901e-06\n",
            "Total Loss: 1.8071626981303944e-07\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "Var loss:  tensor(1.8008e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7288458342981847e-06\n",
            "E_s_wdiff_all_sq: 1.2131666079459246e-07\n",
            "E_IS_SCOPE: -1.0449804815504884e-05\n",
            "E_IS_E_SCOPE: -9.17352014580186e-06\n",
            "Total Loss: 1.8008290053096103e-07\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "Var loss:  tensor(1.7944e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.73012698474879e-06\n",
            "E_s_wdiff_all_sq: 1.2276587322528217e-07\n",
            "E_IS_SCOPE: -1.0448439266615675e-05\n",
            "E_IS_E_SCOPE: -9.171915224447814e-06\n",
            "Total Loss: 1.7943609362120188e-07\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "Var loss:  tensor(1.7879e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7314723255312158e-06\n",
            "E_s_wdiff_all_sq: 1.2441889666259154e-07\n",
            "E_IS_SCOPE: -1.044588618773662e-05\n",
            "E_IS_E_SCOPE: -9.169192811441629e-06\n",
            "Total Loss: 1.787897427120558e-07\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "Var loss:  tensor(1.7815e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7314718123529534e-06\n",
            "E_s_wdiff_all_sq: 1.2497368843671597e-07\n",
            "E_IS_SCOPE: -1.044355001031678e-05\n",
            "E_IS_E_SCOPE: -9.166812085278547e-06\n",
            "Total Loss: 1.781453402731871e-07\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "Var loss:  tensor(1.7750e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7313581090285558e-06\n",
            "E_s_wdiff_all_sq: 1.255611359360994e-07\n",
            "E_IS_SCOPE: -1.0441436487574397e-05\n",
            "E_IS_E_SCOPE: -9.164728213518812e-06\n",
            "Total Loss: 1.7750349141470122e-07\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "Var loss:  tensor(1.7686e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.732254380250222e-06\n",
            "E_s_wdiff_all_sq: 1.2673335891493593e-07\n",
            "E_IS_SCOPE: -1.044224526833879e-05\n",
            "E_IS_E_SCOPE: -9.165354040357223e-06\n",
            "Total Loss: 1.768616318055687e-07\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "Var loss:  tensor(1.7622e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7334322496411794e-06\n",
            "E_s_wdiff_all_sq: 1.2801544705381397e-07\n",
            "E_IS_SCOPE: -1.0445846846929028e-05\n",
            "E_IS_E_SCOPE: -9.168684814141537e-06\n",
            "Total Loss: 1.762158034457966e-07\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "Var loss:  tensor(1.7557e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7342935530482898e-06\n",
            "E_s_wdiff_all_sq: 1.2933596106128676e-07\n",
            "E_IS_SCOPE: -1.0450796369171591e-05\n",
            "E_IS_E_SCOPE: -9.173539167685017e-06\n",
            "Total Loss: 1.7556625544726995e-07\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "Var loss:  tensor(1.7492e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7348823894473463e-06\n",
            "E_s_wdiff_all_sq: 1.3057577563522624e-07\n",
            "E_IS_SCOPE: -1.0455836529418268e-05\n",
            "E_IS_E_SCOPE: -9.178582595232803e-06\n",
            "Total Loss: 1.7492181187460597e-07\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "Var loss:  tensor(1.7427e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7348368761451904e-06\n",
            "E_s_wdiff_all_sq: 1.3107353068898027e-07\n",
            "E_IS_SCOPE: -1.0458450486876691e-05\n",
            "E_IS_E_SCOPE: -9.18114251407371e-06\n",
            "Total Loss: 1.7427046628366533e-07\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "Var loss:  tensor(1.7362e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7347099235538289e-06\n",
            "E_s_wdiff_all_sq: 1.312764416852881e-07\n",
            "E_IS_SCOPE: -1.0459172140731963e-05\n",
            "E_IS_E_SCOPE: -9.181704466914928e-06\n",
            "Total Loss: 1.7362120066788649e-07\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "Var loss:  tensor(1.7298e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.734987009221059e-06\n",
            "E_s_wdiff_all_sq: 1.3200271406801536e-07\n",
            "E_IS_SCOPE: -1.0456045981331547e-05\n",
            "E_IS_E_SCOPE: -9.178481639155905e-06\n",
            "Total Loss: 1.7297867723517795e-07\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "Var loss:  tensor(1.7234e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7356993957767622e-06\n",
            "E_s_wdiff_all_sq: 1.3337644820277146e-07\n",
            "E_IS_SCOPE: -1.0453085206119747e-05\n",
            "E_IS_E_SCOPE: -9.175533701182518e-06\n",
            "Total Loss: 1.7234300413294596e-07\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "Var loss:  tensor(1.7169e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.736584547819053e-06\n",
            "E_s_wdiff_all_sq: 1.3474950551539924e-07\n",
            "E_IS_SCOPE: -1.045132080476293e-05\n",
            "E_IS_E_SCOPE: -9.173687022459105e-06\n",
            "Total Loss: 1.7169054412941905e-07\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "Var loss:  tensor(1.7105e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7378456335274344e-06\n",
            "E_s_wdiff_all_sq: 1.3635409772614254e-07\n",
            "E_IS_SCOPE: -1.0451318561646616e-05\n",
            "E_IS_E_SCOPE: -9.173538168921441e-06\n",
            "Total Loss: 1.7105381678435864e-07\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "Var loss:  tensor(1.7042e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7389556440313436e-06\n",
            "E_s_wdiff_all_sq: 1.377811526933446e-07\n",
            "E_IS_SCOPE: -1.0451330095824766e-05\n",
            "E_IS_E_SCOPE: -9.17338915795263e-06\n",
            "Total Loss: 1.704156820271425e-07\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "Var loss:  tensor(1.6977e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7392665028421308e-06\n",
            "E_s_wdiff_all_sq: 1.386087277063833e-07\n",
            "E_IS_SCOPE: -1.0452244048437906e-05\n",
            "E_IS_E_SCOPE: -9.174239774450834e-06\n",
            "Total Loss: 1.697722935950181e-07\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "Var loss:  tensor(1.6912e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7385596932136388e-06\n",
            "E_s_wdiff_all_sq: 1.3858609099367413e-07\n",
            "E_IS_SCOPE: -1.0453109069422676e-05\n",
            "E_IS_E_SCOPE: -9.175123224702976e-06\n",
            "Total Loss: 1.691249792139804e-07\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "Var loss:  tensor(1.6848e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7385066676488703e-06\n",
            "E_s_wdiff_all_sq: 1.389511094917098e-07\n",
            "E_IS_SCOPE: -1.0455118799583097e-05\n",
            "E_IS_E_SCOPE: -9.177019978671165e-06\n",
            "Total Loss: 1.6848098276671291e-07\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "Var loss:  tensor(1.6783e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7393821108027646e-06\n",
            "E_s_wdiff_all_sq: 1.3989979736613458e-07\n",
            "E_IS_SCOPE: -1.0459703977310559e-05\n",
            "E_IS_E_SCOPE: -9.181315995543567e-06\n",
            "Total Loss: 1.6782941633605957e-07\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "Var loss:  tensor(1.6718e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.740273654646725e-06\n",
            "E_s_wdiff_all_sq: 1.410474862471362e-07\n",
            "E_IS_SCOPE: -1.0459643617122113e-05\n",
            "E_IS_E_SCOPE: -9.181060657244333e-06\n",
            "Total Loss: 1.6718331507744353e-07\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "Var loss:  tensor(1.6655e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7411817674774657e-06\n",
            "E_s_wdiff_all_sq: 1.424647795281127e-07\n",
            "E_IS_SCOPE: -1.0459903344764308e-05\n",
            "E_IS_E_SCOPE: -9.181257151825665e-06\n",
            "Total Loss: 1.6654766850548166e-07\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "Var loss:  tensor(1.6590e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7417042984427773e-06\n",
            "E_s_wdiff_all_sq: 1.4386432174723282e-07\n",
            "E_IS_SCOPE: -1.0456258586706909e-05\n",
            "E_IS_E_SCOPE: -9.177729233962356e-06\n",
            "Total Loss: 1.659043376398569e-07\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "Var loss:  tensor(1.6527e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7434479808515223e-06\n",
            "E_s_wdiff_all_sq: 1.4597025657158138e-07\n",
            "E_IS_SCOPE: -1.0454784482197305e-05\n",
            "E_IS_E_SCOPE: -9.176117668950777e-06\n",
            "Total Loss: 1.6526716422030155e-07\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "Var loss:  tensor(1.6463e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7454947317432827e-06\n",
            "E_s_wdiff_all_sq: 1.4812983423275126e-07\n",
            "E_IS_SCOPE: -1.0454754252648039e-05\n",
            "E_IS_E_SCOPE: -9.175824730557847e-06\n",
            "Total Loss: 1.6462891976356403e-07\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "Var loss:  tensor(1.6398e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7473079231103659e-06\n",
            "E_s_wdiff_all_sq: 1.500898268054322e-07\n",
            "E_IS_SCOPE: -1.045644023072339e-05\n",
            "E_IS_E_SCOPE: -9.17725833563972e-06\n",
            "Total Loss: 1.639773725710098e-07\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "Var loss:  tensor(1.6333e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7471696707860037e-06\n",
            "E_s_wdiff_all_sq: 1.5075674336481026e-07\n",
            "E_IS_SCOPE: -1.0455776458203247e-05\n",
            "E_IS_E_SCOPE: -9.176675251591441e-06\n",
            "Total Loss: 1.6333358063099792e-07\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "Var loss:  tensor(1.6270e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.745256333981652e-06\n",
            "E_s_wdiff_all_sq: 1.4978696654863541e-07\n",
            "E_IS_SCOPE: -1.0454565870824841e-05\n",
            "E_IS_E_SCOPE: -9.17561748314054e-06\n",
            "Total Loss: 1.6269565849782852e-07\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "Var loss:  tensor(1.6205e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7437798831952323e-06\n",
            "E_s_wdiff_all_sq: 1.487689221174582e-07\n",
            "E_IS_SCOPE: -1.0454678057638115e-05\n",
            "E_IS_E_SCOPE: -9.175637973142926e-06\n",
            "Total Loss: 1.6205385852081215e-07\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "Var loss:  tensor(1.6142e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7442396759684765e-06\n",
            "E_s_wdiff_all_sq: 1.4941162801690616e-07\n",
            "E_IS_SCOPE: -1.0458061000412243e-05\n",
            "E_IS_E_SCOPE: -9.178794473640043e-06\n",
            "Total Loss: 1.6141806084058316e-07\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "Var loss:  tensor(1.6078e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7456679839955844e-06\n",
            "E_s_wdiff_all_sq: 1.5123773315250453e-07\n",
            "E_IS_SCOPE: -1.0459716808749948e-05\n",
            "E_IS_E_SCOPE: -9.180328428986796e-06\n",
            "Total Loss: 1.6077655775019172e-07\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "Var loss:  tensor(1.6014e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7468399993177723e-06\n",
            "E_s_wdiff_all_sq: 1.530051479814524e-07\n",
            "E_IS_SCOPE: -1.045734105343696e-05\n",
            "E_IS_E_SCOPE: -9.17793062692639e-06\n",
            "Total Loss: 1.601370647485958e-07\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "Var loss:  tensor(1.5949e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7484830711520996e-06\n",
            "E_s_wdiff_all_sq: 1.54786100023696e-07\n",
            "E_IS_SCOPE: -1.0458052182294134e-05\n",
            "E_IS_E_SCOPE: -9.178388101406893e-06\n",
            "Total Loss: 1.59491875787338e-07\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "Var loss:  tensor(1.5885e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7507326501469544e-06\n",
            "E_s_wdiff_all_sq: 1.5700627626755758e-07\n",
            "E_IS_SCOPE: -1.045989639186633e-05\n",
            "E_IS_E_SCOPE: -9.179898414596901e-06\n",
            "Total Loss: 1.5885348577395397e-07\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "Var loss:  tensor(1.5821e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.751565671510783e-06\n",
            "E_s_wdiff_all_sq: 1.584821597114168e-07\n",
            "E_IS_SCOPE: -1.0460484734337986e-05\n",
            "E_IS_E_SCOPE: -9.18048751262316e-06\n",
            "Total Loss: 1.582121348031317e-07\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "Var loss:  tensor(1.5757e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7516173472166448e-06\n",
            "E_s_wdiff_all_sq: 1.594104393135381e-07\n",
            "E_IS_SCOPE: -1.0460008210153274e-05\n",
            "E_IS_E_SCOPE: -9.180126192850398e-06\n",
            "Total Loss: 1.5756593973077322e-07\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "Var loss:  tensor(1.5692e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.752702207286652e-06\n",
            "E_s_wdiff_all_sq: 1.6078765936794585e-07\n",
            "E_IS_SCOPE: -1.0461080246618529e-05\n",
            "E_IS_E_SCOPE: -9.181023103050093e-06\n",
            "Total Loss: 1.5692332721524754e-07\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "Var loss:  tensor(1.5628e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7523995269052183e-06\n",
            "E_s_wdiff_all_sq: 1.6078051001768047e-07\n",
            "E_IS_SCOPE: -1.046048271620256e-05\n",
            "E_IS_E_SCOPE: -9.180252251235532e-06\n",
            "Total Loss: 1.562811533868966e-07\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "Var loss:  tensor(1.5564e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7509988101800129e-06\n",
            "E_s_wdiff_all_sq: 1.5956252102996786e-07\n",
            "E_IS_SCOPE: -1.0460839370505924e-05\n",
            "E_IS_E_SCOPE: -9.180380992616438e-06\n",
            "Total Loss: 1.5564259980448994e-07\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "Var loss:  tensor(1.5500e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.748630436049306e-06\n",
            "E_s_wdiff_all_sq: 1.5795472743779332e-07\n",
            "E_IS_SCOPE: -1.0460836271398226e-05\n",
            "E_IS_E_SCOPE: -9.180436086459448e-06\n",
            "Total Loss: 1.549984051673694e-07\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "Var loss:  tensor(1.5436e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.747823058915892e-06\n",
            "E_s_wdiff_all_sq: 1.578094731979114e-07\n",
            "E_IS_SCOPE: -1.0457820966329391e-05\n",
            "E_IS_E_SCOPE: -9.177433532822301e-06\n",
            "Total Loss: 1.5436178513721452e-07\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "Var loss:  tensor(1.5372e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7495722502941363e-06\n",
            "E_s_wdiff_all_sq: 1.5949434645601895e-07\n",
            "E_IS_SCOPE: -1.0458696722046427e-05\n",
            "E_IS_E_SCOPE: -9.177957132727783e-06\n",
            "Total Loss: 1.5372179163424397e-07\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "Var loss:  tensor(1.5308e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7518526970942281e-06\n",
            "E_s_wdiff_all_sq: 1.621680460030213e-07\n",
            "E_IS_SCOPE: -1.0460095358712852e-05\n",
            "E_IS_E_SCOPE: -9.17923165663916e-06\n",
            "Total Loss: 1.5308031337723694e-07\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "Var loss:  tensor(1.5244e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.75447432477904e-06\n",
            "E_s_wdiff_all_sq: 1.6536910705884774e-07\n",
            "E_IS_SCOPE: -1.046280501500442e-05\n",
            "E_IS_E_SCOPE: -9.181913262289017e-06\n",
            "Total Loss: 1.524447787228019e-07\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "Var loss:  tensor(1.5180e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7567182860073056e-06\n",
            "E_s_wdiff_all_sq: 1.6840025226733468e-07\n",
            "E_IS_SCOPE: -1.0461486258712005e-05\n",
            "E_IS_E_SCOPE: -9.180666878423921e-06\n",
            "Total Loss: 1.5180233959721798e-07\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "Var loss:  tensor(1.5116e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7591926759199087e-06\n",
            "E_s_wdiff_all_sq: 1.7128499260436842e-07\n",
            "E_IS_SCOPE: -1.0460876800915892e-05\n",
            "E_IS_E_SCOPE: -9.179939976177304e-06\n",
            "Total Loss: 1.511571002717782e-07\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "Var loss:  tensor(1.5053e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7612708060504384e-06\n",
            "E_s_wdiff_all_sq: 1.735193010791507e-07\n",
            "E_IS_SCOPE: -1.0460753271206583e-05\n",
            "E_IS_E_SCOPE: -9.179580263859504e-06\n",
            "Total Loss: 1.5052855671054326e-07\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "Var loss:  tensor(1.4989e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7612159817841874e-06\n",
            "E_s_wdiff_all_sq: 1.7398767486133782e-07\n",
            "E_IS_SCOPE: -1.046046556140337e-05\n",
            "E_IS_E_SCOPE: -9.179232549581669e-06\n",
            "Total Loss: 1.4988534971286493e-07\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "Var loss:  tensor(1.4924e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7597609463033071e-06\n",
            "E_s_wdiff_all_sq: 1.732982009341844e-07\n",
            "E_IS_SCOPE: -1.0460757960355661e-05\n",
            "E_IS_E_SCOPE: -9.179586688669593e-06\n",
            "Total Loss: 1.4924326843040171e-07\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "Var loss:  tensor(1.4860e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7593921587130802e-06\n",
            "E_s_wdiff_all_sq: 1.7322126226950647e-07\n",
            "E_IS_SCOPE: -1.046192579287724e-05\n",
            "E_IS_E_SCOPE: -9.180578689378714e-06\n",
            "Total Loss: 1.4859975587993454e-07\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "Var loss:  tensor(1.4795e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7599302888829527e-06\n",
            "E_s_wdiff_all_sq: 1.7357964344731667e-07\n",
            "E_IS_SCOPE: -1.046460037451883e-05\n",
            "E_IS_E_SCOPE: -9.182839976327962e-06\n",
            "Total Loss: 1.4795291548731723e-07\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "Var loss:  tensor(1.4731e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7600955930526417e-06\n",
            "E_s_wdiff_all_sq: 1.7394179096784093e-07\n",
            "E_IS_SCOPE: -1.0464514090801401e-05\n",
            "E_IS_E_SCOPE: -9.182530029627216e-06\n",
            "Total Loss: 1.4730874616984876e-07\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "Var loss:  tensor(1.4666e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7600552270100056e-06\n",
            "E_s_wdiff_all_sq: 1.7448501591811216e-07\n",
            "E_IS_SCOPE: -1.0463452047713957e-05\n",
            "E_IS_E_SCOPE: -9.181437868345602e-06\n",
            "Total Loss: 1.466649187885999e-07\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "Var loss:  tensor(1.4602e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7599482329442396e-06\n",
            "E_s_wdiff_all_sq: 1.7489761560690423e-07\n",
            "E_IS_SCOPE: -1.0463911700489385e-05\n",
            "E_IS_E_SCOPE: -9.181832929029563e-06\n",
            "Total Loss: 1.460161408511103e-07\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "Var loss:  tensor(1.4537e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7597081048368775e-06\n",
            "E_s_wdiff_all_sq: 1.7546909543590988e-07\n",
            "E_IS_SCOPE: -1.0462726451589788e-05\n",
            "E_IS_E_SCOPE: -9.180730911284939e-06\n",
            "Total Loss: 1.4537099522468424e-07\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "Var loss:  tensor(1.4473e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.760441119439797e-06\n",
            "E_s_wdiff_all_sq: 1.7682921079583578e-07\n",
            "E_IS_SCOPE: -1.046238172181875e-05\n",
            "E_IS_E_SCOPE: -9.180380576380438e-06\n",
            "Total Loss: 1.4473268420075234e-07\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "Var loss:  tensor(1.4408e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7624567909047894e-06\n",
            "E_s_wdiff_all_sq: 1.789674116711514e-07\n",
            "E_IS_SCOPE: -1.0459599646463285e-05\n",
            "E_IS_E_SCOPE: -9.177331624509329e-06\n",
            "Total Loss: 1.4407640175914274e-07\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "Var loss:  tensor(1.4343e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7633982811940541e-06\n",
            "E_s_wdiff_all_sq: 1.8002966405584798e-07\n",
            "E_IS_SCOPE: -1.045430413598943e-05\n",
            "E_IS_E_SCOPE: -9.171771191314112e-06\n",
            "Total Loss: 1.4342579422098563e-07\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "Var loss:  tensor(1.4278e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7640436953847062e-06\n",
            "E_s_wdiff_all_sq: 1.8098976762098602e-07\n",
            "E_IS_SCOPE: -1.045028098644712e-05\n",
            "E_IS_E_SCOPE: -9.167584760592755e-06\n",
            "Total Loss: 1.4278454248840528e-07\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "Var loss:  tensor(1.4214e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7634472847825978e-06\n",
            "E_s_wdiff_all_sq: 1.8131989982456647e-07\n",
            "E_IS_SCOPE: -1.0445941598797853e-05\n",
            "E_IS_E_SCOPE: -9.163384501255257e-06\n",
            "Total Loss: 1.4213625630625622e-07\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "Var loss:  tensor(1.4149e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.764415700787053e-06\n",
            "E_s_wdiff_all_sq: 1.8280952148201338e-07\n",
            "E_IS_SCOPE: -1.0443944949440603e-05\n",
            "E_IS_E_SCOPE: -9.16132344407908e-06\n",
            "Total Loss: 1.4148623501540997e-07\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "Var loss:  tensor(1.4083e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7671742281428323e-06\n",
            "E_s_wdiff_all_sq: 1.8564507388594667e-07\n",
            "E_IS_SCOPE: -1.0445721299336475e-05\n",
            "E_IS_E_SCOPE: -9.16280967134644e-06\n",
            "Total Loss: 1.4082896471023093e-07\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "Var loss:  tensor(1.4018e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.769720434306535e-06\n",
            "E_s_wdiff_all_sq: 1.8841869647411404e-07\n",
            "E_IS_SCOPE: -1.0449456372247518e-05\n",
            "E_IS_E_SCOPE: -9.166334744924064e-06\n",
            "Total Loss: 1.401815496189308e-07\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "Var loss:  tensor(1.3952e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7698575739975834e-06\n",
            "E_s_wdiff_all_sq: 1.89644373950154e-07\n",
            "E_IS_SCOPE: -1.0448901594213123e-05\n",
            "E_IS_E_SCOPE: -9.165991806060456e-06\n",
            "Total Loss: 1.395166901755122e-07\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "Var loss:  tensor(1.3886e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7695085445879618e-06\n",
            "E_s_wdiff_all_sq: 1.9023336487219613e-07\n",
            "E_IS_SCOPE: -1.044690595751027e-05\n",
            "E_IS_E_SCOPE: -9.164135335141611e-06\n",
            "Total Loss: 1.388570014118631e-07\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "Var loss:  tensor(1.3820e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7701907405958831e-06\n",
            "E_s_wdiff_all_sq: 1.9062438202763115e-07\n",
            "E_IS_SCOPE: -1.0449437209335548e-05\n",
            "E_IS_E_SCOPE: -9.166191412145714e-06\n",
            "Total Loss: 1.3819783062200228e-07\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "Var loss:  tensor(1.3754e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.769137553642356e-06\n",
            "E_s_wdiff_all_sq: 1.8973285243082855e-07\n",
            "E_IS_SCOPE: -1.0450713624069527e-05\n",
            "E_IS_E_SCOPE: -9.16722071488748e-06\n",
            "Total Loss: 1.3754194928085e-07\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "Var loss:  tensor(1.3689e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7666987737461143e-06\n",
            "E_s_wdiff_all_sq: 1.8836787820051664e-07\n",
            "E_IS_SCOPE: -1.0449605819564161e-05\n",
            "E_IS_E_SCOPE: -9.166321918644114e-06\n",
            "Total Loss: 1.3688616013891785e-07\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "Var loss:  tensor(1.3622e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7656016011496945e-06\n",
            "E_s_wdiff_all_sq: 1.8807953362166853e-07\n",
            "E_IS_SCOPE: -1.0443620799949787e-05\n",
            "E_IS_E_SCOPE: -9.160409831614131e-06\n",
            "Total Loss: 1.3622319729013106e-07\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "Var loss:  tensor(1.3556e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7680662107946642e-06\n",
            "E_s_wdiff_all_sq: 1.9001257585059638e-07\n",
            "E_IS_SCOPE: -1.0440787953824423e-05\n",
            "E_IS_E_SCOPE: -9.156981943277473e-06\n",
            "Total Loss: 1.355646802835842e-07\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "Var loss:  tensor(1.3490e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.770323516887919e-06\n",
            "E_s_wdiff_all_sq: 1.9224045769489836e-07\n",
            "E_IS_SCOPE: -1.043931798237091e-05\n",
            "E_IS_E_SCOPE: -9.155166123176814e-06\n",
            "Total Loss: 1.3490240723824424e-07\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "Var loss:  tensor(1.3424e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7708356349537273e-06\n",
            "E_s_wdiff_all_sq: 1.940186427273107e-07\n",
            "E_IS_SCOPE: -1.0435779307134885e-05\n",
            "E_IS_E_SCOPE: -9.151931646308486e-06\n",
            "Total Loss: 1.3424473700703312e-07\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "Var loss:  tensor(1.3359e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.77196356560798e-06\n",
            "E_s_wdiff_all_sq: 1.9612187149287854e-07\n",
            "E_IS_SCOPE: -1.0430617236285214e-05\n",
            "E_IS_E_SCOPE: -9.146929711222686e-06\n",
            "Total Loss: 1.335897104234637e-07\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "Var loss:  tensor(1.3293e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.77548909727145e-06\n",
            "E_s_wdiff_all_sq: 1.995698041428827e-07\n",
            "E_IS_SCOPE: -1.0429004590830635e-05\n",
            "E_IS_E_SCOPE: -9.144947696388625e-06\n",
            "Total Loss: 1.329285706779634e-07\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "Var loss:  tensor(1.3227e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7785523855361568e-06\n",
            "E_s_wdiff_all_sq: 2.0269590318062503e-07\n",
            "E_IS_SCOPE: -1.042805965285692e-05\n",
            "E_IS_E_SCOPE: -9.14370388279196e-06\n",
            "Total Loss: 1.3226800865902796e-07\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "Var loss:  tensor(1.3162e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7796341427694831e-06\n",
            "E_s_wdiff_all_sq: 2.046307716417365e-07\n",
            "E_IS_SCOPE: -1.0425262641072191e-05\n",
            "E_IS_E_SCOPE: -9.141009510331204e-06\n",
            "Total Loss: 1.3162017607918817e-07\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "Var loss:  tensor(1.3096e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7789890088167458e-06\n",
            "E_s_wdiff_all_sq: 2.049856178529891e-07\n",
            "E_IS_SCOPE: -1.0421360817532884e-05\n",
            "E_IS_E_SCOPE: -9.13727903172707e-06\n",
            "Total Loss: 1.309628857855432e-07\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "Var loss:  tensor(1.3029e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7781198842584413e-06\n",
            "E_s_wdiff_all_sq: 2.0438164743723147e-07\n",
            "E_IS_SCOPE: -1.0419984664052013e-05\n",
            "E_IS_E_SCOPE: -9.13570107677164e-06\n",
            "Total Loss: 1.3029412869388135e-07\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "Var loss:  tensor(1.2964e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.777361957653897e-06\n",
            "E_s_wdiff_all_sq: 2.0380817626837826e-07\n",
            "E_IS_SCOPE: -1.0417414752588068e-05\n",
            "E_IS_E_SCOPE: -9.132895603981939e-06\n",
            "Total Loss: 1.2963855060667575e-07\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "Var loss:  tensor(1.2899e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7763105401164026e-06\n",
            "E_s_wdiff_all_sq: 2.0341013893713345e-07\n",
            "E_IS_SCOPE: -1.0416539458764655e-05\n",
            "E_IS_E_SCOPE: -9.132020244212534e-06\n",
            "Total Loss: 1.2898503850844248e-07\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "Var loss:  tensor(1.2832e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7751777161232545e-06\n",
            "E_s_wdiff_all_sq: 2.029930363698069e-07\n",
            "E_IS_SCOPE: -1.0415670960538858e-05\n",
            "E_IS_E_SCOPE: -9.131178060387017e-06\n",
            "Total Loss: 1.2832194588318155e-07\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "Var loss:  tensor(1.2766e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7763876577993641e-06\n",
            "E_s_wdiff_all_sq: 2.0411471294798634e-07\n",
            "E_IS_SCOPE: -1.0417525046655218e-05\n",
            "E_IS_E_SCOPE: -9.1326588564687e-06\n",
            "Total Loss: 1.2766363091175617e-07\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "Var loss:  tensor(1.2702e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7789918351959847e-06\n",
            "E_s_wdiff_all_sq: 2.0646381043275854e-07\n",
            "E_IS_SCOPE: -1.0420175725332962e-05\n",
            "E_IS_E_SCOPE: -9.13486013848053e-06\n",
            "Total Loss: 1.2701991749178068e-07\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "Var loss:  tensor(1.2635e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7796083787126626e-06\n",
            "E_s_wdiff_all_sq: 2.0810291646705268e-07\n",
            "E_IS_SCOPE: -1.041348378287602e-05\n",
            "E_IS_E_SCOPE: -9.12834679623124e-06\n",
            "Total Loss: 1.2635455538946315e-07\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "Var loss:  tensor(1.2569e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7799369660920976e-06\n",
            "E_s_wdiff_all_sq: 2.0953812730450945e-07\n",
            "E_IS_SCOPE: -1.0407141406025578e-05\n",
            "E_IS_E_SCOPE: -9.122224712898652e-06\n",
            "Total Loss: 1.2568851896715273e-07\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "Var loss:  tensor(1.2504e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7834675224954335e-06\n",
            "E_s_wdiff_all_sq: 2.130356633332161e-07\n",
            "E_IS_SCOPE: -1.040680094322707e-05\n",
            "E_IS_E_SCOPE: -9.121544642465962e-06\n",
            "Total Loss: 1.250423240734157e-07\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "Var loss:  tensor(1.2440e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7866853823331606e-06\n",
            "E_s_wdiff_all_sq: 2.1632412594151053e-07\n",
            "E_IS_SCOPE: -1.0408179001069024e-05\n",
            "E_IS_E_SCOPE: -9.122639266020722e-06\n",
            "Total Loss: 1.2440485272846273e-07\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "Var loss:  tensor(1.2376e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7868240593460986e-06\n",
            "E_s_wdiff_all_sq: 2.175604824046332e-07\n",
            "E_IS_SCOPE: -1.0403423051419139e-05\n",
            "E_IS_E_SCOPE: -9.11811180243828e-06\n",
            "Total Loss: 1.2376414541316366e-07\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "Var loss:  tensor(1.2312e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7868524714920438e-06\n",
            "E_s_wdiff_all_sq: 2.1867561328055697e-07\n",
            "E_IS_SCOPE: -1.0399227293205882e-05\n",
            "E_IS_E_SCOPE: -9.11413872178555e-06\n",
            "Total Loss: 1.2312278180424125e-07\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "Var loss:  tensor(1.2250e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7902801220221295e-06\n",
            "E_s_wdiff_all_sq: 2.2162535083602078e-07\n",
            "E_IS_SCOPE: -1.0401451241030636e-05\n",
            "E_IS_E_SCOPE: -9.11581042789991e-06\n",
            "Total Loss: 1.2249621135807247e-07\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "Var loss:  tensor(1.2186e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7920082654065135e-06\n",
            "E_s_wdiff_all_sq: 2.2299257574964347e-07\n",
            "E_IS_SCOPE: -1.0403110665061582e-05\n",
            "E_IS_E_SCOPE: -9.116969695554372e-06\n",
            "Total Loss: 1.2185681707586308e-07\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "Var loss:  tensor(1.2122e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7888360740298392e-06\n",
            "E_s_wdiff_all_sq: 2.2123878833948505e-07\n",
            "E_IS_SCOPE: -1.0396548224484091e-05\n",
            "E_IS_E_SCOPE: -9.110795849409268e-06\n",
            "Total Loss: 1.2121560197412344e-07\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "Var loss:  tensor(1.2058e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7862276753803672e-06\n",
            "E_s_wdiff_all_sq: 2.1942278040138897e-07\n",
            "E_IS_SCOPE: -1.0392967167857434e-05\n",
            "E_IS_E_SCOPE: -9.107293872774308e-06\n",
            "Total Loss: 1.2058137124614278e-07\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "Var loss:  tensor(1.1995e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7866842556344687e-06\n",
            "E_s_wdiff_all_sq: 2.196125024758515e-07\n",
            "E_IS_SCOPE: -1.0394038691874905e-05\n",
            "E_IS_E_SCOPE: -9.10791580431767e-06\n",
            "Total Loss: 1.1994904447756047e-07\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "Var loss:  tensor(1.1932e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.787005008038995e-06\n",
            "E_s_wdiff_all_sq: 2.2035834332368694e-07\n",
            "E_IS_SCOPE: -1.039511007922034e-05\n",
            "E_IS_E_SCOPE: -9.108886012504627e-06\n",
            "Total Loss: 1.1932159771729535e-07\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "Var loss:  tensor(1.1869e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7869275095264578e-06\n",
            "E_s_wdiff_all_sq: 2.2111929944694488e-07\n",
            "E_IS_SCOPE: -1.0393742402430107e-05\n",
            "E_IS_E_SCOPE: -9.107619929835728e-06\n",
            "Total Loss: 1.1868633132416935e-07\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "Var loss:  tensor(1.1805e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7878777394131112e-06\n",
            "E_s_wdiff_all_sq: 2.2242493350761248e-07\n",
            "E_IS_SCOPE: -1.0394241320850136e-05\n",
            "E_IS_E_SCOPE: -9.107979237051593e-06\n",
            "Total Loss: 1.1805170474182911e-07\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "Var loss:  tensor(1.1742e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.789271556648441e-06\n",
            "E_s_wdiff_all_sq: 2.2418822445444706e-07\n",
            "E_IS_SCOPE: -1.0393910768304846e-05\n",
            "E_IS_E_SCOPE: -9.107519044389159e-06\n",
            "Total Loss: 1.1742295079603649e-07\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "Var loss:  tensor(1.1680e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7908770319842185e-06\n",
            "E_s_wdiff_all_sq: 2.2607898292583807e-07\n",
            "E_IS_SCOPE: -1.03922041704708e-05\n",
            "E_IS_E_SCOPE: -9.105642324505715e-06\n",
            "Total Loss: 1.1679742356162505e-07\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "Var loss:  tensor(1.1617e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7919382745084536e-06\n",
            "E_s_wdiff_all_sq: 2.2750067128988802e-07\n",
            "E_IS_SCOPE: -1.0389273056368621e-05\n",
            "E_IS_E_SCOPE: -9.102578475251142e-06\n",
            "Total Loss: 1.161715074170197e-07\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "Var loss:  tensor(1.1554e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.792143657592719e-06\n",
            "E_s_wdiff_all_sq: 2.2797854203732862e-07\n",
            "E_IS_SCOPE: -1.038773721774323e-05\n",
            "E_IS_E_SCOPE: -9.100863973648154e-06\n",
            "Total Loss: 1.1554169379865563e-07\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "Var loss:  tensor(1.1493e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7907459993759377e-06\n",
            "E_s_wdiff_all_sq: 2.2719775213939785e-07\n",
            "E_IS_SCOPE: -1.0383448312964843e-05\n",
            "E_IS_E_SCOPE: -9.096575543411794e-06\n",
            "Total Loss: 1.1492577456385684e-07\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "Var loss:  tensor(1.1431e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7891368126472525e-06\n",
            "E_s_wdiff_all_sq: 2.2667283941292478e-07\n",
            "E_IS_SCOPE: -1.0377694310915142e-05\n",
            "E_IS_E_SCOPE: -9.091053504862099e-06\n",
            "Total Loss: 1.1430542756165728e-07\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "Var loss:  tensor(1.1367e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7899119733127507e-06\n",
            "E_s_wdiff_all_sq: 2.2813610952904193e-07\n",
            "E_IS_SCOPE: -1.03759071398555e-05\n",
            "E_IS_E_SCOPE: -9.089294115208419e-06\n",
            "Total Loss: 1.1367288092296075e-07\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "Var loss:  tensor(1.1304e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7936552441597232e-06\n",
            "E_s_wdiff_all_sq: 2.3202224055865683e-07\n",
            "E_IS_SCOPE: -1.0380146763917824e-05\n",
            "E_IS_E_SCOPE: -9.093290758524629e-06\n",
            "Total Loss: 1.130440592480939e-07\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "Var loss:  tensor(1.1243e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7971000373839665e-06\n",
            "E_s_wdiff_all_sq: 2.354888071559719e-07\n",
            "E_IS_SCOPE: -1.0386152808417919e-05\n",
            "E_IS_E_SCOPE: -9.098999324263099e-06\n",
            "Total Loss: 1.1242732835177043e-07\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "Var loss:  tensor(1.1180e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7969682693787913e-06\n",
            "E_s_wdiff_all_sq: 2.361542953821434e-07\n",
            "E_IS_SCOPE: -1.038216046557734e-05\n",
            "E_IS_E_SCOPE: -9.095089457404167e-06\n",
            "Total Loss: 1.1179502408371662e-07\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "Var loss:  tensor(1.1117e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7966095231007444e-06\n",
            "E_s_wdiff_all_sq: 2.365775962092629e-07\n",
            "E_IS_SCOPE: -1.0372975909110613e-05\n",
            "E_IS_E_SCOPE: -9.085985679040843e-06\n",
            "Total Loss: 1.1117453318535594e-07\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "Var loss:  tensor(1.1056e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7987056443128666e-06\n",
            "E_s_wdiff_all_sq: 2.3850206938688644e-07\n",
            "E_IS_SCOPE: -1.0368712039555494e-05\n",
            "E_IS_E_SCOPE: -9.081328937663862e-06\n",
            "Total Loss: 1.1056043757613148e-07\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "Var loss:  tensor(1.0993e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.799605218506197e-06\n",
            "E_s_wdiff_all_sq: 2.3919681381749194e-07\n",
            "E_IS_SCOPE: -1.0369280290589961e-05\n",
            "E_IS_E_SCOPE: -9.081479491550445e-06\n",
            "Total Loss: 1.0992987304308782e-07\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "Var loss:  tensor(1.0930e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.797164722089172e-06\n",
            "E_s_wdiff_all_sq: 2.374055471136057e-07\n",
            "E_IS_SCOPE: -1.0368029803934094e-05\n",
            "E_IS_E_SCOPE: -9.080239587607725e-06\n",
            "Total Loss: 1.0930180875624557e-07\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "Var loss:  tensor(1.0868e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7928762227193067e-06\n",
            "E_s_wdiff_all_sq: 2.3393090430943315e-07\n",
            "E_IS_SCOPE: -1.036439421159407e-05\n",
            "E_IS_E_SCOPE: -9.076699960883182e-06\n",
            "Total Loss: 1.0867988342151072e-07\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "Var loss:  tensor(1.0806e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.789914254803339e-06\n",
            "E_s_wdiff_all_sq: 2.316438975205221e-07\n",
            "E_IS_SCOPE: -1.0361254986746827e-05\n",
            "E_IS_E_SCOPE: -9.073588716656031e-06\n",
            "Total Loss: 1.0806088353464069e-07\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "Var loss:  tensor(1.0743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7904555065522625e-06\n",
            "E_s_wdiff_all_sq: 2.3241589233025768e-07\n",
            "E_IS_SCOPE: -1.0361915728598315e-05\n",
            "E_IS_E_SCOPE: -9.074050448855403e-06\n",
            "Total Loss: 1.074321211695986e-07\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "Var loss:  tensor(1.0681e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.79363136683934e-06\n",
            "E_s_wdiff_all_sq: 2.3542894080123295e-07\n",
            "E_IS_SCOPE: -1.0366592564989412e-05\n",
            "E_IS_E_SCOPE: -9.078332806464287e-06\n",
            "Total Loss: 1.0680597542127319e-07\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "Var loss:  tensor(1.0618e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7954871822353848e-06\n",
            "E_s_wdiff_all_sq: 2.3772076166190373e-07\n",
            "E_IS_SCOPE: -1.0368545578542543e-05\n",
            "E_IS_E_SCOPE: -9.080191764511522e-06\n",
            "Total Loss: 1.0618185894485306e-07\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "Var loss:  tensor(1.0557e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.796094286448647e-06\n",
            "E_s_wdiff_all_sq: 2.3925479616587945e-07\n",
            "E_IS_SCOPE: -1.0367660109871508e-05\n",
            "E_IS_E_SCOPE: -9.07946382712844e-06\n",
            "Total Loss: 1.0556999123004566e-07\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "Var loss:  tensor(1.0495e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7974176418106343e-06\n",
            "E_s_wdiff_all_sq: 2.4163849454421917e-07\n",
            "E_IS_SCOPE: -1.0361000675555545e-05\n",
            "E_IS_E_SCOPE: -9.07302383794864e-06\n",
            "Total Loss: 1.0494853848601913e-07\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "Var loss:  tensor(1.0432e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8036874862586164e-06\n",
            "E_s_wdiff_all_sq: 2.4749250547790794e-07\n",
            "E_IS_SCOPE: -1.0359895685103116e-05\n",
            "E_IS_E_SCOPE: -9.071395124762296e-06\n",
            "Total Loss: 1.0431692653248355e-07\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "Var loss:  tensor(1.0370e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8106445901650156e-06\n",
            "E_s_wdiff_all_sq: 2.5391256072762406e-07\n",
            "E_IS_SCOPE: -1.0364616507943786e-05\n",
            "E_IS_E_SCOPE: -9.075538677267025e-06\n",
            "Total Loss: 1.0369943451728638e-07\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "Var loss:  tensor(1.0308e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8120113503744706e-06\n",
            "E_s_wdiff_all_sq: 2.5616298922386205e-07\n",
            "E_IS_SCOPE: -1.036250862856882e-05\n",
            "E_IS_E_SCOPE: -9.073560448369175e-06\n",
            "Total Loss: 1.0307506718473634e-07\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "Var loss:  tensor(1.0246e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.809645521938129e-06\n",
            "E_s_wdiff_all_sq: 2.552108537319324e-07\n",
            "E_IS_SCOPE: -1.0353187276728851e-05\n",
            "E_IS_E_SCOPE: -9.064636247226528e-06\n",
            "Total Loss: 1.0245567563496757e-07\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "Var loss:  tensor(1.0184e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8090177758928519e-06\n",
            "E_s_wdiff_all_sq: 2.547402845703968e-07\n",
            "E_IS_SCOPE: -1.0347670537270873e-05\n",
            "E_IS_E_SCOPE: -9.058892002823624e-06\n",
            "Total Loss: 1.0184348886137021e-07\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "Var loss:  tensor(1.0122e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8099851319002228e-06\n",
            "E_s_wdiff_all_sq: 2.551755251734757e-07\n",
            "E_IS_SCOPE: -1.0351712268160344e-05\n",
            "E_IS_E_SCOPE: -9.062357432849048e-06\n",
            "Total Loss: 1.0122300253757114e-07\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "Var loss:  tensor(1.0060e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8073908457370315e-06\n",
            "E_s_wdiff_all_sq: 2.532226102058629e-07\n",
            "E_IS_SCOPE: -1.0354904938504863e-05\n",
            "E_IS_E_SCOPE: -9.06556073912949e-06\n",
            "Total Loss: 1.0060290321383896e-07\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "Var loss:  tensor(9.9988e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8024382439765327e-06\n",
            "E_s_wdiff_all_sq: 2.4960834715332584e-07\n",
            "E_IS_SCOPE: -1.0347692701347623e-05\n",
            "E_IS_E_SCOPE: -9.05871036073377e-06\n",
            "Total Loss: 9.998828202891707e-08\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "Var loss:  tensor(9.9369e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8020365575015896e-06\n",
            "E_s_wdiff_all_sq: 2.4927179088168595e-07\n",
            "E_IS_SCOPE: -1.034288681475707e-05\n",
            "E_IS_E_SCOPE: -9.053627299224829e-06\n",
            "Total Loss: 9.936880198883544e-08\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "Var loss:  tensor(9.8755e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8059413079658765e-06\n",
            "E_s_wdiff_all_sq: 2.5271658810291076e-07\n",
            "E_IS_SCOPE: -1.0344971079032945e-05\n",
            "E_IS_E_SCOPE: -9.05517460541063e-06\n",
            "Total Loss: 9.875483905175465e-08\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "Var loss:  tensor(9.8129e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8087379248865416e-06\n",
            "E_s_wdiff_all_sq: 2.563609343439698e-07\n",
            "E_IS_SCOPE: -1.0348890346872117e-05\n",
            "E_IS_E_SCOPE: -9.059204992786168e-06\n",
            "Total Loss: 9.812934880408833e-08\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "Var loss:  tensor(9.7524e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8101969854755372e-06\n",
            "E_s_wdiff_all_sq: 2.5904382213906636e-07\n",
            "E_IS_SCOPE: -1.0351197089628065e-05\n",
            "E_IS_E_SCOPE: -9.061821140632929e-06\n",
            "Total Loss: 9.752433177961212e-08\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "Var loss:  tensor(9.6905e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8129369998475493e-06\n",
            "E_s_wdiff_all_sq: 2.6188957876502213e-07\n",
            "E_IS_SCOPE: -1.0349291910870698e-05\n",
            "E_IS_E_SCOPE: -9.059659296367752e-06\n",
            "Total Loss: 9.690525851005231e-08\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "Var loss:  tensor(9.6281e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8153851242992811e-06\n",
            "E_s_wdiff_all_sq: 2.6405561122287423e-07\n",
            "E_IS_SCOPE: -1.0347852240092736e-05\n",
            "E_IS_E_SCOPE: -9.057766547064224e-06\n",
            "Total Loss: 9.628119345280041e-08\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "Var loss:  tensor(9.5660e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8161308231553348e-06\n",
            "E_s_wdiff_all_sq: 2.653033467737564e-07\n",
            "E_IS_SCOPE: -1.0348077058037463e-05\n",
            "E_IS_E_SCOPE: -9.057931677670204e-06\n",
            "Total Loss: 9.565978208047432e-08\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "Var loss:  tensor(9.5047e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8168862539513685e-06\n",
            "E_s_wdiff_all_sq: 2.6672989349135306e-07\n",
            "E_IS_SCOPE: -1.0348822372452423e-05\n",
            "E_IS_E_SCOPE: -9.058706301059348e-06\n",
            "Total Loss: 9.50472841072792e-08\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "Var loss:  tensor(9.4435e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8178079689416856e-06\n",
            "E_s_wdiff_all_sq: 2.6747287871556757e-07\n",
            "E_IS_SCOPE: -1.0348756534917272e-05\n",
            "E_IS_E_SCOPE: -9.058244722546864e-06\n",
            "Total Loss: 9.443453191871724e-08\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "Var loss:  tensor(9.3814e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8159476781140604e-06\n",
            "E_s_wdiff_all_sq: 2.661700704995671e-07\n",
            "E_IS_SCOPE: -1.0340605077764634e-05\n",
            "E_IS_E_SCOPE: -9.050061535741709e-06\n",
            "Total Loss: 9.381359000205804e-08\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "Var loss:  tensor(9.3194e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8150493608844139e-06\n",
            "E_s_wdiff_all_sq: 2.6633188539830744e-07\n",
            "E_IS_SCOPE: -1.0335514466200388e-05\n",
            "E_IS_E_SCOPE: -9.04519113096402e-06\n",
            "Total Loss: 9.319387144678703e-08\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "Var loss:  tensor(9.2578e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8184523268055284e-06\n",
            "E_s_wdiff_all_sq: 2.6965573088217917e-07\n",
            "E_IS_SCOPE: -1.0339562369459293e-05\n",
            "E_IS_E_SCOPE: -9.048891651550014e-06\n",
            "Total Loss: 9.257822653820746e-08\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "Var loss:  tensor(9.1973e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8227743827776751e-06\n",
            "E_s_wdiff_all_sq: 2.7372057672716976e-07\n",
            "E_IS_SCOPE: -1.0343876525829274e-05\n",
            "E_IS_E_SCOPE: -9.052774495894961e-06\n",
            "Total Loss: 9.19728126152952e-08\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "Var loss:  tensor(9.1361e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8240343634623943e-06\n",
            "E_s_wdiff_all_sq: 2.7561818180105647e-07\n",
            "E_IS_SCOPE: -1.0342583762812455e-05\n",
            "E_IS_E_SCOPE: -9.051494664761084e-06\n",
            "Total Loss: 9.136105199201496e-08\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "Var loss:  tensor(9.0757e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8240842497709499e-06\n",
            "E_s_wdiff_all_sq: 2.765325262641265e-07\n",
            "E_IS_SCOPE: -1.0340055834849804e-05\n",
            "E_IS_E_SCOPE: -9.049097150987182e-06\n",
            "Total Loss: 9.075742221499456e-08\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "Var loss:  tensor(9.0147e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.824537297462487e-06\n",
            "E_s_wdiff_all_sq: 2.7771191304310383e-07\n",
            "E_IS_SCOPE: -1.0336628489948187e-05\n",
            "E_IS_E_SCOPE: -9.045727976229757e-06\n",
            "Total Loss: 9.014742341593825e-08\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "Var loss:  tensor(8.9546e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8292504105494805e-06\n",
            "E_s_wdiff_all_sq: 2.819569413978799e-07\n",
            "E_IS_SCOPE: -1.0336719875042142e-05\n",
            "E_IS_E_SCOPE: -9.045284423582013e-06\n",
            "Total Loss: 8.954563266475817e-08\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "Var loss:  tensor(8.8950e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8316428938779768e-06\n",
            "E_s_wdiff_all_sq: 2.845387036444346e-07\n",
            "E_IS_SCOPE: -1.0334778595459528e-05\n",
            "E_IS_E_SCOPE: -9.043139976395644e-06\n",
            "Total Loss: 8.89500185391897e-08\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "Var loss:  tensor(8.8347e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8302399655883206e-06\n",
            "E_s_wdiff_all_sq: 2.8384834913232284e-07\n",
            "E_IS_SCOPE: -1.033271864118667e-05\n",
            "E_IS_E_SCOPE: -9.041134579747029e-06\n",
            "Total Loss: 8.834656001013166e-08\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "Var loss:  tensor(8.7751e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8299523008747598e-06\n",
            "E_s_wdiff_all_sq: 2.8425101840628476e-07\n",
            "E_IS_SCOPE: -1.0333430923017393e-05\n",
            "E_IS_E_SCOPE: -9.04189412742951e-06\n",
            "Total Loss: 8.775075772612055e-08\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "Var loss:  tensor(8.7151e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8317749612539097e-06\n",
            "E_s_wdiff_all_sq: 2.860129220690963e-07\n",
            "E_IS_SCOPE: -1.033777496352962e-05\n",
            "E_IS_E_SCOPE: -9.045907695781059e-06\n",
            "Total Loss: 8.7150570121106e-08\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "Var loss:  tensor(8.6553e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8340378911640413e-06\n",
            "E_s_wdiff_all_sq: 2.881645550946215e-07\n",
            "E_IS_SCOPE: -1.0342370425020625e-05\n",
            "E_IS_E_SCOPE: -9.050148605802377e-06\n",
            "Total Loss: 8.655276406633746e-08\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "Var loss:  tensor(8.5947e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.833374224959294e-06\n",
            "E_s_wdiff_all_sq: 2.885023528716069e-07\n",
            "E_IS_SCOPE: -1.034095832096228e-05\n",
            "E_IS_E_SCOPE: -9.048934364541016e-06\n",
            "Total Loss: 8.594702567857271e-08\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "Var loss:  tensor(8.5363e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8345458505696458e-06\n",
            "E_s_wdiff_all_sq: 2.905258782244738e-07\n",
            "E_IS_SCOPE: -1.034068835371835e-05\n",
            "E_IS_E_SCOPE: -9.048798522546331e-06\n",
            "Total Loss: 8.536337643454943e-08\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "Var loss:  tensor(8.4763e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8382635928979762e-06\n",
            "E_s_wdiff_all_sq: 2.9377076046009085e-07\n",
            "E_IS_SCOPE: -1.0345106652618594e-05\n",
            "E_IS_E_SCOPE: -9.05268013420536e-06\n",
            "Total Loss: 8.476286204483232e-08\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "Var loss:  tensor(8.4165e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8410891513533072e-06\n",
            "E_s_wdiff_all_sq: 2.96541423453398e-07\n",
            "E_IS_SCOPE: -1.0348866636237782e-05\n",
            "E_IS_E_SCOPE: -9.05611393707684e-06\n",
            "Total Loss: 8.416539601144338e-08\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "Var loss:  tensor(8.3571e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.839962371354311e-06\n",
            "E_s_wdiff_all_sq: 2.9660907993746774e-07\n",
            "E_IS_SCOPE: -1.0343066525123418e-05\n",
            "E_IS_E_SCOPE: -9.050613678561328e-06\n",
            "Total Loss: 8.357066472607879e-08\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "Var loss:  tensor(8.2979e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8401116317700725e-06\n",
            "E_s_wdiff_all_sq: 2.9733365488619694e-07\n",
            "E_IS_SCOPE: -1.0334660170572307e-05\n",
            "E_IS_E_SCOPE: -9.042199070996025e-06\n",
            "Total Loss: 8.297884416472764e-08\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "Var loss:  tensor(8.2392e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8448962370485599e-06\n",
            "E_s_wdiff_all_sq: 3.0158148573267923e-07\n",
            "E_IS_SCOPE: -1.033480636250772e-05\n",
            "E_IS_E_SCOPE: -9.041783488554047e-06\n",
            "Total Loss: 8.239206984195125e-08\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "Var loss:  tensor(8.1802e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.848633549892066e-06\n",
            "E_s_wdiff_all_sq: 3.056729590876866e-07\n",
            "E_IS_SCOPE: -1.0335611585361874e-05\n",
            "E_IS_E_SCOPE: -9.042470579321423e-06\n",
            "Total Loss: 8.180164515689151e-08\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "Var loss:  tensor(8.1206e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8486309924552107e-06\n",
            "E_s_wdiff_all_sq: 3.066268593174746e-07\n",
            "E_IS_SCOPE: -1.0333586690667498e-05\n",
            "E_IS_E_SCOPE: -9.040626156865051e-06\n",
            "Total Loss: 8.120613196625841e-08\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "Var loss:  tensor(8.0613e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8491148360019207e-06\n",
            "E_s_wdiff_all_sq: 3.072831325904955e-07\n",
            "E_IS_SCOPE: -1.0334127471472567e-05\n",
            "E_IS_E_SCOPE: -9.040956723359244e-06\n",
            "Total Loss: 8.061327361819397e-08\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "Var loss:  tensor(8.0025e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8494941103721963e-06\n",
            "E_s_wdiff_all_sq: 3.0780308985469343e-07\n",
            "E_IS_SCOPE: -1.0335757340960319e-05\n",
            "E_IS_E_SCOPE: -9.042362846083374e-06\n",
            "Total Loss: 8.002509719702872e-08\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "Var loss:  tensor(7.9428e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8495146721495728e-06\n",
            "E_s_wdiff_all_sq: 3.0846935347571106e-07\n",
            "E_IS_SCOPE: -1.0335895365578172e-05\n",
            "E_IS_E_SCOPE: -9.042525076801941e-06\n",
            "Total Loss: 7.942780755481887e-08\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "Var loss:  tensor(7.8835e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8496907828852022e-06\n",
            "E_s_wdiff_all_sq: 3.088716849800798e-07\n",
            "E_IS_SCOPE: -1.0335584283279913e-05\n",
            "E_IS_E_SCOPE: -9.04203072540654e-06\n",
            "Total Loss: 7.883504859179393e-08\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "Var loss:  tensor(7.8245e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8497122878233997e-06\n",
            "E_s_wdiff_all_sq: 3.0880752106345143e-07\n",
            "E_IS_SCOPE: -1.0333061473182443e-05\n",
            "E_IS_E_SCOPE: -9.03917022733646e-06\n",
            "Total Loss: 7.824534150139712e-08\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "Var loss:  tensor(7.7657e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8488429888800533e-06\n",
            "E_s_wdiff_all_sq: 3.0865484641433305e-07\n",
            "E_IS_SCOPE: -1.0324552984730756e-05\n",
            "E_IS_E_SCOPE: -9.030726109337433e-06\n",
            "Total Loss: 7.765745811248985e-08\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "Var loss:  tensor(7.7074e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8492435755341458e-06\n",
            "E_s_wdiff_all_sq: 3.094937148022092e-07\n",
            "E_IS_SCOPE: -1.0317479644424225e-05\n",
            "E_IS_E_SCOPE: -9.023580106171744e-06\n",
            "Total Loss: 7.70738506603917e-08\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "Var loss:  tensor(7.6491e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.854053715743091e-06\n",
            "E_s_wdiff_all_sq: 3.13887580722104e-07\n",
            "E_IS_SCOPE: -1.0318309661867713e-05\n",
            "E_IS_E_SCOPE: -9.023910456706952e-06\n",
            "Total Loss: 7.649079113288018e-08\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "Var loss:  tensor(7.5908e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8580182006351142e-06\n",
            "E_s_wdiff_all_sq: 3.1813788184245966e-07\n",
            "E_IS_SCOPE: -1.0319279635006984e-05\n",
            "E_IS_E_SCOPE: -9.024731949275916e-06\n",
            "Total Loss: 7.590801376393387e-08\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "Var loss:  tensor(7.5324e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8590351111638258e-06\n",
            "E_s_wdiff_all_sq: 3.201984763624952e-07\n",
            "E_IS_SCOPE: -1.0318070682949e-05\n",
            "E_IS_E_SCOPE: -9.023752928199771e-06\n",
            "Total Loss: 7.532419173629035e-08\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "Var loss:  tensor(7.4740e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8599573183867416e-06\n",
            "E_s_wdiff_all_sq: 3.2143856144486204e-07\n",
            "E_IS_SCOPE: -1.032172722953697e-05\n",
            "E_IS_E_SCOPE: -9.027276323559471e-06\n",
            "Total Loss: 7.474001142029603e-08\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "Var loss:  tensor(7.4155e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8599834629728588e-06\n",
            "E_s_wdiff_all_sq: 3.2176288193937834e-07\n",
            "E_IS_SCOPE: -1.0326212261310873e-05\n",
            "E_IS_E_SCOPE: -9.031618139537151e-06\n",
            "Total Loss: 7.415540391945212e-08\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "Var loss:  tensor(7.3566e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8616804326720498e-06\n",
            "E_s_wdiff_all_sq: 3.236606325783838e-07\n",
            "E_IS_SCOPE: -1.0331318756779252e-05\n",
            "E_IS_E_SCOPE: -9.036530383617665e-06\n",
            "Total Loss: 7.356612020390772e-08\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "Var loss:  tensor(7.2992e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.862586076969805e-06\n",
            "E_s_wdiff_all_sq: 3.2486816383940227e-07\n",
            "E_IS_SCOPE: -1.0332144661005726e-05\n",
            "E_IS_E_SCOPE: -9.037220019742587e-06\n",
            "Total Loss: 7.29916970375391e-08\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "Var loss:  tensor(7.2415e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.861561522809238e-06\n",
            "E_s_wdiff_all_sq: 3.2458534001938727e-07\n",
            "E_IS_SCOPE: -1.0328223483705207e-05\n",
            "E_IS_E_SCOPE: -9.033381580126701e-06\n",
            "Total Loss: 7.24154420662548e-08\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "Var loss:  tensor(7.1830e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8634452647169618e-06\n",
            "E_s_wdiff_all_sq: 3.2650501955743144e-07\n",
            "E_IS_SCOPE: -1.0323907472611562e-05\n",
            "E_IS_E_SCOPE: -9.028790606698202e-06\n",
            "Total Loss: 7.182957976622821e-08\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "Var loss:  tensor(7.1262e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8676502331548532e-06\n",
            "E_s_wdiff_all_sq: 3.303831036841755e-07\n",
            "E_IS_SCOPE: -1.0321619274773419e-05\n",
            "E_IS_E_SCOPE: -9.026054948291937e-06\n",
            "Total Loss: 7.126154294112883e-08\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "Var loss:  tensor(7.0677e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8681204770205192e-06\n",
            "E_s_wdiff_all_sq: 3.3139491307600796e-07\n",
            "E_IS_SCOPE: -1.0316836122740247e-05\n",
            "E_IS_E_SCOPE: -9.021250347513743e-06\n",
            "Total Loss: 7.067707992491899e-08\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "Var loss:  tensor(7.0102e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8669983469061603e-06\n",
            "E_s_wdiff_all_sq: 3.307291853931478e-07\n",
            "E_IS_SCOPE: -1.031377437964768e-05\n",
            "E_IS_E_SCOPE: -9.018129460907222e-06\n",
            "Total Loss: 7.0102390465511e-08\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "Var loss:  tensor(6.9521e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8676519147512837e-06\n",
            "E_s_wdiff_all_sq: 3.316985786358116e-07\n",
            "E_IS_SCOPE: -1.0315321764380118e-05\n",
            "E_IS_E_SCOPE: -9.019544189385059e-06\n",
            "Total Loss: 6.952125255876894e-08\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "Var loss:  tensor(6.8938e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.870940628827859e-06\n",
            "E_s_wdiff_all_sq: 3.3529385816867433e-07\n",
            "E_IS_SCOPE: -1.0318959180402473e-05\n",
            "E_IS_E_SCOPE: -9.023043027015365e-06\n",
            "Total Loss: 6.893753031838255e-08\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "Var loss:  tensor(6.8360e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.874489070021739e-06\n",
            "E_s_wdiff_all_sq: 3.392391729777743e-07\n",
            "E_IS_SCOPE: -1.032022593879432e-05\n",
            "E_IS_E_SCOPE: -9.024219372773333e-06\n",
            "Total Loss: 6.835983143540615e-08\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "Var loss:  tensor(6.7776e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8795333290878558e-06\n",
            "E_s_wdiff_all_sq: 3.4417118551940225e-07\n",
            "E_IS_SCOPE: -1.032156993597268e-05\n",
            "E_IS_E_SCOPE: -9.02521539240835e-06\n",
            "Total Loss: 6.777612287321225e-08\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "Var loss:  tensor(6.7201e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8825330268905687e-06\n",
            "E_s_wdiff_all_sq: 3.475911849865068e-07\n",
            "E_IS_SCOPE: -1.0319648464937042e-05\n",
            "E_IS_E_SCOPE: -9.023216723525299e-06\n",
            "Total Loss: 6.72014255139905e-08\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "Var loss:  tensor(6.6629e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8821120359793671e-06\n",
            "E_s_wdiff_all_sq: 3.481520009204671e-07\n",
            "E_IS_SCOPE: -1.0314261774066302e-05\n",
            "E_IS_E_SCOPE: -9.018034483617153e-06\n",
            "Total Loss: 6.66285205940154e-08\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "Var loss:  tensor(6.6051e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8823419332205307e-06\n",
            "E_s_wdiff_all_sq: 3.487557818776904e-07\n",
            "E_IS_SCOPE: -1.030952085576445e-05\n",
            "E_IS_E_SCOPE: -9.01319178759603e-06\n",
            "Total Loss: 6.605108143941231e-08\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "Var loss:  tensor(6.5471e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.885504268802815e-06\n",
            "E_s_wdiff_all_sq: 3.512676843518606e-07\n",
            "E_IS_SCOPE: -1.0311361925394809e-05\n",
            "E_IS_E_SCOPE: -9.014417560974977e-06\n",
            "Total Loss: 6.547092204470775e-08\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "Var loss:  tensor(6.4906e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.887933591448443e-06\n",
            "E_s_wdiff_all_sq: 3.53466754280809e-07\n",
            "E_IS_SCOPE: -1.0315666362387826e-05\n",
            "E_IS_E_SCOPE: -9.01832423622435e-06\n",
            "Total Loss: 6.490565127409993e-08\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "Var loss:  tensor(6.4317e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8850755718474016e-06\n",
            "E_s_wdiff_all_sq: 3.516648239895659e-07\n",
            "E_IS_SCOPE: -1.0313485464848984e-05\n",
            "E_IS_E_SCOPE: -9.016377079633204e-06\n",
            "Total Loss: 6.43170438596891e-08\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "Var loss:  tensor(6.3726e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8809827221564462e-06\n",
            "E_s_wdiff_all_sq: 3.483556380783978e-07\n",
            "E_IS_SCOPE: -1.0309813220813691e-05\n",
            "E_IS_E_SCOPE: -9.012800972668712e-06\n",
            "Total Loss: 6.372565422150538e-08\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "Var loss:  tensor(6.3141e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.880338003323336e-06\n",
            "E_s_wdiff_all_sq: 3.4750566505935696e-07\n",
            "E_IS_SCOPE: -1.0312759210735495e-05\n",
            "E_IS_E_SCOPE: -9.015352134769041e-06\n",
            "Total Loss: 6.314125276448568e-08\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "Var loss:  tensor(6.2529e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8819795373454795e-06\n",
            "E_s_wdiff_all_sq: 3.494679144676805e-07\n",
            "E_IS_SCOPE: -1.0318060142803307e-05\n",
            "E_IS_E_SCOPE: -9.020507060561814e-06\n",
            "Total Loss: 6.252852482822872e-08\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "Var loss:  tensor(6.1938e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8849082075612048e-06\n",
            "E_s_wdiff_all_sq: 3.5322293056670525e-07\n",
            "E_IS_SCOPE: -1.032171481721677e-05\n",
            "E_IS_E_SCOPE: -9.024279739247746e-06\n",
            "Total Loss: 6.193818748986602e-08\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "Var loss:  tensor(6.1343e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8905244518062983e-06\n",
            "E_s_wdiff_all_sq: 3.5850958950463845e-07\n",
            "E_IS_SCOPE: -1.0320892157275671e-05\n",
            "E_IS_E_SCOPE: -9.022994571556825e-06\n",
            "Total Loss: 6.134275729738373e-08\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "Var loss:  tensor(6.0731e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8945049780451192e-06\n",
            "E_s_wdiff_all_sq: 3.6242396586569633e-07\n",
            "E_IS_SCOPE: -1.0315906718008786e-05\n",
            "E_IS_E_SCOPE: -9.017669979755636e-06\n",
            "Total Loss: 6.07306021065379e-08\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "Var loss:  tensor(6.0128e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8933896283100598e-06\n",
            "E_s_wdiff_all_sq: 3.622817607253569e-07\n",
            "E_IS_SCOPE: -1.0308766163670232e-05\n",
            "E_IS_E_SCOPE: -9.010714791335528e-06\n",
            "Total Loss: 6.012818934871049e-08\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "Var loss:  tensor(5.9533e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8921185792208823e-06\n",
            "E_s_wdiff_all_sq: 3.619872245046737e-07\n",
            "E_IS_SCOPE: -1.0303741004338369e-05\n",
            "E_IS_E_SCOPE: -9.005880202986834e-06\n",
            "Total Loss: 5.953281844655509e-08\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "Var loss:  tensor(5.8929e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8946915887260108e-06\n",
            "E_s_wdiff_all_sq: 3.641635357853031e-07\n",
            "E_IS_SCOPE: -1.0305975408668714e-05\n",
            "E_IS_E_SCOPE: -9.007614569889478e-06\n",
            "Total Loss: 5.892944181565286e-08\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "Var loss:  tensor(5.8325e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8963814821725818e-06\n",
            "E_s_wdiff_all_sq: 3.656874957201422e-07\n",
            "E_IS_SCOPE: -1.0308182679635689e-05\n",
            "E_IS_E_SCOPE: -9.009436690409244e-06\n",
            "Total Loss: 5.832507443296512e-08\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "Var loss:  tensor(5.7720e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8962954565972808e-06\n",
            "E_s_wdiff_all_sq: 3.6654028664441846e-07\n",
            "E_IS_SCOPE: -1.0308799451297773e-05\n",
            "E_IS_E_SCOPE: -9.01022041947686e-06\n",
            "Total Loss: 5.772017274445536e-08\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "Var loss:  tensor(5.7117e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8992425019596346e-06\n",
            "E_s_wdiff_all_sq: 3.698782339621514e-07\n",
            "E_IS_SCOPE: -1.0310907302631664e-05\n",
            "E_IS_E_SCOPE: -9.012222295707965e-06\n",
            "Total Loss: 5.711732058350304e-08\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "Var loss:  tensor(5.6511e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.903375168422438e-06\n",
            "E_s_wdiff_all_sq: 3.7431849631479723e-07\n",
            "E_IS_SCOPE: -1.0311693879535486e-05\n",
            "E_IS_E_SCOPE: -9.012859653331763e-06\n",
            "Total Loss: 5.6511286133611004e-08\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "Var loss:  tensor(5.5912e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9068964534486692e-06\n",
            "E_s_wdiff_all_sq: 3.7841254345400153e-07\n",
            "E_IS_SCOPE: -1.0310228319411227e-05\n",
            "E_IS_E_SCOPE: -9.01138063858352e-06\n",
            "Total Loss: 5.591161477266701e-08\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "Var loss:  tensor(5.5315e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9090275103618617e-06\n",
            "E_s_wdiff_all_sq: 3.810555537619144e-07\n",
            "E_IS_SCOPE: -1.0308605153245816e-05\n",
            "E_IS_E_SCOPE: -9.00971519963542e-06\n",
            "Total Loss: 5.531511581257126e-08\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "Var loss:  tensor(5.4695e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9097894419856842e-06\n",
            "E_s_wdiff_all_sq: 3.818784353735083e-07\n",
            "E_IS_SCOPE: -1.0308717363608888e-05\n",
            "E_IS_E_SCOPE: -9.009547759632338e-06\n",
            "Total Loss: 5.469486509249143e-08\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "Var loss:  tensor(5.4094e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9095886597959903e-06\n",
            "E_s_wdiff_all_sq: 3.8175170597980735e-07\n",
            "E_IS_SCOPE: -1.0306582002584975e-05\n",
            "E_IS_E_SCOPE: -9.007148817107538e-06\n",
            "Total Loss: 5.4093649294724934e-08\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "Var loss:  tensor(5.3500e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9106805315814025e-06\n",
            "E_s_wdiff_all_sq: 3.8295038058861307e-07\n",
            "E_IS_SCOPE: -1.0306421080388691e-05\n",
            "E_IS_E_SCOPE: -9.00674427756139e-06\n",
            "Total Loss: 5.349961177160531e-08\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "Var loss:  tensor(5.2899e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9124749859369774e-06\n",
            "E_s_wdiff_all_sq: 3.8538953250880145e-07\n",
            "E_IS_SCOPE: -1.0305837511398478e-05\n",
            "E_IS_E_SCOPE: -9.006182886934876e-06\n",
            "Total Loss: 5.2899270934386346e-08\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "Var loss:  tensor(5.2288e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.916742737206139e-06\n",
            "E_s_wdiff_all_sq: 3.899225905310482e-07\n",
            "E_IS_SCOPE: -1.0308637794441105e-05\n",
            "E_IS_E_SCOPE: -9.008810123198848e-06\n",
            "Total Loss: 5.228787062399303e-08\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "Var loss:  tensor(5.1689e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.921960955053436e-06\n",
            "E_s_wdiff_all_sq: 3.953565836214308e-07\n",
            "E_IS_SCOPE: -1.0312402731527401e-05\n",
            "E_IS_E_SCOPE: -9.01238374838736e-06\n",
            "Total Loss: 5.168947158534095e-08\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "Var loss:  tensor(5.1088e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9263836476506966e-06\n",
            "E_s_wdiff_all_sq: 4.001696409414085e-07\n",
            "E_IS_SCOPE: -1.0315468640460884e-05\n",
            "E_IS_E_SCOPE: -9.015343983908966e-06\n",
            "Total Loss: 5.108776003886853e-08\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "Var loss:  tensor(5.0496e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.928243872312046e-06\n",
            "E_s_wdiff_all_sq: 4.026839433969053e-07\n",
            "E_IS_SCOPE: -1.0315367066493988e-05\n",
            "E_IS_E_SCOPE: -9.015273516281268e-06\n",
            "Total Loss: 5.0495894923119075e-08\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "Var loss:  tensor(4.9893e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.928279119808373e-06\n",
            "E_s_wdiff_all_sq: 4.0316330998112404e-07\n",
            "E_IS_SCOPE: -1.031276202353378e-05\n",
            "E_IS_E_SCOPE: -9.012589329517008e-06\n",
            "Total Loss: 4.9893488227120005e-08\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "Var loss:  tensor(4.9287e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9286787303341227e-06\n",
            "E_s_wdiff_all_sq: 4.035944525186352e-07\n",
            "E_IS_SCOPE: -1.0312871556318868e-05\n",
            "E_IS_E_SCOPE: -9.012411584664777e-06\n",
            "Total Loss: 4.928740094072229e-08\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "Var loss:  tensor(4.8683e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9277680282338125e-06\n",
            "E_s_wdiff_all_sq: 4.029852566040519e-07\n",
            "E_IS_SCOPE: -1.0311963799916697e-05\n",
            "E_IS_E_SCOPE: -9.01135224469221e-06\n",
            "Total Loss: 4.868272761420326e-08\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "Var loss:  tensor(4.8088e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.925455778907526e-06\n",
            "E_s_wdiff_all_sq: 4.011546046490546e-07\n",
            "E_IS_SCOPE: -1.030914507920772e-05\n",
            "E_IS_E_SCOPE: -9.008477149483244e-06\n",
            "Total Loss: 4.808838124293403e-08\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "Var loss:  tensor(4.7484e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9259531111147583e-06\n",
            "E_s_wdiff_all_sq: 4.0177157110714343e-07\n",
            "E_IS_SCOPE: -1.0302810841748247e-05\n",
            "E_IS_E_SCOPE: -9.001900469608946e-06\n",
            "Total Loss: 4.748386216242956e-08\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "Var loss:  tensor(4.6893e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.930656330309447e-06\n",
            "E_s_wdiff_all_sq: 4.0642532623652443e-07\n",
            "E_IS_SCOPE: -1.0296972168748347e-05\n",
            "E_IS_E_SCOPE: -8.995741575516742e-06\n",
            "Total Loss: 4.6892884043128745e-08\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "Var loss:  tensor(4.6310e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9371871025886784e-06\n",
            "E_s_wdiff_all_sq: 4.133183968838577e-07\n",
            "E_IS_SCOPE: -1.0294429272677638e-05\n",
            "E_IS_E_SCOPE: -8.993088372611993e-06\n",
            "Total Loss: 4.6309972006947576e-08\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "Var loss:  tensor(4.5700e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9423607590056343e-06\n",
            "E_s_wdiff_all_sq: 4.1892784958815415e-07\n",
            "E_IS_SCOPE: -1.0290417381247346e-05\n",
            "E_IS_E_SCOPE: -8.988989385913393e-06\n",
            "Total Loss: 4.569998518298775e-08\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "Var loss:  tensor(4.5103e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9452350853392965e-06\n",
            "E_s_wdiff_all_sq: 4.22396313785321e-07\n",
            "E_IS_SCOPE: -1.0285999651299317e-05\n",
            "E_IS_E_SCOPE: -8.984570377647036e-06\n",
            "Total Loss: 4.510329068283076e-08\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "Var loss:  tensor(4.4529e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9471939934897836e-06\n",
            "E_s_wdiff_all_sq: 4.247724661096949e-07\n",
            "E_IS_SCOPE: -1.0289086262470626e-05\n",
            "E_IS_E_SCOPE: -8.987578519233446e-06\n",
            "Total Loss: 4.452910733914403e-08\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "Var loss:  tensor(4.3930e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.947574658466445e-06\n",
            "E_s_wdiff_all_sq: 4.2558459641404884e-07\n",
            "E_IS_SCOPE: -1.0294991997778182e-05\n",
            "E_IS_E_SCOPE: -8.99340032609152e-06\n",
            "Total Loss: 4.392978511248535e-08\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "Var loss:  tensor(4.3359e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9479600237661343e-06\n",
            "E_s_wdiff_all_sq: 4.2597404088463045e-07\n",
            "E_IS_SCOPE: -1.0300030910587423e-05\n",
            "E_IS_E_SCOPE: -8.998156013432985e-06\n",
            "Total Loss: 4.335925500604425e-08\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "Var loss:  tensor(4.2790e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.947921239678948e-06\n",
            "E_s_wdiff_all_sq: 4.254612447949879e-07\n",
            "E_IS_SCOPE: -1.0302317154034801e-05\n",
            "E_IS_E_SCOPE: -8.999920495019092e-06\n",
            "Total Loss: 4.2789743285956995e-08\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "Var loss:  tensor(4.2206e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.94530247543964e-06\n",
            "E_s_wdiff_all_sq: 4.229146323097299e-07\n",
            "E_IS_SCOPE: -1.030173416437278e-05\n",
            "E_IS_E_SCOPE: -8.999081864077862e-06\n",
            "Total Loss: 4.220630897348957e-08\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "Var loss:  tensor(4.1624e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9401216619518816e-06\n",
            "E_s_wdiff_all_sq: 4.1866445602970125e-07\n",
            "E_IS_SCOPE: -1.0297414168841731e-05\n",
            "E_IS_E_SCOPE: -8.994936224371753e-06\n",
            "Total Loss: 4.162438341564022e-08\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "Var loss:  tensor(4.1048e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9388431987567555e-06\n",
            "E_s_wdiff_all_sq: 4.175990908218464e-07\n",
            "E_IS_SCOPE: -1.0295132022411679e-05\n",
            "E_IS_E_SCOPE: -8.992472580103146e-06\n",
            "Total Loss: 4.104828975125745e-08\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "Var loss:  tensor(4.0468e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.941982110452639e-06\n",
            "E_s_wdiff_all_sq: 4.2051051540512925e-07\n",
            "E_IS_SCOPE: -1.029263201829579e-05\n",
            "E_IS_E_SCOPE: -8.98956871717617e-06\n",
            "Total Loss: 4.0468059241684484e-08\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "Var loss:  tensor(3.9898e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9471119902807254e-06\n",
            "E_s_wdiff_all_sq: 4.2625371780903963e-07\n",
            "E_IS_SCOPE: -1.0288374890701507e-05\n",
            "E_IS_E_SCOPE: -8.985333177324015e-06\n",
            "Total Loss: 3.989791215011724e-08\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "Var loss:  tensor(3.9337e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.954560415571042e-06\n",
            "E_s_wdiff_all_sq: 4.339844567023788e-07\n",
            "E_IS_SCOPE: -1.0287451916620904e-05\n",
            "E_IS_E_SCOPE: -8.984270753892916e-06\n",
            "Total Loss: 3.9336699846103246e-08\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "Var loss:  tensor(3.8773e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9622411521689833e-06\n",
            "E_s_wdiff_all_sq: 4.4200240313091826e-07\n",
            "E_IS_SCOPE: -1.0285787726604281e-05\n",
            "E_IS_E_SCOPE: -8.982493069529045e-06\n",
            "Total Loss: 3.877250132100615e-08\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "Var loss:  tensor(3.8202e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9685726572620084e-06\n",
            "E_s_wdiff_all_sq: 4.490687293141164e-07\n",
            "E_IS_SCOPE: -1.028333315974993e-05\n",
            "E_IS_E_SCOPE: -8.980120613142e-06\n",
            "Total Loss: 3.820190116544822e-08\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "Var loss:  tensor(3.7642e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9726499148576263e-06\n",
            "E_s_wdiff_all_sq: 4.539485898120544e-07\n",
            "E_IS_SCOPE: -1.0282220308088313e-05\n",
            "E_IS_E_SCOPE: -8.979129358468066e-06\n",
            "Total Loss: 3.76424922384916e-08\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "Var loss:  tensor(3.7086e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.975743583839813e-06\n",
            "E_s_wdiff_all_sq: 4.5713783269794133e-07\n",
            "E_IS_SCOPE: -1.0285969785079868e-05\n",
            "E_IS_E_SCOPE: -8.98264828801081e-06\n",
            "Total Loss: 3.7085823437170286e-08\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "Var loss:  tensor(3.6525e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9757471303206706e-06\n",
            "E_s_wdiff_all_sq: 4.5706293198430473e-07\n",
            "E_IS_SCOPE: -1.029230595366593e-05\n",
            "E_IS_E_SCOPE: -8.988664774185958e-06\n",
            "Total Loss: 3.652490580983657e-08\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "Var loss:  tensor(3.5968e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9716167161454974e-06\n",
            "E_s_wdiff_all_sq: 4.533516761518446e-07\n",
            "E_IS_SCOPE: -1.0297272931334995e-05\n",
            "E_IS_E_SCOPE: -8.993562889114314e-06\n",
            "Total Loss: 3.596802198570827e-08\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "Var loss:  tensor(3.5410e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9667405396391795e-06\n",
            "E_s_wdiff_all_sq: 4.490371122098463e-07\n",
            "E_IS_SCOPE: -1.029872891911679e-05\n",
            "E_IS_E_SCOPE: -8.9950207235799e-06\n",
            "Total Loss: 3.541010278896939e-08\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "Var loss:  tensor(3.4848e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9658863268248642e-06\n",
            "E_s_wdiff_all_sq: 4.4828732170732727e-07\n",
            "E_IS_SCOPE: -1.0300728832402589e-05\n",
            "E_IS_E_SCOPE: -8.996791687024787e-06\n",
            "Total Loss: 3.484778079534966e-08\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "Var loss:  tensor(3.4293e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9685372005665407e-06\n",
            "E_s_wdiff_all_sq: 4.506852260804692e-07\n",
            "E_IS_SCOPE: -1.030413098421614e-05\n",
            "E_IS_E_SCOPE: -8.999789796555668e-06\n",
            "Total Loss: 3.429266559854117e-08\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "Var loss:  tensor(3.3741e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.967275125692619e-06\n",
            "E_s_wdiff_all_sq: 4.504043240216321e-07\n",
            "E_IS_SCOPE: -1.0299167883881777e-05\n",
            "E_IS_E_SCOPE: -8.995041237554212e-06\n",
            "Total Loss: 3.3740575449273e-08\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "Var loss:  tensor(3.3191e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9673300299335046e-06\n",
            "E_s_wdiff_all_sq: 4.50968007791106e-07\n",
            "E_IS_SCOPE: -1.0296486394932122e-05\n",
            "E_IS_E_SCOPE: -8.992339345408752e-06\n",
            "Total Loss: 3.3190989529073914e-08\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "Var loss:  tensor(3.2646e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.971708487182637e-06\n",
            "E_s_wdiff_all_sq: 4.5504771166667184e-07\n",
            "E_IS_SCOPE: -1.0299287893714963e-05\n",
            "E_IS_E_SCOPE: -8.994718758509122e-06\n",
            "Total Loss: 3.264557153769931e-08\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "Var loss:  tensor(3.2085e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.975958718338566e-06\n",
            "E_s_wdiff_all_sq: 4.592709909401639e-07\n",
            "E_IS_SCOPE: -1.0303370209107688e-05\n",
            "E_IS_E_SCOPE: -8.998507479317703e-06\n",
            "Total Loss: 3.2085334251847386e-08\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "Var loss:  tensor(3.1549e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9783750632307583e-06\n",
            "E_s_wdiff_all_sq: 4.6228985319246573e-07\n",
            "E_IS_SCOPE: -1.0301947276556897e-05\n",
            "E_IS_E_SCOPE: -8.997117435776314e-06\n",
            "Total Loss: 3.1548594910541065e-08\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "Var loss:  tensor(3.1004e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.979640589823085e-06\n",
            "E_s_wdiff_all_sq: 4.6378258893867996e-07\n",
            "E_IS_SCOPE: -1.0299063776970112e-05\n",
            "E_IS_E_SCOPE: -8.994075409726573e-06\n",
            "Total Loss: 3.1004332830741265e-08\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "Var loss:  tensor(3.0451e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9789138135608665e-06\n",
            "E_s_wdiff_all_sq: 4.632855400394444e-07\n",
            "E_IS_SCOPE: -1.0295340625861947e-05\n",
            "E_IS_E_SCOPE: -8.990190232283805e-06\n",
            "Total Loss: 3.045055279855164e-08\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "Var loss:  tensor(2.9913e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9750544455106806e-06\n",
            "E_s_wdiff_all_sq: 4.6057671334858063e-07\n",
            "E_IS_SCOPE: -1.0290084810830747e-05\n",
            "E_IS_E_SCOPE: -8.985240843047508e-06\n",
            "Total Loss: 2.9912863029036915e-08\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "Var loss:  tensor(2.9367e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.974880816956654e-06\n",
            "E_s_wdiff_all_sq: 4.608332820575906e-07\n",
            "E_IS_SCOPE: -1.0290867242869428e-05\n",
            "E_IS_E_SCOPE: -8.985965647594675e-06\n",
            "Total Loss: 2.9367410782973942e-08\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "Var loss:  tensor(2.8822e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9801333808803957e-06\n",
            "E_s_wdiff_all_sq: 4.655344720903491e-07\n",
            "E_IS_SCOPE: -1.0294914512798929e-05\n",
            "E_IS_E_SCOPE: -8.989464480203053e-06\n",
            "Total Loss: 2.882191003171197e-08\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "Var loss:  tensor(2.8284e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.982815472153122e-06\n",
            "E_s_wdiff_all_sq: 4.683797620209274e-07\n",
            "E_IS_SCOPE: -1.0295163194026595e-05\n",
            "E_IS_E_SCOPE: -8.989526020200222e-06\n",
            "Total Loss: 2.8284428912865203e-08\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "Var loss:  tensor(2.7740e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9823941336797825e-06\n",
            "E_s_wdiff_all_sq: 4.6915035507205683e-07\n",
            "E_IS_SCOPE: -1.0290395715213404e-05\n",
            "E_IS_E_SCOPE: -8.985082200798287e-06\n",
            "Total Loss: 2.7739816210904987e-08\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "Var loss:  tensor(2.7204e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9836686399468414e-06\n",
            "E_s_wdiff_all_sq: 4.7096921868742543e-07\n",
            "E_IS_SCOPE: -1.0288014591082486e-05\n",
            "E_IS_E_SCOPE: -8.9827054548465e-06\n",
            "Total Loss: 2.720421522085587e-08\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "Var loss:  tensor(2.6660e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.98827204289551e-06\n",
            "E_s_wdiff_all_sq: 4.7502999380114606e-07\n",
            "E_IS_SCOPE: -1.028764712693516e-05\n",
            "E_IS_E_SCOPE: -8.981794516470897e-06\n",
            "Total Loss: 2.6659894599252716e-08\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "Var loss:  tensor(2.6126e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9904602106515353e-06\n",
            "E_s_wdiff_all_sq: 4.771517346678013e-07\n",
            "E_IS_SCOPE: -1.028731356273192e-05\n",
            "E_IS_E_SCOPE: -8.981160915145488e-06\n",
            "Total Loss: 2.6126247244283324e-08\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "Var loss:  tensor(2.5589e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9876724712908743e-06\n",
            "E_s_wdiff_all_sq: 4.753837819776823e-07\n",
            "E_IS_SCOPE: -1.0284261785265774e-05\n",
            "E_IS_E_SCOPE: -8.978350454765674e-06\n",
            "Total Loss: 2.55890947464066e-08\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "Var loss:  tensor(2.5052e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.987519936935822e-06\n",
            "E_s_wdiff_all_sq: 4.753993171853836e-07\n",
            "E_IS_SCOPE: -1.028616789807712e-05\n",
            "E_IS_E_SCOPE: -8.980072237445806e-06\n",
            "Total Loss: 2.5052364921225227e-08\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "Var loss:  tensor(2.4525e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9890061147548036e-06\n",
            "E_s_wdiff_all_sq: 4.761384972290951e-07\n",
            "E_IS_SCOPE: -1.0292939354488937e-05\n",
            "E_IS_E_SCOPE: -8.986206490108061e-06\n",
            "Total Loss: 2.4524955197370838e-08\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "Var loss:  tensor(2.3984e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9859373187723843e-06\n",
            "E_s_wdiff_all_sq: 4.7415411311995065e-07\n",
            "E_IS_SCOPE: -1.028793910740668e-05\n",
            "E_IS_E_SCOPE: -8.98147812894845e-06\n",
            "Total Loss: 2.398431516939284e-08\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "Var loss:  tensor(2.3457e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.984895474743378e-06\n",
            "E_s_wdiff_all_sq: 4.7395057700158714e-07\n",
            "E_IS_SCOPE: -1.0284254263461434e-05\n",
            "E_IS_E_SCOPE: -8.977948825960277e-06\n",
            "Total Loss: 2.3457089172890808e-08\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "Var loss:  tensor(2.2930e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.989949091633991e-06\n",
            "E_s_wdiff_all_sq: 4.782974582663617e-07\n",
            "E_IS_SCOPE: -1.0284117899632877e-05\n",
            "E_IS_E_SCOPE: -8.977195746053177e-06\n",
            "Total Loss: 2.293039264164445e-08\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "Var loss:  tensor(2.2394e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9938142547301895e-06\n",
            "E_s_wdiff_all_sq: 4.830442677321873e-07\n",
            "E_IS_SCOPE: -1.0281112612798635e-05\n",
            "E_IS_E_SCOPE: -8.974362879895768e-06\n",
            "Total Loss: 2.2393587625682505e-08\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "Var loss:  tensor(2.1870e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9953250693956728e-06\n",
            "E_s_wdiff_all_sq: 4.859716830305691e-07\n",
            "E_IS_SCOPE: -1.0278185299983794e-05\n",
            "E_IS_E_SCOPE: -8.971881965660985e-06\n",
            "Total Loss: 2.1869784152900174e-08\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "Var loss:  tensor(2.1344e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.003164335266507e-06\n",
            "E_s_wdiff_all_sq: 4.931387667050078e-07\n",
            "E_IS_SCOPE: -1.0283250412551368e-05\n",
            "E_IS_E_SCOPE: -8.976348075778355e-06\n",
            "Total Loss: 2.1343961448888737e-08\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "Var loss:  tensor(2.0814e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.00596918495258e-06\n",
            "E_s_wdiff_all_sq: 4.952635587804395e-07\n",
            "E_IS_SCOPE: -1.0286195390715075e-05\n",
            "E_IS_E_SCOPE: -8.978688053113097e-06\n",
            "Total Loss: 2.0814017401600554e-08\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "Var loss:  tensor(2.0284e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9995584575920467e-06\n",
            "E_s_wdiff_all_sq: 4.903411498157026e-07\n",
            "E_IS_SCOPE: -1.0275274070393226e-05\n",
            "E_IS_E_SCOPE: -8.968245836771698e-06\n",
            "Total Loss: 2.0283906966706e-08\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "Var loss:  tensor(1.9758e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9959596161206824e-06\n",
            "E_s_wdiff_all_sq: 4.873287085325954e-07\n",
            "E_IS_SCOPE: -1.0270748177989506e-05\n",
            "E_IS_E_SCOPE: -8.963750194366115e-06\n",
            "Total Loss: 1.9758006774719977e-08\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "Var loss:  tensor(1.9230e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9985455291651874e-06\n",
            "E_s_wdiff_all_sq: 4.888012164532013e-07\n",
            "E_IS_SCOPE: -1.0275088649430562e-05\n",
            "E_IS_E_SCOPE: -8.967270113601776e-06\n",
            "Total Loss: 1.9230307487831258e-08\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "Var loss:  tensor(1.8714e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9984234763651494e-06\n",
            "E_s_wdiff_all_sq: 4.890398871504153e-07\n",
            "E_IS_SCOPE: -1.0274631358936603e-05\n",
            "E_IS_E_SCOPE: -8.966734901051235e-06\n",
            "Total Loss: 1.8713739877413158e-08\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "Var loss:  tensor(1.8188e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.995669330630659e-06\n",
            "E_s_wdiff_all_sq: 4.884849641922127e-07\n",
            "E_IS_SCOPE: -1.0268853852534552e-05\n",
            "E_IS_E_SCOPE: -8.961794348471656e-06\n",
            "Total Loss: 1.8188424746071312e-08\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "Var loss:  tensor(1.7654e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0009154834961565e-06\n",
            "E_s_wdiff_all_sq: 4.935294380987902e-07\n",
            "E_IS_SCOPE: -1.0270804474898572e-05\n",
            "E_IS_E_SCOPE: -8.96337667772767e-06\n",
            "Total Loss: 1.7653517488978252e-08\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "Var loss:  tensor(1.7130e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0106833652765395e-06\n",
            "E_s_wdiff_all_sq: 5.017487333839017e-07\n",
            "E_IS_SCOPE: -1.0281921310143514e-05\n",
            "E_IS_E_SCOPE: -8.973457569561061e-06\n",
            "Total Loss: 1.7130217161146577e-08\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "Var loss:  tensor(1.6605e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0089824588572434e-06\n",
            "E_s_wdiff_all_sq: 5.016492865707103e-07\n",
            "E_IS_SCOPE: -1.0278737323103787e-05\n",
            "E_IS_E_SCOPE: -8.970811548136593e-06\n",
            "Total Loss: 1.6604688785559573e-08\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "Var loss:  tensor(1.6084e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0070264155972893e-06\n",
            "E_s_wdiff_all_sq: 5.007549154991957e-07\n",
            "E_IS_SCOPE: -1.0272246898742075e-05\n",
            "E_IS_E_SCOPE: -8.964591637726033e-06\n",
            "Total Loss: 1.6084044499427647e-08\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "Var loss:  tensor(1.5556e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.012614379042489e-06\n",
            "E_s_wdiff_all_sq: 5.052714628275577e-07\n",
            "E_IS_SCOPE: -1.027195239757e-05\n",
            "E_IS_E_SCOPE: -8.96349746351898e-06\n",
            "Total Loss: 1.5556114546305388e-08\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "Var loss:  tensor(1.5031e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.013095232489268e-06\n",
            "E_s_wdiff_all_sq: 5.063400791984594e-07\n",
            "E_IS_SCOPE: -1.0270091308184446e-05\n",
            "E_IS_E_SCOPE: -8.961667628328162e-06\n",
            "Total Loss: 1.503086001165506e-08\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "Var loss:  tensor(1.4512e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0101912815628833e-06\n",
            "E_s_wdiff_all_sq: 5.042761565991641e-07\n",
            "E_IS_SCOPE: -1.026830339652073e-05\n",
            "E_IS_E_SCOPE: -8.960040412371295e-06\n",
            "Total Loss: 1.4512223098265357e-08\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "Var loss:  tensor(1.3997e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0084034273743267e-06\n",
            "E_s_wdiff_all_sq: 5.021976627636277e-07\n",
            "E_IS_SCOPE: -1.0267541684777306e-05\n",
            "E_IS_E_SCOPE: -8.958875817994713e-06\n",
            "Total Loss: 1.399709747892942e-08\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "Var loss:  tensor(1.3472e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.00511133658807e-06\n",
            "E_s_wdiff_all_sq: 4.990444905324619e-07\n",
            "E_IS_SCOPE: -1.0264668437748381e-05\n",
            "E_IS_E_SCOPE: -8.955809287950449e-06\n",
            "Total Loss: 1.347161289316056e-08\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "Var loss:  tensor(1.2957e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9995328352099963e-06\n",
            "E_s_wdiff_all_sq: 4.94920380580167e-07\n",
            "E_IS_SCOPE: -1.0259141565745345e-05\n",
            "E_IS_E_SCOPE: -8.950752446623513e-06\n",
            "Total Loss: 1.2957282819580681e-08\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "Var loss:  tensor(1.2438e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0043148972001274e-06\n",
            "E_s_wdiff_all_sq: 4.998115661188598e-07\n",
            "E_IS_SCOPE: -1.0260549988734314e-05\n",
            "E_IS_E_SCOPE: -8.951955932629254e-06\n",
            "Total Loss: 1.2438285304563134e-08\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "Var loss:  tensor(1.1928e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.017045923761808e-06\n",
            "E_s_wdiff_all_sq: 5.117629193993071e-07\n",
            "E_IS_SCOPE: -1.0264801530970467e-05\n",
            "E_IS_E_SCOPE: -8.95556260317696e-06\n",
            "Total Loss: 1.1928215208904065e-08\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "Var loss:  tensor(1.1407e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.022310496883602e-06\n",
            "E_s_wdiff_all_sq: 5.1807453639443e-07\n",
            "E_IS_SCOPE: -1.0263127367008421e-05\n",
            "E_IS_E_SCOPE: -8.954151553771795e-06\n",
            "Total Loss: 1.1407400449336221e-08\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "Var loss:  tensor(1.0893e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.022981893181914e-06\n",
            "E_s_wdiff_all_sq: 5.200435764492271e-07\n",
            "E_IS_SCOPE: -1.0261679164788244e-05\n",
            "E_IS_E_SCOPE: -8.95309509235394e-06\n",
            "Total Loss: 1.0893238297497883e-08\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "Var loss:  tensor(1.0363e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0252071081959425e-06\n",
            "E_s_wdiff_all_sq: 5.22072554799289e-07\n",
            "E_IS_SCOPE: -1.0264293230275965e-05\n",
            "E_IS_E_SCOPE: -8.955346017061737e-06\n",
            "Total Loss: 1.0363193401614356e-08\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "Var loss:  tensor(9.8518e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.024914653712312e-06\n",
            "E_s_wdiff_all_sq: 5.216232890060248e-07\n",
            "E_IS_SCOPE: -1.0265907213115858e-05\n",
            "E_IS_E_SCOPE: -8.956625919005472e-06\n",
            "Total Loss: 9.851842918931338e-09\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "Var loss:  tensor(9.3458e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.022858531667642e-06\n",
            "E_s_wdiff_all_sq: 5.203457590253743e-07\n",
            "E_IS_SCOPE: -1.0265113927732144e-05\n",
            "E_IS_E_SCOPE: -8.955968912106792e-06\n",
            "Total Loss: 9.34580782497589e-09\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "Var loss:  tensor(8.8433e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0267006036201575e-06\n",
            "E_s_wdiff_all_sq: 5.240024881718483e-07\n",
            "E_IS_SCOPE: -1.0265307938302357e-05\n",
            "E_IS_E_SCOPE: -8.955818984906495e-06\n",
            "Total Loss: 8.843275090000414e-09\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "Var loss:  tensor(8.3281e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0309187340696747e-06\n",
            "E_s_wdiff_all_sq: 5.27899398606759e-07\n",
            "E_IS_SCOPE: -1.0263623009476016e-05\n",
            "E_IS_E_SCOPE: -8.953715860084739e-06\n",
            "Total Loss: 8.32810311377693e-09\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "Var loss:  tensor(7.8280e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0281283746860327e-06\n",
            "E_s_wdiff_all_sq: 5.260273939485552e-07\n",
            "E_IS_SCOPE: -1.026008809391416e-05\n",
            "E_IS_E_SCOPE: -8.950390061989873e-06\n",
            "Total Loss: 7.82798332232031e-09\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "Var loss:  tensor(7.3177e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0227103279590094e-06\n",
            "E_s_wdiff_all_sq: 5.218185022823556e-07\n",
            "E_IS_SCOPE: -1.0256673059719374e-05\n",
            "E_IS_E_SCOPE: -8.947324450068174e-06\n",
            "Total Loss: 7.317672807668958e-09\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "Var loss:  tensor(6.8026e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.019462041337302e-06\n",
            "E_s_wdiff_all_sq: 5.181756571681855e-07\n",
            "E_IS_SCOPE: -1.0257478020974765e-05\n",
            "E_IS_E_SCOPE: -8.947674594732654e-06\n",
            "Total Loss: 6.802598118311215e-09\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "Var loss:  tensor(6.2937e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.017559307781662e-06\n",
            "E_s_wdiff_all_sq: 5.15767650089832e-07\n",
            "E_IS_SCOPE: -1.0259784859273294e-05\n",
            "E_IS_E_SCOPE: -8.949474326275213e-06\n",
            "Total Loss: 6.2936581290822296e-09\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "Var loss:  tensor(5.7918e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.015137596547622e-06\n",
            "E_s_wdiff_all_sq: 5.142496071136681e-07\n",
            "E_IS_SCOPE: -1.025826412532849e-05\n",
            "E_IS_E_SCOPE: -8.948154477142417e-06\n",
            "Total Loss: 5.791759495222871e-09\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "Var loss:  tensor(5.2869e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.018153880339629e-06\n",
            "E_s_wdiff_all_sq: 5.18282217484924e-07\n",
            "E_IS_SCOPE: -1.0253491659292948e-05\n",
            "E_IS_E_SCOPE: -8.943637756711987e-06\n",
            "Total Loss: 5.286924126199414e-09\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "Var loss:  tensor(4.7711e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0276998155701463e-06\n",
            "E_s_wdiff_all_sq: 5.273901922229109e-07\n",
            "E_IS_SCOPE: -1.0251325775400617e-05\n",
            "E_IS_E_SCOPE: -8.94099496396742e-06\n",
            "Total Loss: 4.7710669142541285e-09\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "Var loss:  tensor(4.2629e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0401389272714813e-06\n",
            "E_s_wdiff_all_sq: 5.397492775917084e-07\n",
            "E_IS_SCOPE: -1.0251847532007956e-05\n",
            "E_IS_E_SCOPE: -8.941222628017317e-06\n",
            "Total Loss: 4.26290813190995e-09\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "Var loss:  tensor(3.7534e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.046950732785681e-06\n",
            "E_s_wdiff_all_sq: 5.480995169849807e-07\n",
            "E_IS_SCOPE: -1.0251311878486663e-05\n",
            "E_IS_E_SCOPE: -8.941201447996694e-06\n",
            "Total Loss: 3.753421254179856e-09\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "Var loss:  tensor(3.2414e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.051876139884322e-06\n",
            "E_s_wdiff_all_sq: 5.528963214159742e-07\n",
            "E_IS_SCOPE: -1.0254595066316716e-05\n",
            "E_IS_E_SCOPE: -8.944164340235894e-06\n",
            "Total Loss: 3.2414327401195762e-09\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "Var loss:  tensor(2.7303e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0530651413587383e-06\n",
            "E_s_wdiff_all_sq: 5.533114186064268e-07\n",
            "E_IS_SCOPE: -1.0257403787613617e-05\n",
            "E_IS_E_SCOPE: -8.946330523549091e-06\n",
            "Total Loss: 2.7302610566741994e-09\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.2101,  0.3801],\n",
            "        [ 0.7356, -0.4928],\n",
            "        [-0.0438, -0.4692],\n",
            "        [ 0.1624, -0.1203],\n",
            "        [-0.2191, -0.1823],\n",
            "        [-0.6192, -0.4586],\n",
            "        [ 0.4871,  0.4499],\n",
            "        [ 0.0730,  0.3805],\n",
            "        [-0.0262, -0.6044],\n",
            "        [-0.2140, -0.1630],\n",
            "        [-0.5518,  0.5047],\n",
            "        [ 0.6495, -0.4965],\n",
            "        [-0.6236, -0.0745],\n",
            "        [-0.0356,  0.3041],\n",
            "        [ 0.0052,  0.5972],\n",
            "        [-0.0604, -0.1989]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.0844, -0.5681,  0.6441,  0.6516, -0.5922, -0.1688, -0.1012,  0.3523,\n",
            "        -0.0529,  0.7032,  0.4311,  0.7167,  0.5218, -0.4728,  0.1729,  0.0767],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.0723,  0.0443, -0.2342,  0.2346,  0.2472, -0.1674, -0.2108,  0.2270,\n",
            "          0.2062, -0.2065, -0.0532,  0.0441, -0.1241,  0.0217,  0.0297,  0.2058],\n",
            "        [ 0.1407, -0.0838, -0.0309, -0.0524,  0.0307, -0.0390, -0.1469,  0.0782,\n",
            "         -0.1361,  0.3170, -0.2752, -0.2110, -0.1958, -0.0817, -0.2421,  0.2182],\n",
            "        [ 0.1490, -0.1923,  0.2114,  0.0494, -0.1272, -0.0874, -0.1222,  0.1429,\n",
            "          0.1397,  0.1364, -0.1316, -0.2463, -0.1448,  0.0281, -0.1215, -0.1329],\n",
            "        [ 0.1357, -0.1700, -0.1376, -0.0408, -0.2021, -0.0557,  0.0013, -0.0773,\n",
            "          0.2358,  0.1358, -0.1219,  0.0374,  0.0765,  0.2062,  0.0384, -0.2461],\n",
            "        [-0.1683,  0.2549, -0.0666, -0.2172, -0.2492,  0.2069,  0.2020, -0.0604,\n",
            "         -0.0837, -0.1553,  0.1239,  0.0097, -0.1396,  0.1377, -0.1685, -0.0125],\n",
            "        [-0.0887, -0.1167, -0.2472,  0.2480,  0.1460, -0.1333,  0.0869, -0.0297,\n",
            "          0.1020,  0.2673,  0.0181, -0.1046, -0.1542, -0.1216, -0.0773, -0.0919],\n",
            "        [ 0.0961, -0.1260,  0.2149,  0.0128, -0.0109, -0.1642,  0.0273,  0.1218,\n",
            "          0.0393,  0.1113, -0.1200, -0.2115,  0.0602,  0.0367, -0.0153, -0.1823],\n",
            "        [ 0.0389, -0.0843,  0.0426,  0.0417, -0.1042, -0.0314,  0.0859,  0.0507,\n",
            "          0.0765, -0.1602, -0.1115,  0.1037,  0.1218, -0.0143, -0.0750, -0.0884],\n",
            "        [ 0.0089,  0.4062,  0.1052, -0.0295,  0.1986, -0.1902,  0.2464, -0.0310,\n",
            "          0.1342,  0.0531, -0.2306,  0.0636, -0.1858, -0.2073, -0.1100, -0.2053],\n",
            "        [-0.0116, -0.2301, -0.0819, -0.0763,  0.1273, -0.1310,  0.1043,  0.1762,\n",
            "          0.1718,  0.0573, -0.1396, -0.1208,  0.1038,  0.1016, -0.1340,  0.2209],\n",
            "        [ 0.1314, -0.3478, -0.1507,  0.0981,  0.0243,  0.2286,  0.1045, -0.0915,\n",
            "         -0.0558,  0.0997, -0.1871,  0.1925,  0.0995,  0.0429, -0.0423, -0.1166],\n",
            "        [ 0.0751, -0.0163,  0.1346,  0.0925, -0.2416,  0.0813, -0.2958, -0.0724,\n",
            "          0.0433,  0.2542,  0.1256, -0.2655,  0.0154,  0.0138, -0.0757, -0.1927],\n",
            "        [ 0.2209, -0.0048,  0.0346, -0.2223,  0.0038,  0.0669, -0.1826,  0.1822,\n",
            "          0.2285,  0.0287, -0.1796, -0.0091,  0.0505, -0.1555, -0.0848,  0.1192],\n",
            "        [-0.0816,  0.0704,  0.0109, -0.1508, -0.0177,  0.2430,  0.1335, -0.2067,\n",
            "          0.0896, -0.2968,  0.2249, -0.1285, -0.0861, -0.0375,  0.1871,  0.0676],\n",
            "        [-0.1169, -0.1662,  0.0133,  0.1843, -0.2427, -0.2037, -0.1257, -0.0658,\n",
            "         -0.0482,  0.1870, -0.1433,  0.1704,  0.2412,  0.2343, -0.1149,  0.2100],\n",
            "        [-0.0814, -0.0236, -0.1137, -0.1326, -0.1443,  0.1173,  0.1302, -0.0051,\n",
            "          0.1721, -0.1738,  0.0825, -0.0336,  0.0855, -0.0797,  0.0132,  0.1194],\n",
            "        [-0.2904,  0.1067, -0.2938, -0.1049, -0.1551,  0.0998,  0.1479,  0.1157,\n",
            "         -0.1763, -0.1254,  0.0138,  0.2312, -0.1980,  0.1132, -0.2773, -0.2279],\n",
            "        [-0.1073, -0.1993,  0.1531,  0.0594,  0.0292,  0.0082,  0.0678, -0.0263,\n",
            "         -0.2444, -0.0980,  0.0504, -0.1207,  0.2453, -0.2473,  0.2290, -0.1811],\n",
            "        [ 0.0217,  0.1852, -0.0128,  0.0377, -0.0341,  0.1431, -0.2219,  0.0861,\n",
            "         -0.0946,  0.0917,  0.0913,  0.1392,  0.1109, -0.3874, -0.0792, -0.0132],\n",
            "        [ 0.1445, -0.0582, -0.2403, -0.0522,  0.1757,  0.0614,  0.1480, -0.0291,\n",
            "         -0.1732, -0.2209,  0.1266, -0.1022, -0.1371, -0.2013,  0.0909, -0.0258],\n",
            "        [-0.1988, -0.2591, -0.1653, -0.2291,  0.0325,  0.1640, -0.2165, -0.1013,\n",
            "          0.0831, -0.0624, -0.1373,  0.0671, -0.2039,  0.0062,  0.0244,  0.2164],\n",
            "        [ 0.0578,  0.1973, -0.0365,  0.2350, -0.1320, -0.0176, -0.2484,  0.0699,\n",
            "          0.1687, -0.1458,  0.0152,  0.1684, -0.2164, -0.1875,  0.2008,  0.1275],\n",
            "        [-0.2907,  0.1481,  0.2162,  0.1830, -0.0871, -0.1800,  0.0038,  0.1564,\n",
            "         -0.2033,  0.2414,  0.0755,  0.0118,  0.1514, -0.2136, -0.1369,  0.0037],\n",
            "        [ 0.0123,  0.1065,  0.1411,  0.1744,  0.0520,  0.0412, -0.2828, -0.1565,\n",
            "          0.2441,  0.0524,  0.2814, -0.1340,  0.0186, -0.1726, -0.1644,  0.1237],\n",
            "        [ 0.0383,  0.3420,  0.2942,  0.1720, -0.0857,  0.2014, -0.1948, -0.1641,\n",
            "         -0.0152,  0.1601,  0.1854, -0.0968,  0.3323, -0.0686, -0.0844,  0.1973],\n",
            "        [-0.2468, -0.1675, -0.1414,  0.1380,  0.2404, -0.1686, -0.0242,  0.0605,\n",
            "         -0.2336, -0.0629,  0.0349, -0.3694, -0.0238, -0.1747, -0.0088,  0.1758],\n",
            "        [-0.0784,  0.0665, -0.2722,  0.0654, -0.0289, -0.1542,  0.1631,  0.0431,\n",
            "         -0.2163,  0.1303,  0.1347, -0.1966, -0.1760, -0.0225, -0.2000,  0.1045],\n",
            "        [-0.0615,  0.3851,  0.2880, -0.1568, -0.1623, -0.1406, -0.2765,  0.0808,\n",
            "          0.0429,  0.0209, -0.1395,  0.0537,  0.1785,  0.1555,  0.1116, -0.2451],\n",
            "        [-0.0438, -0.0040, -0.2408, -0.1435, -0.0551,  0.1013, -0.0878,  0.0008,\n",
            "          0.2385, -0.1580,  0.1218, -0.1817, -0.0245,  0.0712, -0.0395,  0.0799],\n",
            "        [-0.0294, -0.1168, -0.1768, -0.4298, -0.0596, -0.1157, -0.0414, -0.1549,\n",
            "          0.0198,  0.2689,  0.0352, -0.1089,  0.0212, -0.1252,  0.1863,  0.1202],\n",
            "        [-0.0183, -0.0076, -0.0205,  0.2282, -0.0270, -0.0412, -0.0038, -0.0265,\n",
            "         -0.0269, -0.1750, -0.0062,  0.1763,  0.0688,  0.1550, -0.0042,  0.1926],\n",
            "        [-0.1474, -0.0022, -0.0472,  0.1161,  0.0839, -0.0988, -0.0731, -0.1240,\n",
            "          0.1890,  0.1056, -0.0994, -0.6337, -0.0903, -0.0600,  0.0467,  0.2175]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0023, -0.1293,  0.1437, -0.2342, -0.0009,  0.0433,  0.0330, -0.2351,\n",
            "         0.1822, -0.1495, -0.0861, -0.2659,  0.2627, -0.0961,  0.1377, -0.0565,\n",
            "         0.1741, -0.2573,  0.1343,  0.0675, -0.1959,  0.0510, -0.1727,  0.1640,\n",
            "         0.0957, -0.1765,  0.2066, -0.0127, -0.1928,  0.0063, -0.1169,  0.3009],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-9.1361e-03, -8.1587e-03, -8.1484e-02,  8.3674e-03, -1.3339e-02,\n",
            "         -5.7281e-02, -1.1561e-02,  7.4972e-02, -5.4146e-03,  1.7219e-02,\n",
            "         -2.5101e-02, -7.5459e-02,  7.2642e-02, -2.3989e-03, -1.5589e-01,\n",
            "         -8.0905e-03, -1.3245e-02,  9.6031e-05, -5.5253e-02,  3.6214e-03,\n",
            "         -2.3125e-01,  6.9517e-04, -1.6196e-02,  8.6999e-02, -6.9840e-02,\n",
            "          1.2434e-01,  1.4296e-02, -7.9747e-03,  5.2897e-02, -8.6052e-03,\n",
            "          7.8192e-02, -2.6261e-01]], dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0026], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model12 = train_var_play(model11, 500, 0.0001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TpygwFvCGOLV",
        "outputId": "2a9bcaca-aaaf-4e96-94e9-9f10930c3f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(2.2263e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0454397267940005e-06\n",
            "E_s_wdiff_all_sq: 5.467628114465457e-07\n",
            "E_IS_SCOPE: -1.0254970373924974e-05\n",
            "E_IS_E_SCOPE: -8.944183529765734e-06\n",
            "Total Loss: 2.2262934623888673e-09\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(6.5306e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.65793187982493e-06\n",
            "E_s_wdiff_all_sq: 1.2877612576471057e-07\n",
            "E_IS_SCOPE: -9.075641433495659e-06\n",
            "E_IS_E_SCOPE: -7.781154824562122e-06\n",
            "Total Loss: 6.530560262656123e-08\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(1.9184e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 3.6306633195734738e-06\n",
            "E_s_wdiff_all_sq: 1.7726246188113302e-06\n",
            "E_IS_SCOPE: -1.1890450153615224e-05\n",
            "E_IS_E_SCOPE: -1.0494788465396067e-05\n",
            "Total Loss: 1.9183839075724527e-07\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(3.7999e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.4990283990365634e-06\n",
            "E_s_wdiff_all_sq: 9.370953803085665e-07\n",
            "E_IS_SCOPE: -1.079701560358715e-05\n",
            "E_IS_E_SCOPE: -9.472486973329307e-06\n",
            "Total Loss: 3.799882464572611e-08\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(4.2666e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6728484945990395e-06\n",
            "E_s_wdiff_all_sq: 2.4253645884522285e-07\n",
            "E_IS_SCOPE: -9.249256192303062e-06\n",
            "E_IS_E_SCOPE: -7.992871776672937e-06\n",
            "Total Loss: 4.2666270926984354e-08\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(1.0662e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.608193151590466e-06\n",
            "E_s_wdiff_all_sq: 1.2806360816480075e-07\n",
            "E_IS_SCOPE: -8.765931068606625e-06\n",
            "E_IS_E_SCOPE: -7.51661677239007e-06\n",
            "Total Loss: 1.066240174259725e-07\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(4.5669e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8056038189969946e-06\n",
            "E_s_wdiff_all_sq: 3.2133003772692877e-07\n",
            "E_IS_SCOPE: -9.370670709967898e-06\n",
            "E_IS_E_SCOPE: -8.088806824909606e-06\n",
            "Total Loss: 4.566907758689896e-08\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(8.1549e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.3477212622009084e-06\n",
            "E_s_wdiff_all_sq: 8.180333063325221e-07\n",
            "E_IS_SCOPE: -1.0408065671711388e-05\n",
            "E_IS_E_SCOPE: -9.084737627037868e-06\n",
            "Total Loss: 8.154932954762701e-09\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(4.8483e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.9482423854384237e-06\n",
            "E_s_wdiff_all_sq: 1.328140216626351e-06\n",
            "E_IS_SCOPE: -1.1202955715851152e-05\n",
            "E_IS_E_SCOPE: -9.854584417812217e-06\n",
            "Total Loss: 4.8482639167617086e-08\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(5.7106e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.99805086697032e-06\n",
            "E_s_wdiff_all_sq: 1.3731808895837784e-06\n",
            "E_IS_SCOPE: -1.1319287672495042e-05\n",
            "E_IS_E_SCOPE: -9.972843998552723e-06\n",
            "Total Loss: 5.710569593531947e-08\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(1.5587e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.532865144912458e-06\n",
            "E_s_wdiff_all_sq: 9.922791607161005e-07\n",
            "E_IS_SCOPE: -1.0836657340886324e-05\n",
            "E_IS_E_SCOPE: -9.511596541181188e-06\n",
            "Total Loss: 1.5587451219502673e-08\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(2.8988e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0223316178676115e-06\n",
            "E_s_wdiff_all_sq: 5.476404855329914e-07\n",
            "E_IS_SCOPE: -1.0103498458886906e-05\n",
            "E_IS_E_SCOPE: -8.805040765470641e-06\n",
            "Total Loss: 2.8988119355073726e-09\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(3.1376e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7574157726583948e-06\n",
            "E_s_wdiff_all_sq: 2.883126171883475e-07\n",
            "E_IS_SCOPE: -9.535296196954057e-06\n",
            "E_IS_E_SCOPE: -8.25387102207524e-06\n",
            "Total Loss: 3.1375872145828754e-08\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(3.8228e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7052472153957135e-06\n",
            "E_s_wdiff_all_sq: 2.2872666677047923e-07\n",
            "E_IS_SCOPE: -9.418262156012151e-06\n",
            "E_IS_E_SCOPE: -8.136554509896575e-06\n",
            "Total Loss: 3.822832282749832e-08\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(1.1918e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7913785855639713e-06\n",
            "E_s_wdiff_all_sq: 3.1137623828872424e-07\n",
            "E_IS_SCOPE: -9.73522999509544e-06\n",
            "E_IS_E_SCOPE: -8.43862629482213e-06\n",
            "Total Loss: 1.191801316204334e-08\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(-4.8566e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0036845900537093e-06\n",
            "E_s_wdiff_all_sq: 4.94979475248252e-07\n",
            "E_IS_SCOPE: -1.0256996658681559e-05\n",
            "E_IS_E_SCOPE: -8.939839736762956e-06\n",
            "Total Loss: -4.85662598332864e-10\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(1.5389e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.2290155307542045e-06\n",
            "E_s_wdiff_all_sq: 6.732558133721486e-07\n",
            "E_IS_SCOPE: -1.0683645186787486e-05\n",
            "E_IS_E_SCOPE: -9.350898132367572e-06\n",
            "Total Loss: 1.5388674975643242e-08\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(2.3111e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.274936542776133e-06\n",
            "E_s_wdiff_all_sq: 7.047807549844749e-07\n",
            "E_IS_SCOPE: -1.079232018614846e-05\n",
            "E_IS_E_SCOPE: -9.456236285494397e-06\n",
            "Total Loss: 2.3111052916951816e-08\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(7.9511e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1049937209070637e-06\n",
            "E_s_wdiff_all_sq: 5.683517889969924e-07\n",
            "E_IS_SCOPE: -1.055909797818024e-05\n",
            "E_IS_E_SCOPE: -9.23219100822281e-06\n",
            "Total Loss: 7.951058428624494e-09\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(-2.4889e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8704765994039856e-06\n",
            "E_s_wdiff_all_sq: 3.761509426158727e-07\n",
            "E_IS_SCOPE: -1.0139025399839854e-05\n",
            "E_IS_E_SCOPE: -8.828056573225597e-06\n",
            "Total Loss: -2.4889300069854286e-09\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(6.7332e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7188875842519047e-06\n",
            "E_s_wdiff_all_sq: 2.43736449977665e-07\n",
            "E_IS_SCOPE: -9.770997087798155e-06\n",
            "E_IS_E_SCOPE: -8.47422661181701e-06\n",
            "Total Loss: 6.733248745365261e-09\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(1.4259e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6828102960631392e-06\n",
            "E_s_wdiff_all_sq: 2.107352975635334e-07\n",
            "E_IS_SCOPE: -9.654894028161382e-06\n",
            "E_IS_E_SCOPE: -8.363424427472517e-06\n",
            "Total Loss: 1.4258863555291614e-08\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(5.5985e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7499156544064517e-06\n",
            "E_s_wdiff_all_sq: 2.753077209570467e-07\n",
            "E_IS_SCOPE: -9.836817859364206e-06\n",
            "E_IS_E_SCOPE: -8.539751623021573e-06\n",
            "Total Loss: 5.598527197554554e-09\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(-3.0188e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9199213315060747e-06\n",
            "E_s_wdiff_all_sq: 4.282633078187896e-07\n",
            "E_IS_SCOPE: -1.0199640373845419e-05\n",
            "E_IS_E_SCOPE: -8.889740407281066e-06\n",
            "Total Loss: -3.01884300800533e-09\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(1.6337e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1379403932650914e-06\n",
            "E_s_wdiff_all_sq: 6.151188678561323e-07\n",
            "E_IS_SCOPE: -1.054162539355591e-05\n",
            "E_IS_E_SCOPE: -9.21846992273857e-06\n",
            "Total Loss: 1.633650207696397e-09\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(7.2470e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.272737573357248e-06\n",
            "E_s_wdiff_all_sq: 7.305798163246795e-07\n",
            "E_IS_SCOPE: -1.0679218140984182e-05\n",
            "E_IS_E_SCOPE: -9.349201205240987e-06\n",
            "Total Loss: 7.246951979593888e-09\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(2.0994e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.244149197724913e-06\n",
            "E_s_wdiff_all_sq: 7.125754440284311e-07\n",
            "E_IS_SCOPE: -1.0552396077269611e-05\n",
            "E_IS_E_SCOPE: -9.225097376676322e-06\n",
            "Total Loss: 2.0994189433187347e-09\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(-4.1642e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1072409416105232e-06\n",
            "E_s_wdiff_all_sq: 6.025610774163309e-07\n",
            "E_IS_SCOPE: -1.0245847636005125e-05\n",
            "E_IS_E_SCOPE: -8.928864093977677e-06\n",
            "Total Loss: -4.1641534272860706e-09\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(-1.4225e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.977730430989686e-06\n",
            "E_s_wdiff_all_sq: 4.947392966653689e-07\n",
            "E_IS_SCOPE: -9.933041141213564e-06\n",
            "E_IS_E_SCOPE: -8.628272815129899e-06\n",
            "Total Loss: -1.4224514095970944e-09\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(2.7102e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9293878724989144e-06\n",
            "E_s_wdiff_all_sq: 4.577848917958676e-07\n",
            "E_IS_SCOPE: -9.779328763147705e-06\n",
            "E_IS_E_SCOPE: -8.482320857905994e-06\n",
            "Total Loss: 2.7102366530397027e-09\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(-4.5556e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9831465700422948e-06\n",
            "E_s_wdiff_all_sq: 5.13713300620971e-07\n",
            "E_IS_SCOPE: -9.851801228994431e-06\n",
            "E_IS_E_SCOPE: -8.554295278679982e-06\n",
            "Total Loss: -4.555647741596266e-10\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(-4.7566e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1268637121412923e-06\n",
            "E_s_wdiff_all_sq: 6.461666938826711e-07\n",
            "E_IS_SCOPE: -1.00877837794804e-05\n",
            "E_IS_E_SCOPE: -8.782495414164582e-06\n",
            "Total Loss: -4.756645939598935e-09\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(-3.1391e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.296936988863881e-06\n",
            "E_s_wdiff_all_sq: 7.94248319390156e-07\n",
            "E_IS_SCOPE: -1.0341415715436838e-05\n",
            "E_IS_E_SCOPE: -9.025940283370465e-06\n",
            "Total Loss: -3.139128225602964e-09\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(-7.9965e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.388167147307035e-06\n",
            "E_s_wdiff_all_sq: 8.697817398213587e-07\n",
            "E_IS_SCOPE: -1.0471372414918928e-05\n",
            "E_IS_E_SCOPE: -9.149218353156198e-06\n",
            "Total Loss: -7.996496063676509e-10\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(-3.2679e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.3424686913632853e-06\n",
            "E_s_wdiff_all_sq: 8.272612205428611e-07\n",
            "E_IS_SCOPE: -1.0422966314532416e-05\n",
            "E_IS_E_SCOPE: -9.10116710545891e-06\n",
            "Total Loss: -3.2678808931710317e-09\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(-5.8994e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.2035525446867224e-06\n",
            "E_s_wdiff_all_sq: 7.041061742223488e-07\n",
            "E_IS_SCOPE: -1.0251540354566407e-05\n",
            "E_IS_E_SCOPE: -8.936305940591546e-06\n",
            "Total Loss: -5.899391051932471e-09\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(-4.3999e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.065288766853955e-06\n",
            "E_s_wdiff_all_sq: 5.809361454438431e-07\n",
            "E_IS_SCOPE: -1.0080679131466384e-05\n",
            "E_IS_E_SCOPE: -8.773741318620893e-06\n",
            "Total Loss: -4.399937847453072e-09\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(-3.0209e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.991715851293202e-06\n",
            "E_s_wdiff_all_sq: 5.15309182209182e-07\n",
            "E_IS_SCOPE: -1.002294481857319e-05\n",
            "E_IS_E_SCOPE: -8.720669496919584e-06\n",
            "Total Loss: -3.020907789773035e-09\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(-5.0437e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9970586119530063e-06\n",
            "E_s_wdiff_all_sq: 5.188513016666733e-07\n",
            "E_IS_SCOPE: -1.0110620654553642e-05\n",
            "E_IS_E_SCOPE: -8.806433618906716e-06\n",
            "Total Loss: -5.043694574100036e-09\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(-6.6662e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0569913583397095e-06\n",
            "E_s_wdiff_all_sq: 5.659813749117779e-07\n",
            "E_IS_SCOPE: -1.0279330213865076e-05\n",
            "E_IS_E_SCOPE: -8.967930591941114e-06\n",
            "Total Loss: -6.666193986576173e-09\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(-5.6267e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1153510287362964e-06\n",
            "E_s_wdiff_all_sq: 6.073533886343014e-07\n",
            "E_IS_SCOPE: -1.0414883075742426e-05\n",
            "E_IS_E_SCOPE: -9.095509383179949e-06\n",
            "Total Loss: -5.626678589540541e-09\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(-5.2464e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.112886907952283e-06\n",
            "E_s_wdiff_all_sq: 5.969161359064466e-07\n",
            "E_IS_SCOPE: -1.042978523463228e-05\n",
            "E_IS_E_SCOPE: -9.106615110591327e-06\n",
            "Total Loss: -5.246409602655439e-09\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(-6.8132e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.039923866230653e-06\n",
            "E_s_wdiff_all_sq: 5.30574700159961e-07\n",
            "E_IS_SCOPE: -1.031689196804094e-05\n",
            "E_IS_E_SCOPE: -8.99624923568608e-06\n",
            "Total Loss: -6.813232205611442e-09\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(-7.3928e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9441578551521687e-06\n",
            "E_s_wdiff_all_sq: 4.4916410118914387e-07\n",
            "E_IS_SCOPE: -1.0151281513607879e-05\n",
            "E_IS_E_SCOPE: -8.837526703431912e-06\n",
            "Total Loss: -7.392799955492662e-09\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(-6.5178e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8821676349355666e-06\n",
            "E_s_wdiff_all_sq: 3.9936381639448614e-07\n",
            "E_IS_SCOPE: -1.0037807575901622e-05\n",
            "E_IS_E_SCOPE: -8.7305852292044e-06\n",
            "Total Loss: -6.517808419948901e-09\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(-6.7853e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.883060704527282e-06\n",
            "E_s_wdiff_all_sq: 4.0428624088720274e-07\n",
            "E_IS_SCOPE: -1.0041732370649016e-05\n",
            "E_IS_E_SCOPE: -8.736390935578567e-06\n",
            "Total Loss: -6.785340067401595e-09\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(-8.0597e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.94533537712362e-06\n",
            "E_s_wdiff_all_sq: 4.603580130029238e-07\n",
            "E_IS_SCOPE: -1.0149056124069345e-05\n",
            "E_IS_E_SCOPE: -8.83997607268987e-06\n",
            "Total Loss: -8.059672204838145e-09\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(-8.1724e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.036555760763813e-06\n",
            "E_s_wdiff_all_sq: 5.386882930020705e-07\n",
            "E_IS_SCOPE: -1.0281581526552437e-05\n",
            "E_IS_E_SCOPE: -8.966000075588007e-06\n",
            "Total Loss: -8.172367733702172e-09\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(-7.7063e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1039205169944664e-06\n",
            "E_s_wdiff_all_sq: 5.96166041379565e-07\n",
            "E_IS_SCOPE: -1.0353639049823191e-05\n",
            "E_IS_E_SCOPE: -9.033347149177912e-06\n",
            "Total Loss: -7.70625924224273e-09\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(-8.2901e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1115693399332563e-06\n",
            "E_s_wdiff_all_sq: 6.047857123156647e-07\n",
            "E_IS_SCOPE: -1.0327009954743108e-05\n",
            "E_IS_E_SCOPE: -9.006911578708541e-06\n",
            "Total Loss: -8.290058018125898e-09\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(-9.0166e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0730990201433454e-06\n",
            "E_s_wdiff_all_sq: 5.76369688901628e-07\n",
            "E_IS_SCOPE: -1.0234164964291299e-05\n",
            "E_IS_E_SCOPE: -8.918730486870515e-06\n",
            "Total Loss: -9.016557166433678e-09\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(-8.8202e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0333898849087516e-06\n",
            "E_s_wdiff_all_sq: 5.476780900266462e-07\n",
            "E_IS_SCOPE: -1.0148520386632672e-05\n",
            "E_IS_E_SCOPE: -8.83869284565458e-06\n",
            "Total Loss: -8.820220640663851e-09\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(-8.8394e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0303466839366845e-06\n",
            "E_s_wdiff_all_sq: 5.496380813985817e-07\n",
            "E_IS_SCOPE: -1.0131618277069346e-05\n",
            "E_IS_E_SCOPE: -8.824282723437756e-06\n",
            "Total Loss: -8.839438291661334e-09\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(-9.5629e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.071353188420848e-06\n",
            "E_s_wdiff_all_sq: 5.870432309364803e-07\n",
            "E_IS_SCOPE: -1.0189145134420258e-05\n",
            "E_IS_E_SCOPE: -8.879647174873827e-06\n",
            "Total Loss: -9.5628951750787e-09\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(-9.8628e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1319225434191327e-06\n",
            "E_s_wdiff_all_sq: 6.380365940098327e-07\n",
            "E_IS_SCOPE: -1.0273122960965279e-05\n",
            "E_IS_E_SCOPE: -8.958687054734043e-06\n",
            "Total Loss: -9.862796619757214e-09\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(-9.6851e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1696649498068823e-06\n",
            "E_s_wdiff_all_sq: 6.677167580673232e-07\n",
            "E_IS_SCOPE: -1.0319913981473181e-05\n",
            "E_IS_E_SCOPE: -9.001535783660428e-06\n",
            "Total Loss: -9.68513745252954e-09\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(-1.0012e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.157701761166814e-06\n",
            "E_s_wdiff_all_sq: 6.557746591509468e-07\n",
            "E_IS_SCOPE: -1.0298095446149528e-05\n",
            "E_IS_E_SCOPE: -8.979564532562231e-06\n",
            "Total Loss: -1.0011658725310767e-08\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(-1.0537e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1083444142817814e-06\n",
            "E_s_wdiff_all_sq: 6.137402800020223e-07\n",
            "E_IS_SCOPE: -1.0229141090254144e-05\n",
            "E_IS_E_SCOPE: -8.914008818664182e-06\n",
            "Total Loss: -1.0537342466748804e-08\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(-1.0580e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0588787535783285e-06\n",
            "E_s_wdiff_all_sq: 5.723536189983016e-07\n",
            "E_IS_SCOPE: -1.0168141237396644e-05\n",
            "E_IS_E_SCOPE: -8.857026995763894e-06\n",
            "Total Loss: -1.0580282252057838e-08\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(-1.0683e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0404932774222043e-06\n",
            "E_s_wdiff_all_sq: 5.568538343567911e-07\n",
            "E_IS_SCOPE: -1.0160223961351329e-05\n",
            "E_IS_E_SCOPE: -8.85050113647764e-06\n",
            "Total Loss: -1.0683140248548155e-08\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(-1.1170e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.058299025902971e-06\n",
            "E_s_wdiff_all_sq: 5.705509876058819e-07\n",
            "E_IS_SCOPE: -1.0209825847674995e-05\n",
            "E_IS_E_SCOPE: -8.897805118531843e-06\n",
            "Total Loss: -1.1170353555799432e-08\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(-1.1406e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0901270627097105e-06\n",
            "E_s_wdiff_all_sq: 5.946714261195164e-07\n",
            "E_IS_SCOPE: -1.0275634508564324e-05\n",
            "E_IS_E_SCOPE: -8.959642263040774e-06\n",
            "Total Loss: -1.1405788023489006e-08\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(-1.1426e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1044643209911997e-06\n",
            "E_s_wdiff_all_sq: 6.038609792329203e-07\n",
            "E_IS_SCOPE: -1.030907090466257e-05\n",
            "E_IS_E_SCOPE: -8.990494736880702e-06\n",
            "Total Loss: -1.142592737204359e-08\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(-1.1745e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.085697139219106e-06\n",
            "E_s_wdiff_all_sq: 5.868093456695682e-07\n",
            "E_IS_SCOPE: -1.0288330525939115e-05\n",
            "E_IS_E_SCOPE: -8.970452580051253e-06\n",
            "Total Loss: -1.1745031792772768e-08\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(-1.2092e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.047154380205936e-06\n",
            "E_s_wdiff_all_sq: 5.549632068238898e-07\n",
            "E_IS_SCOPE: -1.0234604895454022e-05\n",
            "E_IS_E_SCOPE: -8.919902012283507e-06\n",
            "Total Loss: -1.209152652556809e-08\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(-1.2192e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.017162186569903e-06\n",
            "E_s_wdiff_all_sq: 5.310615526495849e-07\n",
            "E_IS_SCOPE: -1.019084382793026e-05\n",
            "E_IS_E_SCOPE: -8.87913575983426e-06\n",
            "Total Loss: -1.2192435838268324e-08\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(-1.2409e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0161724200981404e-06\n",
            "E_s_wdiff_all_sq: 5.312603184207926e-07\n",
            "E_IS_SCOPE: -1.018788869146272e-05\n",
            "E_IS_E_SCOPE: -8.87666664007372e-06\n",
            "Total Loss: -1.240893466723844e-08\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(-1.2773e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0428988421615277e-06\n",
            "E_s_wdiff_all_sq: 5.539229937661871e-07\n",
            "E_IS_SCOPE: -1.0222739984150881e-05\n",
            "E_IS_E_SCOPE: -8.909303854742165e-06\n",
            "Total Loss: -1.2773343988675469e-08\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(-1.2941e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.076200481918031e-06\n",
            "E_s_wdiff_all_sq: 5.815902528574173e-07\n",
            "E_IS_SCOPE: -1.0263462195842254e-05\n",
            "E_IS_E_SCOPE: -8.947125245419527e-06\n",
            "Total Loss: -1.2940605351425109e-08\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(-1.3090e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0915139289719753e-06\n",
            "E_s_wdiff_all_sq: 5.947428316835495e-07\n",
            "E_IS_SCOPE: -1.0274280079701651e-05\n",
            "E_IS_E_SCOPE: -8.956788238687128e-06\n",
            "Total Loss: -1.3089518307204045e-08\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(-1.3410e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.081608196225933e-06\n",
            "E_s_wdiff_all_sq: 5.878709593076894e-07\n",
            "E_IS_SCOPE: -1.0249122306728301e-05\n",
            "E_IS_E_SCOPE: -8.93298711846665e-06\n",
            "Total Loss: -1.3410073171642398e-08\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(-1.3650e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0618559211137135e-06\n",
            "E_s_wdiff_all_sq: 5.733219881087013e-07\n",
            "E_IS_SCOPE: -1.021148406058251e-05\n",
            "E_IS_E_SCOPE: -8.897830473701985e-06\n",
            "Total Loss: -1.365017432262253e-08\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(-1.3805e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0535637637923985e-06\n",
            "E_s_wdiff_all_sq: 5.679519160408657e-07\n",
            "E_IS_SCOPE: -1.0192157862549516e-05\n",
            "E_IS_E_SCOPE: -8.879887826466524e-06\n",
            "Total Loss: -1.3805157981037316e-08\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(-1.4072e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0663840449086025e-06\n",
            "E_s_wdiff_all_sq: 5.793946264130268e-07\n",
            "E_IS_SCOPE: -1.0204611607333337e-05\n",
            "E_IS_E_SCOPE: -8.891519487590294e-06\n",
            "Total Loss: -1.4071754557094975e-08\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(-1.4331e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0909028504966113e-06\n",
            "E_s_wdiff_all_sq: 5.998950380494457e-07\n",
            "E_IS_SCOPE: -1.0233972282377307e-05\n",
            "E_IS_E_SCOPE: -8.918741358588417e-06\n",
            "Total Loss: -1.4330968697198656e-08\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(-1.4510e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.109465215007962e-06\n",
            "E_s_wdiff_all_sq: 6.154703433585179e-07\n",
            "E_IS_SCOPE: -1.0253579130586587e-05\n",
            "E_IS_E_SCOPE: -8.936765289734745e-06\n",
            "Total Loss: -1.4509743620823597e-08\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(-1.4764e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1087995336194855e-06\n",
            "E_s_wdiff_all_sq: 6.155301512283624e-07\n",
            "E_IS_SCOPE: -1.0246530105306173e-05\n",
            "E_IS_E_SCOPE: -8.929951883834188e-06\n",
            "Total Loss: -1.4763994119431213e-08\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(-1.5028e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.093237095393229e-06\n",
            "E_s_wdiff_all_sq: 6.034111063565782e-07\n",
            "E_IS_SCOPE: -1.0219937106723515e-05\n",
            "E_IS_E_SCOPE: -8.904948493532769e-06\n",
            "Total Loss: -1.5028170911426167e-08\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(-1.5221e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.078180154434319e-06\n",
            "E_s_wdiff_all_sq: 5.91307000361544e-07\n",
            "E_IS_SCOPE: -1.019520344627778e-05\n",
            "E_IS_E_SCOPE: -8.88159497871888e-06\n",
            "Total Loss: -1.5220714611610247e-08\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(-1.5450e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.076155542762418e-06\n",
            "E_s_wdiff_all_sq: 5.893733451721251e-07\n",
            "E_IS_SCOPE: -1.0190543106159438e-05\n",
            "E_IS_E_SCOPE: -8.87686543224567e-06\n",
            "Total Loss: -1.545008380382493e-08\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(-1.5716e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0864177772724906e-06\n",
            "E_s_wdiff_all_sq: 5.971980885534593e-07\n",
            "E_IS_SCOPE: -1.0205015559041124e-05\n",
            "E_IS_E_SCOPE: -8.88998623011595e-06\n",
            "Total Loss: -1.5715902697901463e-08\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(-1.5931e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0969009367687504e-06\n",
            "E_s_wdiff_all_sq: 6.052145464012129e-07\n",
            "E_IS_SCOPE: -1.0222006612789805e-05\n",
            "E_IS_E_SCOPE: -8.905636546449801e-06\n",
            "Total Loss: -1.593067587905463e-08\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(-1.6155e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0955619619847117e-06\n",
            "E_s_wdiff_all_sq: 6.03834491251812e-07\n",
            "E_IS_SCOPE: -1.0222915566011725e-05\n",
            "E_IS_E_SCOPE: -8.906412696594876e-06\n",
            "Total Loss: -1.6155201667381245e-08\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a8a140889831>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-4dcebd0cbd6f>\u001b[0m in \u001b[0;36mtrain_var_play\u001b[0;34m(model, num_epochs, learning_rate, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_sums_states_weight_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_gamma_weight_states_last_sub_states_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_all_shaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS_SCOPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_all_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums_states_weight_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_weights_states_last_sub_states_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIS_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-314ae88ec427>\u001b[0m in \u001b[0;36mbootstrap_all_terms\u001b[0;34m(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# Sample indices with replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0msampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums_states_weight_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_bootstraps_lin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mreshaped_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msums_states_weight_diff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greater policy randomness in pi_b"
      ],
      "metadata": {
        "id": "mw24KxKZ4l8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 2, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e = experiment_actions(200, env, P_pi_e)\n",
        "model_200_2_p4 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)\n",
        "testing = SCOPE_variance_play(model_200_2_p4, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)\n",
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()\n"
      ],
      "metadata": {
        "id": "Qsp5-eqR4owZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference, weights_first = testing.prep_policies()"
      ],
      "metadata": {
        "id": "8ysYBr-r-AFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the variance within trajectories is quite low, which keeps the variance quite low, might need to consider normalizing in some manner, found this function of PDIS that does this based on maximum and minimum possible discounted reward\n",
        "\n",
        "https://github.com/hari-sikchi/safeRL/blob/master/importance_sampling/importance_sampling.py\n",
        "\n"
      ],
      "metadata": {
        "id": "SNvSFJCaOD_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '''\n",
        "# Per Decision Importance Sampling\n",
        "# reward: list of reward obtained per time step\n",
        "\n",
        "# gamma: discount factor\n",
        "# trajectory_reward_high: Maximum value of sum of discounted rewards in a trajectory\n",
        "# trajectory_reward_low: Minimum value of sum of discounted rewards in a trajectory\n",
        "\n",
        "# returns normalized estimate of reward under evaluation policy\n",
        "# '''\n",
        "\n",
        "# def per_decision_is(pi_b,pi_e,gamma,reward,trajectory_reward_high,trajectory_reward_low):\n",
        "#     horizon = len(reward)\n",
        "#     expected_reward = 0\n",
        "#     gamma_t = 1\n",
        "#     importance_weight = 1\n",
        "#     for t in range(1,horizon+1):\n",
        "#         importance_weight *= pi_e[t-1]/pi_b[t-1]\n",
        "#         expected_reward+= gamma_t * reward[t-1] *importance_weight\n",
        "#         gamma_t *= gamma\n",
        "\n",
        "#     return (expected_reward - trajectory_reward_low)/(trajectory_reward_high-trajectory_reward_low)"
      ],
      "metadata": {
        "id": "DYBdIiUKOP0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_reward_high = 0.9**16 * 1\n",
        "trajectory_reward_low = 0.9**7 * -1"
      ],
      "metadata": {
        "id": "jd8aOsLxVciK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0.9**80"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBzJV2LgXRRC",
        "outputId": "fb3ecaab-6753-4e24-be15-a207f564c369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00021847450052839255"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_reward_high"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZdhy9nIXAx-",
        "outputId": "c6ff4c60-09dd-4e07-fece-c372bb48a974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18530201888518416"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_reward_low"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKjqsz0hXD-s",
        "outputId": "48e2a73c-d7e8-4071-e919-3d6d09947e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.4782969000000001"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trajectory_reward_high-trajectory_reward_low)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CLW6JGnW-Xc",
        "outputId": "3f557d92-d255-4a04-9f3a-84a5b61c9249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6635989188851843"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cum_ratio = 1\n",
        "cumul_weights = []\n",
        "P_pi_e_probs = []\n",
        "P_pi_b_probs = []\n",
        "\n",
        "for step in pi_b[0]:\n",
        "    P_pi_b_prob = P_pi_b[tuple(np.append(step[0].astype(int), (step[1],)))]\n",
        "    P_pi_e_prob = P_pi_e[tuple(np.append(step[0].astype(int), (step[1],)))]\n",
        "\n",
        "    P_pi_b_probs.append(P_pi_b_prob)\n",
        "    P_pi_e_probs.append(P_pi_e_prob)\n",
        "\n",
        "    ratio = P_pi_e_prob / P_pi_b_prob\n",
        "    cum_ratio *= ratio\n",
        "    cumul_weights.append(cum_ratio)\n"
      ],
      "metadata": {
        "id": "aJX3KvmBZzvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8eE5sZAani4",
        "outputId": "59e0dfba-52dc-4ab6-e06f-8df805397465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_e[2,8,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HHyVC2nbugu",
        "outputId": "9078bda2-0225-44bc-af77-6a1bc4bc47fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb9-8ChfbIP9",
        "outputId": "17463c14-6ac0-471a-f9b5-c613ebd1c11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([([2., 9.], 1, 0., [2., 8.],  0, 3.),\n",
              "       ([2., 8.], 0, 0., [2., 8.],  1, 3.),\n",
              "       ([2., 8.], 1, 0., [2., 7.],  2, 3.),\n",
              "       ([2., 7.], 1, 0., [2., 6.],  3, 3.),\n",
              "       ([2., 6.], 3, 0., [1., 6.],  4, 3.),\n",
              "       ([1., 6.], 2, 0., [1., 7.],  5, 4.),\n",
              "       ([1., 7.], 3, 0., [0., 7.],  6, 4.),\n",
              "       ([0., 7.], 0, 0., [0., 7.],  7, 5.),\n",
              "       ([0., 7.], 1, 0., [0., 6.],  8, 5.),\n",
              "       ([0., 6.], 3, 0., [0., 6.],  9, 5.),\n",
              "       ([0., 6.], 1, 0., [0., 5.], 10, 5.),\n",
              "       ([0., 5.], 1, 0., [0., 4.], 11, 5.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 12, 6.),\n",
              "       ([0., 3.], 2, 0., [0., 4.], 13, 7.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 14, 6.),\n",
              "       ([0., 3.], 4, 0., [1., 3.], 15, 7.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 16, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 17, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 18, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 19, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 20, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 21, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 22, 5.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 23, 6.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 24, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 25, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 26, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 27, 5.),\n",
              "       ([1., 3.], 4, 0., [2., 3.], 28, 6.),\n",
              "       ([2., 3.], 1, 0., [2., 2.], 29, 5.),\n",
              "       ([2., 2.], 4, 0., [3., 2.], 30, 6.),\n",
              "       ([3., 2.], 4, 0., [4., 2.], 31, 5.),\n",
              "       ([4., 2.], 4, 0., [5., 2.], 32, 4.),\n",
              "       ([5., 2.], 3, 0., [4., 2.], 33, 3.),\n",
              "       ([4., 2.], 1, 0., [4., 1.], 34, 4.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 35, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 36, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 37, 5.),\n",
              "       ([4., 1.], 4, 0., [5., 1.], 38, 5.),\n",
              "       ([5., 1.], 0, 0., [5., 1.], 39, 4.),\n",
              "       ([5., 1.], 4, 0., [6., 1.], 40, 4.),\n",
              "       ([6., 1.], 3, 0., [5., 1.], 41, 4.),\n",
              "       ([5., 1.], 1, 1., [5., 0.], 42, 4.)],\n",
              "      dtype=[('state', '<f8', (2,)), ('action', '<i8'), ('reward', '<f8'), ('state_next', '<f8', (2,)), ('timestep', '<i8'), ('psi', '<f8')])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_e_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFZBF-V1av1q",
        "outputId": "029d57c9-0f53-4a66-f73d-a0b74b29ffd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHWedeeOZhg2",
        "outputId": "1d5f68a3-3695-475f-f14b-d7dda7f91c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([([2., 9.], 1, 0., [2., 8.],  0, 3.),\n",
              "       ([2., 8.], 0, 0., [2., 8.],  1, 3.),\n",
              "       ([2., 8.], 1, 0., [2., 7.],  2, 3.),\n",
              "       ([2., 7.], 1, 0., [2., 6.],  3, 3.),\n",
              "       ([2., 6.], 3, 0., [1., 6.],  4, 3.),\n",
              "       ([1., 6.], 2, 0., [1., 7.],  5, 4.),\n",
              "       ([1., 7.], 3, 0., [0., 7.],  6, 4.),\n",
              "       ([0., 7.], 0, 0., [0., 7.],  7, 5.),\n",
              "       ([0., 7.], 1, 0., [0., 6.],  8, 5.),\n",
              "       ([0., 6.], 3, 0., [0., 6.],  9, 5.),\n",
              "       ([0., 6.], 1, 0., [0., 5.], 10, 5.),\n",
              "       ([0., 5.], 1, 0., [0., 4.], 11, 5.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 12, 6.),\n",
              "       ([0., 3.], 2, 0., [0., 4.], 13, 7.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 14, 6.),\n",
              "       ([0., 3.], 4, 0., [1., 3.], 15, 7.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 16, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 17, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 18, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 19, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 20, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 21, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 22, 5.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 23, 6.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 24, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 25, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 26, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 27, 5.),\n",
              "       ([1., 3.], 4, 0., [2., 3.], 28, 6.),\n",
              "       ([2., 3.], 1, 0., [2., 2.], 29, 5.),\n",
              "       ([2., 2.], 4, 0., [3., 2.], 30, 6.),\n",
              "       ([3., 2.], 4, 0., [4., 2.], 31, 5.),\n",
              "       ([4., 2.], 4, 0., [5., 2.], 32, 4.),\n",
              "       ([5., 2.], 3, 0., [4., 2.], 33, 3.),\n",
              "       ([4., 2.], 1, 0., [4., 1.], 34, 4.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 35, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 36, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 37, 5.),\n",
              "       ([4., 1.], 4, 0., [5., 1.], 38, 5.),\n",
              "       ([5., 1.], 0, 0., [5., 1.], 39, 4.),\n",
              "       ([5., 1.], 4, 0., [6., 1.], 40, 4.),\n",
              "       ([6., 1.], 3, 0., [5., 1.], 41, 4.),\n",
              "       ([5., 1.], 1, 1., [5., 0.], 42, 4.)],\n",
              "      dtype=[('state', '<f8', (2,)), ('action', '<i8'), ('reward', '<f8'), ('state_next', '<f8', (2,)), ('timestep', '<i8'), ('psi', '<f8')])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aWPsckKYhao",
        "outputId": "10ac346c-55c2-4009-ccdc-57572fd970ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02631578947368421,\n",
              " 0.003289473684210526,\n",
              " 8.656509695290857e-05,\n",
              " 2.2780288671818044e-06,\n",
              " 5.755020296038243e-06,\n",
              " 7.193775370047803e-07,\n",
              " 1.817374830327866e-06,\n",
              " 2.2717185379098326e-07,\n",
              " 5.739078411561682e-07,\n",
              " 1.510283792516232e-08,\n",
              " 3.815453791619955e-08,\n",
              " 9.639041157776727e-08,\n",
              " 2.5365897783622966e-09,\n",
              " 6.408226808494222e-09,\n",
              " 1.686375475919532e-10,\n",
              " 4.437830199788242e-12,\n",
              " 1.167850052575853e-13,\n",
              " 1.4598125657198164e-14,\n",
              " 3.841612015052148e-16,\n",
              " 1.010950530276881e-17,\n",
              " 2.6603961323075813e-19,\n",
              " 7.001042453441003e-21,\n",
              " 1.7686844092903583e-20,\n",
              " 4.654432656027258e-22,\n",
              " 1.2248506989545416e-23,\n",
              " 1.531063373693177e-24,\n",
              " 4.029114141297834e-26,\n",
              " 1.0178814672752422e-25,\n",
              " 2.571490022590085e-25,\n",
              " 6.496395846543372e-25,\n",
              " 1.6411947401793782e-24,\n",
              " 2.0514934252242227e-25,\n",
              " 2.5643667815302784e-26,\n",
              " 6.748333635605995e-28,\n",
              " 1.7048421816267776e-27,\n",
              " 4.4864267937546775e-29,\n",
              " 1.1806386299354413e-30,\n",
              " 3.1069437629880036e-32,\n",
              " 7.849121085443377e-32,\n",
              " 2.065558180379836e-33,\n",
              " 2.581947725474795e-34,\n",
              " 6.79459927756525e-36,\n",
              " 1.7165303438059576e-35]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW62FfxyPmXv",
        "outputId": "0bd68c05-652b-4bf9-9b2b-7f685da4acf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.0551e-37],\n",
              "        [-4.8452e-12],\n",
              "        [ 3.4739e-26],\n",
              "        [ 1.9805e-52],\n",
              "        [ 5.6599e-30],\n",
              "        [ 3.6186e-28],\n",
              "        [ 1.2260e-37],\n",
              "        [ 3.3817e-61],\n",
              "        [ 4.8221e-73],\n",
              "        [ 8.0587e-33],\n",
              "        [ 2.3787e-34],\n",
              "        [ 2.5989e-18],\n",
              "        [ 1.1778e-45],\n",
              "        [ 1.5114e-51],\n",
              "        [ 1.0731e-23],\n",
              "        [ 3.1264e-31],\n",
              "        [ 4.8743e-37],\n",
              "        [ 6.9782e-22],\n",
              "        [ 7.5361e-54],\n",
              "        [ 6.3329e-16],\n",
              "        [ 2.5512e-42],\n",
              "        [ 2.8200e-22],\n",
              "        [ 1.0058e-30],\n",
              "        [ 3.5798e-20],\n",
              "        [ 4.5442e-51],\n",
              "        [ 2.2281e-20],\n",
              "        [ 1.8043e-30],\n",
              "        [ 1.2700e-46],\n",
              "        [ 1.1456e-37],\n",
              "        [ 6.1262e-48],\n",
              "        [ 2.1988e-26],\n",
              "        [ 9.2430e-31],\n",
              "        [ 7.5947e-22],\n",
              "        [ 1.7820e-57],\n",
              "        [ 5.8006e-42],\n",
              "        [ 1.3517e-53],\n",
              "        [ 3.3349e-24],\n",
              "        [ 2.6211e-40],\n",
              "        [ 3.5798e-20],\n",
              "        [ 4.9731e-44],\n",
              "        [ 1.4578e-21],\n",
              "        [ 1.0805e-47],\n",
              "        [ 4.2534e-27],\n",
              "        [ 5.4923e-36],\n",
              "        [ 6.1497e-65],\n",
              "        [ 4.9654e-13],\n",
              "        [ 5.3505e-26],\n",
              "        [ 8.9888e-45],\n",
              "        [ 5.7611e-29],\n",
              "        [ 7.7836e-34],\n",
              "        [ 1.5779e-72],\n",
              "        [ 1.0404e-41],\n",
              "        [ 2.3371e-46],\n",
              "        [ 9.4352e-81],\n",
              "        [ 3.2290e-11],\n",
              "        [ 4.4306e-29],\n",
              "        [ 3.4365e-51],\n",
              "        [ 1.2925e-56],\n",
              "        [ 2.5025e-12],\n",
              "        [ 4.0775e-27],\n",
              "        [ 2.8678e-22],\n",
              "        [ 1.2222e-30],\n",
              "        [ 1.4578e-21],\n",
              "        [ 2.2871e-63],\n",
              "        [ 5.4835e-38],\n",
              "        [ 3.2514e-35],\n",
              "        [ 1.7018e-40],\n",
              "        [ 2.5809e-27],\n",
              "        [ 2.1988e-26],\n",
              "        [ 4.2534e-27],\n",
              "        [ 2.5513e-09],\n",
              "        [ 7.7239e-33],\n",
              "        [ 1.1193e-56],\n",
              "        [ 1.7781e-38],\n",
              "        [ 1.2334e-29],\n",
              "        [ 4.0584e-22],\n",
              "        [ 3.5443e-33],\n",
              "        [ 8.8318e-24],\n",
              "        [ 9.1998e-26],\n",
              "        [ 2.5722e-86],\n",
              "        [ 6.8861e-61],\n",
              "        [ 1.8365e-18],\n",
              "        [ 7.6832e-51],\n",
              "        [ 2.4021e-76],\n",
              "        [ 1.3793e-38],\n",
              "        [ 2.0899e-37],\n",
              "        [ 7.6941e-49],\n",
              "        [ 1.6463e-39],\n",
              "        [ 2.2380e-14],\n",
              "        [ 3.2414e-28],\n",
              "        [ 7.0866e-68],\n",
              "        [ 5.7293e-36],\n",
              "        [ 5.2929e-51],\n",
              "        [ 5.2887e-74],\n",
              "        [ 2.3062e-41],\n",
              "        [ 1.6414e-43],\n",
              "        [-3.4057e-30],\n",
              "        [ 8.8247e-03],\n",
              "        [ 1.7765e-50],\n",
              "        [ 4.9887e-18],\n",
              "        [ 4.0674e-41],\n",
              "        [ 1.0160e-17],\n",
              "        [ 1.5528e-49],\n",
              "        [ 2.1922e-30],\n",
              "        [ 3.8162e-69],\n",
              "        [ 7.2350e-19],\n",
              "        [ 2.5045e-33],\n",
              "        [ 3.4055e-19],\n",
              "        [ 2.3513e-05],\n",
              "        [ 5.0422e-48],\n",
              "        [ 6.8240e-29],\n",
              "        [ 9.3633e-47],\n",
              "        [ 8.3418e-32],\n",
              "        [ 2.2923e-49],\n",
              "        [ 2.1254e-37],\n",
              "        [ 3.5520e-41],\n",
              "        [ 8.3229e-46],\n",
              "        [ 1.3941e-35],\n",
              "        [ 4.6152e-31],\n",
              "        [ 2.9757e-40],\n",
              "        [ 3.0548e-17],\n",
              "        [ 3.3840e-49],\n",
              "        [ 5.2120e-49],\n",
              "        [ 5.1606e-29],\n",
              "        [ 4.2992e-68],\n",
              "        [ 5.9680e-38],\n",
              "        [ 1.3750e-31],\n",
              "        [ 1.4399e-15],\n",
              "        [ 1.3528e-41],\n",
              "        [ 2.8285e-18],\n",
              "        [ 7.7903e-22],\n",
              "        [ 3.3477e-41],\n",
              "        [ 3.0735e-20],\n",
              "        [ 1.8867e-49],\n",
              "        [ 8.1149e-24],\n",
              "        [ 1.3770e-29],\n",
              "        [ 7.7060e-80],\n",
              "        [ 4.4817e-80],\n",
              "        [ 4.5307e-22],\n",
              "        [ 3.2290e-11],\n",
              "        [ 1.6822e-11],\n",
              "        [ 7.6477e-13],\n",
              "        [ 1.4522e-37],\n",
              "        [ 2.5868e-13],\n",
              "        [ 2.8458e-21],\n",
              "        [ 2.2885e-40],\n",
              "        [ 5.8138e-28],\n",
              "        [ 5.9731e-26],\n",
              "        [ 2.7447e-57],\n",
              "        [ 2.6010e-39],\n",
              "        [ 9.6121e-24],\n",
              "        [ 4.9462e-29],\n",
              "        [ 3.8070e-50],\n",
              "        [ 9.5384e-23],\n",
              "        [ 2.5220e-24],\n",
              "        [ 2.1554e-52],\n",
              "        [ 3.4233e-34],\n",
              "        [ 6.8237e-62],\n",
              "        [ 3.6295e-24],\n",
              "        [ 1.6450e-18],\n",
              "        [ 5.3580e-24],\n",
              "        [ 1.2908e-69],\n",
              "        [ 3.2891e-53],\n",
              "        [ 5.0490e-79],\n",
              "        [ 7.1123e-41],\n",
              "        [ 2.7154e-16],\n",
              "        [ 2.3602e-55],\n",
              "        [ 1.0796e-26],\n",
              "        [ 1.3395e-21],\n",
              "        [ 2.1420e-16],\n",
              "        [ 1.7903e-51],\n",
              "        [ 8.2912e-29],\n",
              "        [ 1.9561e-46],\n",
              "        [ 1.9367e-59],\n",
              "        [ 1.1474e-35],\n",
              "        [ 2.1940e-51],\n",
              "        [ 4.6369e-36],\n",
              "        [ 7.4787e-20],\n",
              "        [ 5.2844e-53],\n",
              "        [ 9.0940e-41],\n",
              "        [ 9.3196e-42],\n",
              "        [ 8.4854e-43],\n",
              "        [ 1.3373e-12],\n",
              "        [ 8.2775e-64],\n",
              "        [ 9.8046e-64],\n",
              "        [ 5.5902e-24],\n",
              "        [ 1.0955e-51],\n",
              "        [ 7.9969e-32],\n",
              "        [ 5.8862e-34],\n",
              "        [ 9.6572e-29],\n",
              "        [ 9.2704e-60],\n",
              "        [ 8.7830e-31],\n",
              "        [ 5.6165e-29],\n",
              "        [ 3.2864e-32],\n",
              "        [ 1.0880e-27],\n",
              "        [ 7.0969e-33],\n",
              "        [ 4.6944e-75],\n",
              "        [ 3.7112e-83],\n",
              "        [ 1.0191e-46],\n",
              "        [ 6.0707e-49]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.var(IS_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MENIklmqKgq6",
        "outputId": "dadbf702-f264-4417-c359-13f26c689133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8937e-07, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(IS_tensor**2) - torch.mean(IS_tensor)**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjd3r5nCMFWG",
        "outputId": "7411b265-8782-41bf-f250-2a3fd7dda739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8742e-07, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(IS_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSBBkdn5LpI0",
        "outputId": "a988c264-2707-486b-956e-c5ba6a45e43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.4241e-05, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(weights[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmC6YFqmHzcL",
        "outputId": "f0ed6cf3-a94f-42da-8a1e-e075b2db1b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(weights_difference[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DI1Hfg1JWRu",
        "outputId": "9a4045e7-e683-4fb0-bb34-38db58f495d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pi_b[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FflnxUpHpPC",
        "outputId": "b530f2e9-b988-4d9c-e85e-2e5180146932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single cumprod\n",
        "# 200 trajectories\n",
        "model_200_2_p4 = train_var_play(model_200_2_p4, 200, 0.001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_WriHen4pWo",
        "outputId": "3662f880-4886-4038-eeb8-608e6f25a4d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(1.1985, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 2.297909386211681\n",
            "E_s_wdiff_all_sq: 1.0994508765271211\n",
            "E_IS_SCOPE: 3.878983758204295e-05\n",
            "E_IS_E_SCOPE: 3.843762575160876e-05\n",
            "Total Loss: 1.1984592160084957\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(0.0416, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.04392587686827187\n",
            "E_s_wdiff_all_sq: 0.0023080316182087575\n",
            "E_IS_SCOPE: -8.007193464295585e-06\n",
            "E_IS_E_SCOPE: -7.634354580536492e-06\n",
            "Total Loss: 0.04161710147257035\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(0.0388, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03925886301233597\n",
            "E_s_wdiff_all_sq: 0.0004488434884700709\n",
            "E_IS_SCOPE: -7.451422098909373e-06\n",
            "E_IS_E_SCOPE: -7.078667767300758e-06\n",
            "Total Loss: 0.03880927591547743\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(0.0362, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03618221541199196\n",
            "E_s_wdiff_all_sq: 1.5627195795477096e-05\n",
            "E_IS_SCOPE: -6.73635978293311e-06\n",
            "E_IS_E_SCOPE: -6.363300668902292e-06\n",
            "Total Loss: 0.03616584399824317\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(0.0341, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03483415076299158\n",
            "E_s_wdiff_all_sq: 0.0007483471171284855\n",
            "E_IS_SCOPE: -5.954896256454207e-06\n",
            "E_IS_E_SCOPE: -5.581613167763779e-06\n",
            "Total Loss: 0.03408505897996047\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(0.0327, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03500008997453642\n",
            "E_s_wdiff_all_sq: 0.002299828566122942\n",
            "E_IS_SCOPE: -5.201083616526263e-06\n",
            "E_IS_E_SCOPE: -4.8279615663606775e-06\n",
            "Total Loss: 0.032699517064587895\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03627056723217435\n",
            "E_s_wdiff_all_sq: 0.004386374656823539\n",
            "E_IS_SCOPE: -4.4822491843661086e-06\n",
            "E_IS_E_SCOPE: -4.109621191323106e-06\n",
            "Total Loss: 0.03188344921963948\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03824929035390946\n",
            "E_s_wdiff_all_sq: 0.006738201877200653\n",
            "E_IS_SCOPE: -3.82324042087388e-06\n",
            "E_IS_E_SCOPE: -3.4514823381124335e-06\n",
            "Total Loss: 0.031510346860818036\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.040508941581502686\n",
            "E_s_wdiff_all_sq: 0.009076811804137457\n",
            "E_IS_SCOPE: -3.245941847961306e-06\n",
            "E_IS_E_SCOPE: -2.8754542389428553e-06\n",
            "Total Loss: 0.03143139070242195\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.042621271923216415\n",
            "E_s_wdiff_all_sq: 0.011158634778542032\n",
            "E_IS_SCOPE: -2.765903893180527e-06\n",
            "E_IS_E_SCOPE: -2.3967410027452646e-06\n",
            "Total Loss: 0.03146190071916826\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.044266651997166125\n",
            "E_s_wdiff_all_sq: 0.01281841741840197\n",
            "E_IS_SCOPE: -2.389031988940191e-06\n",
            "E_IS_E_SCOPE: -2.0209475150507352e-06\n",
            "Total Loss: 0.03144750031009113\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.045239818172975184\n",
            "E_s_wdiff_all_sq: 0.013948519258881251\n",
            "E_IS_SCOPE: -2.1186112441408252e-06\n",
            "E_IS_E_SCOPE: -1.7521169803677011e-06\n",
            "Total Loss: 0.03129056782584114\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0454763667053736\n",
            "E_s_wdiff_all_sq: 0.014534955972714323\n",
            "E_IS_SCOPE: -1.946147086723511e-06\n",
            "E_IS_E_SCOPE: -1.581752904500871e-06\n",
            "Total Loss: 0.030940683844569578\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.044982254200287265\n",
            "E_s_wdiff_all_sq: 0.014590674951117004\n",
            "E_IS_SCOPE: -1.8653044406692305e-06\n",
            "E_IS_E_SCOPE: -1.5035736953486128e-06\n",
            "Total Loss: 0.030390857687954374\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.04385896261366019\n",
            "E_s_wdiff_all_sq: 0.014184396941775479\n",
            "E_IS_SCOPE: -1.8642884714399405e-06\n",
            "E_IS_E_SCOPE: -1.5055700636623406e-06\n",
            "Total Loss: 0.02967385013534391\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.04223117382857745\n",
            "E_s_wdiff_all_sq: 0.013393948540381943\n",
            "E_IS_SCOPE: -1.9327902088660277e-06\n",
            "E_IS_E_SCOPE: -1.5773754704137532e-06\n",
            "Total Loss: 0.02883651635899335\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.040272442555752234\n",
            "E_s_wdiff_all_sq: 0.012329139230491027\n",
            "E_IS_SCOPE: -2.0548381139786605e-06\n",
            "E_IS_E_SCOPE: -1.7029494763619422e-06\n",
            "Total Loss: 0.027942601448260725\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03815787516764467\n",
            "E_s_wdiff_all_sq: 0.011103359885243462\n",
            "E_IS_SCOPE: -2.214917342017269e-06\n",
            "E_IS_E_SCOPE: -1.8667013467230403e-06\n",
            "Total Loss: 0.027053820750685374\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(0.0262, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.036045122030530674\n",
            "E_s_wdiff_all_sq: 0.009819596471660913\n",
            "E_IS_SCOPE: -2.394384643898371e-06\n",
            "E_IS_E_SCOPE: -2.049887566771903e-06\n",
            "Total Loss: 0.026224838464990262\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(0.0255, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.034048284507499645\n",
            "E_s_wdiff_all_sq: 0.00856380955915508\n",
            "E_IS_SCOPE: -2.578006777514063e-06\n",
            "E_IS_E_SCOPE: -2.2373787193848528e-06\n",
            "Total Loss: 0.025483795592503057\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(0.0248, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03210011705996097\n",
            "E_s_wdiff_all_sq: 0.007265569052274326\n",
            "E_IS_SCOPE: -2.7869321418720623e-06\n",
            "E_IS_E_SCOPE: -2.4503620409244804e-06\n",
            "Total Loss: 0.024833876767759503\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(0.0243, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03035880143875993\n",
            "E_s_wdiff_all_sq: 0.0060609501289704635\n",
            "E_IS_SCOPE: -2.9886672191389325e-06\n",
            "E_IS_E_SCOPE: -2.656169330458181e-06\n",
            "Total Loss: 0.024297188214286856\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(0.0239, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.028893437377904292\n",
            "E_s_wdiff_all_sq: 0.005036224433765073\n",
            "E_IS_SCOPE: -3.1565300334446345e-06\n",
            "E_IS_E_SCOPE: -2.8279737328275426e-06\n",
            "Total Loss: 0.023856557731812736\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(0.0235, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.027683324209120598\n",
            "E_s_wdiff_all_sq: 0.00420977443350421\n",
            "E_IS_SCOPE: -3.2748137328653198e-06\n",
            "E_IS_E_SCOPE: -2.9499748416950865e-06\n",
            "Total Loss: 0.023472901998108798\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(0.0231, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.026686837610308146\n",
            "E_s_wdiff_all_sq: 0.0035836433560412716\n",
            "E_IS_SCOPE: -3.331727970206348e-06\n",
            "E_IS_E_SCOPE: -3.0105376470245005e-06\n",
            "Total Loss: 0.023102553773895265\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(0.0227, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.025847027049085376\n",
            "E_s_wdiff_all_sq: 0.003139009703658511\n",
            "E_IS_SCOPE: -3.321684196379081e-06\n",
            "E_IS_E_SCOPE: -3.0038344210674964e-06\n",
            "Total Loss: 0.02270738354615099\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.025110536788134106\n",
            "E_s_wdiff_all_sq: 0.0028530780417820333\n",
            "E_IS_SCOPE: -3.2439638220504366e-06\n",
            "E_IS_E_SCOPE: -2.9291155523118645e-06\n",
            "Total Loss: 0.022256830950087344\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(0.0217, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02445254827845828\n",
            "E_s_wdiff_all_sq: 0.0027121430335832987\n",
            "E_IS_SCOPE: -3.0950811895847455e-06\n",
            "E_IS_E_SCOPE: -2.7828293869470027e-06\n",
            "Total Loss: 0.021739782641544456\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(0.0212, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.023862469079324513\n",
            "E_s_wdiff_all_sq: 0.002687277465738614\n",
            "E_IS_SCOPE: -2.8846996881920006e-06\n",
            "E_IS_E_SCOPE: -2.5747940778952074e-06\n",
            "Total Loss: 0.02117457370264006\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(0.0206, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02334199743582177\n",
            "E_s_wdiff_all_sq: 0.00275876791942823\n",
            "E_IS_SCOPE: -2.6212076654539654e-06\n",
            "E_IS_E_SCOPE: -2.3133736047279843e-06\n",
            "Total Loss: 0.020582615748546838\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(0.0200, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0228877954925864\n",
            "E_s_wdiff_all_sq: 0.00290140251193011\n",
            "E_IS_SCOPE: -2.3180876457147406e-06\n",
            "E_IS_E_SCOPE: -2.0120692325446993e-06\n",
            "Total Loss: 0.019985782844104703\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.022499263463222115\n",
            "E_s_wdiff_all_sq: 0.0030931384249713507\n",
            "E_IS_SCOPE: -1.9912770986092742e-06\n",
            "E_IS_E_SCOPE: -1.686844240184114e-06\n",
            "Total Loss: 0.019405518072808665\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02218138527822573\n",
            "E_s_wdiff_all_sq: 0.003315533238852356\n",
            "E_IS_SCOPE: -1.6519068431043025e-06\n",
            "E_IS_E_SCOPE: -1.3489632049508678e-06\n",
            "Total Loss: 0.018865248052371816\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.021939676598509893\n",
            "E_s_wdiff_all_sq: 0.00357011099691371\n",
            "E_IS_SCOPE: -1.3011227865717189e-06\n",
            "E_IS_E_SCOPE: -1.0006736465147596e-06\n",
            "Total Loss: 0.01836896660359082\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02169695958143122\n",
            "E_s_wdiff_all_sq: 0.003766596027349277\n",
            "E_IS_SCOPE: -9.76442423531455e-07\n",
            "E_IS_E_SCOPE: -6.791607499717546e-07\n",
            "Total Loss: 0.01792977089100958\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(0.0175, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.021367123602767508\n",
            "E_s_wdiff_all_sq: 0.00384817055518921\n",
            "E_IS_SCOPE: -6.995754675542332e-07\n",
            "E_IS_E_SCOPE: -4.0584075933746697e-07\n",
            "Total Loss: 0.017518367478436617\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(0.0171, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02084119261402764\n",
            "E_s_wdiff_all_sq: 0.003728740153148207\n",
            "E_IS_SCOPE: -4.962908312687996e-07\n",
            "E_IS_E_SCOPE: -2.0787027719281508e-07\n",
            "Total Loss: 0.01711187752004603\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02015661990200089\n",
            "E_s_wdiff_all_sq: 0.003452574263615173\n",
            "E_IS_SCOPE: -3.5428511539102974e-07\n",
            "E_IS_E_SCOPE: -7.174935513163259e-08\n",
            "Total Loss: 0.01670348246713995\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(0.0163, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.019171650322192545\n",
            "E_s_wdiff_all_sq: 0.002899953543942618\n",
            "E_IS_SCOPE: -3.236982939354758e-07\n",
            "E_IS_E_SCOPE: -4.786063992429541e-08\n",
            "Total Loss: 0.016271147003216656\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.01816520961836425\n",
            "E_s_wdiff_all_sq: 0.0023204547289400346\n",
            "E_IS_SCOPE: -3.259520373806938e-07\n",
            "E_IS_E_SCOPE: -5.7348620134436905e-08\n",
            "Total Loss: 0.01584421958286447\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(0.0155, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.017220117575009262\n",
            "E_s_wdiff_all_sq: 0.0017643030091933796\n",
            "E_IS_SCOPE: -3.5217191558103625e-07\n",
            "E_IS_E_SCOPE: -9.12109017177355e-08\n",
            "Total Loss: 0.015455294544062907\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.016420745982184005\n",
            "E_s_wdiff_all_sq: 0.001303225480171744\n",
            "E_IS_SCOPE: -3.719972859653301e-07\n",
            "E_IS_E_SCOPE: -1.2056273848951452e-07\n",
            "Total Loss: 0.015117019533192059\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.01576500741449024\n",
            "E_s_wdiff_all_sq: 0.0009415106538215532\n",
            "E_IS_SCOPE: -3.5853933490358923e-07\n",
            "E_IS_E_SCOPE: -1.1643066324927331e-07\n",
            "Total Loss: 0.01482301444360013\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(0.0145, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.015234540157521206\n",
            "E_s_wdiff_all_sq: 0.0006907269713655656\n",
            "E_IS_SCOPE: -3.0736108187771806e-07\n",
            "E_IS_E_SCOPE: -7.377243254886983e-08\n",
            "Total Loss: 0.014543347909131737\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.014775702376684519\n",
            "E_s_wdiff_all_sq: 0.000515355339383985\n",
            "E_IS_SCOPE: -2.3301816794342082e-07\n",
            "E_IS_E_SCOPE: -7.519761420032742e-09\n",
            "Total Loss: 0.014259897940762241\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.014392534465630536\n",
            "E_s_wdiff_all_sq: 0.00042761431519573815\n",
            "E_IS_SCOPE: -1.049192526817825e-07\n",
            "E_IS_E_SCOPE: 1.1335665116636626e-07\n",
            "Total Loss: 0.013964485498901856\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.014067031877123798\n",
            "E_s_wdiff_all_sq: 0.00040057910337717485\n",
            "E_IS_SCOPE: 6.670478460470299e-08\n",
            "E_IS_E_SCOPE: 2.78495260210021e-07\n",
            "Total Loss: 0.013666031093070167\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013789714953882109\n",
            "E_s_wdiff_all_sq: 0.00041245234746356015\n",
            "E_IS_SCOPE: 2.673981181367783e-07\n",
            "E_IS_E_SCOPE: 4.7321575210973444e-07\n",
            "Total Loss: 0.013376852871425355\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013556134420975323\n",
            "E_s_wdiff_all_sq: 0.00044693663210773057\n",
            "E_IS_SCOPE: 4.837544551306583e-07\n",
            "E_IS_E_SCOPE: 6.838840547672098e-07\n",
            "Total Loss: 0.013108799429943073\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013344168280251149\n",
            "E_s_wdiff_all_sq: 0.00048146223359412635\n",
            "E_IS_SCOPE: 6.958703707207129e-07\n",
            "E_IS_E_SCOPE: 8.902933590755734e-07\n",
            "Total Loss: 0.012862319100955066\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013128497113832781\n",
            "E_s_wdiff_all_sq: 0.0004947913318387111\n",
            "E_IS_SCOPE: 8.819550360020273e-07\n",
            "E_IS_E_SCOPE: 1.07036226466189e-06\n",
            "Total Loss: 0.012633330867811505\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.012888148026360948\n",
            "E_s_wdiff_all_sq: 0.00047671112836318146\n",
            "E_IS_SCOPE: 1.0334036262810518e-06\n",
            "E_IS_E_SCOPE: 1.2153569936101924e-06\n",
            "Total Loss: 0.012411074891537862\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.012611285251020059\n",
            "E_s_wdiff_all_sq: 0.0004208746598268171\n",
            "E_IS_SCOPE: 1.1424879654273389e-06\n",
            "E_IS_E_SCOPE: 1.3173864995723452e-06\n",
            "Total Loss: 0.012190062694399706\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.012293206601517117\n",
            "E_s_wdiff_all_sq: 0.00032659131231060353\n",
            "E_IS_SCOPE: 1.200809310645725e-06\n",
            "E_IS_E_SCOPE: 1.3680133678632635e-06\n",
            "Total Loss: 0.011966282781366832\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011953148298318882\n",
            "E_s_wdiff_all_sq: 0.00020929931751925048\n",
            "E_IS_SCOPE: 1.2111480021756202e-06\n",
            "E_IS_E_SCOPE: 1.370250048353744e-06\n",
            "Total Loss: 0.011743532676982029\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011645708295181655\n",
            "E_s_wdiff_all_sq: 0.00010824049892926428\n",
            "E_IS_SCOPE: 1.2012511809202424e-06\n",
            "E_IS_E_SCOPE: 1.3520291652705321e-06\n",
            "Total Loss: 0.011537168140558442\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011390184585635009\n",
            "E_s_wdiff_all_sq: 4.2006434280738924e-05\n",
            "E_IS_SCOPE: 1.1931914026906156e-06\n",
            "E_IS_E_SCOPE: 1.3357072338403815e-06\n",
            "Total Loss: 0.011347895019966723\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011182751502713443\n",
            "E_s_wdiff_all_sq: 1.0410333692265589e-05\n",
            "E_IS_SCOPE: 1.207172404805416e-06\n",
            "E_IS_E_SCOPE: 1.3418427795148682e-06\n",
            "Total Loss: 0.011172073728546512\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.01100348079444672\n",
            "E_s_wdiff_all_sq: 9.079580379452349e-07\n",
            "E_IS_SCOPE: 1.2548485067268862e-06\n",
            "E_IS_E_SCOPE: 1.3822636411868356e-06\n",
            "Total Loss: 0.011002319906414608\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010836025698227928\n",
            "E_s_wdiff_all_sq: 1.3815001815035173e-07\n",
            "E_IS_SCOPE: 1.3363864376115195e-06\n",
            "E_IS_E_SCOPE: 1.4571433487103514e-06\n",
            "Total Loss: 0.010835647934662332\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010668746086285097\n",
            "E_s_wdiff_all_sq: 5.618208118544752e-07\n",
            "E_IS_SCOPE: 1.452084320592511e-06\n",
            "E_IS_E_SCOPE: 1.5668181991774236e-06\n",
            "Total Loss: 0.010667956697990828\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0105050270238876\n",
            "E_s_wdiff_all_sq: 2.0560060934047763e-07\n",
            "E_IS_SCOPE: 1.5908895916688176e-06\n",
            "E_IS_E_SCOPE: 1.7000739559691682e-06\n",
            "Total Loss: 0.010504604954824413\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010351152255609296\n",
            "E_s_wdiff_all_sq: 1.9453383284759797e-09\n",
            "E_IS_SCOPE: 1.73403924650792e-06\n",
            "E_IS_E_SCOPE: 1.8378746227886796e-06\n",
            "Total Loss: 0.01035094453979316\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010207433070852897\n",
            "E_s_wdiff_all_sq: 3.8801967234060255e-08\n",
            "E_IS_SCOPE: 1.8596894964328984e-06\n",
            "E_IS_E_SCOPE: 1.958050106032603e-06\n",
            "Total Loss: 0.010207199447941216\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010069114085118094\n",
            "E_s_wdiff_all_sq: 1.202498069755943e-07\n",
            "E_IS_SCOPE: 1.95333524059022e-06\n",
            "E_IS_E_SCOPE: 2.0459116797379765e-06\n",
            "Total Loss: 0.010068810582707578\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00993492218837907\n",
            "E_s_wdiff_all_sq: 3.1880861893030127e-06\n",
            "E_IS_SCOPE: 2.0069427726803724e-06\n",
            "E_IS_E_SCOPE: 2.093326725353096e-06\n",
            "Total Loss: 0.009931563234559175\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009812929052107218\n",
            "E_s_wdiff_all_sq: 1.6722923492097697e-05\n",
            "E_IS_SCOPE: 2.023164420470091e-06\n",
            "E_IS_E_SCOPE: 2.1029772945105716e-06\n",
            "Total Loss: 0.009796048403141792\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009718403173824651\n",
            "E_s_wdiff_all_sq: 4.805244770819048e-05\n",
            "E_IS_SCOPE: 2.010905888881555e-06\n",
            "E_IS_E_SCOPE: 2.0839336144940737e-06\n",
            "Total Loss: 0.00967020657093999\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009646690656586228\n",
            "E_s_wdiff_all_sq: 9.592515433326874e-05\n",
            "E_IS_SCOPE: 1.991218020249977e-06\n",
            "E_IS_E_SCOPE: 2.057533762100899e-06\n",
            "Total Loss: 0.00955063477104401\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00958774507183524\n",
            "E_s_wdiff_all_sq: 0.00015066772413066895\n",
            "E_IS_SCOPE: 1.98067809308604e-06\n",
            "E_IS_E_SCOPE: 2.040582687637834e-06\n",
            "Total Loss: 0.009436959438790223\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009517022312448793\n",
            "E_s_wdiff_all_sq: 0.00019145463698150625\n",
            "E_IS_SCOPE: 1.997583556408386e-06\n",
            "E_IS_E_SCOPE: 2.0515918204922955e-06\n",
            "Total Loss: 0.009325461559213872\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009418213695419123\n",
            "E_s_wdiff_all_sq: 0.00020742827477355716\n",
            "E_IS_SCOPE: 2.0459906089688907e-06\n",
            "E_IS_E_SCOPE: 2.0946950829359754e-06\n",
            "Total Loss: 0.009210689911972386\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00930921134127681\n",
            "E_s_wdiff_all_sq: 0.00020976405315419923\n",
            "E_IS_SCOPE: 2.1087619122286057e-06\n",
            "E_IS_E_SCOPE: 2.1525672249549158e-06\n",
            "Total Loss: 0.009099361577771912\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0091995964762784\n",
            "E_s_wdiff_all_sq: 0.00020638041314544842\n",
            "E_IS_SCOPE: 2.174446446355403e-06\n",
            "E_IS_E_SCOPE: 2.213590572456769e-06\n",
            "Total Loss: 0.008993139675155502\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009099993714022\n",
            "E_s_wdiff_all_sq: 0.00020799981881966122\n",
            "E_IS_SCOPE: 2.229414726698709e-06\n",
            "E_IS_E_SCOPE: 2.2638977190429157e-06\n",
            "Total Loss: 0.008891926829492403\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00901508851990273\n",
            "E_s_wdiff_all_sq: 0.00022232141393947887\n",
            "E_IS_SCOPE: 2.263489411115759e-06\n",
            "E_IS_E_SCOPE: 2.2931601150703357e-06\n",
            "Total Loss: 0.008792709664830095\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008948379686704047\n",
            "E_s_wdiff_all_sq: 0.0002544096968894246\n",
            "E_IS_SCOPE: 2.27176921013607e-06\n",
            "E_IS_E_SCOPE: 2.296363760415371e-06\n",
            "Total Loss: 0.008693922700988817\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008903714796784342\n",
            "E_s_wdiff_all_sq: 0.00030649060883905483\n",
            "E_IS_SCOPE: 2.255168584142636e-06\n",
            "E_IS_E_SCOPE: 2.2744780981584286e-06\n",
            "Total Loss: 0.008597187469192009\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008873805120559361\n",
            "E_s_wdiff_all_sq: 0.00037051924468563816\n",
            "E_IS_SCOPE: 2.2279324486813705e-06\n",
            "E_IS_E_SCOPE: 2.2419142898709893e-06\n",
            "Total Loss: 0.008503259812466097\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008848989949106278\n",
            "E_s_wdiff_all_sq: 0.0004372885365886362\n",
            "E_IS_SCOPE: 2.199943390433275e-06\n",
            "E_IS_E_SCOPE: 2.2087120864441973e-06\n",
            "Total Loss: 0.008411685775400373\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008819390982655982\n",
            "E_s_wdiff_all_sq: 0.0004971544392122861\n",
            "E_IS_SCOPE: 2.179381013885778e-06\n",
            "E_IS_E_SCOPE: 2.1832001489248226e-06\n",
            "Total Loss: 0.008322230805448373\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00877775243334565\n",
            "E_s_wdiff_all_sq: 0.0005436831752453883\n",
            "E_IS_SCOPE: 2.1706706433754043e-06\n",
            "E_IS_E_SCOPE: 2.169872214253779e-06\n",
            "Total Loss: 0.008234072755233258\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008722117012827362\n",
            "E_s_wdiff_all_sq: 0.0005755438795128182\n",
            "E_IS_SCOPE: 2.173043277642234e-06\n",
            "E_IS_E_SCOPE: 2.1679445469076365e-06\n",
            "Total Loss: 0.008146585231050767\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00865713397376764\n",
            "E_s_wdiff_all_sq: 0.0005968876700513027\n",
            "E_IS_SCOPE: 2.1812827323806136e-06\n",
            "E_IS_E_SCOPE: 2.1721280726982123e-06\n",
            "Total Loss: 0.008060266513310455\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008591523021600633\n",
            "E_s_wdiff_all_sq: 0.0006160458063093296\n",
            "E_IS_SCOPE: 2.188087841227219e-06\n",
            "E_IS_E_SCOPE: 2.1750132367066322e-06\n",
            "Total Loss: 0.007975505264775098\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008534388989960964\n",
            "E_s_wdiff_all_sq: 0.0006421742388989396\n",
            "E_IS_SCOPE: 2.1860096005905963e-06\n",
            "E_IS_E_SCOPE: 2.169041484994533e-06\n",
            "Total Loss: 0.00789225058756797\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008495956476267847\n",
            "E_s_wdiff_all_sq: 0.0006836606500257036\n",
            "E_IS_SCOPE: 2.1685216007829194e-06\n",
            "E_IS_E_SCOPE: 2.147613013266405e-06\n",
            "Total Loss: 0.007812339543691931\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008438616504133668\n",
            "E_s_wdiff_all_sq: 0.0007051137022769351\n",
            "E_IS_SCOPE: 2.162775627442828e-06\n",
            "E_IS_E_SCOPE: 2.138088171608812e-06\n",
            "Total Loss: 0.007733554077043155\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008382767285299476\n",
            "E_s_wdiff_all_sq: 0.0007277951754567229\n",
            "E_IS_SCOPE: 2.1515679659045613e-06\n",
            "E_IS_E_SCOPE: 2.123148081443343e-06\n",
            "Total Loss: 0.00765503084988643\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008350625449189129\n",
            "E_s_wdiff_all_sq: 0.0007734205879803565\n",
            "E_IS_SCOPE: 2.1242675411020434e-06\n",
            "E_IS_E_SCOPE: 2.0920589961909506e-06\n",
            "Total Loss: 0.007577271178573348\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008338909341958117\n",
            "E_s_wdiff_all_sq: 0.0008377826568160024\n",
            "E_IS_SCOPE: 2.083992684941488e-06\n",
            "E_IS_E_SCOPE: 2.047999580028704e-06\n",
            "Total Loss: 0.0075012005716266926\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008340456621861845\n",
            "E_s_wdiff_all_sq: 0.0009135643477882987\n",
            "E_IS_SCOPE: 2.037985537153975e-06\n",
            "E_IS_E_SCOPE: 1.9982779815977825e-06\n",
            "Total Loss: 0.0074269735894594135\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008322226772457341\n",
            "E_s_wdiff_all_sq: 0.0009688195844378601\n",
            "E_IS_SCOPE: 2.003250075498307e-06\n",
            "E_IS_E_SCOPE: 1.960055877607679e-06\n",
            "Total Loss: 0.007353495476690015\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00829933268020982\n",
            "E_s_wdiff_all_sq: 0.0010186131999866516\n",
            "E_IS_SCOPE: 1.9726130296331335e-06\n",
            "E_IS_E_SCOPE: 1.9261336703498657e-06\n",
            "Total Loss: 0.007280814339216488\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008268338222415501\n",
            "E_s_wdiff_all_sq: 0.0010597202431958793\n",
            "E_IS_SCOPE: 1.9476434350998863e-06\n",
            "E_IS_E_SCOPE: 1.8980991362425127e-06\n",
            "Total Loss: 0.007208718968092089\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008228019505571805\n",
            "E_s_wdiff_all_sq: 0.0010901304783836638\n",
            "E_IS_SCOPE: 1.9285687496650107e-06\n",
            "E_IS_E_SCOPE: 1.8761760300814585e-06\n",
            "Total Loss: 0.0071379957129020614\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008188059319690483\n",
            "E_s_wdiff_all_sq: 0.001119838593450259\n",
            "E_IS_SCOPE: 1.9086996121029974e-06\n",
            "E_IS_E_SCOPE: 1.8536047458625981e-06\n",
            "Total Loss: 0.007068332816247459\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008131621464777009\n",
            "E_s_wdiff_all_sq: 0.001131341432804316\n",
            "E_IS_SCOPE: 1.8948996149661494e-06\n",
            "E_IS_E_SCOPE: 1.837261599497312e-06\n",
            "Total Loss: 0.007000397208278384\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008091475457291983\n",
            "E_s_wdiff_all_sq: 0.001158503447014413\n",
            "E_IS_SCOPE: 1.8711429744163476e-06\n",
            "E_IS_E_SCOPE: 1.8109872176100253e-06\n",
            "Total Loss: 0.006933094222065936\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008072609172742242\n",
            "E_s_wdiff_all_sq: 0.001206256147582139\n",
            "E_IS_SCOPE: 1.8349806167476927e-06\n",
            "E_IS_E_SCOPE: 1.7722987515428524e-06\n",
            "Total Loss: 0.006866480289165266\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008046360764405952\n",
            "E_s_wdiff_all_sq: 0.0012457914777252535\n",
            "E_IS_SCOPE: 1.8007419374267148e-06\n",
            "E_IS_E_SCOPE: 1.7356187210704045e-06\n",
            "Total Loss: 0.006800701433388167\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008010073504638674\n",
            "E_s_wdiff_all_sq: 0.0012735504894248878\n",
            "E_IS_SCOPE: 1.7701676130225247e-06\n",
            "E_IS_E_SCOPE: 1.7027008319874566e-06\n",
            "Total Loss: 0.00673665984905061\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007982981601109865\n",
            "E_s_wdiff_all_sq: 0.0013100400272689976\n",
            "E_IS_SCOPE: 1.7361428319988846e-06\n",
            "E_IS_E_SCOPE: 1.6663933662575958e-06\n",
            "Total Loss: 0.006673082973047103\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007960983096211528\n",
            "E_s_wdiff_all_sq: 0.0013510410062976422\n",
            "E_IS_SCOPE: 1.7009924837652738e-06\n",
            "E_IS_E_SCOPE: 1.6290515038665392e-06\n",
            "Total Loss: 0.006610087872148437\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007941187348380688\n",
            "E_s_wdiff_all_sq: 0.0013928527068352817\n",
            "E_IS_SCOPE: 1.6666344370623034e-06\n",
            "E_IS_E_SCOPE: 1.5926054372174672e-06\n",
            "Total Loss: 0.0065484845998198486\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007929160114803062\n",
            "E_s_wdiff_all_sq: 0.0014414044496099986\n",
            "E_IS_SCOPE: 1.6310413009012685e-06\n",
            "E_IS_E_SCOPE: 1.5549824447389268e-06\n",
            "Total Loss: 0.006487909683180141\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007882529541872995\n",
            "E_s_wdiff_all_sq: 0.0014541886221567746\n",
            "E_IS_SCOPE: 1.6103684643082914e-06\n",
            "E_IS_E_SCOPE: 1.5324918873259775e-06\n",
            "Total Loss: 0.006428498573144939\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007828247810569958\n",
            "E_s_wdiff_all_sq: 0.001458003663583914\n",
            "E_IS_SCOPE: 1.5922409160034266e-06\n",
            "E_IS_E_SCOPE: 1.5126207297610886e-06\n",
            "Total Loss: 0.006370405287633282\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007774522355229317\n",
            "E_s_wdiff_all_sq: 0.001461459370749036\n",
            "E_IS_SCOPE: 1.573984608401368e-06\n",
            "E_IS_E_SCOPE: 1.492636922030676e-06\n",
            "Total Loss: 0.006313227580127775\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007729801544134302\n",
            "E_s_wdiff_all_sq: 0.0014730817657564001\n",
            "E_IS_SCOPE: 1.5511099301739699e-06\n",
            "E_IS_E_SCOPE: 1.4680061995190064e-06\n",
            "Total Loss: 0.006256887886113965\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007689218330536046\n",
            "E_s_wdiff_all_sq: 0.001488256669386754\n",
            "E_IS_SCOPE: 1.5268100435176147e-06\n",
            "E_IS_E_SCOPE: 1.4419294316260533e-06\n",
            "Total Loss: 0.006201133322647828\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00764986162838397\n",
            "E_s_wdiff_all_sq: 0.0015040386920734993\n",
            "E_IS_SCOPE: 1.5025672888491617e-06\n",
            "E_IS_E_SCOPE: 1.415909799266442e-06\n",
            "Total Loss: 0.006145998151564388\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007608384174394664\n",
            "E_s_wdiff_all_sq: 0.0015169963680661982\n",
            "E_IS_SCOPE: 1.4800542433381779e-06\n",
            "E_IS_E_SCOPE: 1.391650719518582e-06\n",
            "Total Loss: 0.006091566513650858\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007547147064110846\n",
            "E_s_wdiff_all_sq: 0.0015093571606669895\n",
            "E_IS_SCOPE: 1.4657493679299505e-06\n",
            "E_IS_E_SCOPE: 1.375752170910689e-06\n",
            "Total Loss: 0.006037971798112648\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00748462639294576\n",
            "E_s_wdiff_all_sq: 0.0014993438389927026\n",
            "E_IS_SCOPE: 1.452981223145976e-06\n",
            "E_IS_E_SCOPE: 1.361413219865486e-06\n",
            "Total Loss: 0.005985467590234371\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007415313631006333\n",
            "E_s_wdiff_all_sq: 0.0014812321668752466\n",
            "E_IS_SCOPE: 1.4441175696071432e-06\n",
            "E_IS_E_SCOPE: 1.3509423470563495e-06\n",
            "Total Loss: 0.0059342697148509396\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007356485457028489\n",
            "E_s_wdiff_all_sq: 0.001472739044274259\n",
            "E_IS_SCOPE: 1.4278485096937465e-06\n",
            "E_IS_E_SCOPE: 1.3329679244867772e-06\n",
            "Total Loss: 0.005883938074199397\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0073268216578304705\n",
            "E_s_wdiff_all_sq: 0.0014936613589037365\n",
            "E_IS_SCOPE: 1.3974716596526374e-06\n",
            "E_IS_E_SCOPE: 1.3007555661750458e-06\n",
            "Total Loss: 0.005833355631388442\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007294701334065443\n",
            "E_s_wdiff_all_sq: 0.0015098690749145154\n",
            "E_IS_SCOPE: 1.3686414240181257e-06\n",
            "E_IS_E_SCOPE: 1.2701327172619556e-06\n",
            "Total Loss: 0.005785031176839193\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007225942935946969\n",
            "E_s_wdiff_all_sq: 0.0014892553321432405\n",
            "E_IS_SCOPE: 1.3556778278444911e-06\n",
            "E_IS_E_SCOPE: 1.2556353493752482e-06\n",
            "Total Loss: 0.00573688958903542\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007152278539623219\n",
            "E_s_wdiff_all_sq: 0.0014628651594356874\n",
            "E_IS_SCOPE: 1.3461843768804664e-06\n",
            "E_IS_E_SCOPE: 1.2447528269742843e-06\n",
            "Total Loss: 0.005689618143562097\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007074413319081597\n",
            "E_s_wdiff_all_sq: 0.0014316689383678577\n",
            "E_IS_SCOPE: 1.3403322511287078e-06\n",
            "E_IS_E_SCOPE: 1.2376358346618868e-06\n",
            "Total Loss: 0.005642951673821426\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007000544982317966\n",
            "E_s_wdiff_all_sq: 0.0014038677994502034\n",
            "E_IS_SCOPE: 1.3335626127466436e-06\n",
            "E_IS_E_SCOPE: 1.2296538005665591e-06\n",
            "Total Loss: 0.005596886900766876\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006951674911733834\n",
            "E_s_wdiff_all_sq: 0.0014007879258936772\n",
            "E_IS_SCOPE: 1.3165956700811214e-06\n",
            "E_IS_E_SCOPE: 1.2113745842074228e-06\n",
            "Total Loss: 0.005551099328286657\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006910616518839402\n",
            "E_s_wdiff_all_sq: 0.001404698638286044\n",
            "E_IS_SCOPE: 1.2960562156893523e-06\n",
            "E_IS_E_SCOPE: 1.1895223380392421e-06\n",
            "Total Loss: 0.0055061328485834105\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0068463596398622316\n",
            "E_s_wdiff_all_sq: 0.0013858323463310847\n",
            "E_IS_SCOPE: 1.284891444488107e-06\n",
            "E_IS_E_SCOPE: 1.1771498437661987e-06\n",
            "Total Loss: 0.005460744677007343\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006770904359962036\n",
            "E_s_wdiff_all_sq: 0.0013540954745472522\n",
            "E_IS_SCOPE: 1.2781708719986338e-06\n",
            "E_IS_E_SCOPE: 1.1692739404065535e-06\n",
            "Total Loss: 0.005417028579552721\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006720479414765168\n",
            "E_s_wdiff_all_sq: 0.0013476359590089938\n",
            "E_IS_SCOPE: 1.2596155827891558e-06\n",
            "E_IS_E_SCOPE: 1.1494572489196661e-06\n",
            "Total Loss: 0.0053730656726986665\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0066869499611581845\n",
            "E_s_wdiff_all_sq: 0.001357977841158285\n",
            "E_IS_SCOPE: 1.2337182991687376e-06\n",
            "E_IS_E_SCOPE: 1.122249166794644e-06\n",
            "Total Loss: 0.0053291969585394\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0066629114468284316\n",
            "E_s_wdiff_all_sq: 0.0013770921206919784\n",
            "E_IS_SCOPE: 1.2058350823056723e-06\n",
            "E_IS_E_SCOPE: 1.0930828888053644e-06\n",
            "Total Loss: 0.005286046730798206\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006609913975435086\n",
            "E_s_wdiff_all_sq: 0.0013663212871194293\n",
            "E_IS_SCOPE: 1.194634791959628e-06\n",
            "E_IS_E_SCOPE: 1.0808221491119755e-06\n",
            "Total Loss: 0.005243822213876106\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0065137915671138955\n",
            "E_s_wdiff_all_sq: 0.001312693205911151\n",
            "E_IS_SCOPE: 1.2048009314342784e-06\n",
            "E_IS_E_SCOPE: 1.0902539980780411e-06\n",
            "Total Loss: 0.005201329355344209\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006441660412753178\n",
            "E_s_wdiff_all_sq: 0.0012820780833259875\n",
            "E_IS_SCOPE: 1.2050802100283971e-06\n",
            "E_IS_E_SCOPE: 1.0897147696042058e-06\n",
            "Total Loss: 0.005159814960582792\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006399931183514836\n",
            "E_s_wdiff_all_sq: 0.0012814043527221858\n",
            "E_IS_SCOPE: 1.191291880673237e-06\n",
            "E_IS_E_SCOPE: 1.0749311780345552e-06\n",
            "Total Loss: 0.00511876145247268\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006366413808944962\n",
            "E_s_wdiff_all_sq: 0.0012885176488628446\n",
            "E_IS_SCOPE: 1.1723458822767625e-06\n",
            "E_IS_E_SCOPE: 1.0548939970827308e-06\n",
            "Total Loss: 0.005078132964127257\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006312099861591627\n",
            "E_s_wdiff_all_sq: 0.0012743497244230239\n",
            "E_IS_SCOPE: 1.1625331872437664e-06\n",
            "E_IS_E_SCOPE: 1.0440762996815318e-06\n",
            "Total Loss: 0.005037988951218481\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006272489538555492\n",
            "E_s_wdiff_all_sq: 0.001274334701018714\n",
            "E_IS_SCOPE: 1.1463993019073197e-06\n",
            "E_IS_E_SCOPE: 1.0268739411575622e-06\n",
            "Total Loss: 0.004998395788533031\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006250096713026883\n",
            "E_s_wdiff_all_sq: 0.0012913969959237332\n",
            "E_IS_SCOPE: 1.123464539059661e-06\n",
            "E_IS_E_SCOPE: 1.0028174076336424e-06\n",
            "Total Loss: 0.004958942911640754\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0062359845645877056\n",
            "E_s_wdiff_all_sq: 0.0013154454564992138\n",
            "E_IS_SCOPE: 1.0995180758221853e-06\n",
            "E_IS_E_SCOPE: 9.777372472925195e-07\n",
            "Total Loss: 0.0049207845700203045\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006178405807424129\n",
            "E_s_wdiff_all_sq: 0.0012969492441318147\n",
            "E_IS_SCOPE: 1.0968729176095886e-06\n",
            "E_IS_E_SCOPE: 9.743265119429493e-07\n",
            "Total Loss: 0.0048817035563784\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006100416668453988\n",
            "E_s_wdiff_all_sq: 0.0012561137516923717\n",
            "E_IS_SCOPE: 1.1040868061173614e-06\n",
            "E_IS_E_SCOPE: 9.809455442584906e-07\n",
            "Total Loss: 0.004844551099560087\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006045040778288479\n",
            "E_s_wdiff_all_sq: 0.0012373447039182677\n",
            "E_IS_SCOPE: 1.1001374816064936e-06\n",
            "E_IS_E_SCOPE: 9.762659299457236e-07\n",
            "Total Loss: 0.0048079457177482845\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006029664292706384\n",
            "E_s_wdiff_all_sq: 0.0012589130266997526\n",
            "E_IS_SCOPE: 1.0756739584144667e-06\n",
            "E_IS_E_SCOPE: 9.508580890478709e-07\n",
            "Total Loss: 0.004771002798020117\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006030931833783016\n",
            "E_s_wdiff_all_sq: 0.0012969954327172988\n",
            "E_IS_SCOPE: 1.0460167265358186e-06\n",
            "E_IS_E_SCOPE: 9.202104105541383e-07\n",
            "Total Loss: 0.004734189913972433\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006024382087127848\n",
            "E_s_wdiff_all_sq: 0.0013268896348691112\n",
            "E_IS_SCOPE: 1.0253406143075266e-06\n",
            "E_IS_E_SCOPE: 8.986220157935793e-07\n",
            "Total Loss: 0.0046977477897305175\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006003590182129443\n",
            "E_s_wdiff_all_sq: 0.0013411004233950558\n",
            "E_IS_SCOPE: 1.0172971018529609e-06\n",
            "E_IS_E_SCOPE: 8.898543808519225e-07\n",
            "Total Loss: 0.004662746544451142\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005932188363824686\n",
            "E_s_wdiff_all_sq: 0.001304873581964718\n",
            "E_IS_SCOPE: 1.0351949278007678e-06\n",
            "E_IS_E_SCOPE: 9.074548383172794e-07\n",
            "Total Loss: 0.0046275721623136885\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005847017980544554\n",
            "E_s_wdiff_all_sq: 0.0012545165979354071\n",
            "E_IS_SCOPE: 1.058325729658441e-06\n",
            "E_IS_E_SCOPE: 9.304037679667907e-07\n",
            "Total Loss: 0.0045927591268072835\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0057864792047962665\n",
            "E_s_wdiff_all_sq: 0.0012280846619330378\n",
            "E_IS_SCOPE: 1.0638555298258055e-06\n",
            "E_IS_E_SCOPE: 9.355511779591883e-07\n",
            "Total Loss: 0.004558653051841714\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005775198157417325\n",
            "E_s_wdiff_all_sq: 0.0012511988495153249\n",
            "E_IS_SCOPE: 1.0392389072007122e-06\n",
            "E_IS_E_SCOPE: 9.100855669703931e-07\n",
            "Total Loss: 0.004524259514857214\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005806709020051685\n",
            "E_s_wdiff_all_sq: 0.001316670237545853\n",
            "E_IS_SCOPE: 9.928177515809362e-07\n",
            "E_IS_E_SCOPE: 8.624680672708002e-07\n",
            "Total Loss: 0.004490301382149205\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005835706223027883\n",
            "E_s_wdiff_all_sq: 0.0013779019380111789\n",
            "E_IS_SCOPE: 9.526219224088915e-07\n",
            "E_IS_E_SCOPE: 8.212133337724664e-07\n",
            "Total Loss: 0.0044580690024687295\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00580564321532073\n",
            "E_s_wdiff_all_sq: 0.001380680863311377\n",
            "E_IS_SCOPE: 9.450948906026216e-07\n",
            "E_IS_E_SCOPE: 8.131769960039123e-07\n",
            "Total Loss: 0.004425228088073304\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00571764488842596\n",
            "E_s_wdiff_all_sq: 0.001326188853642343\n",
            "E_IS_SCOPE: 9.703379517381517e-07\n",
            "E_IS_E_SCOPE: 8.384405073264432e-07\n",
            "Total Loss: 0.004391721729947193\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005616803859623317\n",
            "E_s_wdiff_all_sq: 0.001257354041170326\n",
            "E_IS_SCOPE: 1.004380804212145e-06\n",
            "E_IS_E_SCOPE: 8.726444675556512e-07\n",
            "Total Loss: 0.004359715191401057\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005562133315554134\n",
            "E_s_wdiff_all_sq: 0.0012343110226743735\n",
            "E_IS_SCOPE: 1.0140942655088695e-06\n",
            "E_IS_E_SCOPE: 8.821420197532515e-07\n",
            "Total Loss: 0.004328088097646024\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005548745523510721\n",
            "E_s_wdiff_all_sq: 0.0012529292381400921\n",
            "E_IS_SCOPE: 9.978248504623217e-07\n",
            "E_IS_E_SCOPE: 8.652371128870706e-07\n",
            "Total Loss: 0.004296083361120532\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005559204012189817\n",
            "E_s_wdiff_all_sq: 0.001294855830239539\n",
            "E_IS_SCOPE: 9.67086012070673e-07\n",
            "E_IS_E_SCOPE: 8.336320146194316e-07\n",
            "Total Loss: 0.0042646169902199335\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005557752326399675\n",
            "E_s_wdiff_all_sq: 0.0013233540527439747\n",
            "E_IS_SCOPE: 9.442048266983648e-07\n",
            "E_IS_E_SCOPE: 8.100140388094933e-07\n",
            "Total Loss: 0.00423466855550623\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005518625580161883\n",
            "E_s_wdiff_all_sq: 0.0013142774805072405\n",
            "E_IS_SCOPE: 9.431347576064318e-07\n",
            "E_IS_E_SCOPE: 8.085636947515616e-07\n",
            "Total Loss: 0.004204619142055104\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005446060910532108\n",
            "E_s_wdiff_all_sq: 0.0012717598974359254\n",
            "E_IS_SCOPE: 9.607231528934881e-07\n",
            "E_IS_E_SCOPE: 8.260958306385952e-07\n",
            "Total Loss: 0.004174572168015445\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005368492280207882\n",
            "E_s_wdiff_all_sq: 0.001223253442569503\n",
            "E_IS_SCOPE: 9.773930772689486e-07\n",
            "E_IS_E_SCOPE: 8.42734566980901e-07\n",
            "Total Loss: 0.004145510054933708\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005326084894938203\n",
            "E_s_wdiff_all_sq: 0.0012090980387912406\n",
            "E_IS_SCOPE: 9.760191229215644e-07\n",
            "E_IS_E_SCOPE: 8.410903289034203e-07\n",
            "Total Loss: 0.004117258614009752\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005321481684160546\n",
            "E_s_wdiff_all_sq: 0.001232679512619521\n",
            "E_IS_SCOPE: 9.531446000280616e-07\n",
            "E_IS_E_SCOPE: 8.175631466880593e-07\n",
            "Total Loss: 0.004089075234722459\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005334680552508796\n",
            "E_s_wdiff_all_sq: 0.0012729881376299537\n",
            "E_IS_SCOPE: 9.213696238139901e-07\n",
            "E_IS_E_SCOPE: 7.849510235024732e-07\n",
            "Total Loss: 0.004061967152354218\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005318466179485129\n",
            "E_s_wdiff_all_sq: 0.0012836492597140473\n",
            "E_IS_SCOPE: 9.052685418127412e-07\n",
            "E_IS_E_SCOPE: 7.682247034172523e-07\n",
            "Total Loss: 0.004035092907722625\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005264425101702584\n",
            "E_s_wdiff_all_sq: 0.0012566894794211387\n",
            "E_IS_SCOPE: 9.094188369113313e-07\n",
            "E_IS_E_SCOPE: 7.720420052833662e-07\n",
            "Total Loss: 0.004008012276219454\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005193052441715927\n",
            "E_s_wdiff_all_sq: 0.0012119403957072095\n",
            "E_IS_SCOPE: 9.228597256264463e-07\n",
            "E_IS_E_SCOPE: 7.852754751720164e-07\n",
            "Total Loss: 0.00398138911478438\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005134882069096538\n",
            "E_s_wdiff_all_sq: 0.0011801184221524466\n",
            "E_IS_SCOPE: 9.268569701980983e-07\n",
            "E_IS_E_SCOPE: 7.889318019898651e-07\n",
            "Total Loss: 0.00395504139755526\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005098758882083571\n",
            "E_s_wdiff_all_sq: 0.0011703966543161178\n",
            "E_IS_SCOPE: 9.166515621243388e-07\n",
            "E_IS_E_SCOPE: 7.781152696345467e-07\n",
            "Total Loss: 0.003928641200627186\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005078734428481101\n",
            "E_s_wdiff_all_sq: 0.0011764447434115851\n",
            "E_IS_SCOPE: 8.959611941256223e-07\n",
            "E_IS_E_SCOPE: 7.566057236142552e-07\n",
            "Total Loss: 0.0039025702962852907\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005067777516373937\n",
            "E_s_wdiff_all_sq: 0.0011910896128824598\n",
            "E_IS_SCOPE: 8.715901871625362e-07\n",
            "E_IS_E_SCOPE: 7.313480148413162e-07\n",
            "Total Loss: 0.003876970288110873\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005041734322092077\n",
            "E_s_wdiff_all_sq: 0.0011904918142149462\n",
            "E_IS_SCOPE: 8.580975759760437e-07\n",
            "E_IS_E_SCOPE: 7.17141540871298e-07\n",
            "Total Loss: 0.003851526320222093\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004995700770393556\n",
            "E_s_wdiff_all_sq: 0.0011699683128826666\n",
            "E_IS_SCOPE: 8.575884887187991e-07\n",
            "E_IS_E_SCOPE: 7.161439977385609e-07\n",
            "Total Loss: 0.003826017246767602\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004942487627150221\n",
            "E_s_wdiff_all_sq: 0.001141972813686249\n",
            "E_IS_SCOPE: 8.626024070203891e-07\n",
            "E_IS_E_SCOPE: 7.207700224896264e-07\n",
            "Total Loss: 0.003800800378507786\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004889388032648047\n",
            "E_s_wdiff_all_sq: 0.0011137203007227888\n",
            "E_IS_SCOPE: 8.668604604543136e-07\n",
            "E_IS_E_SCOPE: 7.246127747364586e-07\n",
            "Total Loss: 0.0037759541275714462\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004851455578606807\n",
            "E_s_wdiff_all_sq: 0.0011006254558783525\n",
            "E_IS_SCOPE: 8.608900150070084e-07\n",
            "E_IS_E_SCOPE: 7.18033795434341e-07\n",
            "Total Loss: 0.003751117735442353\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004831378697673755\n",
            "E_s_wdiff_all_sq: 0.0011051875617490872\n",
            "E_IS_SCOPE: 8.426187659234638e-07\n",
            "E_IS_E_SCOPE: 6.989407859613245e-07\n",
            "Total Loss: 0.003726480392159345\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0048249035947001894\n",
            "E_s_wdiff_all_sq: 0.0011231388540928254\n",
            "E_IS_SCOPE: 8.172766048711727e-07\n",
            "E_IS_E_SCOPE: 6.726684801074345e-07\n",
            "Total Loss: 0.0037020558571316444\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004810112711160102\n",
            "E_s_wdiff_all_sq: 0.0011325047064383992\n",
            "E_IS_SCOPE: 7.984570469702854e-07\n",
            "E_IS_E_SCOPE: 6.530426608695024e-07\n",
            "Total Loss: 0.0036779007337686574\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004764548128711829\n",
            "E_s_wdiff_all_sq: 0.0011112316521693622\n",
            "E_IS_SCOPE: 7.97640404429613e-07\n",
            "E_IS_E_SCOPE: 6.517311229947027e-07\n",
            "Total Loss: 0.003653610195380089\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004712310194641897\n",
            "E_s_wdiff_all_sq: 0.0010828972227594448\n",
            "E_IS_SCOPE: 8.024652665894328e-07\n",
            "E_IS_E_SCOPE: 6.561677301145933e-07\n",
            "Total Loss: 0.003629707467230155\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0046709069476284885\n",
            "E_s_wdiff_all_sq: 0.0010651705965772271\n",
            "E_IS_SCOPE: 8.01668018823555e-07\n",
            "E_IS_E_SCOPE: 6.548995988544426e-07\n",
            "Total Loss: 0.003606031788165953\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0046494355893586135\n",
            "E_s_wdiff_all_sq: 0.0010672905028057899\n",
            "E_IS_SCOPE: 7.889046296089398e-07\n",
            "E_IS_E_SCOPE: 6.41476588797913e-07\n",
            "Total Loss: 0.003582441842909198\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0046349041007615515\n",
            "E_s_wdiff_all_sq: 0.0010762206752812865\n",
            "E_IS_SCOPE: 7.697467985990959e-07\n",
            "E_IS_E_SCOPE: 6.2156329711649e-07\n",
            "Total Loss: 0.003558981692757982\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004609581304227192\n",
            "E_s_wdiff_all_sq: 0.0010741162147654528\n",
            "E_IS_SCOPE: 7.566114774605808e-07\n",
            "E_IS_E_SCOPE: 6.07784845230346e-07\n",
            "Total Loss: 0.0035357646430009522\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004576704808092104\n",
            "E_s_wdiff_all_sq: 0.0010642753377744089\n",
            "E_IS_SCOPE: 7.485972758357742e-07\n",
            "E_IS_E_SCOPE: 5.992416780840037e-07\n",
            "Total Loss: 0.003512730081787951\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004536206148322164\n",
            "E_s_wdiff_all_sq: 0.0010466724343208987\n",
            "E_IS_SCOPE: 7.467388651630075e-07\n",
            "E_IS_E_SCOPE: 5.969592894551453e-07\n",
            "Total Loss: 0.003489835173427433\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004498236491801987\n",
            "E_s_wdiff_all_sq: 0.0010314592779661997\n",
            "E_IS_SCOPE: 7.441602339296764e-07\n",
            "E_IS_E_SCOPE: 5.939615051099517e-07\n",
            "Total Loss: 0.00346707951156818\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004468924180444248\n",
            "E_s_wdiff_all_sq: 0.001024723811763508\n",
            "E_IS_SCOPE: 7.368173174951087e-07\n",
            "E_IS_E_SCOPE: 5.861297242028363e-07\n",
            "Total Loss: 0.003444503644142078\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004448983925283799\n",
            "E_s_wdiff_all_sq: 0.0010271130909300162\n",
            "E_IS_SCOPE: 7.242571222734109e-07\n",
            "E_IS_E_SCOPE: 5.729302937282573e-07\n",
            "Total Loss: 0.003422175388285626\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004423233194831453\n",
            "E_s_wdiff_all_sq: 0.0010232874800201837\n",
            "E_IS_SCOPE: 7.149746002165773e-07\n",
            "E_IS_E_SCOPE: 5.628919936941227e-07\n",
            "Total Loss: 0.0034002517802990675\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004389443386687223\n",
            "E_s_wdiff_all_sq: 0.001011307603792663\n",
            "E_IS_SCOPE: 7.101616689289592e-07\n",
            "E_IS_E_SCOPE: 5.573902690416607e-07\n",
            "Total Loss: 0.0033784432259690873\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004359353417463506\n",
            "E_s_wdiff_all_sq: 0.0010028278609429215\n",
            "E_IS_SCOPE: 7.039567721772232e-07\n",
            "E_IS_E_SCOPE: 5.504752838751707e-07\n",
            "Total Loss: 0.0033568344197719424\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00433250644488849\n",
            "E_s_wdiff_all_sq: 0.0009974266834676922\n",
            "E_IS_SCOPE: 6.961567879279808e-07\n",
            "E_IS_E_SCOPE: 5.419506713140584e-07\n",
            "Total Loss: 0.0033353900739287777\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004307191150940204\n",
            "E_s_wdiff_all_sq: 0.0009934225166424882\n",
            "E_IS_SCOPE: 6.88138711898242e-07\n",
            "E_IS_E_SCOPE: 5.3321454970314e-07\n",
            "Total Loss: 0.003314080382896859\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004281452467245057\n",
            "E_s_wdiff_all_sq: 0.0009888347871489878\n",
            "E_IS_SCOPE: 6.811485412985601e-07\n",
            "E_IS_E_SCOPE: 5.255322502037095e-07\n",
            "Total Loss: 0.003292930812953011\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004254658478690678\n",
            "E_s_wdiff_all_sq: 0.0009830391035873592\n",
            "E_IS_SCOPE: 6.754693697462542e-07\n",
            "E_IS_E_SCOPE: 5.191929017375946e-07\n",
            "Total Loss: 0.0032719338283140886\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004227576518762368\n",
            "E_s_wdiff_all_sq: 0.0009768376099179945\n",
            "E_IS_SCOPE: 6.705222658861819e-07\n",
            "E_IS_E_SCOPE: 5.136074783411824e-07\n",
            "Total Loss: 0.0032510546386942166\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004201757957507674\n",
            "E_s_wdiff_all_sq: 0.00097174064474578\n",
            "E_IS_SCOPE: 6.652389060076409e-07\n",
            "E_IS_E_SCOPE: 5.077035404547203e-07\n",
            "Total Loss: 0.003230334283767753\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1982, -0.5572],\n",
            "        [-0.1966,  0.6373],\n",
            "        [-0.1872,  0.6034],\n",
            "        [ 0.2048,  0.2073],\n",
            "        [ 0.0360,  0.0917],\n",
            "        [-0.5381, -0.2891],\n",
            "        [ 0.4075,  0.6089],\n",
            "        [-0.0640,  0.5867],\n",
            "        [-0.4904,  0.6757],\n",
            "        [ 0.4426, -0.2146],\n",
            "        [-0.0742, -0.5438],\n",
            "        [ 0.5966, -0.7549],\n",
            "        [ 0.5963, -0.2325],\n",
            "        [-0.2952,  0.0108],\n",
            "        [ 0.1167, -0.6869],\n",
            "        [ 0.1609, -0.6295]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.6531, -0.2189, -0.6595, -0.4758,  0.1414, -0.0896, -0.4736, -0.6275,\n",
            "        -0.2590, -0.2865, -0.0873,  0.2530, -0.1865,  0.3412, -0.6498, -0.2523],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1546, -0.0545, -0.0697, -0.0867, -0.0794, -0.2138, -0.2200,  0.0882,\n",
            "         -0.0215,  0.0129,  0.0420,  0.1505,  0.1874,  0.1642, -0.2323, -0.0318],\n",
            "        [ 0.0802,  0.0086, -0.0644, -0.1551,  0.1024, -0.0680, -0.0411, -0.1347,\n",
            "         -0.1220,  0.1177, -0.0411, -0.1531,  0.0137,  0.0704,  0.0098,  0.0463],\n",
            "        [-0.1535, -0.2394,  0.1020,  0.1508,  0.2561,  0.0950,  0.1881, -0.0211,\n",
            "         -0.1755,  0.2078, -0.1304,  0.1400,  0.0854, -0.1028, -0.0756,  0.0118],\n",
            "        [ 0.1521,  0.1843,  0.1161, -0.1471, -0.2114, -0.0303,  0.2202,  0.0156,\n",
            "          0.2065,  0.0229, -0.0116, -0.1288, -0.1105, -0.1625,  0.2154,  0.2138],\n",
            "        [ 0.0022,  0.0768, -0.0332,  0.2388,  0.2647,  0.0675,  0.1308,  0.1305,\n",
            "         -0.2184, -0.0698, -0.1668, -0.1146, -0.0992,  0.0173,  0.0410,  0.0983],\n",
            "        [ 0.0632, -0.1089, -0.0067, -0.2158, -0.2066,  0.1576,  0.0614,  0.1457,\n",
            "         -0.2282,  0.0700, -0.1871, -0.1209,  0.1555,  0.0320, -0.0318,  0.2479],\n",
            "        [-0.2332, -0.1246,  0.2135,  0.1455,  0.1984, -0.1430,  0.2140,  0.1744,\n",
            "         -0.1596, -0.0706,  0.2149,  0.1696, -0.1465,  0.0323, -0.1672,  0.0926],\n",
            "        [ 0.1089,  0.1670, -0.2249, -0.2189,  0.1179, -0.0113, -0.0678,  0.2028,\n",
            "         -0.1757,  0.0023, -0.0385,  0.1358, -0.1601, -0.0097,  0.1769, -0.2432],\n",
            "        [-0.0463,  0.1378, -0.0290,  0.0715,  0.1556, -0.0367,  0.1482, -0.1757,\n",
            "         -0.1539, -0.1673, -0.0841,  0.0339,  0.2838,  0.1859,  0.2242,  0.2398],\n",
            "        [ 0.1387,  0.1727,  0.2009,  0.0136, -0.1266,  0.1731, -0.2164,  0.1936,\n",
            "         -0.0926,  0.1236, -0.0625, -0.2264, -0.4129, -0.1619, -0.1795, -0.0079],\n",
            "        [-0.0399,  0.1163,  0.1206, -0.1231,  0.1247, -0.0755, -0.2203,  0.1003,\n",
            "          0.0034, -0.0572,  0.1353, -0.0008, -0.2254, -0.2079, -0.1988, -0.1142],\n",
            "        [ 0.0976,  0.0315,  0.0430, -0.0254, -0.1001,  0.2371, -0.1523, -0.2132,\n",
            "          0.1539, -0.0044,  0.0943,  0.0544,  0.1760, -0.1598, -0.0526, -0.2768],\n",
            "        [ 0.0351,  0.0720, -0.0836,  0.1628, -0.0845, -0.0819,  0.1836, -0.2252,\n",
            "         -0.1398, -0.0636, -0.1314,  0.1209, -0.2052,  0.1925,  0.1158, -0.1535],\n",
            "        [ 0.0212,  0.1279, -0.1914,  0.1408,  0.0490,  0.0389,  0.0423, -0.0826,\n",
            "          0.2231,  0.0557,  0.0821,  0.2298,  0.2168, -0.2212,  0.0398,  0.2307],\n",
            "        [-0.0565, -0.0334, -0.0393,  0.1867,  0.0327,  0.0709, -0.1260, -0.0740,\n",
            "         -0.0886, -0.2016,  0.2351,  0.2023, -0.0943,  0.0312,  0.2274, -0.0230],\n",
            "        [-0.1809,  0.1610, -0.1408, -0.1244,  0.1742,  0.0923, -0.2062,  0.2557,\n",
            "         -0.2121, -0.0775,  0.2405,  0.2165,  0.1261,  0.2476,  0.1001, -0.1018],\n",
            "        [-0.0192,  0.0173,  0.1256, -0.0156, -0.0270,  0.0490, -0.0512,  0.0649,\n",
            "         -0.1934, -0.1255,  0.0803, -0.1295, -0.1560,  0.0079,  0.0418,  0.2188],\n",
            "        [-0.2111,  0.1921,  0.2242,  0.0515, -0.0755,  0.1394,  0.1820, -0.1806,\n",
            "         -0.0030, -0.1068,  0.2356,  0.0478, -0.1334, -0.1540, -0.0214, -0.0463],\n",
            "        [ 0.0334, -0.1430, -0.0417, -0.2481, -0.1653,  0.2342,  0.0070,  0.0118,\n",
            "         -0.2491, -0.0443, -0.0636, -0.0087,  0.0592,  0.1518,  0.2170, -0.0180],\n",
            "        [ 0.1481,  0.1155,  0.2205,  0.0945,  0.0494,  0.1236, -0.0701, -0.0263,\n",
            "         -0.3350, -0.0497, -0.1500, -0.3071,  0.1145,  0.1081,  0.1766,  0.1611],\n",
            "        [-0.2410, -0.1346,  0.1229,  0.1418, -0.0822, -0.0168, -0.1592, -0.1896,\n",
            "          0.1664,  0.0893, -0.0971,  0.1895,  0.2506,  0.1666, -0.0472,  0.0458],\n",
            "        [ 0.0842,  0.2755, -0.2420,  0.0596,  0.0655,  0.0495,  0.1064, -0.0195,\n",
            "          0.2155, -0.1148,  0.0489, -0.2266,  0.1923, -0.0160,  0.1085, -0.2453],\n",
            "        [-0.1452,  0.2444, -0.1142, -0.1677, -0.1545, -0.0282, -0.0396,  0.1553,\n",
            "         -0.1745,  0.1249,  0.0963, -0.0875, -0.0083,  0.1906, -0.2387, -0.1926],\n",
            "        [-0.1340,  0.1325, -0.1715, -0.0767, -0.3052,  0.0273, -0.0505,  0.0942,\n",
            "         -0.2032, -0.1079, -0.1551,  0.1173,  0.1880, -0.1975, -0.1104,  0.1976],\n",
            "        [-0.0623,  0.1707,  0.2052,  0.1002,  0.0170, -0.2230,  0.2580,  0.0406,\n",
            "         -0.1152, -0.0750, -0.1574,  0.0559, -0.1226,  0.2420, -0.1214,  0.0797],\n",
            "        [ 0.0108,  0.1957,  0.0510, -0.2114, -0.0662, -0.2477,  0.0530,  0.1546,\n",
            "          0.1367, -0.2128, -0.1689, -0.0409,  0.1100, -0.1452,  0.1201,  0.0693],\n",
            "        [ 0.0493, -0.1933, -0.1683, -0.1329,  0.2132,  0.1135, -0.0402, -0.1131,\n",
            "         -0.0138, -0.1450,  0.0649,  0.1615, -0.2229,  0.2334,  0.0560, -0.1925],\n",
            "        [ 0.0568, -0.1142, -0.0405, -0.2190,  0.3011, -0.1397, -0.0906,  0.1108,\n",
            "          0.1830,  0.1712, -0.2286, -0.0654,  0.0701, -0.2764, -0.2392,  0.1708],\n",
            "        [-0.0850, -0.1332,  0.0961, -0.0646, -0.1389,  0.2093, -0.1233, -0.2249,\n",
            "         -0.0603, -0.0842,  0.0493, -0.1323, -0.2014, -0.0563, -0.2218, -0.1645],\n",
            "        [-0.2214,  0.1204,  0.1781, -0.1904,  0.0810, -0.2487, -0.0085, -0.1260,\n",
            "          0.0559, -0.1381, -0.0150, -0.2701,  0.0648,  0.2134,  0.2258, -0.1195],\n",
            "        [-0.0683, -0.0635, -0.0428, -0.2306, -0.0144,  0.0132, -0.1317,  0.1891,\n",
            "         -0.1345,  0.1695, -0.1253,  0.0689,  0.1748, -0.0326,  0.0112,  0.0301],\n",
            "        [ 0.0842,  0.1448, -0.1303,  0.0008, -0.1123, -0.0491, -0.1082,  0.1981,\n",
            "          0.0015,  0.1279,  0.2473,  0.1515, -0.0186, -0.2113,  0.0246,  0.1176]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0172, -0.1504, -0.0874, -0.2893,  0.2289, -0.1769,  0.1101,  0.0386,\n",
            "         0.1417,  0.0211, -0.0096,  0.0535,  0.1977,  0.0695,  0.2758,  0.2096,\n",
            "        -0.1818, -0.0889, -0.1757, -0.0723, -0.2244,  0.2384,  0.2637,  0.1348,\n",
            "        -0.1132,  0.0609,  0.1632, -0.1413, -0.1888,  0.1368,  0.0030, -0.1752],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.0866,  0.0072,  0.1330,  0.0939,  0.0215, -0.2428, -0.0581,  0.1353,\n",
            "         -0.0059,  0.0968, -0.0737,  0.0536,  0.1304, -0.1576, -0.1444, -0.1279,\n",
            "          0.0682, -0.0187, -0.1720, -0.0956,  0.0347, -0.0174, -0.1482,  0.0554,\n",
            "          0.0281, -0.0432,  0.0036, -0.1145, -0.0082, -0.0987,  0.1181,  0.1102]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.1307], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doubly cumprod, not sure which is right for stepIS\n",
        "model5 = train_var_play(model4, 50, 0.00001, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymZsAiRhT_Y7",
        "outputId": "0e2605cb-8f98-4742-ed50-1a64d5f7046a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(3.8975e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 7.837653119776905e+86\n",
            "E_s_wdiff_all_sq: 3.936778943589322e+86\n",
            "E_IS_SCOPE: -4.922151070341052e+83\n",
            "E_IS_E_SCOPE: -3.229592269140938e+83\n",
            "Total Loss: 3.897490314804813e+86\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(6.8576e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.3783057143777487e+89\n",
            "E_s_wdiff_all_sq: 6.925931966846359e+88\n",
            "E_IS_SCOPE: 6.527757697009708e+84\n",
            "E_IS_E_SCOPE: 4.283174687928771e+84\n",
            "Total Loss: 6.857574106095142e+88\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(4.5003e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 9.044137064483694e+87\n",
            "E_s_wdiff_all_sq: 4.545021682025533e+87\n",
            "E_IS_SCOPE: 1.672171354213606e+84\n",
            "E_IS_E_SCOPE: 1.0971964008089646e+84\n",
            "Total Loss: 4.500265457986933e+87\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(1.5214e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.0583029353013085e+88\n",
            "E_s_wdiff_all_sq: 1.5366475625865213e+88\n",
            "E_IS_SCOPE: -3.074858116302592e+84\n",
            "E_IS_E_SCOPE: -2.017552623022135e+84\n",
            "Total Loss: 1.5214439241783276e+88\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(3.8990e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 7.837268553336831e+88\n",
            "E_s_wdiff_all_sq: 3.9379339053594285e+88\n",
            "E_IS_SCOPE: -4.922308531912808e+84\n",
            "E_IS_E_SCOPE: -3.2297516233039736e+84\n",
            "Total Loss: 3.898996149157877e+88\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(2.7116e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.4506295872945704e+88\n",
            "E_s_wdiff_all_sq: 2.7387164761149973e+88\n",
            "E_IS_SCOPE: -4.104963120562134e+84\n",
            "E_IS_E_SCOPE: -2.693452904678721e+84\n",
            "Total Loss: 2.711630821698593e+88\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(5.9902e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2041596706721822e+88\n",
            "E_s_wdiff_all_sq: 6.050094371557648e+87\n",
            "E_IS_SCOPE: -1.9294089061961931e+84\n",
            "E_IS_E_SCOPE: -1.2659695895298638e+84\n",
            "Total Loss: 5.990175582152803e+87\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(6.2260e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2509352348714792e+87\n",
            "E_s_wdiff_all_sq: 6.287611866075718e+86\n",
            "E_IS_SCOPE: 6.219108809846561e+83\n",
            "E_IS_E_SCOPE: 4.080711692570723e+83\n",
            "Total Loss: 6.226018533093256e+86\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(1.1302e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.2715648269907793e+88\n",
            "E_s_wdiff_all_sq: 1.1415002787395577e+88\n",
            "E_IS_SCOPE: 2.6500667929330647e+84\n",
            "E_IS_E_SCOPE: 1.7388395342654813e+84\n",
            "Total Loss: 1.1302468062651514e+88\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(1.9833e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.986042073292496e+88\n",
            "E_s_wdiff_all_sq: 2.0030198205023387e+88\n",
            "E_IS_SCOPE: 3.510459375607212e+84\n",
            "E_IS_E_SCOPE: 2.303383524109326e+84\n",
            "Total Loss: 1.9832636805226533e+88\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(1.5900e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.195653088273935e+88\n",
            "E_s_wdiff_all_sq: 1.6058526817015858e+88\n",
            "E_IS_SCOPE: 3.143209092939606e+84\n",
            "E_IS_E_SCOPE: 2.062413362375359e+84\n",
            "Total Loss: 1.5900165782806578e+88\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(5.7458e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.1547485063429879e+88\n",
            "E_s_wdiff_all_sq: 5.802974245104604e+87\n",
            "E_IS_SCOPE: 1.8894699655776472e+84\n",
            "E_IS_E_SCOPE: 1.239776227470915e+84\n",
            "Total Loss: 5.74581033142345e+87\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(7.9471e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.5956256908839205e+86\n",
            "E_s_wdiff_all_sq: 8.024481018307015e+85\n",
            "E_IS_SCOPE: 2.2213395875670698e+83\n",
            "E_IS_E_SCOPE: 1.45758751542778e+83\n",
            "Total Loss: 7.947063494171279e+85\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(2.9157e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.861457695178025e+87\n",
            "E_s_wdiff_all_sq: 2.9448653606518576e+87\n",
            "E_IS_SCOPE: -1.3461146328497164e+84\n",
            "E_IS_E_SCOPE: -8.83242816702203e+83\n",
            "Total Loss: 2.9156667165158357e+87\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(8.9492e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.798943371559614e+88\n",
            "E_s_wdiff_all_sq: 9.038642868581803e+87\n",
            "E_IS_SCOPE: -2.3582630793778606e+84\n",
            "E_IS_E_SCOPE: -1.5473609573610972e+84\n",
            "Total Loss: 8.949169168392268e+87\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(1.0661e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.1429836072185233e+88\n",
            "E_s_wdiff_all_sq: 1.0767316325215912e+88\n",
            "E_IS_SCOPE: -2.573910293310698e+84\n",
            "E_IS_E_SCOPE: -1.6888572242494243e+84\n",
            "Total Loss: 1.0660749766453165e+88\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(6.6488e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.3365460659669224e+88\n",
            "E_s_wdiff_all_sq: 6.7152802868889205e+87\n",
            "E_IS_SCOPE: -2.032705961192708e+84\n",
            "E_IS_E_SCOPE: -1.333747639224853e+84\n",
            "Total Loss: 6.64878258175833e+87\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(1.5255e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.067038500759716e+87\n",
            "E_s_wdiff_all_sq: 1.5408342807567995e+87\n",
            "E_IS_SCOPE: -9.737221076570453e+83\n",
            "E_IS_E_SCOPE: -6.388985878829503e+83\n",
            "Total Loss: 1.5255346985853312e+87\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(1.1045e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.217950638602012e+86\n",
            "E_s_wdiff_all_sq: 1.1152759314217639e+86\n",
            "E_IS_SCOPE: 2.6188838977173844e+83\n",
            "E_IS_E_SCOPE: 1.7184350142558822e+83\n",
            "Total Loss: 1.1044768611668018e+86\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(2.7594e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.54534866802881e+87\n",
            "E_s_wdiff_all_sq: 2.7868343232000967e+87\n",
            "E_IS_SCOPE: 1.309374437032462e+84\n",
            "E_IS_E_SCOPE: 8.591483019713049e+83\n",
            "Total Loss: 2.7594149227207985e+87\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(5.6809e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.1417080144477217e+88\n",
            "E_s_wdiff_all_sq: 5.737444915957507e+87\n",
            "E_IS_SCOPE: 1.8787710174160626e+84\n",
            "E_IS_E_SCOPE: 1.2327561453964254e+84\n",
            "Total Loss: 5.680927383885712e+87\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(5.5033e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.1060027672678821e+88\n",
            "E_s_wdiff_all_sq: 5.558023590427719e+87\n",
            "E_IS_SCOPE: 1.849160244884443e+84\n",
            "E_IS_E_SCOPE: 1.2133271266416297e+84\n",
            "Total Loss: 5.50327587410955e+87\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(2.6745e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.3745910497876315e+87\n",
            "E_s_wdiff_all_sq: 2.701025572434766e+87\n",
            "E_IS_SCOPE: 1.2890575346034187e+84\n",
            "E_IS_E_SCOPE: 8.458174280586367e+83\n",
            "Total Loss: 2.6744520831879185e+87\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(2.6730e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.369605364434185e+86\n",
            "E_s_wdiff_all_sq: 2.699367556334373e+86\n",
            "E_IS_SCOPE: 4.074677525458872e+83\n",
            "E_IS_E_SCOPE: 2.673649600634012e+83\n",
            "Total Loss: 2.6730411201690913e+86\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(4.2614e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 8.56936141220449e+86\n",
            "E_s_wdiff_all_sq: 4.3043805516183637e+86\n",
            "E_IS_SCOPE: -5.146800735968692e+83\n",
            "E_IS_E_SCOPE: -3.376995458396228e+83\n",
            "Total Loss: 4.261442506250611e+86\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(2.3215e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 4.667121919114039e+87\n",
            "E_s_wdiff_all_sq: 2.3447776402080183e+87\n",
            "E_IS_SCOPE: -1.2011648130209186e+84\n",
            "E_IS_E_SCOPE: -7.881344304440632e+83\n",
            "Total Loss: 2.32151834376283e+87\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(3.4505e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 6.9364773411371185e+87\n",
            "E_s_wdiff_all_sq: 3.4850070260869156e+87\n",
            "E_IS_SCOPE: -1.4643656124980096e+84\n",
            "E_IS_E_SCOPE: -9.608328385946076e+83\n",
            "Total Loss: 3.4504633751243594e+87\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(2.5625e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.151474009308681e+87\n",
            "E_s_wdiff_all_sq: 2.5881371826118765e+87\n",
            "E_IS_SCOPE: -1.2619563216603506e+84\n",
            "E_IS_E_SCOPE: -8.280225947952616e+83\n",
            "Total Loss: 2.5624690848650376e+87\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(7.7909e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.5664877086556264e+87\n",
            "E_s_wdiff_all_sq: 7.869195685604381e+86\n",
            "E_IS_SCOPE: -6.958784933936726e+83\n",
            "E_IS_E_SCOPE: -4.5659234052440576e+83\n",
            "Total Loss: 7.790896934114128e+86\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(1.6952e+84, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.3820384868950102e+84\n",
            "E_s_wdiff_all_sq: 1.7092209991157447e+84\n",
            "E_IS_SCOPE: 3.2365863302345985e+82\n",
            "E_IS_E_SCOPE: 2.1242990703737244e+82\n",
            "Total Loss: 1.6951888549395312e+84\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(7.5709e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.5211939901987585e+87\n",
            "E_s_wdiff_all_sq: 7.645806988566776e+86\n",
            "E_IS_SCOPE: 6.858055967814821e+83\n",
            "E_IS_E_SCOPE: 4.49995494747505e+83\n",
            "Total Loss: 7.57085037168112e+86\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(1.8262e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.6698412575815546e+87\n",
            "E_s_wdiff_all_sq: 1.8443519647089066e+87\n",
            "E_IS_SCOPE: 1.06518590189668e+84\n",
            "E_IS_E_SCOPE: 6.989247341010318e+83\n",
            "Total Loss: 1.8262219408302022e+87\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(1.8518e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.7211967054981814e+87\n",
            "E_s_wdiff_all_sq: 1.870159395351237e+87\n",
            "E_IS_SCOPE: 1.0726128530914907e+84\n",
            "E_IS_E_SCOPE: 7.037979057110123e+83\n",
            "Total Loss: 1.851775065663668e+87\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(8.7443e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.7570158690357867e+87\n",
            "E_s_wdiff_all_sq: 8.830924585106656e+86\n",
            "E_IS_SCOPE: 7.370470422235385e+83\n",
            "E_IS_E_SCOPE: 4.8361741429783514e+83\n",
            "Total Loss: 8.744303954029355e+86\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(6.0753e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2196174581559286e+86\n",
            "E_s_wdiff_all_sq: 6.134259163521959e+85\n",
            "E_IS_SCOPE: 1.9420922956911794e+83\n",
            "E_IS_E_SCOPE: 1.2743602606239946e+83\n",
            "Total Loss: 6.0752826209349756e+85\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(2.1256e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 4.275253337170368e+86\n",
            "E_s_wdiff_all_sq: 2.1471299098150054e+86\n",
            "E_IS_SCOPE: -3.635241037565288e+83\n",
            "E_IS_E_SCOPE: -2.385190129908618e+83\n",
            "Total Loss: 2.1256245817596795e+86\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(9.0814e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.8259214394910263e+87\n",
            "E_s_wdiff_all_sq: 9.172633943479747e+86\n",
            "E_IS_SCOPE: -7.512982716219675e+83\n",
            "E_IS_E_SCOPE: -4.929558598773401e+83\n",
            "Total Loss: 9.081414859415255e+86\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(1.1718e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.355984214996604e+87\n",
            "E_s_wdiff_all_sq: 1.1835791444580413e+87\n",
            "E_IS_SCOPE: -8.534138190174724e+83\n",
            "E_IS_E_SCOPE: -5.599586672679444e+83\n",
            "Total Loss: 1.1718182858570266e+87\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(6.9890e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.4052720717014727e+87\n",
            "E_s_wdiff_all_sq: 7.059228570094e+86\n",
            "E_IS_SCOPE: -6.590965774498347e+83\n",
            "E_IS_E_SCOPE: -4.3245799710571113e+83\n",
            "Total Loss: 6.988960631533475e+86\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(1.0744e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.1615783609290368e+86\n",
            "E_s_wdiff_all_sq: 1.0853666241201738e+86\n",
            "E_IS_SCOPE: -2.584775092475388e+83\n",
            "E_IS_E_SCOPE: -1.695930076104556e+83\n",
            "Total Loss: 1.0744353029957517e+86\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(6.1167e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2279312067750127e+86\n",
            "E_s_wdiff_all_sq: 6.176054380017834e+85\n",
            "E_IS_SCOPE: 1.9486992637973178e+83\n",
            "E_IS_E_SCOPE: 1.278695406294073e+83\n",
            "Total Loss: 6.116670327078663e+85\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(4.6883e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 9.419116464001514e+86\n",
            "E_s_wdiff_all_sq: 4.734574838098272e+86\n",
            "E_IS_SCOPE: 5.396585778275006e+83\n",
            "E_IS_E_SCOPE: 3.541015711001669e+83\n",
            "Total Loss: 4.6882540222574187e+86\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(7.0907e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.4247039376532172e+87\n",
            "E_s_wdiff_all_sq: 7.160894951414018e+86\n",
            "E_IS_SCOPE: 6.636997883289355e+83\n",
            "E_IS_E_SCOPE: 4.3549083611694844e+83\n",
            "Total Loss: 7.090709860382026e+86\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(4.7157e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 9.474196544894399e+86\n",
            "E_s_wdiff_all_sq: 4.762256367036719e+86\n",
            "E_IS_SCOPE: 5.41234064027121e+83\n",
            "E_IS_E_SCOPE: 3.551353217268139e+83\n",
            "Total Loss: 4.715663408923316e+86\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(8.9897e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.80508205151314e+86\n",
            "E_s_wdiff_all_sq: 9.07739096634913e+85\n",
            "E_IS_SCOPE: 2.3626221442221024e+83\n",
            "E_IS_E_SCOPE: 1.5502896543407176e+83\n",
            "Total Loss: 8.989688760776205e+85\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(2.5718e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.179049186358142e+85\n",
            "E_s_wdiff_all_sq: 2.5985241595554088e+85\n",
            "E_IS_SCOPE: -1.2650507802836305e+83\n",
            "E_IS_E_SCOPE: -8.299969580777913e+82\n",
            "Total Loss: 2.5718365125549215e+85\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(2.7068e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.443731186792979e+86\n",
            "E_s_wdiff_all_sq: 2.734126528315301e+86\n",
            "E_IS_SCOPE: -4.1020867225103166e+83\n",
            "E_IS_E_SCOPE: -2.691509506822782e+83\n",
            "Total Loss: 2.706784760265933e+86\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(4.2963e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 8.639441264088649e+86\n",
            "E_s_wdiff_all_sq: 4.339587949052286e+86\n",
            "E_IS_SCOPE: -5.167804526906915e+83\n",
            "E_IS_E_SCOPE: -3.390777018957542e+83\n",
            "Total Loss: 4.296300516240094e+86\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(2.8546e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.740822526524662e+86\n",
            "E_s_wdiff_all_sq: 2.88337586359815e+86\n",
            "E_IS_SCOPE: -4.212543734590628e+83\n",
            "E_IS_E_SCOPE: -2.7639855397922327e+83\n",
            "Total Loss: 2.854550802756545e+86\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(4.9920e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.0047394444118317e+86\n",
            "E_s_wdiff_all_sq: 5.043265829926229e+85\n",
            "E_IS_SCOPE: -1.7621372108929036e+83\n",
            "E_IS_E_SCOPE: -1.156158712885409e+83\n",
            "Total Loss: 4.992021606428242e+85\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.0057, -0.6100],\n",
            "        [ 0.3443,  0.3599],\n",
            "        [ 0.0603, -0.6894],\n",
            "        [ 0.0467,  0.0746],\n",
            "        [-0.2990, -0.5145],\n",
            "        [ 0.5804, -0.5688],\n",
            "        [ 0.2525,  0.6377],\n",
            "        [-0.0274, -0.5872],\n",
            "        [ 0.3506,  0.6663],\n",
            "        [-0.2037,  0.2161],\n",
            "        [ 0.1259, -0.1210],\n",
            "        [ 0.5856,  0.6529],\n",
            "        [-0.5431, -0.4579],\n",
            "        [-0.3938, -0.1607],\n",
            "        [ 0.5919, -0.2230],\n",
            "        [ 0.2164,  0.1424]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.2603,  0.3900, -0.1267,  0.3600, -0.3407, -0.4320, -0.4568,  0.0077,\n",
            "         0.1181, -0.0323,  0.3781, -0.2170, -0.1138,  0.3433,  0.5592, -0.6726],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.0385,  0.1607,  0.0537,  0.1362,  0.1027, -0.1052, -0.0967,  0.1405,\n",
            "         -0.2242,  0.1343,  0.2250,  0.1195,  0.0101, -0.0537,  0.0888, -0.0150],\n",
            "        [-0.2443, -0.2089,  0.1078, -0.2029,  0.2421,  0.0321, -0.2072,  0.1845,\n",
            "         -0.1160, -0.2427, -0.1520, -0.2045,  0.1968,  0.1299, -0.0931,  0.0351],\n",
            "        [-0.1388, -0.0849, -0.1800, -0.0828,  0.0163,  0.2144,  0.0428, -0.1220,\n",
            "          0.1630, -0.0051,  0.2334,  0.1353,  0.0479, -0.2065,  0.0663,  0.0205],\n",
            "        [-0.0223, -0.0925,  0.0553,  0.1817,  0.1728,  0.0358,  0.1021,  0.0723,\n",
            "         -0.2108,  0.1436,  0.1223,  0.0515, -0.2234, -0.2380,  0.2588, -0.1484],\n",
            "        [ 0.2326, -0.2058,  0.0210,  0.0105,  0.2428, -0.1296,  0.0172, -0.2466,\n",
            "         -0.0725,  0.2136, -0.1839,  0.1385,  0.2397,  0.1813,  0.0985, -0.0114],\n",
            "        [-0.0598,  0.1158, -0.0868, -0.0648,  0.0944,  0.1485,  0.1504,  0.2069,\n",
            "         -0.1268,  0.1903, -0.0059, -0.1603, -0.1928,  0.2256,  0.0258, -0.0301],\n",
            "        [ 0.0028, -0.1960, -0.1355,  0.2132,  0.1930, -0.1458,  0.1829, -0.2268,\n",
            "         -0.2057,  0.1018, -0.2002, -0.0316,  0.0088, -0.1407, -0.2071, -0.2563],\n",
            "        [ 0.1226, -0.2321, -0.2095,  0.1210,  0.2011, -0.0797, -0.2472, -0.1447,\n",
            "         -0.1118, -0.1112, -0.0644, -0.0462,  0.2324,  0.0267, -0.0405,  0.0270],\n",
            "        [ 0.0356,  0.0735,  0.1655, -0.1377,  0.2421, -0.0151, -0.2196, -0.2296,\n",
            "          0.1087,  0.1373, -0.1671, -0.1895, -0.1617,  0.0957, -0.1707, -0.0964],\n",
            "        [ 0.0864,  0.1653,  0.1580,  0.2232,  0.2087,  0.2240, -0.0733,  0.1772,\n",
            "          0.2404, -0.0513,  0.1970, -0.0834,  0.0132, -0.1743, -0.0942,  0.0490],\n",
            "        [ 0.1404,  0.1331,  0.1049, -0.1975, -0.1276, -0.1781, -0.0294,  0.0525,\n",
            "         -0.0680,  0.0958,  0.0937,  0.0449, -0.2339, -0.1146,  0.0658, -0.2119],\n",
            "        [-0.1854,  0.1002, -0.0539,  0.2179,  0.2327, -0.0351, -0.1866,  0.0155,\n",
            "          0.1941,  0.1905, -0.1512,  0.0818, -0.0459,  0.2223,  0.1095,  0.1137],\n",
            "        [ 0.1301, -0.0741,  0.0088, -0.2102, -0.0019,  0.1090,  0.2121,  0.0169,\n",
            "          0.1982,  0.1137, -0.0476, -0.1419, -0.0138,  0.0242,  0.1944, -0.0159],\n",
            "        [-0.1140,  0.1794,  0.0216, -0.2030, -0.0781, -0.1073, -0.0901,  0.2027,\n",
            "          0.0276, -0.1373, -0.1219, -0.0507,  0.0966, -0.1865,  0.2059,  0.1724],\n",
            "        [-0.0525, -0.2466,  0.0758,  0.2112, -0.2105, -0.0317,  0.0676,  0.0982,\n",
            "          0.0120, -0.1962,  0.1114,  0.0919,  0.0579, -0.1252, -0.2141,  0.1544],\n",
            "        [-0.0700,  0.1529, -0.0512,  0.0674, -0.1620,  0.2611, -0.1782,  0.2083,\n",
            "         -0.1981, -0.1330, -0.1570,  0.2139, -0.2148,  0.1181, -0.0496, -0.1860],\n",
            "        [ 0.2095, -0.1590, -0.0726,  0.0835,  0.0676,  0.0158,  0.1621,  0.2150,\n",
            "          0.0275, -0.0673, -0.0519, -0.0873, -0.1941,  0.1961, -0.0169,  0.2167],\n",
            "        [-0.1702,  0.0076,  0.0832,  0.1387, -0.0534, -0.1946, -0.0532,  0.1080,\n",
            "          0.2263,  0.2426, -0.1710,  0.0973, -0.0738, -0.0918, -0.0796,  0.1665],\n",
            "        [ 0.0752,  0.2095, -0.1088, -0.1003, -0.1436, -0.0289, -0.1112, -0.0959,\n",
            "          0.2292,  0.2397,  0.0689, -0.1798, -0.0281,  0.0557, -0.0527, -0.0226],\n",
            "        [ 0.1749, -0.0238,  0.0266, -0.0917,  0.2317,  0.1405,  0.0147,  0.0478,\n",
            "          0.0114, -0.0634, -0.1340, -0.2402, -0.1246,  0.1135,  0.2237, -0.1618],\n",
            "        [ 0.1508, -0.1032,  0.0307,  0.1573,  0.1597, -0.2207, -0.0863,  0.0799,\n",
            "         -0.0957, -0.1142,  0.1997, -0.0183,  0.0878, -0.1367,  0.1528, -0.1219],\n",
            "        [-0.1164,  0.1273, -0.1732, -0.1619,  0.1850, -0.0230,  0.0280,  0.1014,\n",
            "          0.0235,  0.1276,  0.1700, -0.2250, -0.2457, -0.2397,  0.2155,  0.0816],\n",
            "        [ 0.0717,  0.1566, -0.2082, -0.1406,  0.1578,  0.2227,  0.1878, -0.1951,\n",
            "         -0.0506,  0.0416, -0.1165, -0.0838, -0.2011, -0.0309,  0.0655,  0.1953],\n",
            "        [ 0.1506, -0.0581,  0.0545, -0.1305,  0.0410, -0.0670, -0.1568, -0.2053,\n",
            "         -0.2224, -0.1154,  0.0073,  0.0638, -0.0847, -0.2224, -0.2494,  0.0066],\n",
            "        [ 0.2441, -0.2159,  0.1701,  0.1729,  0.0498, -0.2286, -0.2306,  0.0044,\n",
            "         -0.2085,  0.2553,  0.1823,  0.0364,  0.0049,  0.0330,  0.1710,  0.1530],\n",
            "        [-0.1691,  0.0183,  0.0151,  0.1456, -0.1523,  0.0140,  0.1107,  0.1649,\n",
            "         -0.0961,  0.0369,  0.1660,  0.0854,  0.0902,  0.2101, -0.2266,  0.0532],\n",
            "        [-0.0305,  0.0595, -0.0412, -0.1722, -0.1480,  0.1776,  0.1730, -0.0601,\n",
            "          0.0148, -0.1616,  0.1800,  0.0327,  0.0449, -0.1433, -0.1982,  0.1902],\n",
            "        [-0.2281,  0.1787,  0.2350,  0.1225,  0.1040, -0.2257,  0.1944, -0.1659,\n",
            "         -0.1148,  0.1082, -0.1264,  0.2329, -0.0157,  0.0391, -0.0187,  0.1562],\n",
            "        [ 0.1872, -0.0049, -0.1972, -0.2247,  0.1307,  0.0958, -0.2034,  0.0847,\n",
            "         -0.0691, -0.2042,  0.0478,  0.0534, -0.2466,  0.1539,  0.0483,  0.1013],\n",
            "        [ 0.0984, -0.0091, -0.0703, -0.1365, -0.0303,  0.2239,  0.0346,  0.1965,\n",
            "         -0.0163, -0.1643,  0.1658, -0.0299, -0.2271, -0.0389, -0.2230,  0.1360],\n",
            "        [ 0.0846, -0.1789,  0.1758, -0.0041, -0.0720,  0.1870,  0.1668,  0.0533,\n",
            "          0.1085, -0.2203, -0.0854, -0.1453, -0.0079,  0.1412, -0.1511,  0.2060],\n",
            "        [ 0.1633,  0.1194,  0.2112, -0.2535,  0.2361, -0.1522, -0.1092, -0.1170,\n",
            "         -0.1035, -0.2434, -0.0377,  0.2140,  0.1338,  0.0197, -0.0060, -0.0218]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0844,  0.2144,  0.2339,  0.1293, -0.2160,  0.1337, -0.1717,  0.0917,\n",
            "        -0.0122,  0.2378, -0.1503,  0.1356,  0.0690, -0.1095, -0.1798,  0.1041,\n",
            "         0.0093,  0.0048, -0.0405, -0.1691,  0.0958,  0.1319,  0.1541,  0.0802,\n",
            "         0.0656,  0.2310, -0.2521,  0.0452,  0.1527,  0.0092,  0.1901, -0.0566],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1005,  0.1250, -0.1375, -0.0578,  0.0231, -0.1704, -0.0235,  0.0314,\n",
            "         -0.1519,  0.1800, -0.1501,  0.0119, -0.0097, -0.1317,  0.0177, -0.0431,\n",
            "          0.1433,  0.1614,  0.0847,  0.0759,  0.1391, -0.0207,  0.1146,  0.0106,\n",
            "         -0.1546, -0.1361, -0.0071, -0.0994,  0.1144, -0.1813, -0.0998, -0.1650]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0674], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IS Play"
      ],
      "metadata": {
        "id": "hlu2XrJwhJFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_importance_weights(eval_policy, behav_policy, behavior_policies):\n",
        "    \"\"\"\n",
        "    Calculate importance weights for behavior policies.\n",
        "\n",
        "    Parameters:\n",
        "    - eval_policy: Evaluation policy\n",
        "    - behav_policy: Behavior policy\n",
        "    - behavior_policies: List of behavior policies\n",
        "\n",
        "    Returns:\n",
        "    - all_weights: List of importance weights\n",
        "    \"\"\"\n",
        "    all_weights_temp = []\n",
        "    for trajectory in behavior_policies:\n",
        "        cum_ratio = 1\n",
        "        cumul_weights = []\n",
        "        for step in trajectory:\n",
        "            # eval_action_probs = get_quadrant_policy(step[0], eval_policy)\n",
        "            # behav_action_probs = get_quadrant_policy(step[0], behav_policy)\n",
        "\n",
        "            P_pi_b = behav_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "            P_pi_e = eval_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "\n",
        "            # ratio = (0.8*eval_action_probs[step[1]] +0.2*0.25)/ (0.8*behav_action_probs[step[1]]+0.2*0.25)\n",
        "            ratio = P_pi_e/P_pi_b\n",
        "            cum_ratio *= ratio\n",
        "            cumul_weights.append(cum_ratio)\n",
        "        all_weights_temp.append(cumul_weights)\n",
        "\n",
        "        all_weights = [list(np.cumprod(i)) for i in all_weights_temp]\n",
        "\n",
        "    return all_weights_temp, all_weights"
      ],
      "metadata": {
        "id": "3NvlDTygDhon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights_temp, all_weights = calculate_importance_weights(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "eWX9DHMDDl-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights_temp[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqKsg2xDDtgF",
        "outputId": "b1ba3c6a-026d-4de6-8605-95a8381f831e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471,\n",
              " 0.5087045847750865,\n",
              " 0.36282606414105434,\n",
              " 0.2587803545711932,\n",
              " 0.18457128230445397,\n",
              " 0.1316427528200885,\n",
              " 0.09389225752609254,\n",
              " 0.06696727191199248,\n",
              " 0.0477634218784064,\n",
              " 0.03406655825151045,\n",
              " 0.004258319781438806,\n",
              " 0.0005322899726798508,\n",
              " 0.00037964799522018767,\n",
              " 0.0002707783495320456,\n",
              " 3.38472936915057e-05,\n",
              " 2.4141084471147448e-05,\n",
              " 1.721827348309781e-05,\n",
              " 2.1522841853872264e-06,\n",
              " 1.304822287391006e-05,\n",
              " 9.306453079185852e-06,\n",
              " 1.1633066348982315e-06,\n",
              " 8.297113498906504e-07,\n",
              " 5.917794186720081e-07]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uEATYCyLNex",
        "outputId": "0a34724c-c9d0-4457-d76f-59ff5617b6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471,\n",
              " 0.36282606414105434,\n",
              " 0.13164275282008847,\n",
              " 0.034066558251510434,\n",
              " 0.006287708340180658,\n",
              " 0.0008277312348312113,\n",
              " 7.771755426316267e-05,\n",
              " 5.204532588676245e-06,\n",
              " 2.48586285712858e-07,\n",
              " 8.468479182763697e-09,\n",
              " 3.6061492422665387e-11,\n",
              " 1.9195170816455204e-14,\n",
              " 7.287408118376271e-18,\n",
              " 1.973272342660357e-21,\n",
              " 6.678992851535058e-26,\n",
              " 1.612381306110978e-30,\n",
              " 2.776242228765327e-35,\n",
              " 5.9752622437758e-41,\n",
              " 7.796655348684653e-46,\n",
              " 7.255920717711713e-51,\n",
              " 8.440860713209574e-57,\n",
              " 7.003477936596074e-63,\n",
              " 4.1445141020010597e-69]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract probability for each state-action pair\n",
        "num_steps, num_states, num_actions = P_pi_b.shape\n",
        "num_samples = states_test.shape[0]\n",
        "\n",
        "# Convert states_test to integers for indexing\n",
        "states_int = states_test.astype(int)\n",
        "\n",
        "# Extract probabilities using array indexing\n",
        "probs_pi_b = P_pi_b[states_int[:, 0], states_int[:, 1], actions_test]\n",
        "probs_pi_e = P_pi_e[states_int[:, 0], states_int[:, 1], actions_test]"
      ],
      "metadata": {
        "id": "psMIyTu1j0PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs_pi_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrGoFbE3kx-K",
        "outputId": "f80b0739-0035-4628-a24b-a610ef62764d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.08,\n",
              "       0.08, 0.68, 0.68, 0.08, 0.68, 0.68, 0.08, 0.08, 0.68, 0.08, 0.68,\n",
              "       0.68])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs_pi_e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d9hkR7wk_mf",
        "outputId": "3edb3fdf-94bb-4a27-f7f0-3079dca07bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.485, 0.485, 0.485, 0.485, 0.485, 0.485, 0.485, 0.485, 0.485,\n",
              "       0.485, 0.01 , 0.01 , 0.485, 0.485, 0.01 , 0.485, 0.485, 0.01 ,\n",
              "       0.485, 0.485, 0.01 , 0.485, 0.485])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(probs_pi_e/probs_pi_b).cumprod(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iVhb2RVlCI8",
        "outputId": "6af4e661-1c4e-4398-ff9b-170e9bc7e28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.13235294e-01, 5.08704585e-01, 3.62826064e-01, 2.58780355e-01,\n",
              "       1.84571282e-01, 1.31642753e-01, 9.38922575e-02, 6.69672719e-02,\n",
              "       4.77634219e-02, 3.40665583e-02, 4.25831978e-03, 5.32289973e-04,\n",
              "       3.79647995e-04, 2.70778350e-04, 3.38472937e-05, 2.41410845e-05,\n",
              "       1.72182735e-05, 2.15228419e-06, 1.30482229e-05, 9.30645308e-06,\n",
              "       1.16330663e-06, 8.29711350e-07, 5.91779419e-07])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(probs_pi_e/probs_pi_b).prod(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haf3CzhmnP-g",
        "outputId": "8a4cc96b-b454-43f3-d94c-e4546858ecd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.917794186720081e-07"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFeC8cDJlRqF",
        "outputId": "04d5b1ae-ed42-465b-eccd-b87ee7f98e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471,\n",
              " 0.36282606414105434,\n",
              " 0.13164275282008847,\n",
              " 0.034066558251510434,\n",
              " 0.006287708340180658,\n",
              " 0.0008277312348312113,\n",
              " 7.771755426316267e-05,\n",
              " 5.204532588676245e-06,\n",
              " 2.48586285712858e-07,\n",
              " 8.468479182763697e-09,\n",
              " 3.6061492422665387e-11,\n",
              " 1.9195170816455204e-14,\n",
              " 7.287408118376271e-18,\n",
              " 1.973272342660357e-21,\n",
              " 6.678992851535058e-26,\n",
              " 1.612381306110978e-30,\n",
              " 2.776242228765327e-35,\n",
              " 5.9752622437758e-41,\n",
              " 7.796655348684653e-46,\n",
              " 7.255920717711713e-51,\n",
              " 8.440860713209574e-57,\n",
              " 7.003477936596074e-63,\n",
              " 4.1445141020010597e-69]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSZax_wTBuz2",
        "outputId": "10644bfa-fb7d-4b7d-ca1a-ecb9f63bd4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.7132352941176471,\n",
              "  0.36282606414105434,\n",
              "  0.13164275282008847,\n",
              "  0.034066558251510434,\n",
              "  0.006287708340180658,\n",
              "  0.0008277312348312113,\n",
              "  7.771755426316267e-05,\n",
              "  5.204532588676245e-06,\n",
              "  2.48586285712858e-07,\n",
              "  8.468479182763697e-09,\n",
              "  3.6061492422665387e-11,\n",
              "  1.9195170816455204e-14,\n",
              "  7.287408118376271e-18,\n",
              "  1.973272342660357e-21,\n",
              "  6.678992851535058e-26,\n",
              "  1.612381306110978e-30,\n",
              "  2.776242228765327e-35,\n",
              "  5.9752622437758e-41,\n",
              "  7.796655348684653e-46,\n",
              "  7.255920717711713e-51,\n",
              "  8.440860713209574e-57,\n",
              "  7.003477936596074e-63,\n",
              "  4.1445141020010597e-69],\n",
              " [6.0625,\n",
              "  26.214183134191178,\n",
              "  80.84510557563685,\n",
              "  177.82956323277526,\n",
              "  278.98895939887166,\n",
              "  2653.5166914163347,\n",
              "  18000.702591032885,\n",
              "  87094.33652773884,\n",
              "  300554.4756778875,\n",
              "  739757.3859855295,\n",
              "  227596.42361250217,\n",
              "  49942.971995499654,\n",
              "  1369.9141292252755,\n",
              "  26.80063802941003,\n",
              "  0.37396395766511065,\n",
              "  0.03163487428795419,\n",
              "  0.001908689588734961,\n",
              "  8.213671358375234e-05,\n",
              "  2.1428466437824626e-05,\n",
              "  3.9872887390228824e-06,\n",
              "  5.291723054894178e-07],\n",
              " [0.7132352941176471,\n",
              "  0.06358807309688581,\n",
              "  0.004043443040174894,\n",
              "  0.00018338331548064946,\n",
              "  1.0396288528903333e-06,\n",
              "  4.203680049584427e-09,\n",
              "  1.2123103392960128e-11,\n",
              "  2.493622974018479e-14,\n",
              "  3.658310788273809e-17,\n",
              "  3.827923332764183e-20,\n",
              "  2.8567924540782985e-23,\n",
              "  1.5206419773333412e-26,\n",
              "  1.011778095713248e-30,\n",
              "  8.41498960820744e-36,\n",
              "  4.991771772741668e-41,\n",
              "  3.7013987228869067e-47,\n",
              "  1.957536400670582e-53,\n",
              "  1.2940880754943391e-60,\n",
              "  6.1016971764870074e-68,\n",
              "  3.596230150266961e-76,\n",
              "  1.2849790795932546e-83,\n",
              "  3.274744808368086e-91,\n",
              "  5.95239431745802e-99,\n",
              "  7.716826756593017e-107,\n",
              "  7.135405081264397e-115,\n",
              "  4.7057769931646824e-123,\n",
              "  1.881463521646853e-130,\n",
              "  5.365288613487482e-138,\n",
              "  1.0912473473433638e-145],\n",
              " [0.125,\n",
              "  0.011144301470588236,\n",
              "  0.0007086446565254968,\n",
              "  3.213934395021691e-05,\n",
              "  1.039628852890333e-06,\n",
              "  2.3985703812334665e-08,\n",
              "  6.917300171277249e-11,\n",
              "  2.4936229740184782e-14,\n",
              "  6.411472515531416e-18,\n",
              "  1.175757087011211e-21,\n",
              "  2.6951779101998296e-26,\n",
              "  4.40646269442255e-31,\n",
              "  4.367616605600319e-35,\n",
              "  3.087676164250621e-39,\n",
              "  1.5568680559372986e-43,\n",
              "  5.598925597374785e-48,\n",
              "  1.2207011013886082e-51,\n",
              "  1.6134879567799814e-54,\n",
              "  1.521090121055426e-57,\n",
              "  1.022767664998916e-60,\n",
              "  4.904919212915387e-64,\n",
              "  1.426062237134181e-66,\n",
              "  2.9571811322967266e-69,\n",
              "  4.3737121729807376e-72,\n",
              "  4.613763172345368e-75,\n",
              "  3.4713085877923017e-78,\n",
              "  1.8627903232948804e-81,\n",
              "  7.129639150096391e-85,\n",
              "  1.946273869590634e-88,\n",
              "  3.789423814439231e-92,\n",
              "  5.262295527618552e-96,\n",
              "  5.212068491909747e-100],\n",
              " [0.7132352941176471,\n",
              "  3.0840215451989623,\n",
              "  9.511188891251395,\n",
              "  177.82956323277526,\n",
              "  2371.406154890409,\n",
              "  22554.891877038845,\n",
              "  153005.9720237795,\n",
              "  740301.8604857799,\n",
              "  447733.2137675746,\n",
              "  193135.72310271577,\n",
              "  10413.960365070396,\n",
              "  400.49957250084367,\n",
              "  10.985530119573722,\n",
              "  0.21491800837354608,\n",
              "  0.0029988684932305667,\n",
              "  2.9845225280935253e-05,\n",
              "  2.1184837024610783e-07,\n",
              "  1.0725269631729829e-09,\n",
              "  3.291872929075463e-11,\n",
              "  7.206273348629824e-13,\n",
              "  1.9719160146074268e-15,\n",
              "  3.848565853595951e-18,\n",
              "  5.357254229013603e-21]]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_first = [trajectory[0] for trajectory in weights]\n"
      ],
      "metadata": {
        "id": "fsu9StgFC5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmEx-WpwC-FU",
        "outputId": "eeed1cc6-afbf-4cf0-a28e-24aa8de7c279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471, 6.0625, 0.7132352941176471, 0.125, 0.7132352941176471]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states[0].astype(int)[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6k1h2M-j_ur",
        "outputId": "98f2d6a9-cc37-4828-9d0b-7abf66df9714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 7, 8, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCOPE Test"
      ],
      "metadata": {
        "id": "fgmds9QUTHJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eval_SCOPE(P_pi_b, P_pi_e, eval_policies):\n"
      ],
      "metadata": {
        "id": "FWnObkFSTN8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env, P_pi_e)"
      ],
      "metadata": {
        "id": "8ZK7sTFeLmHl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_policies(P_pi_e, P_pi_b, pi_b):\n",
        "        # Initialize lists to store axis data for each policy\n",
        "        timesteps = []\n",
        "        states = []\n",
        "        state_first = []\n",
        "        state_last = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        gamma_last = []\n",
        "        weight_last = []\n",
        "        weight_first = []\n",
        "        # all_weights_temp, weights = calculate_importance_weights(P_pi_e, P_pi_b, pi_b)\n",
        "        weights = calculate_importance_weights(P_pi_e, P_pi_b, pi_b)\n",
        "        psi = []\n",
        "\n",
        "        states_current = []\n",
        "        states_next = []\n",
        "\n",
        "        for index, policy in enumerate(pi_b):\n",
        "            policy_array = np.array(policy)\n",
        "            timesteps.append(policy_array['timestep'].astype(int))\n",
        "            # s.append(policy_array[:, 0])\n",
        "\n",
        "            # last timestep for gamma\n",
        "            # gamma_last.append(len(policy))\n",
        "            # last importance weight\n",
        "            # weight_last.append(weights[index][-1])\n",
        "            # weight_first.append(weights[index][0])\n",
        "\n",
        "\n",
        "            # states.append(policy_array['state'][1:])\n",
        "            # psi.append(policy_array['psi'][1:])\n",
        "            # state_first.append(policy_array['state'][0])\n",
        "            # state_last.append(policy_array['state'][-1])\n",
        "            actions.append(policy_array['action'])\n",
        "            rewards.append(policy_array['reward'].astype(float))\n",
        "\n",
        "            states_next.append(policy_array['state_next'])\n",
        "            states_current.append(policy_array['state'])\n",
        "\n",
        "        # weights_difference = []\n",
        "        # for index, weight in enumerate(weights):\n",
        "        #     # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "        #     diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "        #     weights_difference.append(diff)\n",
        "\n",
        "        # return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference, weight_first\n",
        "        return timesteps, rewards, states_next, states_current, weights, actions\n",
        "\n",
        "def padding_IS_terms(timesteps, actions, rewards, weights):\n",
        "    # Find the maximum length among all lists\n",
        "    max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "    # Define the padding values\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each list to match the maximum length\n",
        "    padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "    padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "    padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "    padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "    return padded_timesteps, padded_rewards, padded_actions, padded_weights\n",
        "\n",
        "def padding_states(states_next, states_current):\n",
        "  # Find the maximum length of trajectories\n",
        "    max_length = max(len(trajectory) for trajectory in states_current)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states_next = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states_next\n",
        "    ]\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states_current = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states_current\n",
        "    ]\n",
        "\n",
        "    return padded_states_next, padded_states_current\n",
        "\n",
        "\n",
        "def tensorize_padded_terms(padded_states_next, padded_states_current):\n",
        "  padded_states_next_tensors = torch.tensor(padded_states_next, dtype = torch.float64)\n",
        "  padded_states_current_tensors = torch.tensor(padded_states_current, dtype = torch.float64)\n",
        "\n",
        "  return padded_states_next_tensors, padded_states_current_tensors\n",
        "\n",
        "def tensorize_IS_terms(padded_timesteps, padded_rewards, padded_weights):\n",
        "  padded_timestep_tensors = torch.tensor(padded_timesteps, dtype = torch.float64)\n",
        "  padded_reward_tensors = torch.tensor(padded_rewards, dtype = torch.float64)\n",
        "  padded_weight_tensors = torch.tensor(padded_weights, dtype = torch.float64)\n",
        "\n",
        "  return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors\n",
        "\n",
        "\n",
        "# def\n",
        "\n",
        "# def padding_states_weights_difference(states, weights_difference):\n",
        "#     # Find the maximum length of trajectories\n",
        "#     max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "#     zero_padding = 0\n",
        "\n",
        "#     # Pad each trajectory to make them all the same length\n",
        "#     padded_states = [\n",
        "#         [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "#         for trajectory in states\n",
        "#     ]\n",
        "\n",
        "#     padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "#     return padded_states, padded_weights_difference\n",
        "\n",
        "# def tensorize_padded_terms(padded_states, padded_weights_difference):\n",
        "#     padded_state_tensors = torch.tensor(padded_states, dtype = torch.float64)\n",
        "#     padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n",
        "#     padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "#     return padded_state_tensors, padded_weight_diff_tensors\n"
      ],
      "metadata": {
        "id": "9elNUMw6T2vx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output):\n",
        "  num_samples = 1000\n",
        "  num_bootstraps_lin = num_samples*padded_timestep_tensors.shape[0]\n",
        "\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(padded_timestep_tensors), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "  reshaped_size = (num_samples, padded_timestep_tensors.shape[0], padded_timestep_tensors.shape[1])\n",
        "\n",
        "  timestep_bootstraps = padded_timestep_tensors[sampled_indices].view(reshaped_size)\n",
        "  rewards_bootstraps = padded_reward_tensors[sampled_indices].view(reshaped_size)\n",
        "  weights_bootstraps = padded_weight_tensors[sampled_indices].view(reshaped_size)\n",
        "\n",
        "  phi_states_next_bootstraps = states_next_output[sampled_indices].view(reshaped_size)\n",
        "  phi_states_current_bootstraps = states_current_output[sampled_indices].view(reshaped_size)\n",
        "\n",
        "  return timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps"
      ],
      "metadata": {
        "id": "GVCK9WCfQGZD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 100\n",
        "\n",
        "num_bootstraps_lin = num_samples*padded_timestep_tensors.shape[0]\n",
        "\n",
        "\n",
        "# Sample indices with replacement\n",
        "sampled_indices = torch.randint(0, len(padded_timestep_tensors), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "reshaped_size = (num_samples, padded_timestep_tensors.shape[0], padded_timestep_tensors.shape[1])\n",
        "\n",
        "timestep_bootstraps = padded_timestep_tensors[sampled_indices].view(reshaped_size)"
      ],
      "metadata": {
        "id": "xoIsb4MTSfX6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "b6DOzxqaXCEM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_next_output = model(padded_states_next_tensors)\n",
        "states_current_output = model(padded_states_current_tensors)"
      ],
      "metadata": {
        "id": "X9QrUNCfXTqE"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0.9**padded_timestep_tensors[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY-iKstVYXes",
        "outputId": "228778d3-bf96-4d28-a744-ed9b9318eb21"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 0.9000, 0.8100, 0.7290, 0.6561, 0.5905, 0.5314, 0.4783, 0.4305,\n",
              "        0.3874, 0.3487, 0.3138, 0.2824, 0.2542, 0.2288, 0.2059, 0.1853, 0.1668,\n",
              "        0.1501, 0.1351, 0.1216, 0.1094, 0.0985, 0.0886, 0.0798, 0.0718, 0.0646,\n",
              "        0.0581, 0.0523, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states_next_output.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ-g13FPYBeq",
        "outputId": "40576e62-c09a-4c9e-83bc-ac309b8d8730"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestep_bootstraps.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnY6MQO9TWHD",
        "outputId": "dce9fb97-9329-455a-eca4-1f4959bc5244"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1000, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestep_bootstraps[1][7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCuQoenNTbmp",
        "outputId": "d8770f17-08d6-4abf-b4be-6d919d6e4de4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
              "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
              "        28., 29., 30.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, rewards, states_next, states_current, weights, actions = prep_policies(P_pi_e, P_pi_b, pi_b)\n",
        "padded_timesteps, padded_rewards, padded_actions, padded_weights = padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors = tensorize_IS_terms(padded_timesteps, padded_rewards, padded_weights)\n",
        "padded_states_next, padded_states_current = padding_states(states_next, states_current)\n",
        "padded_states_next_tensors, padded_states_current_tensors = tensorize_padded_terms(padded_states_next, padded_states_current)"
      ],
      "metadata": {
        "id": "hyA49e0K8uzd"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scope_test = (0.9**padded_timestep_tensors)*padded_weight_tensors*(padded_reward_tensors+states_next_output.squeeze() - states_current_output.squeeze())"
      ],
      "metadata": {
        "id": "NeRhh1XhgQop"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scope_test[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1vHurKXiAl8",
        "outputId": "828740e8-c6a4-41b3-9a84-ffcf36386f12"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.5865e-02, -2.2567e-02, -1.7560e-01,  2.3558e-02,  5.8623e-02,\n",
              "        -5.0348e-03, -1.1531e-02, -8.0764e-04, -4.2570e-04, -4.4718e-05,\n",
              "        -1.9944e-04,  4.7190e-05,  3.1694e-05, -3.5147e-05, -8.0302e-07,\n",
              "         1.4772e-06,  1.1920e-06, -5.4377e-07,  6.7569e-08,  3.7064e-09,\n",
              "        -4.8298e-09, -4.4925e-09, -5.4239e-09,  1.9661e-08, -6.4367e-08,\n",
              "         1.9997e-08, -5.8315e-09, -9.6278e-10,  1.7487e-09, -2.4521e-09,\n",
              "         8.8629e-11, -1.1496e-10, -6.7492e-11, -1.0766e-11, -3.7793e-11,\n",
              "         4.7752e-11, -2.4209e-11,  2.6250e-11,  0.0000e+00, -0.0000e+00,\n",
              "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
              "        -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
              "        -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
              "        -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
              "       dtype=torch.float64, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output.squeeze(), states_current_output.squeeze())"
      ],
      "metadata": {
        "id": "Cv358b_TiZpU"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_boostraps = 0.9**(timestep_bootstraps)* weights_bootstraps *(rewards_bootstraps)"
      ],
      "metadata": {
        "id": "mfu8BYVQkZcB"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scope_bootstraps = 0.9**(timestep_bootstraps)* weights_bootstraps *(rewards_bootstraps  +0.9*phi_states_next_bootstraps - phi_states_current_bootstraps)"
      ],
      "metadata": {
        "id": "v2TWSlpxioxv"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scope_bootstraps.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yUgSE7pjCJ3",
        "outputId": "5be69308-e6d7-41cb-d74c-993e356469cf"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 1000, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Sum along the third dimension\n",
        "sum_IS_trajectories = torch.sum(IS_boostraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "# Step 2: Take the mean along the second dimension\n",
        "mean_IS_sum = torch.mean(sum_IS_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "# Step 3: Calculate the variance across the first dimension\n",
        "variance_between_means_IS = torch.var(mean_IS_sum)  # A single scalar value\n",
        "\n",
        "print(\"Variance between means:\", variance_between_means_IS.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an7ieFFQkg3M",
        "outputId": "98562f29-d584-454b-d9ee-a128de1b6e76"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance between means: 6.455531652210303e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Sum along the third dimension\n",
        "sum_trajectories = torch.sum(scope_bootstraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "# Step 2: Take the mean along the second dimension\n",
        "mean_sum = torch.mean(sum_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "# Step 3: Calculate the variance across the first dimension\n",
        "variance_between_means = torch.var(mean_sum)  # A single scalar value\n",
        "\n",
        "print(\"Variance between means:\", variance_between_means.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04yJwa4gjRbQ",
        "outputId": "1c52cde6-5cc2-48dd-aa02-5150fd8abd07"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance between means: 0.38324388798349407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "variance_between_means"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5Tgx5nFkwnP",
        "outputId": "293a5269-554a-4972-9118-2a78f8876bf3"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3832, dtype=torch.float64, grad_fn=<VarBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_reward_tensors+states_next_output.squeeze() - states_current_output.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uwsMkryghVE",
        "outputId": "a0ae2b2d-814f-447d-82b1-1eac8823a162"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2996,  0.6964,  0.4542,  ...,  0.0684, -0.0102,  0.0245],\n",
              "        [-0.9795, -0.3233,  0.3702,  ..., -0.0119,  0.0225, -0.0095],\n",
              "        [ 0.8207, -0.2718,  0.4454,  ...,  0.0112, -0.0491,  0.0160],\n",
              "        ...,\n",
              "        [-0.1522, -0.1322, -1.0524,  ..., -0.0470,  0.0290, -0.0161],\n",
              "        [-0.9772, -0.3646, -0.4086,  ...,  0.0118, -0.1220,  0.0338],\n",
              "        [ 0.8783,  0.0653,  0.0629,  ..., -0.1160,  0.0416,  0.0465]],\n",
              "       dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "67l2YiLWoTYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCOPE straight class"
      ],
      "metadata": {
        "id": "XwoA1mU18F-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b_train, pi_b_test = subset_policies(pi_b, 0.3)"
      ],
      "metadata": {
        "id": "xTOadqLeVE_c"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SCOPE_straight(object):\n",
        "\n",
        "  def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, dtype):\n",
        "        self.model = model\n",
        "        self.gamma = gamma\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.pi_b = pi_b\n",
        "        self.P_pi_b = P_pi_b\n",
        "        self.P_pi_e = P_pi_e\n",
        "        self.dtype = dtype\n",
        "\n",
        "\n",
        "  def prep_policies(self, P_pi_e, P_pi_b, pi_b):\n",
        "      # Initialize lists to store axis data for each policy\n",
        "      timesteps = []\n",
        "      # states = []\n",
        "      # state_first = []\n",
        "      # state_last = []\n",
        "      actions = []\n",
        "      rewards = []\n",
        "      # gamma_last = []\n",
        "      # weight_last = []\n",
        "      # weight_first = []\n",
        "      # all_weights_temp, weights = calculate_importance_weights(P_pi_e, P_pi_b, pi_b)\n",
        "      weights = calculate_importance_weights(P_pi_e, P_pi_b, pi_b)\n",
        "      psi = []\n",
        "\n",
        "      states_current = []\n",
        "      states_next = []\n",
        "\n",
        "      for index, policy in enumerate(pi_b):\n",
        "          policy_array = np.array(policy)\n",
        "          timesteps.append(policy_array['timestep'].astype(int))\n",
        "          # s.append(policy_array[:, 0])\n",
        "\n",
        "          # last timestep for gamma\n",
        "          # gamma_last.append(len(policy))\n",
        "          # last importance weight\n",
        "          # weight_last.append(weights[index][-1])\n",
        "          # weight_first.append(weights[index][0])\n",
        "\n",
        "\n",
        "          # states.append(policy_array['state'][1:])\n",
        "          # psi.append(policy_array['psi'][1:])\n",
        "          # state_first.append(policy_array['state'][0])\n",
        "          # state_last.append(policy_array['state'][-1])\n",
        "          actions.append(policy_array['action'])\n",
        "          rewards.append(policy_array['reward'].astype(float))\n",
        "\n",
        "          states_next.append(policy_array['state_next'])\n",
        "          states_current.append(policy_array['state'])\n",
        "\n",
        "      # weights_difference = []\n",
        "      # for index, weight in enumerate(weights):\n",
        "      #     # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "      #     diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "      #     weights_difference.append(diff)\n",
        "\n",
        "      # return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference, weight_first\n",
        "      return timesteps, rewards, states_next, states_current, weights, actions\n",
        "\n",
        "  def padding_IS_terms(self, timesteps, actions, rewards, weights):\n",
        "\n",
        "    # Find the maximum length among all lists\n",
        "    max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "    # Define the padding values\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each list to match the maximum length\n",
        "    padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "    padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "    padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "    padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "    return padded_timesteps, padded_rewards, padded_actions, padded_weights\n",
        "\n",
        "\n",
        "  def tensorize_IS_terms(self, padded_timesteps, padded_rewards, padded_weights):\n",
        "\n",
        "    padded_timestep_tensors = torch.tensor(padded_timesteps, dtype = torch.float64)\n",
        "    padded_reward_tensors = torch.tensor(padded_rewards, dtype = torch.float64)\n",
        "    padded_weight_tensors = torch.tensor(padded_weights, dtype = torch.float64)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors\n",
        "\n",
        "  def padding_states(self, states_next, states_current):\n",
        "    # Find the maximum length of trajectories\n",
        "    max_length = max(len(trajectory) for trajectory in states_current)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states_next = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states_next\n",
        "    ]\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states_current = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states_current\n",
        "    ]\n",
        "\n",
        "    return padded_states_next, padded_states_current\n",
        "\n",
        "\n",
        "  def tensorize_padded_terms(self, padded_states_next, padded_states_current):\n",
        "    padded_states_next_tensors = torch.tensor(padded_states_next, dtype = torch.float64)\n",
        "    padded_states_current_tensors = torch.tensor(padded_states_current, dtype = torch.float64)\n",
        "\n",
        "    return padded_states_next_tensors, padded_states_current_tensors\n",
        "\n",
        "\n",
        "  def prepare(self):\n",
        "    timesteps, rewards, states_next, states_current, weights, actions = self.prep_policies(P_pi_e, P_pi_b, pi_b)\n",
        "    padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors = self.tensorize_IS_terms(padded_timesteps, padded_rewards, padded_weights)\n",
        "    padded_states_next, padded_states_current = self.padding_states(states_next, states_current)\n",
        "    padded_states_next_tensors, padded_states_current_tensors = self.tensorize_padded_terms(padded_states_next, padded_states_current)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors\n",
        "\n",
        "\n",
        "  def pass_states(self, model, padded_states_next_tensors, padded_states_current_tensors):\n",
        "    states_next_output = self.model(padded_states_next_tensors)\n",
        "    states_current_output = self.model(padded_states_current_tensors)\n",
        "\n",
        "    return states_next_output.squeeze(), states_current_output.squeeze()\n",
        "\n",
        "  def bootstrap_straight(self, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output):\n",
        "    seed = 42\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    num_samples = 1000\n",
        "    num_bootstraps_lin = num_samples*padded_timestep_tensors.shape[0]\n",
        "\n",
        "    # states_next_output_res = states_next_output.squeeze()\n",
        "    # states_current_output_res = states_current_output.squeeze()\n",
        "\n",
        "    # Sample indices with replacement\n",
        "    sampled_indices = torch.randint(0, len(padded_timestep_tensors), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "    reshaped_size = (num_samples, padded_timestep_tensors.shape[0], padded_timestep_tensors.shape[1])\n",
        "\n",
        "    timestep_bootstraps = padded_timestep_tensors[sampled_indices].view(reshaped_size)\n",
        "    rewards_bootstraps = padded_reward_tensors[sampled_indices].view(reshaped_size)\n",
        "    weights_bootstraps = padded_weight_tensors[sampled_indices].view(reshaped_size)\n",
        "\n",
        "    phi_states_next_bootstraps = states_next_output[sampled_indices].view(reshaped_size)\n",
        "    phi_states_current_bootstraps = states_current_output[sampled_indices].view(reshaped_size)\n",
        "\n",
        "    return timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps\n",
        "\n",
        "  def pass_then_boostraps(self, model, padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors):\n",
        "    states_next_output, states_current_output = self.pass_states(model, padded_states_next_tensors, padded_states_current_tensors)\n",
        "    timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output)\n",
        "\n",
        "    return timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps\n",
        "\n",
        "  def calc_variance_straight(self, timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps):\n",
        "\n",
        "    IS_boostraps = self.gamma**(timestep_bootstraps)* weights_bootstraps *(rewards_bootstraps)\n",
        "    scope_bootstraps = self.gamma**(timestep_bootstraps)* weights_bootstraps *(rewards_bootstraps  +self.gamma*phi_states_next_bootstraps - phi_states_current_bootstraps)\n",
        "\n",
        "    # Step 1: Sum along the third dimension\n",
        "    sum_IS_trajectories = torch.sum(IS_boostraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "    # Step 2: Take the mean along the second dimension\n",
        "    mean_IS_sum = torch.mean(sum_IS_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "    # Step 3: Calculate the variance across the first dimension\n",
        "    IS_variance = torch.var(mean_IS_sum)  # A single scalar value\n",
        "\n",
        "\n",
        "    # Step 1: Sum along the third dimension\n",
        "    sum_scope_trajectories = torch.sum(scope_bootstraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "    # Step 2: Take the mean along the second dimension\n",
        "    mean_scope_sum = torch.mean(sum_scope_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "    # Step 3: Calculate the variance across the first dimension\n",
        "    scope_variance = torch.var(mean_scope_sum)  # A single scalar value\n",
        "\n",
        "    return IS_variance, scope_variance\n",
        "\n"
      ],
      "metadata": {
        "id": "O14wffyXoj-3"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scope_testing = SCOPE_straight(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "pmjnzbuDy9sE"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = scope_testing.prepare()\n",
        "timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = scope_testing.pass_then_boostraps(model, padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "IS_variance, scope_variance = scope_testing.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)"
      ],
      "metadata": {
        "id": "hoOaF9W7zLoD"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAZat-2Wdb8z",
        "outputId": "e58fb214-cab1-465c-f5ec-55fd98a74d93"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.4054e-06, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_var_scope(model, num_epochs, learning_rate, test1):\n",
        "\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = test1.prepare()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Enable anomaly detection\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Forward pass\n",
        "        # states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "        # sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "        # gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "        # # sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "        # samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor, padded_psi_tensors)\n",
        "\n",
        "\n",
        "        # Calculate MSE loss between states_output and padded_state_tensors\n",
        "        # mse_loss = F.mse_loss(states_output, padded_state_tensors)\n",
        "\n",
        "        # E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss, E_IS, E_SCOPE = calculate_shaped_variance_play(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)\n",
        "\n",
        "        timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = test1.pass_then_boostraps(model, padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "        IS_variance, variance_loss = test1.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"IS variance: \", IS_variance)\n",
        "        print(\"SCOPE Var loss: \", variance_loss)\n",
        "        # print(\"MSE loss: \", mse_loss.item())\n",
        "\n",
        "\n",
        "        tot = variance_loss\n",
        "        # tot = variance_loss + mse_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Retain the graph to avoid clearing it before backward pass\n",
        "        tot.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Disable anomaly detection after running the code\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "c0xC288M7vT0"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_var_scope(model, 300, 0.0005, scope_testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TTokbMZdsFz",
        "outputId": "3e2f1d98-003d-4804-e989-da6e76fb8922"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(6.8257e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.825676446471801e-06\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(8.8679e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.867944450531838e-06\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010322699638132436\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(8.9483e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.948318015431168e-06\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(4.5600e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.559951382458116e-05\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(6.1606e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.160575699239191e-05\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(2.5116e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5116343575518453e-05\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(6.8150e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.815048645393906e-06\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(2.5630e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5630273315959773e-05\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(3.9287e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.928718717261198e-05\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(2.6311e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.631076034197332e-05\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(9.0356e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.035601389361588e-06\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(9.5675e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.567491718767473e-06\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(2.1859e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1859012484178606e-05\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(2.5137e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5137089001166717e-05\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(1.5619e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5619463977068565e-05\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(7.0791e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.0790709604821805e-06\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(9.2696e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.269604541558708e-06\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(1.6380e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6380473168721743e-05\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(1.7281e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7280635991868833e-05\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(1.1223e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1222952297058225e-05\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(6.6499e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.649890942918133e-06\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(8.6520e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.65201089631448e-06\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(1.2857e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.28567766141008e-05\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(1.2727e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2726877295985088e-05\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(8.7442e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.744233416101576e-06\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(6.4928e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.492801514898987e-06\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(8.3347e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.33472591203273e-06\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(1.0688e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0687909239486949e-05\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(9.8965e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.89645929952536e-06\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(7.2776e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.277561173844685e-06\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(6.5133e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.5132811542512825e-06\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(8.1119e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.11194268806201e-06\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(9.1586e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.158589084709487e-06\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(8.0328e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.032761273406628e-06\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(6.5458e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.545815046419322e-06\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(6.7486e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.748622943645051e-06\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(7.8833e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.88331198359129e-06\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(7.9438e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.943811950412799e-06\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(6.8792e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.879235162649997e-06\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(6.3567e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.3566903830856986e-06\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(6.9560e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.9560492551347964e-06\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(7.4470e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.4470141757639275e-06\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(6.9793e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.979314549305864e-06\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(6.3525e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.352508334523439e-06\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(6.4920e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.491988468189666e-06\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(6.9591e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.959140213609735e-06\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(6.8705e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.870500909892751e-06\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(6.3933e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.393273577090961e-06\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(6.3034e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.3034401687246135e-06\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(6.6171e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.617077907065302e-06\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(6.6851e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.6850609580330095e-06\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(6.3821e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.382112073585794e-06\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(6.2314e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.231406973023415e-06\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(6.4145e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.414508356242272e-06\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(6.5173e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.517286753188177e-06\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(6.3368e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.336772899837394e-06\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(6.1968e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.196772311921238e-06\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(6.2986e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.298586530902128e-06\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(6.3872e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.387174120533743e-06\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(6.2758e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.275775976458442e-06\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(6.1679e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.167877607845675e-06\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(6.2267e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.226724447113572e-06\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(6.2894e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.289408720060042e-06\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(6.2157e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.215735961877486e-06\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(6.1395e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.139527893710763e-06\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(6.1775e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.177453135671901e-06\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(6.2166e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.2165695770114595e-06\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(6.1622e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.162246997726373e-06\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(6.1117e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.111655894779218e-06\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(6.1389e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.138860585454764e-06\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(6.1587e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.1587106963880595e-06\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(6.1154e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.115449249929736e-06\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(6.0842e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.084243520346547e-06\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(6.1047e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.104665219214917e-06\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(6.1103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.110268577336014e-06\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(6.0752e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.075219395287265e-06\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(6.0581e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.058149065675528e-06\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(6.0723e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.072298961381089e-06\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(6.0672e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.067174616555141e-06\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(6.0397e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.039701613190722e-06\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(6.0321e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.032136556119135e-06\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(6.0396e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.039575769630645e-06\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(6.0280e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.027956812699199e-06\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(6.0081e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.0080600318202715e-06\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(6.0058e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.005836946872861e-06\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(6.0067e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.006653697083564e-06\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(5.9924e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.992362987272151e-06\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(5.9793e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.97928154878293e-06\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(5.9783e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.978340180743997e-06\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(5.9733e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.973311885720809e-06\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(5.9594e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.95940901748433e-06\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(5.9514e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.951381502881955e-06\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(5.9490e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.948973108835075e-06\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(5.9402e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.940158567309512e-06\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(5.9288e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.928766013246091e-06\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(5.9235e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.923541486510357e-06\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(5.9185e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.918450092966692e-06\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(5.9082e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.9081968114478585e-06\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(5.8996e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.899614168498984e-06\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(5.8947e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.8947485873786735e-06\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(5.8872e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.8872063038770745e-06\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(5.8776e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.87761975205534e-06\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(5.8710e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.871027366101929e-06\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(5.8650e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.864956154991298e-06\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(5.8562e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.856249696150627e-06\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(5.8483e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.8483291774667285e-06\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(5.8423e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.842290945520832e-06\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(5.8349e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.834913219660957e-06\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(5.8266e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.826612233270498e-06\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(5.8198e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.819803868891486e-06\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(5.8131e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.813064579761187e-06\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(5.8050e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.805002057170554e-06\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(5.7974e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.797405062763143e-06\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(5.7906e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.790601954912233e-06\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(5.7830e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7829839029543925e-06\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(5.7750e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.775040157966051e-06\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(5.7679e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7679008623645946e-06\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(5.7606e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.760623867783802e-06\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(5.7528e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.752760845870278e-06\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(5.7453e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.74532342980094e-06\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(5.7381e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.738130931998307e-06\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(5.7304e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7303532893636334e-06\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(5.7226e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.722597378559302e-06\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(5.7152e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7151670786527915e-06\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(5.7075e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.707518293453739e-06\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(5.6997e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.6997155414114905e-06\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(5.6922e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.692186456971004e-06\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(5.6847e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.684658698611279e-06\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(5.6769e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.676942054508335e-06\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(5.6693e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.6693168643834834e-06\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(5.6618e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.661783130559329e-06\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(5.6541e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.654084279936008e-06\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(5.6464e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.6464143975541386e-06\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(5.6389e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.63890775155607e-06\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(5.6313e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.63130385997834e-06\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(5.6237e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.623694047833303e-06\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(5.6162e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.616225614745347e-06\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(5.6087e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.608749801588944e-06\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(5.6012e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.601239108284018e-06\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(5.5939e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.5939220749838755e-06\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(5.5866e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.586642408867545e-06\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(5.5794e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.579364537572336e-06\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(5.5721e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.5721110397448955e-06\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(5.5649e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.5648950423413774e-06\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(5.5577e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.557668054022677e-06\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(5.5505e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.550456085438544e-06\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(5.5433e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.543293033196618e-06\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(5.5361e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.536134809314515e-06\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(5.5290e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.529003714532914e-06\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(5.5219e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.521936069848232e-06\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(5.5148e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.514838236890738e-06\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(5.5078e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.507798081387211e-06\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(5.5008e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.50078111000845e-06\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(5.4938e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.493757740706216e-06\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(5.4868e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.486811307003357e-06\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(5.4799e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.479887522236854e-06\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(5.4729e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.472936409109541e-06\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(5.4660e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.465984941725059e-06\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(5.4591e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.459071457819555e-06\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(5.4522e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.452160826550902e-06\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(5.4453e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.445252462325949e-06\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(5.4384e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.43836909192135e-06\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(5.4315e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.4314761117420016e-06\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(5.4246e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.424610014316842e-06\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(5.4178e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.417766570189998e-06\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(5.4109e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.410879278559685e-06\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(5.4040e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.404047621284448e-06\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(5.3972e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.3972318939817766e-06\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(5.3904e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.390400526059181e-06\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(5.3836e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.383622827756666e-06\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(5.3769e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.376864852540726e-06\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(5.3701e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.370096696014223e-06\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(5.3633e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.36332693103986e-06\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(5.3566e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.356574523605285e-06\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(5.3498e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.349822591176665e-06\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(5.3431e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.343074561209222e-06\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(5.3364e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.33635330904923e-06\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(5.3297e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.329671009067645e-06\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(5.3230e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.322961033903167e-06\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(5.3162e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.3162455673104255e-06\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(5.3096e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.309567918864968e-06\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(5.3029e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.302895888366556e-06\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(5.2963e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.296268406347516e-06\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "Var loss:  tensor(5.2896e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.289631350707458e-06\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "Var loss:  tensor(5.2830e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.282989765333272e-06\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "Var loss:  tensor(5.2764e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.2763809300259184e-06\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "Var loss:  tensor(5.2698e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.269793212959851e-06\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "Var loss:  tensor(5.2632e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.263213578109215e-06\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "Var loss:  tensor(5.2567e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.256661566138957e-06\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "Var loss:  tensor(5.2501e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.250125271851488e-06\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "Var loss:  tensor(5.2436e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.2435901541238436e-06\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "Var loss:  tensor(5.2371e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.237067603643038e-06\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "Var loss:  tensor(5.2306e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.230550304330427e-06\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "Var loss:  tensor(5.2240e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.22403283497054e-06\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "Var loss:  tensor(5.2175e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.2175294849881955e-06\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "Var loss:  tensor(5.2110e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.211028753993753e-06\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "Var loss:  tensor(5.2045e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.20454949096698e-06\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "Var loss:  tensor(5.1981e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.198078981980246e-06\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "Var loss:  tensor(5.1916e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.191623697619073e-06\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "Var loss:  tensor(5.1852e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.185182306816995e-06\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "Var loss:  tensor(5.1788e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.178753637010674e-06\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "Var loss:  tensor(5.1723e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.172328921877509e-06\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "Var loss:  tensor(5.1659e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.1659357245078746e-06\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "Var loss:  tensor(5.1595e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.159526518018177e-06\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "Var loss:  tensor(5.1531e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.153141691589929e-06\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "Var loss:  tensor(5.1468e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.146775915107473e-06\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "Var loss:  tensor(5.1404e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.1404038096047245e-06\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "Var loss:  tensor(5.1340e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.134028333663935e-06\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "Var loss:  tensor(5.1277e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.127727507597527e-06\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "Var loss:  tensor(5.1213e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.121346614140674e-06\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "Var loss:  tensor(5.1149e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.114862782858124e-06\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "Var loss:  tensor(5.1084e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.108403138014491e-06\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "Var loss:  tensor(5.1019e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.101941578654302e-06\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "Var loss:  tensor(5.0954e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.095446805926879e-06\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "Var loss:  tensor(5.0889e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.0889098722119885e-06\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "Var loss:  tensor(5.0823e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.082315841474342e-06\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "Var loss:  tensor(5.0757e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.075726565909687e-06\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "Var loss:  tensor(5.0691e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.069066273258092e-06\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "Var loss:  tensor(5.0624e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.0624065979755974e-06\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "Var loss:  tensor(5.0557e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.055727190809805e-06\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "Var loss:  tensor(5.0490e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.049031707297275e-06\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "Var loss:  tensor(5.0424e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.04237289332459e-06\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "Var loss:  tensor(5.0357e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.0356506795907956e-06\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "Var loss:  tensor(5.0289e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.0289131624129755e-06\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "Var loss:  tensor(5.0222e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.022209430781157e-06\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "Var loss:  tensor(5.0155e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.015492661412009e-06\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "Var loss:  tensor(5.0087e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.0087031261281405e-06\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "Var loss:  tensor(5.0019e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.001900608167124e-06\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "Var loss:  tensor(4.9951e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.995099725749314e-06\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "Var loss:  tensor(4.9883e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9883312839393284e-06\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "Var loss:  tensor(4.9815e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.981548771713814e-06\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "Var loss:  tensor(4.9748e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.974783870371929e-06\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "Var loss:  tensor(4.9680e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.967988543395585e-06\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "Var loss:  tensor(4.9612e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.961190931805094e-06\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "Var loss:  tensor(4.9544e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.954391091318988e-06\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "Var loss:  tensor(4.9476e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.947593764553107e-06\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "Var loss:  tensor(4.9408e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.940825429797696e-06\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "Var loss:  tensor(4.9341e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.934065620941124e-06\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "Var loss:  tensor(4.9273e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.927315694205353e-06\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "Var loss:  tensor(4.9206e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9205840081660536e-06\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "Var loss:  tensor(4.9139e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.913897633705734e-06\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "Var loss:  tensor(4.9073e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.907273569440355e-06\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "Var loss:  tensor(4.9006e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.900629976993059e-06\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "Var loss:  tensor(4.8940e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8939871045511015e-06\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "Var loss:  tensor(4.8874e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.887378320040099e-06\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "Var loss:  tensor(4.8808e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.880767527962282e-06\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "Var loss:  tensor(4.8742e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.874156718602314e-06\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "Var loss:  tensor(4.8675e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.867535505331366e-06\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "Var loss:  tensor(4.8609e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.86093712060403e-06\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "Var loss:  tensor(4.8543e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8543490423068445e-06\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "Var loss:  tensor(4.8478e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.847762681695098e-06\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "Var loss:  tensor(4.8412e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.841195682278405e-06\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "Var loss:  tensor(4.8347e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.834654980621142e-06\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "Var loss:  tensor(4.8281e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.828132344000631e-06\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "Var loss:  tensor(4.8216e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8216008724556244e-06\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "Var loss:  tensor(4.8151e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.815064969632021e-06\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "Var loss:  tensor(4.8086e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8085607063039e-06\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "Var loss:  tensor(4.8021e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.802071089415264e-06\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "Var loss:  tensor(4.7956e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.795606403720984e-06\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "Var loss:  tensor(4.7892e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.789179189194767e-06\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "Var loss:  tensor(4.7827e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.782739524209218e-06\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "Var loss:  tensor(4.7763e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.776338042270754e-06\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "Var loss:  tensor(4.7699e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.769948448474563e-06\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "Var loss:  tensor(4.7636e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.763589802241862e-06\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "Var loss:  tensor(4.7573e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.757255974498645e-06\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "Var loss:  tensor(4.7509e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.75094116259476e-06\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "Var loss:  tensor(4.7446e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.744639567686787e-06\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "Var loss:  tensor(4.7383e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.738273807213028e-06\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "Var loss:  tensor(4.7319e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.731886239539201e-06\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "Var loss:  tensor(4.7255e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.725503490759152e-06\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "Var loss:  tensor(4.7192e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.719154726138823e-06\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "Var loss:  tensor(4.7128e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.712784571219407e-06\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "Var loss:  tensor(4.7064e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.706387636653825e-06\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "Var loss:  tensor(4.7000e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.699994404641353e-06\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "Var loss:  tensor(4.6936e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.693638943793152e-06\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "Var loss:  tensor(4.6873e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.687308894815233e-06\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "Var loss:  tensor(4.6810e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.6809834993803094e-06\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "Var loss:  tensor(4.6747e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.674704414447676e-06\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "Var loss:  tensor(4.6684e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.6683979726471195e-06\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "Var loss:  tensor(4.6621e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.662125447382126e-06\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "Var loss:  tensor(4.6558e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.655845746592723e-06\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "Var loss:  tensor(4.6496e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.649572162462344e-06\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "Var loss:  tensor(4.6433e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.643323390192354e-06\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "Var loss:  tensor(4.6371e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.637087902992652e-06\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "Var loss:  tensor(4.6309e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.630868386053454e-06\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "Var loss:  tensor(4.6247e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.624667498486511e-06\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "Var loss:  tensor(4.6185e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.618474474911417e-06\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "Var loss:  tensor(4.6123e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.6122953894095285e-06\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "Var loss:  tensor(4.6061e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.6061295493335965e-06\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "Var loss:  tensor(4.6000e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.599981118734286e-06\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "Var loss:  tensor(4.5938e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.593847103331699e-06\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "Var loss:  tensor(4.5877e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.587732819289382e-06\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "Var loss:  tensor(4.5816e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.58163903135394e-06\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "Var loss:  tensor(4.5756e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.575588292741164e-06\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "Var loss:  tensor(4.5695e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.569545774783619e-06\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "Var loss:  tensor(4.5635e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.563545563879293e-06\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "Var loss:  tensor(4.5575e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.557542481331321e-06\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "Var loss:  tensor(4.5516e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.551572590164622e-06\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "Var loss:  tensor(4.5456e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.545621465473054e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1857, -0.2283],\n",
            "        [-0.1022,  0.3144],\n",
            "        [-0.2346,  0.4883],\n",
            "        [-0.4470, -0.0224],\n",
            "        [ 0.1728,  0.2109],\n",
            "        [ 0.4880,  0.1529],\n",
            "        [ 0.6984,  0.0070],\n",
            "        [-0.2520, -0.0850],\n",
            "        [ 0.0278,  0.2855],\n",
            "        [ 0.5332, -0.7233],\n",
            "        [ 0.5011,  0.5991],\n",
            "        [ 0.6953, -0.6739],\n",
            "        [-1.1547,  0.6119],\n",
            "        [ 0.5648,  0.6355],\n",
            "        [ 0.2300, -0.0909],\n",
            "        [-0.1068, -0.3215]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.3271,  0.5334,  0.1769,  0.3211, -0.2915,  0.5924, -0.3613,  0.4543,\n",
            "         0.6058,  0.2357, -0.4685,  0.0607, -0.4428,  0.0792,  0.3948, -0.2052],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-1.3449e-01,  7.2081e-02,  1.5845e-01, -4.3266e-02,  1.7452e-01,\n",
            "         -9.1720e-02, -1.5348e-02,  2.5842e-01, -1.0627e-01,  3.2253e-01,\n",
            "         -1.2775e-01,  1.4624e-01, -5.4303e-02,  3.8015e-04, -2.9667e-01,\n",
            "          1.9228e-01],\n",
            "        [ 1.5475e-01, -1.9558e-01, -1.3660e-01, -1.9638e-01,  3.8146e-02,\n",
            "          5.0797e-02, -2.6243e-03, -1.1018e-02, -2.6310e-01,  4.3277e-02,\n",
            "          3.2414e-02, -4.9553e-01,  5.5509e-02,  1.4911e-01, -2.6808e-01,\n",
            "          8.7988e-02],\n",
            "        [ 2.2585e-01, -1.8918e-01, -3.5771e-02, -2.9418e-01, -6.5938e-02,\n",
            "          1.9740e-01,  2.6039e-01,  1.2910e-01,  2.0872e-02,  2.3289e-01,\n",
            "         -1.0010e-01,  1.7507e-01,  1.9311e-01, -2.1370e-01,  4.1901e-02,\n",
            "          2.0981e-01],\n",
            "        [ 1.9971e-03,  6.3670e-02, -6.0029e-01,  6.9231e-01,  2.7129e-02,\n",
            "         -1.4543e-01,  9.9327e-02, -1.3744e-01,  1.1200e-01,  3.3628e-01,\n",
            "         -2.1574e-01, -9.3818e-03, -2.2271e-01, -1.4424e-02, -3.0695e-01,\n",
            "         -5.8808e-03],\n",
            "        [ 3.4231e-03, -4.3919e-02,  1.6641e-01, -7.1107e-02,  8.4186e-02,\n",
            "          1.3823e-01,  1.9147e-01, -7.8367e-02,  6.1782e-02,  1.5931e-01,\n",
            "         -1.3380e-01,  4.0510e-01,  9.5321e-02,  1.5950e-01,  1.3334e-01,\n",
            "          1.1059e-01],\n",
            "        [ 1.0440e-01,  3.2632e-02,  6.0610e-02, -2.7991e-01, -5.5674e-02,\n",
            "         -2.8913e-01,  1.6413e-01, -7.7384e-02,  1.8210e-01,  2.4815e-01,\n",
            "          2.0109e-01,  2.2939e-02, -1.7456e-01,  1.4177e-01, -1.1532e-01,\n",
            "         -9.2439e-02],\n",
            "        [-3.9295e-02, -8.3852e-02, -9.1753e-02,  1.5734e-01,  1.4095e-01,\n",
            "         -7.1323e-02,  3.8302e-02, -2.1834e-01,  9.7361e-02, -2.1357e-01,\n",
            "         -1.9633e-02,  1.3336e-01,  1.2850e-01, -1.5405e-01, -2.1934e-01,\n",
            "         -4.6353e-02],\n",
            "        [-1.9388e-01, -1.4345e-02, -1.2876e-01, -2.6002e-01, -1.1920e-01,\n",
            "         -2.9193e-02, -3.4969e-01, -2.5557e-01, -2.0452e-01,  6.7075e-04,\n",
            "         -2.4316e-01, -1.4348e-01,  1.1704e-01,  1.1714e-01, -3.1933e-01,\n",
            "         -1.9479e-01],\n",
            "        [ 5.4820e-02, -2.1984e-01,  4.0820e-02, -6.4302e-01, -1.2706e-01,\n",
            "          2.4524e-02, -8.6328e-02, -7.3573e-04, -1.2919e-01,  3.5890e-01,\n",
            "          1.9824e-01,  2.6978e-01,  1.5074e-01, -1.5252e-01, -2.8444e-01,\n",
            "         -5.5824e-02],\n",
            "        [ 1.8986e-01, -1.4285e-01, -1.1666e-01,  5.1321e-01, -1.0544e-01,\n",
            "          1.0413e-01,  1.7958e-02, -2.5723e-01,  1.9041e-01, -5.5703e-02,\n",
            "          1.5910e-01, -3.2065e-01, -1.4551e-01, -2.9837e-01, -3.4794e-01,\n",
            "         -1.2402e-01],\n",
            "        [-8.1642e-02,  3.9013e-03,  1.5817e-01, -1.4308e-01, -3.2693e-02,\n",
            "          2.9745e-02,  1.8137e-01,  2.0843e-01, -1.6357e-01,  1.6994e-01,\n",
            "         -3.7209e-02,  3.3541e-01, -4.9620e-01, -9.3680e-02,  1.1449e-02,\n",
            "         -2.0401e-01],\n",
            "        [-1.0622e-01, -9.2194e-02, -1.6720e-02,  1.9213e-01,  1.5940e-01,\n",
            "         -6.4466e-02, -4.7629e-01, -2.8768e-01,  5.5073e-02,  6.2413e-02,\n",
            "          1.0591e-01,  3.4161e-03, -3.4407e-01, -7.1105e-02, -1.5582e-02,\n",
            "         -1.3354e-01],\n",
            "        [ 2.2803e-01,  5.5132e-02,  2.7752e-02, -1.1287e-01, -2.9049e-02,\n",
            "         -2.0468e-01, -7.7299e-02, -1.1419e-01, -1.8669e-01, -2.3650e-01,\n",
            "         -6.8655e-02,  7.2599e-02,  1.0608e-01, -1.8641e-01, -1.0472e-01,\n",
            "         -2.3573e-01],\n",
            "        [ 9.5597e-02,  1.3685e-01, -9.0023e-02,  1.1036e-02, -3.6798e-02,\n",
            "         -1.8942e-01, -2.0733e-01,  5.1009e-01, -8.1706e-02,  5.4623e-02,\n",
            "          1.2295e-01,  1.0764e-01, -3.0309e-01, -1.6811e-01,  3.2623e-01,\n",
            "          1.6423e-01],\n",
            "        [ 2.1491e-01,  6.2608e-02,  1.8916e-01,  4.4897e-01, -2.0997e-01,\n",
            "          9.1423e-02, -5.9668e-03, -2.4664e-01,  2.5146e-02, -2.0291e-02,\n",
            "         -1.5348e-01,  7.2011e-03, -1.9041e-01, -7.0565e-02, -7.3968e-01,\n",
            "          2.2360e-01],\n",
            "        [-7.0969e-02, -3.8602e-02, -1.2587e-01, -3.0868e-01, -7.9173e-02,\n",
            "          1.7126e-02, -1.8508e-01, -1.0896e-01, -8.1500e-03, -4.6231e-02,\n",
            "          1.0074e-01,  2.6353e-01,  1.7995e-01, -6.4268e-02,  1.7007e-01,\n",
            "          1.1586e-01],\n",
            "        [-2.3547e-01,  2.0652e-01,  6.0643e-02, -7.5051e-02, -1.5903e-01,\n",
            "         -6.1915e-02, -1.8528e-01,  4.3143e-01,  1.1256e-01,  2.3367e-02,\n",
            "         -2.2762e-02,  4.5110e-01, -1.4748e-01, -1.4441e-02, -2.0418e-01,\n",
            "          1.0974e-01],\n",
            "        [-7.5089e-03,  6.8457e-02,  1.3896e-01,  3.7873e-01, -2.9242e-01,\n",
            "          1.2623e-01, -1.0994e-01,  2.3502e-01,  1.2606e-01, -2.3896e-01,\n",
            "         -1.3695e-01, -7.2388e-02,  4.3210e-02, -7.7098e-02, -1.6117e-01,\n",
            "          2.3259e-01],\n",
            "        [ 1.7508e-02,  9.8835e-02, -7.3416e-02,  5.3291e-01,  1.0431e-01,\n",
            "          8.3512e-02, -3.0646e-02, -3.0988e-02,  4.0591e-03, -8.0857e-03,\n",
            "         -5.3722e-02, -2.3140e-01, -2.5040e-02, -8.2995e-02,  1.1964e-01,\n",
            "          1.4862e-01],\n",
            "        [-2.0654e-01, -5.8368e-02, -1.2257e-01,  3.4431e-02, -8.7365e-02,\n",
            "         -1.5954e-01,  1.2149e-01, -1.9776e-01, -2.4973e-01, -7.0749e-02,\n",
            "         -5.7540e-02, -1.3513e-01, -8.4464e-02, -4.4607e-02, -2.3763e-01,\n",
            "          1.0024e-01],\n",
            "        [-3.1425e-02, -3.2523e-01, -2.2122e-01, -1.6722e-01,  1.1515e-01,\n",
            "          5.5819e-02,  3.4111e-01, -1.6634e-01, -2.8664e-02, -1.4936e-01,\n",
            "         -5.3730e-02,  1.3863e-01,  1.8339e-01,  6.6339e-02,  1.2363e-01,\n",
            "          2.2453e-01],\n",
            "        [ 8.8375e-02, -1.9242e-01, -1.8309e-01, -1.0910e-01, -4.7220e-02,\n",
            "         -1.6086e-01, -8.9102e-02,  9.8540e-02,  1.4064e-01,  3.7562e-02,\n",
            "          1.4098e-01,  7.9571e-02,  4.3937e-02, -2.5017e-01, -1.7789e-01,\n",
            "         -1.3269e-01],\n",
            "        [ 2.0999e-01, -1.4671e-01,  2.2879e-01, -3.3233e-01,  1.5658e-01,\n",
            "         -6.2353e-03, -1.6809e-01,  3.5164e-01,  7.0870e-02, -2.3817e-02,\n",
            "         -4.7012e-02, -2.9892e-01, -5.5400e-02, -7.2598e-02,  1.5883e-01,\n",
            "         -1.3248e-01],\n",
            "        [-1.8520e-01, -3.4894e-01, -3.3682e-01,  2.7019e-01, -4.5029e-01,\n",
            "         -5.8984e-01,  3.7778e-01,  2.1903e-01, -3.5914e-02,  4.7836e-01,\n",
            "          7.9056e-02, -8.2070e-01, -8.1720e-02, -4.7506e-01, -7.7053e-02,\n",
            "         -1.2113e-01],\n",
            "        [-1.5608e-01,  2.0073e-01, -4.4956e-03, -2.1603e-01, -5.5748e-02,\n",
            "         -2.3755e-01, -7.2294e-02, -3.6187e-01, -3.0130e-01,  3.1815e-01,\n",
            "          4.9235e-02,  1.0787e-01, -5.4978e-02,  1.0252e-01, -1.3943e-01,\n",
            "         -2.2565e-01],\n",
            "        [-9.7349e-03,  3.7395e-02, -1.9847e-01, -8.9088e-02,  1.7509e-02,\n",
            "         -1.8523e-01, -4.6126e-01, -6.0062e-02, -1.3002e-01, -1.1183e-01,\n",
            "         -1.5475e-01,  4.8955e-02,  1.6759e-01,  9.7962e-02, -7.4801e-02,\n",
            "          8.0128e-02],\n",
            "        [-2.0810e-01, -9.9947e-02, -1.1094e-01,  9.6931e-02, -2.1730e-01,\n",
            "          1.3066e-01, -1.3994e-02, -2.3201e-01, -9.3260e-02,  4.9846e-01,\n",
            "          2.0316e-01,  1.0493e-02,  1.4733e-01, -1.5201e-01, -4.2041e-01,\n",
            "          1.8527e-01],\n",
            "        [ 6.6830e-02,  1.0565e-02,  9.7694e-02, -4.0269e-02, -1.7153e-01,\n",
            "         -4.8861e-02,  3.4582e-01,  5.7500e-02,  7.4757e-02,  1.9023e-01,\n",
            "          1.3266e-01,  3.3858e-01, -2.6573e-01, -4.5120e-02,  2.3882e-01,\n",
            "          1.4063e-01],\n",
            "        [ 1.0356e-02,  1.7607e-01,  2.8784e-02, -1.5574e-01, -1.1906e-01,\n",
            "          1.3446e-02, -2.8502e-01,  3.3752e-01, -1.4801e-01, -6.3664e-02,\n",
            "          7.0613e-02, -1.5708e-01,  1.0074e-01, -1.0919e-01, -5.3421e-02,\n",
            "         -6.8502e-02],\n",
            "        [-1.4775e-01,  3.5857e-02,  9.3220e-02,  3.2169e-01,  1.8461e-01,\n",
            "         -1.4312e-01, -4.8123e-02, -4.1849e-01, -1.6221e-01, -3.5479e-01,\n",
            "          2.0434e-01, -2.2339e-01,  1.4503e-01,  1.1704e-01, -3.0152e-01,\n",
            "          1.6257e-01],\n",
            "        [-2.4956e-01, -3.0792e-02,  1.2266e-01,  1.6637e-02,  3.6434e-02,\n",
            "         -2.5467e-01, -2.9629e-02, -5.0758e-01, -1.6335e-01,  2.1026e-01,\n",
            "         -2.3820e-01,  2.1888e-01,  1.9839e-01, -4.3159e-02, -3.9325e-01,\n",
            "          1.8987e-01],\n",
            "        [ 6.4389e-02,  1.3433e-01, -5.8259e-02, -7.3643e-02,  2.1539e-02,\n",
            "         -7.7406e-02, -1.6657e-01,  9.4938e-02, -1.0788e-01,  3.5269e-01,\n",
            "         -2.2623e-02,  2.0748e-01,  1.7993e-01, -1.3239e-02, -1.2124e-01,\n",
            "         -6.0838e-03]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0795, -0.0827,  0.1835, -0.1906,  0.0612,  0.1356,  0.0120, -0.0205,\n",
            "        -0.2965,  0.0952, -0.0624, -0.0788,  0.1827,  0.0950, -0.1313, -0.0077,\n",
            "        -0.2571,  0.1237,  0.1118, -0.1237,  0.0798, -0.0371,  0.1519,  0.3323,\n",
            "         0.1751,  0.1155,  0.0376,  0.0528, -0.0065, -0.2917, -0.2160, -0.2611],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0380,  0.0472,  0.0903,  0.3842,  0.0018,  0.0045, -0.0576,  0.1354,\n",
            "         -0.0667, -0.0102, -0.1671, -0.1091,  0.0901,  0.1635, -0.0428,  0.0371,\n",
            "          0.0582, -0.0208, -0.0556,  0.1602, -0.0265,  0.1031,  0.0268, -0.6735,\n",
            "         -0.0324, -0.0040, -0.0218,  0.0019,  0.0564,  0.0028, -0.0663, -0.0042]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0359], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POIPxXH45s6l",
        "outputId": "7157ca4e-204b-44cb-f3f0-b48ee145bad4"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.4054e-06, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have your model initialized and set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize an empty dictionary to store the results\n",
        "results_dict = {}\n",
        "\n",
        "# Loop through all combinations from [0,0] to [9,9]\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        # Prepare input data\n",
        "        input_data = torch.tensor([i, j], dtype=torch.float64)\n",
        "\n",
        "        # Pass input through the model\n",
        "        output = model(input_data)\n",
        "\n",
        "        # Store the result in the dictionary\n",
        "        results_dict[(i, j)] = output.item()"
      ],
      "metadata": {
        "id": "OjhdOMMtTW4B"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjbKCDToTzEw",
        "outputId": "3965ee14-a93d-490c-aa1e-452f3b9c6903"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0): 0.03741872461511694,\n",
              " (0, 1): -0.036816281318091684,\n",
              " (0, 2): -0.04671332865582693,\n",
              " (0, 3): -0.03999902032548521,\n",
              " (0, 4): -0.031876243302107435,\n",
              " (0, 5): -0.025736671751715713,\n",
              " (0, 6): -0.020077275253833203,\n",
              " (0, 7): -0.013215278360324552,\n",
              " (0, 8): -0.006430375574392251,\n",
              " (0, 9): 0.0003545272115400358,\n",
              " (1, 0): 0.006115346085377421,\n",
              " (1, 1): -0.03322070497001793,\n",
              " (1, 2): -0.03664577118137829,\n",
              " (1, 3): -0.030466168120959574,\n",
              " (1, 4): -0.026027308629532092,\n",
              " (1, 5): -0.02424205296283351,\n",
              " (1, 6): -0.02245679729613493,\n",
              " (1, 7): -0.020592193668774975,\n",
              " (1, 8): -0.018060120397685352,\n",
              " (1, 9): -0.015063093781029414,\n",
              " (2, 0): -0.06328360825801269,\n",
              " (2, 1): -0.031139438753052986,\n",
              " (2, 2): -0.042050197783615746,\n",
              " (2, 3): -0.03254927408760737,\n",
              " (2, 4): -0.024863355296617,\n",
              " (2, 5): -0.022573672475164556,\n",
              " (2, 6): -0.02094881160383137,\n",
              " (2, 7): -0.0193239507324982,\n",
              " (2, 8): -0.01769908986116502,\n",
              " (2, 9): -0.016074228989831834,\n",
              " (3, 0): -0.1168591503575063,\n",
              " (3, 1): -0.06443187482731767,\n",
              " (3, 2): -0.04287806957467872,\n",
              " (3, 3): -0.04106356129621809,\n",
              " (3, 4): -0.03241356849788523,\n",
              " (3, 5): -0.02530975555211212,\n",
              " (3, 6): -0.02021454915045856,\n",
              " (3, 7): -0.018266771263052543,\n",
              " (3, 8): -0.01648318370145408,\n",
              " (3, 9): -0.014699596139855622,\n",
              " (4, 0): -0.17043469245699988,\n",
              " (4, 1): -0.10984314949091797,\n",
              " (4, 2): -0.07312484348201492,\n",
              " (4, 3): -0.052605511947821315,\n",
              " (4, 4): -0.04228343988103011,\n",
              " (4, 5): -0.0347653787528139,\n",
              " (4, 6): -0.02766156580704079,\n",
              " (4, 7): -0.02055775286126768,\n",
              " (4, 8): -0.014410873079003336,\n",
              " (4, 9): -0.012511283567317445,\n",
              " (5, 0): -0.22401023455649352,\n",
              " (5, 1): -0.1701196512723721,\n",
              " (5, 2): -0.10632714307147462,\n",
              " (5, 3): -0.08448193204900512,\n",
              " (5, 4): -0.06075942082160149,\n",
              " (5, 5): -0.044695858018609105,\n",
              " (5, 6): -0.03711718900774257,\n",
              " (5, 7): -0.030013376061969462,\n",
              " (5, 8): -0.02290956311619636,\n",
              " (5, 9): -0.015805750170423252,\n",
              " (6, 0): -0.27646381264420195,\n",
              " (6, 1): -0.22654612788628586,\n",
              " (6, 2): -0.15129418809278938,\n",
              " (6, 3): -0.11568259516977425,\n",
              " (6, 4): -0.0942093744221477,\n",
              " (6, 5): -0.05954284867285852,\n",
              " (6, 6): -0.04710827615618812,\n",
              " (6, 7): -0.03946899926267125,\n",
              " (6, 8): -0.03236518631689814,\n",
              " (6, 9): -0.025261373371125034,\n",
              " (7, 0): -0.3286012031130518,\n",
              " (7, 1): -0.2801216699857794,\n",
              " (7, 2): -0.21156911485415741,\n",
              " (7, 3): -0.14875631476031873,\n",
              " (7, 4): -0.1260857945233315,\n",
              " (7, 5): -0.10369624131515268,\n",
              " (7, 6): -0.058533738420299894,\n",
              " (7, 7): -0.049520694293767126,\n",
              " (7, 8): -0.04182080951759991,\n",
              " (7, 9): -0.034716996571826815,\n",
              " (8, 0): -0.3807385935819015,\n",
              " (8, 1): -0.3336972120852731,\n",
              " (8, 2): -0.2718440416155253,\n",
              " (8, 3): -0.19489361384753295,\n",
              " (8, 4): -0.15859217532440598,\n",
              " (8, 5): -0.13581323689647407,\n",
              " (8, 6): -0.11255181392925859,\n",
              " (8, 7): -0.06094615655787888,\n",
              " (8, 8): -0.05193311243134612,\n",
              " (8, 9): -0.04397784745708257,\n",
              " (9, 0): -0.4328759840507512,\n",
              " (9, 1): -0.38626055832250594,\n",
              " (9, 2): -0.33074734040851034,\n",
              " (9, 3): -0.2530201534560288,\n",
              " (9, 4): -0.19164821044860628,\n",
              " (9, 5): -0.16768965699765787,\n",
              " (9, 6): -0.14539894495296288,\n",
              " (9, 7): -0.11202969351989697,\n",
              " (9, 8): -0.0633585746954579,\n",
              " (9, 9): -0.054345530568925146}"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty matrix to store the outputs\n",
        "outputs = np.zeros((10, 10))\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "\n",
        "# Loop through all combinations from [0,0] to [9,9]\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        # Prepare input data\n",
        "        input_data = torch.tensor([i, j], dtype=torch.float64)\n",
        "\n",
        "        # Pass input through the model\n",
        "        output = model(input_data)\n",
        "\n",
        "        # Store the output in the matrix\n",
        "        outputs[i, j] = output.item()"
      ],
      "metadata": {
        "id": "tLSgzDN2Pl80"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3fu__qePocJ",
        "outputId": "28507f15-9de2-404a-f27d-7d21e92ba9f3"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.74187246e-02, -3.68162813e-02, -4.67133287e-02,\n",
              "        -3.99990203e-02, -3.18762433e-02, -2.57366718e-02,\n",
              "        -2.00772753e-02, -1.32152784e-02, -6.43037557e-03,\n",
              "         3.54527212e-04],\n",
              "       [ 6.11534609e-03, -3.32207050e-02, -3.66457712e-02,\n",
              "        -3.04661681e-02, -2.60273086e-02, -2.42420530e-02,\n",
              "        -2.24567973e-02, -2.05921937e-02, -1.80601204e-02,\n",
              "        -1.50630938e-02],\n",
              "       [-6.32836083e-02, -3.11394388e-02, -4.20501978e-02,\n",
              "        -3.25492741e-02, -2.48633553e-02, -2.25736725e-02,\n",
              "        -2.09488116e-02, -1.93239507e-02, -1.76990899e-02,\n",
              "        -1.60742290e-02],\n",
              "       [-1.16859150e-01, -6.44318748e-02, -4.28780696e-02,\n",
              "        -4.10635613e-02, -3.24135685e-02, -2.53097556e-02,\n",
              "        -2.02145492e-02, -1.82667713e-02, -1.64831837e-02,\n",
              "        -1.46995961e-02],\n",
              "       [-1.70434692e-01, -1.09843149e-01, -7.31248435e-02,\n",
              "        -5.26055119e-02, -4.22834399e-02, -3.47653788e-02,\n",
              "        -2.76615658e-02, -2.05577529e-02, -1.44108731e-02,\n",
              "        -1.25112836e-02],\n",
              "       [-2.24010235e-01, -1.70119651e-01, -1.06327143e-01,\n",
              "        -8.44819320e-02, -6.07594208e-02, -4.46958580e-02,\n",
              "        -3.71171890e-02, -3.00133761e-02, -2.29095631e-02,\n",
              "        -1.58057502e-02],\n",
              "       [-2.76463813e-01, -2.26546128e-01, -1.51294188e-01,\n",
              "        -1.15682595e-01, -9.42093744e-02, -5.95428487e-02,\n",
              "        -4.71082762e-02, -3.94689993e-02, -3.23651863e-02,\n",
              "        -2.52613734e-02],\n",
              "       [-3.28601203e-01, -2.80121670e-01, -2.11569115e-01,\n",
              "        -1.48756315e-01, -1.26085795e-01, -1.03696241e-01,\n",
              "        -5.85337384e-02, -4.95206943e-02, -4.18208095e-02,\n",
              "        -3.47169966e-02],\n",
              "       [-3.80738594e-01, -3.33697212e-01, -2.71844042e-01,\n",
              "        -1.94893614e-01, -1.58592175e-01, -1.35813237e-01,\n",
              "        -1.12551814e-01, -6.09461566e-02, -5.19331124e-02,\n",
              "        -4.39778475e-02],\n",
              "       [-4.32875984e-01, -3.86260558e-01, -3.30747340e-01,\n",
              "        -2.53020153e-01, -1.91648210e-01, -1.67689657e-01,\n",
              "        -1.45398945e-01, -1.12029694e-01, -6.33585747e-02,\n",
              "        -5.43455306e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(outputs, cmap='viridis', interpolation='nearest')\n",
        "plt.colorbar(label='Model Output')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('Heatmap of Model Output for Inputs (0,0) to (9,9)')\n",
        "plt.xticks(np.arange(0, 10), np.arange(0, 10))\n",
        "plt.yticks(np.arange(0, 10), np.arange(0, 10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T_mayK4QSbdN"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps):\n",
        "  IS_boostraps = 0.9**(timestep_bootstraps)* weights_bootstraps *(rewards_bootstraps)\n",
        "  scope_bootstraps = 0.9**(timestep_bootstraps)* weights_bootstraps *(rewards_bootstraps  +0.9*phi_states_next_bootstraps - phi_states_current_bootstraps)\n",
        "\n",
        "  # Step 1: Sum along the third dimension\n",
        "  sum_IS_trajectories = torch.sum(IS_boostraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "  # Step 2: Take the mean along the second dimension\n",
        "  mean_IS_sum = torch.mean(sum_IS_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "  # Step 3: Calculate the variance across the first dimension\n",
        "  IS_variance = torch.var(mean_IS_sum)  # A single scalar value\n",
        "\n",
        "  # Step 1: Sum along the third dimension\n",
        "  sum_scope_trajectories = torch.sum(scope_bootstraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "  # Step 2: Take the mean along the second dimension\n",
        "  mean_scope_sum = torch.mean(sum_scope_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "  # Step 3: Calculate the variance across the first dimension\n",
        "  scope_variance = torch.var(mean_scope_sum)  # A single scalar value\n",
        "\n",
        "  return IS_variance, scope_variance\n",
        "\n"
      ],
      "metadata": {
        "id": "TEtI8x2-zeJw"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okrOG-ra1CEJ",
        "outputId": "e539004e-d9bf-4cc8-92b8-76e05b4444ca"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(6.1521e-06, dtype=torch.float64),\n",
              " tensor(0.3832, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    }
  ]
}